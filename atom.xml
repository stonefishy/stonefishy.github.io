<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andrewsy&#39;s Space</title>
  
  
  <link href="https://stonefishy.github.io/atom.xml" rel="self"/>
  
  <link href="https://stonefishy.github.io/"/>
  <updated>2024-07-09T03:29:33.958Z</updated>
  <id>https://stonefishy.github.io/</id>
  
  <author>
    <name>Andrewsy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Using Pulumi to Import the AWS Resources of the Other Region</title>
    <link href="https://stonefishy.github.io/2024/07/04/using-pulumi-to-import-the-aws-resources-of-the-other-region/"/>
    <id>https://stonefishy.github.io/2024/07/04/using-pulumi-to-import-the-aws-resources-of-the-other-region/</id>
    <published>2024-07-04T10:27:55.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>By default, the Pulumi import the resource in the region which is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file. If we import the resources which is located in other regions. It will cause the error by using <code>pulumi import</code> command.</p><p>For example, we have quicksight resources such like DataSource, DataSet located in the <code>eu-west-1</code> region, we already manage these resources in the pulumi by using <code>pulumi import</code> CLI command. All resources are located in <code>eu-west-1</code> region. It is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file like below.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">config:</span></span><br><span class="line">  <span class="attr">aws:region:</span> <span class="string">eu-west-1</span></span><br></pre></td></tr></table></figure><p>Now we also want to import the existing resources such like QuickSight user Groups into the pulumi. But the AWS Quicksight user Groups resources all are located in the <code>us-east-1</code> region. The pulumi will give us the error if we try to import the other region resource direclty.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-other-region-resource-error.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-other-region-resource-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>This is because the Pulumi is using default <code>provider</code> for the AWS resources. The default provider is set to the region which is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file. So, if we want to import the resources from other region, we need to specify the provider for that region.</p><h2 id="Pulumi-Provider"><a href="#Pulumi-Provider" class="headerlink" title="Pulumi Provider"></a>Pulumi Provider</h2><p>A <code>Pulumi provider</code> is a plugin that enables Pulumi to interact with a specific cloud provider or service. These providers are responsible for translating the Pulumi code into the appropriate API calls for the target cloud platform. </p><p>By default, each provider uses its package’s global configuration settings, which are controlled by your stack’s configuration. You can set information such as your cloud provider credentials with environment variables and configuration files. If you store this data in standard locations, Pulumi knows how to retrieve them. For example, you can run below command to set the AWS region to <code>eu-west-1</code> region for the AWS provider configuration.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi config set aws:region eu-west-1</span><br></pre></td></tr></table></figure><p>This command actually will set the <code>aws:region</code> configuration value for the AWS provider in your Pulumi stack yaml file. You can also define the provider in your pulumi code, and create related resources in the specified region.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new provider for the us-east-1 region</span></span><br><span class="line">us_east_1_provider = aws.Provider(<span class="string">&#x27;us-east-1&#x27;</span>, region=<span class="string">&#x27;us-east-1&#x27;</span>)</span><br><span class="line"><span class="comment"># Create the Quicksight Groups resources in the us-east-1 region</span></span><br><span class="line">quicksight_group = aws.quicksight.Group(</span><br><span class="line">    <span class="string">&quot;dev&quot;</span>,</span><br><span class="line">    aws_account_id=<span class="string">&quot;&lt;aws-account-id&gt;&quot;</span>,</span><br><span class="line">    group_name=<span class="string">&quot;dev&quot;</span>,</span><br><span class="line">    opts=pulumi.ResourceOptions(</span><br><span class="line">        provider=us_east_1_provider</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>In above code, we create a new provider for the <code>us-east-1</code> region and then create the Quicksight user Groups resources in the <code>us-east-1</code> region. The <code>provider</code> option is used to specify the provider to use for the resource. Even we have global configuration for the <code>eu-west-1</code> region, we can still create the resources in the <code>us-east-1</code> region by specifying the provider.</p><h2 id="Importing-the-AWS-Resources-of-the-Other-Region"><a href="#Importing-the-AWS-Resources-of-the-Other-Region" class="headerlink" title="Importing the AWS Resources of the Other Region"></a>Importing the AWS Resources of the Other Region</h2><p>Back to previous topic, if we want to import the AWS Quicksight Users and Groups resources from the <code>us-east-1</code> region in current pulumi stack from the command line, we need to specify the provider for the pulumi command line. The Pulumi CLI import command takes an additional <code>--provider</code> option to specify the provider to use for the import.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:quicksight/group:Group dev xxxxxx/default/dev --provider name=urn</span><br></pre></td></tr></table></figure><p>In above command, we are importing the <code>aws:quicksight/group:Group</code> resource with the <code>dev</code> name in the provider. For the <code>--provider</code> option, The <code>name</code> is the name of the provider to use for the import, and <code>urn</code> is the URN of the provider to use for the import. Typically, the resource urns in pulumis is below format.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urn:pulumi:production::acmecorp-website::custom:resources:Resource$aws:s3/bucket:Bucket::my-bucket</span><br><span class="line">           ^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^</span><br><span class="line">           &lt;stack-name&gt; &lt;project-name&gt;   &lt;parent-type&gt;             &lt;resource-type&gt;       &lt;resource-name&gt;</span><br></pre></td></tr></table></figure><p>If there is no <code>parent-type</code> in the resource urn, the urns will be like below format.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urn:pulumi:production::acmecorp-website::aws:s3/bucket:Bucket::my-bucket</span><br><span class="line">           ^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^</span><br><span class="line">           &lt;stack-name&gt; &lt;project-name&gt;   &lt;resource-type&gt;       &lt;resource-name&gt;</span><br></pre></td></tr></table></figure><p>For the details of Pulumi Resources URNs, please refer to the <a href="https://www.pulumi.com/docs/concepts/resources/names/#urns">Pulumi URNs</a>.</p><p>In our scenario, we can import the Quicksight Groups resources from the <code>us-east-1</code> region by using the provider. <span class='pbg warning'>There is one thing is important to note</span> For example, we don’t have any <code>Provider</code> resources for the <code>us-east-1</code> region in our current stack. If we run below command to import the Quicksight Groups resources from the <code>us-east-1</code> region, it will fail. Below is an examle of the full import resource with <code>--provider</code> option</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:quicksight/group:Group dev &lt;aws-account-id&gt;/default/dev --provider us_east_1_provider=urn:pulumi:&lt;pulumi-project-name&gt;::quicksight::pulumi:providers:aws::us_east_1_provider</span><br></pre></td></tr></table></figure><p>The <code>&lt;aws-account-id&gt;</code> and <code>&lt;pulumi-project-name&gt;</code> are placeholder just for example. Without the <code>Provider</code> resource for the <code>us-east-1</code> region, the import command will fail as below error message.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Preview failed: bad provider reference &#x27;us_east_1_provider=urn:pulumi:&lt;pulumi-project-name&gt;::quicksight::pulumi:providers:aws::us_east_1_provider&#x27; is not valid URN&#x27;</span><br></pre></td></tr></table></figure><p>The error full screenshot is below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-without-provider-error.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-without-provider-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>To fix this issue, we need to create the <code>Provider</code> resource for the <code>us-east-1</code> region in our current stack. We can do this by adding the <code>Provider</code> resource in in our Pulumi code and using <code>Pulumi up</code> command to create the resource.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new provider for the us-east-1 region</span></span><br><span class="line">us_east_1_provider = aws.Provider(<span class="string">&#x27;us-east-1&#x27;</span>, region=<span class="string">&#x27;us-east-1&#x27;</span>)</span><br></pre></td></tr></table></figure><p>After that, we can run the import command again to import the Quicksight Groups resources from the <code>us-east-1</code> region. And now you will see the Quicksight Groups resources of the <code>us-east-1</code> region in your pulumi stack.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-provider-success.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-provider-success.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>To import the AWS resources of the other region, we need to specify the provider for the pulumi command line. The Pulumi CLI import command takes an additional <code>--provider</code> option to specify the provider to use for the import. The <code>provider</code> resource should be created in pulumi before importing the resources of the other region resource.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h2&gt;&lt;p&gt;By default, the Pulumi import the resource in the </summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Keras3.0 - A Multi-framework Machine Learning Library</title>
    <link href="https://stonefishy.github.io/2024/06/25/keras3-0-a-multi-framework-machine-learning-library/"/>
    <id>https://stonefishy.github.io/2024/06/25/keras3-0-a-multi-framework-machine-learning-library/</id>
    <published>2024-06-25T10:12:36.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p><code>Keras</code>3 is a full rewrite of Keras that enables you to run your Keras workflows on top of either <code>JAX</code>, <code>TensorFlow</code>, or <code>PyTorch</code>, and that unlocks brand new large-scale model training and deployment capabilities. It’s multi-framework machine learning, meaning that you can use Keras to train models on top of different backends, and deploy them to different platforms. You can also use Keras as a low-level cross-framework language to develop custom components such as layers, models, or metrics that can be used in native workflows in JAX, TensorFlow, or PyTorch — with one codebase.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/keras3-multi-framework-machine-learning.jpg" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/keras3-multi-framework-machine-learning.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Keras 3 Multi-framework Machine Learning"/></div><span class="image-caption">Keras 3 Multi-framework Machine Learning</span></div><h2 id="What’s-New-in-Keras-3"><a href="#What’s-New-in-Keras-3" class="headerlink" title="What’s New in Keras 3?"></a>What’s New in Keras 3?</h2><p>Keras 3 introduces several exciting features that enhance its usability, performance, and flexibility:</p><h4 id="Unified-API"><a href="#Unified-API" class="headerlink" title="Unified API"></a>Unified API</h4><p>Keras 3 continues to build on its legacy of a user-friendly and intuitive API. It aims to unify the high-level and low-level APIs more seamlessly, providing a consistent experience across different backends such as TensorFlow, PyTorch, and others.</p><h4 id="Multi-backend-Support"><a href="#Multi-backend-Support" class="headerlink" title="Multi-backend Support"></a>Multi-backend Support</h4><p>While Keras has traditionally been closely associated with TensorFlow, Keras 3 expands its compatibility to other popular deep learning frameworks. This means you can now use Keras with PyTorch and other backends, leveraging Keras’ high-level abstractions and ease of use across different environments.</p><h4 id="Improved-Performance"><a href="#Improved-Performance" class="headerlink" title="Improved Performance"></a>Improved Performance</h4><p>Efforts have been made in Keras 3 to optimize performance across various operations, ensuring faster execution times and better utilization of hardware resources. This improvement is crucial for handling larger datasets and complex models efficiently.</p><h4 id="Enhanced-Model-Deployment"><a href="#Enhanced-Model-Deployment" class="headerlink" title="Enhanced Model Deployment"></a>Enhanced Model Deployment</h4><p>Keras 3 simplifies the process of deploying trained models to production environments. With streamlined APIs for model serialization and deployment tools, it becomes easier to integrate Keras models into real-world applications.</p><h4 id="Expanded-Model-Zoo"><a href="#Expanded-Model-Zoo" class="headerlink" title="Expanded Model Zoo"></a>Expanded Model Zoo</h4><p>Keras 3 comes with an expanded model zoo, offering <code>pre-trained models</code> for a wider range of tasks and domains. This includes vision models (e.g., ResNet, EfficientNet), NLP models (e.g., BERT, GPT), and other specialized architectures, all accessible through a unified interface.</p><h4 id="Advanced-AutoML-Capabilities"><a href="#Advanced-AutoML-Capabilities" class="headerlink" title="Advanced AutoML Capabilities"></a>Advanced AutoML Capabilities</h4><p>The new release includes improved AutoML capabilities, allowing developers to automate model selection, hyperparameter tuning, and architecture search. This feature can significantly accelerate the model development process, especially for beginners and researchers exploring new domains.</p><h2 id="Pre-trained-Models"><a href="#Pre-trained-Models" class="headerlink" title="Pre-trained Models"></a>Pre-trained Models</h2><p>There’s a wide range of pretrained models that you can start using today with Keras 3. About 40 Keras Applications models (the <code>keras.applications</code> namespace) are available in all backends. These models are pre-trained on large datasets and can be used for transfer learning or fine-tuning. It includes:</p><h4 id="Pre-trained-Models-for-Natural-Language-Processing"><a href="#Pre-trained-Models-for-Natural-Language-Processing" class="headerlink" title="Pre-trained Models for Natural Language Processing"></a>Pre-trained Models for Natural Language Processing</h4><ul><li>Albert</li><li>Bart</li><li>Bert</li><li>Bloom</li><li>DebertaV3</li><li>DistilBert</li><li>Gemma</li><li>Electra</li><li>Falcon</li><li>FNet</li><li>GPT2</li><li>Llama</li><li>Llama3</li><li>Mistral</li><li>OPT</li><li>PaliGemma</li><li>Phi3</li><li>Roberta</li><li>XLMRoberta</li></ul><h4 id="Pre-trained-Models-for-Computer-Vision"><a href="#Pre-trained-Models-for-Computer-Vision" class="headerlink" title="Pre-trained Models for Computer Vision"></a>Pre-trained Models for Computer Vision</h4><ul><li>CSPDarkNet</li><li>EfficientNetV2</li><li>MiT</li><li>MobileNetV3</li><li>ResNetV1</li><li>ResNetV2</li><li>VideoSwinB</li><li>VideoSwinS</li><li>VideoSwinT</li><li>VitDet</li><li>YOLOV8</li><li>ImageClassifier</li><li>VideoClassifier</li><li>CLIP</li><li>RetinaNet</li></ul><h2 id="How-to-Get-Started-with-Keras-3"><a href="#How-to-Get-Started-with-Keras-3" class="headerlink" title="How to Get Started with Keras 3?"></a>How to Get Started with Keras 3?</h2><h4 id="1-Install-Keras-3"><a href="#1-Install-Keras-3" class="headerlink" title="1.Install Keras 3"></a>1.Install Keras 3</h4><p>Ensure you have the latest version of Keras installed. You can install Keras via pip if you haven’t already:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade keras</span><br></pre></td></tr></table></figure><h4 id="2-Define-Model"><a href="#2-Define-Model" class="headerlink" title="2.Define Model"></a>2.Define Model</h4><p>Use Keras’ high-level API to define your deep learning model. Here’s a simple example of a convolutional neural network (CNN) for image classification:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)),</span><br><span class="line">    MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">    Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">    Flatten(),</span><br><span class="line">    Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h4 id="3-Compile-and-Train-Model"><a href="#3-Compile-and-Train-Model" class="headerlink" title="3.Compile and Train Model"></a>3.Compile and Train Model</h4><p>Compile the model with a loss function, optimizer, and metrics, then train it on your data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>, validation_data=(val_images, val_labels))</span><br></pre></td></tr></table></figure><h4 id="4-Deploy-models"><a href="#4-Deploy-models" class="headerlink" title="4.Deploy models"></a>4.Deploy models</h4><p>Keras 3 provides a simple and unified interface for deploying trained models to production environments. You can serialize your models and deploy them using tools such as TensorFlow Serving, PyTorch Hub, or JAX Hub. </p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Keras 3 bring a lot of exciting features to the table, including multi-backend support, improved performance, and enhanced model deployment. It also includes a wide range of pre-trained models for natural language processing and computer vision, making it easy to get started with deep learning. With these features, Keras 3 is a powerful and flexible tool for building and deploying deep learning models.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Keras&lt;/code&gt;3 is a full rewrite of Keras that enables you to run your Keras workflows on top of either &lt;code&gt;JAX&lt;/code&gt;, &lt;code&gt;Tens</summary>
      
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Keras" scheme="https://stonefishy.github.io/tags/Keras/"/>
    
    <category term="TensorFlow" scheme="https://stonefishy.github.io/tags/TensorFlow/"/>
    
    <category term="PyTorch" scheme="https://stonefishy.github.io/tags/PyTorch/"/>
    
    <category term="JAX" scheme="https://stonefishy.github.io/tags/JAX/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the X-Frame-Options HTTP Header</title>
    <link href="https://stonefishy.github.io/2024/06/14/understanding-the-x-frame-options-http-header/"/>
    <id>https://stonefishy.github.io/2024/06/14/understanding-the-x-frame-options-http-header/</id>
    <published>2024-06-14T14:36:28.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, we build a frontend website as a nginx docker image, before go live on production. We asking the security team to do the security scan for the website on stage environment. One of security issues indicates the X-Frame-Options HTTP header is not set properly. It will cause the website to be vulnerable to clickjacking attacks.</p><h2 id="Clickjacking-Attack"><a href="#Clickjacking-Attack" class="headerlink" title="Clickjacking Attack"></a>Clickjacking Attack</h2><p>Clickjacking is a type of security vulnerability that allows an attacker to trick a user into clicking on a link or button on a malicious website that is designed to look like the legitimate website. This can happen when the attacker embeds the malicious website within a frame on the legitimate website, which can trick the user into clicking on the malicious link or button.</p><p>To prevent clickjacking attacks, web developers can use the X-Frame-Options HTTP header to specify whether a web page can be displayed within a frame or iframe. This header can have three possible values: DENY, SAMEORIGIN, and ALLOW-FROM uri.</p><h2 id="What-is-X-Frame-Options"><a href="#What-is-X-Frame-Options" class="headerlink" title="What is X-Frame-Options?"></a>What is X-Frame-Options?</h2><p>The X-Frame-Options is an HTTP response header used to control whether a web page can be displayed within a frame or iframe. It helps to mitigate clickjacking attacks by preventing malicious websites from embedding a vulnerable site within a frame and tricking users into taking unintended actions.</p><h2 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h2><p>The X-Frame-Options header can have three possible values: DENY, SAMEORIGIN, and ALLOW-FROM uri.</p><p><code>DENY</code>: This value prevents the page from being displayed in a frame, regardless of the site attempting to do so.</p><p><code>SAMEORIGIN</code>: With this value, the page can be displayed in a frame on the same origin as the page itself. This restricts the frame to the same origin as the parent page.</p><p><code>ALLOW-FROM uri</code>: Here, the page can only be displayed in a frame on the specified origin.</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>To implement the X-Frame-Options header, simply include the header in the server’s HTTP response. It can be implemented on code programming, server configuration, or web server configuration.</p><h3 id="Code-Programming"><a href="#Code-Programming" class="headerlink" title="Code Programming"></a>Code Programming</h3><p>Below is an example of how to set the header using different programming languages:</p><h4 id="Using-Node-js-Express"><a href="#Using-Node-js-Express" class="headerlink" title="Using Node.js (Express)"></a>Using Node.js (Express)</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set X-Frame-Options header to DENY</span></span><br><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">  res.<span class="title function_">setHeader</span>(<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>);</span><br><span class="line">  <span class="title function_">next</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="Using-Django-Python"><a href="#Using-Django-Python" class="headerlink" title="Using Django (Python)"></a>Using Django (Python)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set X-Frame-Options header to SAMEORIGIN</span></span><br><span class="line">response[<span class="string">&#x27;X-Frame-Options&#x27;</span>] = <span class="string">&#x27;SAMEORIGIN&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="Using-ASP-NET-C"><a href="#Using-ASP-NET-C" class="headerlink" title="Using ASP.NET (C#)"></a>Using ASP.NET (C#)</h4><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set X-Frame-Options header to ALLOW-FROM</span></span><br><span class="line">Response.AddHeader(<span class="string">&quot;X-Frame-Options&quot;</span>, <span class="string">&quot;ALLOW-FROM https://example.com&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="Server-Configuration"><a href="#Server-Configuration" class="headerlink" title="Server Configuration"></a>Server Configuration</h3><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h4><p>To configure Nginx to send the X-Frame-Options header, add this either to your http, server or location configuration:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_header X-Frame-Options SAMEORIGIN always;</span><br></pre></td></tr></table></figure><h4 id="Apache"><a href="#Apache" class="headerlink" title="Apache"></a>Apache</h4><p>To configure Apache to send the X-Frame-Options header for all pages, add this to your site’s configuration:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Header always set X-Frame-Options &quot;DENY&quot;</span><br></pre></td></tr></table></figure><h4 id="IIS"><a href="#IIS" class="headerlink" title="IIS"></a>IIS</h4><p>To configure IIS to send the X-Frame-Options header for all pages, add this to your web.config file:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">httpProtocol</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">customHeaders</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">&quot;X-Frame-Options&quot;</span> <span class="attr">value</span>=<span class="string">&quot;DENY&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">customHeaders</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">httpProtocol</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>To demonstrate the effectiveness of the X-Frame-Options header, we can create a parent html page, and a child html page that is embedded within a frame in the parent page.</p><h3 id="Parent-HTML-Page"><a href="#Parent-HTML-Page" class="headerlink" title="Parent HTML Page"></a>Parent HTML Page</h3><p>Parent HTML page includes the iframe of the child page. The child page is hosted on a different domain (<a href="http://localhost:3333/child.html">http://localhost:3333/child.html</a>) to demonstrate the effectiveness of the X-Frame-Options header. </p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Parent Page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Parent Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is parent page. below is the iframe of child page.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">iframe</span> <span class="attr">src</span>=<span class="string">&quot;http://localhost:3333/child.html&quot;</span> <span class="attr">frameborder</span>=<span class="string">&quot;0&quot;</span> <span class="attr">sandbox</span>=<span class="string">&quot;allow-scripts&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 100%; height: 200px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Child-HTML-Page"><a href="#Child-HTML-Page" class="headerlink" title="Child HTML Page"></a>Child HTML Page</h3><p>Child HTML page is a simple page that displays a message. It is hosted on the domain (<a href="http://localhost:3333/child.html">http://localhost:3333/child.html</a>) by using <code>httpster</code> tool.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Child Page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Child Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is a child page.<span class="tag">&lt;/<span class="name">p</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><p>To test the effectiveness of the X-Frame-Options header, we can open the parent page in a browser and observe the behavior.</p><h4 id="Without-X-Frame-Options-Header"><a href="#Without-X-Frame-Options-Header" class="headerlink" title="Without X-Frame-Options Header"></a>Without X-Frame-Options Header</h4><p>By default, the <code>httpster</code> does not add the X-Frame-Options header to the response. Therefore, the child page can be embedded within a frame on the parent page. See below screenshot, these is no X-Frame-Options header in the response.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/without-x-frame-options-response-header.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/without-x-frame-options-response-header.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Without X-Frame-Options Header" style="width:500px;"/></div><span class="image-caption">Without X-Frame-Options Header</span></div><h4 id="With-X-Frame-Options-Header"><a href="#With-X-Frame-Options-Header" class="headerlink" title="With X-Frame-Options Header"></a>With X-Frame-Options Header</h4><p>With the X-Frame-Options header set to DENY, the child page cannot be embedded within a frame on the parent page.</p><p>To test the X-Frame-Options header, we need to modify the <code>httpster</code> server source code to add the X-Frame-Options header to the response. Actually, the <code>httpster</code> tool is a simple HTTP server base on node express. We can modify the <code>app.use</code> function to set the X-Frame-Options header in the httpster source code. </p><p>Here is the modified <code>app.use</code> function with the X-Frame-Options header set to DENY:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">   res.<span class="title function_">setHeader</span>(<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>);</span><br><span class="line">   <span class="title function_">next</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>We can then open the parent page in a browser and observe the behavior. See below screenshot, these is with X-Frame-Options header value set to DENY in the response. And the child page is blocked from being embedded within a frame on the parent page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/with-x-frame-options-response-header-deny.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/with-x-frame-options-response-header-deny.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="With X-Frame-Options Header Value DENY" style="width:500px;"/></div><span class="image-caption">With X-Frame-Options Header Value DENY</span></div><p>And also, there is error message in the console of the browser, which indicates that the child page is blocked from being embedded within a frame on the parent page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/with-x-frame-opitons-response-header-deny-console.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/with-x-frame-opitons-response-header-deny-console.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="With X-Frame-Options Header Value DENY Console Error" style="width:500px;"/></div><span class="image-caption">With X-Frame-Options Header Value DENY Console Error</span></div><p>You can also test the X-Frame-Options header with different values such as SAMEORIGIN and ALLOW-FROM uri to see how it affects the behavior of the website.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By implementing the X-Frame-Options header, web developers can enhance the security of their websites and protect users from potential clickjacking attacks. It is recommended to set this header appropriately based on the specific requirements of the web application.</p><p>Remember to test the effectiveness of the header using browser developer tools and security testing tools to ensure that it is properly configured.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently, we build a frontend website as a nginx docker image, before go live on production. We asking the security team to do the securi</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="Web" scheme="https://stonefishy.github.io/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>The Points of AWS China CloudFront You Need to Notice</title>
    <link href="https://stonefishy.github.io/2024/04/18/the-points-of-aws-china-cloudfront-you-need-to-notice/"/>
    <id>https://stonefishy.github.io/2024/04/18/the-points-of-aws-china-cloudfront-you-need-to-notice/</id>
    <published>2024-04-18T10:16:54.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>There are much difference between AWS Global and AWS China. The background of this blog is that I’m responsible for migrating the aws global application to aws china. The application already go lived on AWS Global. The application is  collecting the user inforamtion and for business logic. The business wants this application to serve China customer. Due to the application regulation,  the application needs to deployed in AWS China and store the user information in AWS China.</p><p>The application is using below AWS services:</p><ul><li>AWS S3: store the static website assets and user information.</li><li>AWS ALB: the load balancer for the application.</li><li>AWS ASG: auto scaling group for the application.</li><li>AWS ECR: store the application container image.</li><li>AWS ECS: run the application container.</li><li>AWS ACM: manage the SSL certificate.</li><li>AWS WAF: web application firewall.</li><li>AWS VPC: virtual private cloud.</li><li>AWS S3 VPC Gateway: access the S3 bucket from the VPC.</li><li>AWS CloudWatch: monitor the application logs, performance and alarms.</li><li>AWS SNS: notificate the stack holder when application performance is abnormal.</li><li>AWS CloudFront: serve the static website and user information.</li></ul><h2 id="AWS-China"><a href="#AWS-China" class="headerlink" title="AWS China"></a>AWS China</h2><p>The AWS China is a separate entity operated by a local partner in compliance with Chinese regulations. Data centers located in Beijing and Ningxia. The operator is different between Beijing and Ningxia. Beijing region operated by Sinnet(光环新网)，Ningxia region operated by NWCD(西云数据). Basically， the service price of Ningxia region is cheaper than Beijing region. You can find the detail pricing in the AWS China link <a href="https://calculator.amazonaws.cn/#/">https://calculator.amazonaws.cn/#/</a>. AWS Fargate priciing is here <a href="https://www.amazonaws.cn/en/fargate/pricing">https://www.amazonaws.cn/en/fargate/pricing</a></p><h2 id="Difference-between-AWS-Global-and-AWS-China"><a href="#Difference-between-AWS-Global-and-AWS-China" class="headerlink" title="Difference between AWS Global and AWS China"></a>Difference between AWS Global and AWS China</h2><p>The AWS China has many limiation and difference with AWS Global. And also some new services are not available in AWS China. When you migrate the application to AWS China, you need to consider the below points:</p><ol><li>AWS China has different pricing policy. The pricing policy is different between Beijing and Ningxia. </li><li>The Infrastructure code is different between AWS Global and AWS China. The code need to be modified to adapt to AWS China.</li><li>The Website should be do the ICP filling and Goverment Filling. (域名备案，网安备案)</li></ol><h3 id="Infrastructure-as-Code"><a href="#Infrastructure-as-Code" class="headerlink" title="Infrastructure as Code"></a>Infrastructure as Code</h3><p>We’re using <code>Pulumi</code> to manage the infrastructure as code. Pulumi is a tool for developing, building, and deploying cloud applications and infrastructure. It supports multiple cloud providers including AWS, Azure, GCP, and Kubernetes.<br>There are AWS Service Resource definition is different with AWS Global on AWS China. In AWS China there is an <code>amazonaws.com.cn</code> string for endpoint, and <code>aws-cn</code> ARN prefix. The code need to be modified to adapt to AWS China.</p><h4 id="AWS-China-1"><a href="#AWS-China-1" class="headerlink" title="AWS China"></a>AWS China</h4><ul><li>AWS EndPoint: xxxxxxx.s3.cn-northwest-1.<strong>amazonaws.com.cn</strong>&#x2F;example.txt</li><li>AWS ARNs: arn:<strong>aws-cn</strong>:s3:::xxxxxxx&#x2F;example.txt</li></ul><h4 id="AWS-Global"><a href="#AWS-Global" class="headerlink" title="AWS Global"></a>AWS Global</h4><ul><li>AWS EndPoint: xxxxxxx.s3.cn-northwest-1.<strong>amazonaws.com</strong>&#x2F;example.txt</li><li>AWS ARNs: arn:<strong>aws</strong>:s3:::xxxxxxx&#x2F;example.txt</li></ul><h3 id="CloudFront"><a href="#CloudFront" class="headerlink" title="CloudFront"></a>CloudFront</h3><p>In our application is much difference between AWS Global and AWS China, especially the CloudFront.</p><ul><li>Requires ICP filing and domain name filing in AWS China.</li><li>The CloudFront provides domain name like “*.cloudfront.cn” which cannot be used in for website serving in AWS China. You can not access the website through the CloudFront domain name. It returns 403 Forbidden error.</li><li>The SSL&#x2F;TLS certificates for CloudFront does not support the Amazon Certificate Manager in AWS China. It requires to use SSL&#x2F;TLS certificate from third party, and then - - import certificate in IAM. It is only support IAM to store the certificates for CloudFront in AWS China.</li><li>The CloudFront does not supports the Amazon WAF in AWS China.</li><li>The Cache polices and Origin request polices does not support in AWS China</li><li>The Lambda@Edge is not available in AWS China.</li><li>CloudFront origin access only supports legacy access identities OAI for S3 bucket, does not support OAC in AWS China</li><li>The CloudFront origin for S3 bucket which is not a website endpoint, the following format: <code>bucket-name.s3.region.amazonaws.com.cn</code>, remember <code>region</code> after <code>s3</code></li><li>The CloudFront origin for S3 bucket which is a website endpoint, use the following format: <code>bucket-name.s3-website.region.amazonaws.com.cn</code>, remember <code>region</code> after <code>s3-website</code></li></ul><p>For more information, please refer to the AWS China CloudFront <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/cloudfront.html#feature-diff">https://docs.amazonaws.cn/en_us/aws/latest/userguide/cloudfront.html#feature-diff</a></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this blog, we have discussed the important points when migrate the aws global application to aws china, especially for the AWS CloudFront. We have listed the difference between AWS Global and AWS China, and also the CloudFront difference between AWS Global and AWS China.</p><p>If you want to know more about AWS China service difference with AWS Global, you can refer to this official link <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html">https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html</a></p><p>Hope this blog can help you to migrate the application to AWS China.</p><h2 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h2><ul><li>AWS China Service Difference: <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html">https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html</a></li><li>AWS China Service Pricing: <a href="https://calculator.amazonaws.cn/#/">https://calculator.amazonaws.cn/#/</a></li><li>AWS China Fargate Pricing: <a href="https://www.amazonaws.cn/en/fargate/pricing">https://www.amazonaws.cn/en/fargate/pricing</a></li><li>AWS China Edge Location: <a href="https://www.amazonaws.cn/en/cloudfront/features/">https://www.amazonaws.cn/en/cloudfront/features/</a></li><li>AWS China CloudFront Error Investigation: <a href="https://zhuanlan.zhihu.com/p/182517851">https://zhuanlan.zhihu.com/p/182517851</a></li><li>ICP&#x2F;IP地址&#x2F;域名信息备案管理系统: <a href="https://beian.miit.gov.cn/#/Integrated/index">https://beian.miit.gov.cn/#/Integrated/index</a></li><li>全国互联网安全管理服务平台: <a href="https://beian.mps.gov.cn/#/query/webSearch">https://beian.mps.gov.cn/#/query/webSearch</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;There are much difference between AWS Global and AWS China. The background of this blog is that I’m responsible for migrating the aws glo</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Migrate a legacy application to AWS Cloud</title>
    <link href="https://stonefishy.github.io/2024/03/13/migrate-a-legacy-application-to-aws-cloud/"/>
    <id>https://stonefishy.github.io/2024/03/13/migrate-a-legacy-application-to-aws-cloud/</id>
    <published>2024-03-13T14:20:44.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Recently, we got a requirement from the company to move the application to AWS Cloud. The company has a strong focus on security and compliance, and stack holders also want the application more reliable and scalable. The migration also need to be done as soon as possible.</p><p>The application running on a local data center. The application is consists of two parts, frontend is a static website built with React and provide the user interface to user, the backend is a Python Flask application that provide the API to interact with the frontend. The backend server also contains a machine learning model algorithm that is used to process the user’s ears photo. </p><p>The application main logic is that the user answer some questions and scan and upload their ears photo to the backend server from the website, the backend server will process the photo and return the suggestion result to user to recommend which headset or earphone is the best fit for them.</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>After analysis application technologies and architecture, base on the requirements, we did some architecture design. Below is the architecture of the application on AWS Cloud. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-migrate-legacy-app-arch.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-migrate-legacy-app-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Application Architecture on AWS Cloud"/></div><span class="image-caption">Application Architecture on AWS Cloud</span></div><p>The application is hosted on AWS Cloud, major is that the frontend is served by CloudFront, the backend is served by ECS, and the user’s ears photo is stored in S3 bucket. The application is using the following AWS services:</p><h4 id="AWS-S3-Bucket"><a href="#AWS-S3-Bucket" class="headerlink" title="AWS S3 Bucket"></a>AWS S3 Bucket</h4><p>Setup two s3 buckets, one is for storing the user’s ears photo, and config the object expires after 90 days. second bucket is for storing the static website files. All s3 buckets are public blocked.</p><h4 id="AWS-VPC"><a href="#AWS-VPC" class="headerlink" title="AWS VPC"></a>AWS VPC</h4><p>Create a dedicate VPC for the application, and configure the subnets, route tables, and security groups. Two public subnets and two private subnets are used.</p><h4 id="AWS-ECR"><a href="#AWS-ECR" class="headerlink" title="AWS ECR"></a>AWS ECR</h4><p>Use ECR to store the Docker image of the backend application. The image will be built and pushed to ECR by CI&#x2F;CD pipeline.</p><h4 id="AWS-ECS"><a href="#AWS-ECS" class="headerlink" title="AWS ECS"></a>AWS ECS</h4><p>Use ECS to run the backend application as a container in private subnets, and configure the auto scaling group and load balancer. Autoscaling minimum size is 2 and maximum size is 20.</p><h4 id="AWS-ALB"><a href="#AWS-ALB" class="headerlink" title="AWS ALB"></a>AWS ALB</h4><p>Create a ALB to serve the backend ECS service, and configure the listener rules to forward the traffic to the ECS service. The ALB attached the SSL certificate from ACM.</p><h4 id="AWS-S3-VPC-Gateway-Endpoint"><a href="#AWS-S3-VPC-Gateway-Endpoint" class="headerlink" title="AWS S3 VPC Gateway Endpoint"></a>AWS S3 VPC Gateway Endpoint</h4><p>Use the S3 VPC Gateway Endpoint to access the s3 bucket from the backend ECS container.</p><h4 id="AWS-Internet-Gateway"><a href="#AWS-Internet-Gateway" class="headerlink" title="AWS Internet Gateway"></a>AWS Internet Gateway</h4><p>The Internet Gateway to connect the VPC to the internet. Put the ALB on the two public subnets across two AZs </p><h4 id="AWS-CloudWatch"><a href="#AWS-CloudWatch" class="headerlink" title="AWS CloudWatch"></a>AWS CloudWatch</h4><p>Use CloudWatch to monitor the application performance, and create alarms to notify the team when the application is not running as expected.</p><h4 id="AWS-SNS"><a href="#AWS-SNS" class="headerlink" title="AWS SNS"></a>AWS SNS</h4><p>Use SNS to notify the team when the application performance is not good, and the team can take action to improve the application performance.</p><h4 id="AWS-ACM"><a href="#AWS-ACM" class="headerlink" title="AWS ACM"></a>AWS ACM</h4><p>Use ACM to manage the SSL certificate for the ALB and CloudFront, the certificate is issued by the IT team. The application is served over HTTPS.</p><h4 id="AWS-CloudFront"><a href="#AWS-CloudFront" class="headerlink" title="AWS CloudFront"></a>AWS CloudFront</h4><p>Use CloudFront to serve the static website files, and cache the files to improve the website loading speed. Config CloudFront to access s3 bucket by OAC. Create a another origin for the ALB.</p><h4 id="AWS-Security-Group"><a href="#AWS-Security-Group" class="headerlink" title="AWS Security Group"></a>AWS Security Group</h4><p>Create a security group for the ECS container, and allow the traffic from the ALB to the ECS container. And one more security group for the ALB to allow the traffic only from AWS CloudFront prefix list.</p><h4 id="AWS-IAM"><a href="#AWS-IAM" class="headerlink" title="AWS IAM"></a>AWS IAM</h4><p>Create an IAM role for the ECS container, and attach the necessary policies to the role to access the s3 bucket, ECR, and CloudWatch.</p><h4 id="AWS-WAF"><a href="#AWS-WAF" class="headerlink" title="AWS WAF"></a>AWS WAF</h4><p>Use WAF to protect the application from common web exploits and attacks. This is mandatory for the company’s security policy. The security team will also review the infrastucture and do the security scan the application. The application won’t be deployed to production if the security scan failed.</p><h2 id="IaC-with-Pulumi"><a href="#IaC-with-Pulumi" class="headerlink" title="IaC with Pulumi"></a>IaC with Pulumi</h2><p>Use Pulumi to manage the AWS resources, and create the infrastructure as code. The code will be checked into the source control, and for the pipeline, we’re using Bamboo pipeline as company already using Bamboo for CI&#x2F;CD. The pipeline will doing below major things.</p><ol><li>Build the Docker image and push to ECR.</li><li>Deploy the frontend static website to CloudFront, and invalidate the cache to make the content updated for end user.</li><li>Update the infrastucture by creating or updating the AWS resources by using pulumi.</li></ol><h2 id="Rationale"><a href="#Rationale" class="headerlink" title="Rationale"></a>Rationale</h2><p>The migration of the legacy application to AWS Cloud is a complex task, and we need to follow the best practices to make the migration successful.</p><ol><li>Using CloudFront and S3 bucket to host the static website and user’s ears photo is scalable and cost-effective. </li><li>Using the ECS and ALB to serve the backend application is also a good choice to improve the application performance and scalability. We’re not using AWS API Gateway and AWS Lambda to serve as backend because we are requested to migrate the application to Cloud as soon as possible. Build the python <code>Flask</code> application to a docker image and push to ECR is a good practice to deploy the application to AWS Cloud in this situation.</li><li>Using the VPC and security group to isolate the application and improve the security is a must. The ECS is located in private subnets, and the ALB is in public subnets, and the traffic is only allowed from AWS CloudFront prefix list to ALB, then forward traffic to ECS container.</li><li>Using the ACM to manage the SSL certificate for the ALB and CloudFront is a good practice to improve the security and compliance.</li><li>Using the CloudWatch to monitor the application performance and create alarms to notify the team when the application is not running as expected is a good practice to improve the application reliability.</li><li>Using the IAM role to access the s3 bucket, ECR, and CloudWatch is a good practice to improve the security and control.</li><li>Using the WAF to protect the application from common web exploits and attacks is a mandatory requirement for the company’s security policy.</li><li>Using Pulumi to manage the AWS resources as code is a good practice to improve the automation and reliability of the migration process.</li></ol><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This is just a sample of how to migrate a legacy application to AWS Cloud, and there are many other factors to consider when migrating a legacy application to AWS Cloud. The key is to follow the best practices and use the right tools to make the migration successful base on the requirements.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h2&gt;&lt;p&gt;Recently, we got a requirement from th</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>Manage the Existing Cloud Resources By Using Pulumi Import</title>
    <link href="https://stonefishy.github.io/2024/02/27/importing-existing-cloud-resources-with-pulumi/"/>
    <id>https://stonefishy.github.io/2024/02/27/importing-existing-cloud-resources-with-pulumi/</id>
    <published>2024-02-27T14:26:24.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>In many real-world scenarios, cloud infrastructure is already in place before adopting infrastructure as code (IaC) solutions like Pulumi. Pulumi provides a feature called <code>import</code> to help manage existing cloud resources within its IaC framework. This feature allows users to import the current state of resources into their Pulumi codebase, making it easier to adopt Pulumi for managing existing infrastructure.</p><h2 id="Pulumi-Import"><a href="#Pulumi-Import" class="headerlink" title="Pulumi Import"></a>Pulumi Import</h2><p>Pulumi’s import feature provides a way to bring existing cloud resources under Pulumi’s management. By creating a Pulumi program and using the pulumi import command, users can declare and manage existing infrastructure resources using Pulumi. The pulumi supports both importing existing resources with the CLI and importing existing resources in the code. Here we’re talking about the CLI import to generate the code for the imported resources. </p><h2 id="Usage-and-Syntax"><a href="#Usage-and-Syntax" class="headerlink" title="Usage and Syntax"></a>Usage and Syntax</h2><p>To import an existing cloud resource into Pulumi, you need to follow these steps:</p><ol><li><p>Create a Pulumi Project<br>Create a new Pulumi project or use an existing Pulumi project where you want to manage the imported resources. For creating a pulumi project, you can check the previous blog post on how to create a new Pulumi project.</p></li><li><p>Identify the Resource to Import<br>Identify the existing resource in your cloud provider environment that you want to import into Pulumi. This could be a virtual machine, database, storage bucket, or any other supported resource.</p></li><li><p>Apply the Import<br>Apply the import operation to bring the existing resource under Pulumi’s management. Pulumi will generate the appropriate code for the resource based on its current state in the cloud provider environment.</p></li></ol><p>The syntax for the import command is as follows:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import &lt;type&gt; &lt;name&gt; &lt;id&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;type&gt;</code> is the Pulumi type token to use for the imported resource.</li><li><code>&lt;name&gt;</code> is the resource name to apply to the resource once it’s imported.</li><li><code>&lt;id&gt;</code> is the value to use for the resource lookup in the cloud provider.</li></ul><h2 id="Managing-Imported-Resources"><a href="#Managing-Imported-Resources" class="headerlink" title="Managing Imported Resources"></a>Managing Imported Resources</h2><p>Once the resources are imported, they can be managed just like any other Pulumi-managed resources. The imported resources can be updated, deleted, and included in stacks alongside other Pulumi-declared infrastructure.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>I created a S3 bucket name <code>my-s3-bucket</code> from AWS Console manually. But now I want to manage this S3 bucket by Pulumi. After identifying the bucket to be imported, the import command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:s3/bucket:Bucket my-bucket my-s3-bucket</span><br></pre></td></tr></table></figure><ul><li><code>aws:s3/bucket:Bucket</code> is the Pulumi type token for the S3 bucket resource.</li><li><code>my-bucket</code> is the resource name to apply to the imported resource.</li><li><code>my-s3-bucket</code> is the value to use for the resource lookup in the AWS provider, here it’s bucket name.</li></ul><p>After running the import command, Pulumi will generate the appropriate code for the S3 bucket resource based on its current state in the AWS provider. Below is screenshot of the output of the import command:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Import"/></div><span class="image-caption">Pulumi Import</span></div><p>And generated code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">my_bucket = aws.s3.Bucket(<span class="string">&quot;my-bucket&quot;</span>,</span><br><span class="line">    arn=<span class="string">&quot;arn:aws-cn:s3:::my-s3-bucket&quot;</span>,</span><br><span class="line">    bucket=<span class="string">&quot;my-s3-bucket&quot;</span>,</span><br><span class="line">    hosted_zone_id=<span class="string">&quot;Z282HJ1KT0DH03&quot;</span>,</span><br><span class="line">    request_payer=<span class="string">&quot;BucketOwner&quot;</span>,</span><br><span class="line">    server_side_encryption_configuration=aws.s3.BucketServerSideEncryptionConfigurationArgs(</span><br><span class="line">        rule=aws.s3.BucketServerSideEncryptionConfigurationRuleArgs(</span><br><span class="line">            apply_server_side_encryption_by_default=aws.s3.BucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefaultArgs(</span><br><span class="line">                sse_algorithm=<span class="string">&quot;AES256&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            bucket_key_enabled=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure><p>In above code, you will notice there is a <code>protect=True</code> option set for the imported resource. This is to prevent any accidental deletion of the imported resource.</p><p>So when you try to delete the imported resource, Pulumi will give the errors to you. Let’s try to delete the imported S3 bucket:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi destroy</span><br></pre></td></tr></table></figure><p>You see, it displays the error message that the S3 bucket is protected and cannot be deleted.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-destory-import.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-destory-import.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Destory Import Protected Resource"/></div><span class="image-caption">Pulumi Destory Import Protected Resource</span></div><p>If you want to delete the resource in the cloud provider environment, you can remove the <code>protect=True</code> option from the code or change the <code>protect</code> option to <code>False</code>.</p><p>In above we’re using <code>pulumi import</code> to import the s3 bucket resource and code is generated on console. We can also generate the code into python file directly by using below command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:s3/bucket:Bucket my-bucket my-s3-bucket -o my-s3-bucket.py</span><br></pre></td></tr></table></figure><h2 id="Pulumi-State"><a href="#Pulumi-State" class="headerlink" title="Pulumi State"></a>Pulumi State</h2><p>Pulumi maintains a state file that tracks the current state of all resources in the cloud provider environment. When a resource is imported, Pulumi updates the state file to reflect the imported resource. This allows Pulumi to manage the imported resource as if it were created in the cloud provider environment.</p><p>Sometimes, we want to delete the state which imported in pulumi, but keep the existing cloud resources. In such case, we can use below command to only delete the state and keep the existing cloud resources.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi state delete &lt;urn&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;urn&gt;</code> is the unique resource identifier of the imported resource.</li></ul><p>To check the <code>&lt;urn&gt;</code> of the resource, we can use <code>pulumi stack --show-urns</code> to see the list urns of all resources in the current stack.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack --show-urns</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-stack-show-urns.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-stack-show-urns.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Stack Show Urns"/></div><span class="image-caption">Pulumi Stack Show Urns</span></div><p>In above screenshot, we can see the <code>&lt;urn&gt;</code> of the imported S3 bucket resource.To delete the state of the imported resource, we can use the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi state delete urn:pulumi:dev::pulumi-test::aws:s3/bucket:Bucket::my-bucket --force -y</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-state-delete.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-state-delete.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi State Delete Imported Resource"/></div><span class="image-caption">Pulumi State Delete Imported Resource</span></div><p>After deleting the state, the imported S3 bucket will still exist in the cloud provider environment.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Pulumi’s import feature allows users to seamlessly integrate existing cloud resources into their Pulumi programs. By following the import process and syntax, users can effectively manage their entire infrastructure, including existing resources, through Pulumi’s IaC approach.</p><p>This feature simplifies the transition to Pulumi for managing infrastructure and enables teams to leverage the benefits of IaC without having to recreate their entire cloud environment from scratch.</p><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links"></a>Reference Links</h2><ul><li>Pulumi Import: <a href="https://www.pulumi.com/docs/cli/commands/pulumi_import/">https://www.pulumi.com/docs/cli/commands/pulumi_import/</a></li><li>S3 Bucket Import: <a href="https://www.pulumi.com/registry/packages/aws/api-docs/s3/bucket/#import">https://www.pulumi.com/registry/packages/aws/api-docs/s3/bucket/#import</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In many real-world scenarios, cloud infrastructure is already in place before adopting infrastructure as code (IaC) solutions like Pulumi</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Pulumi - A Powerful IaC to manage the cloud infrastructure</title>
    <link href="https://stonefishy.github.io/2024/02/11/pulumi-a-powerful-iac-to-manage-the-cloud-infrastructure/"/>
    <id>https://stonefishy.github.io/2024/02/11/pulumi-a-powerful-iac-to-manage-the-cloud-infrastructure/</id>
    <published>2024-02-11T15:12:13.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>To manage the application cloud infrastructure more efficiently, we can use the <code>Terraform</code> for <code>IaC(Infrastructure as Code)</code>. But today, we’re not going to talk about the Terraform, we’re going to talk about the Pulumi. A powerful IaC tool that manages the cloud infrastructure.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-platform.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-platform.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Platform"/></div><span class="image-caption">Pulumi Platform</span></div><p>Pulumi is an open-source <code>infrastructure as code (IaC)</code> tool that provides a powerful way to create, deploy, and manage cloud infrastructure. It is the easiest way to build and deploy infrastructure, of any architecture and on any cloud, using programming languages that you already know and love, such as <code>TypeScript</code>, <code>Python</code>, <code>Go</code>, <code>C#</code>, <code>Java</code> etc.</p><p>It is a cross-platform tool that runs on <code>Windows</code>, <code>Linux</code>, and <code>macOS</code>, and supports a wide range of cloud providers, including <code>AWS</code>, <code>Azure</code>, <code>GCP</code>, <code>Kubernetes</code>, <code>Docker</code>, and more. It is also easy to use and has a simple and intuitive interface.</p><p>CI&#x2F;CD integration is also supported, which means you can use Pulumi to deploy your infrastructure as part of your CI&#x2F;CD pipeline. This makes it easier to manage and update your infrastructure as your application evolves.</p><h2 id="Install-Pulumi"><a href="#Install-Pulumi" class="headerlink" title="Install Pulumi"></a>Install Pulumi</h2><p>The pulumi  is a cross-platform tool that runs on Windows, Linux, and macOS. You can find and download the latest version from the official website: <a href="https://www.pulumi.com/docs/install/versions/">https://www.pulumi.com/docs/install/versions/</a>. Follow this link to <a href="https://www.pulumi.com/docs/install/">https://www.pulumi.com/docs/install/</a> to install the Pulumi CLI. It’s very simple to set up the Pulumi CLI on your machine.</p><p>Once you installed pulumi, simply run the below command to check the version:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi version</span><br></pre></td></tr></table></figure><h2 id="Create-a-new-Pulumi-project"><a href="#Create-a-new-Pulumi-project" class="headerlink" title="Create a new Pulumi project"></a>Create a new Pulumi project</h2><p>To create a new Pulumi project, you can use the <code>pulumi new</code> command. Below command is creating a new project with AWS Python template.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi new aws-python</span><br></pre></td></tr></table></figure><p>This will create a new project with a simple AWS Python template. The project will have a <code>Pulumi.yaml</code> file, which is the configuration file for the project.</p><h2 id="Configure-the-Pulumi-project"><a href="#Configure-the-Pulumi-project" class="headerlink" title="Configure the Pulumi project"></a>Configure the Pulumi project</h2><p>The <code>Pulumi.yaml</code> file is the configuration file for the project. It contains the project name and some configuration.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">my-project</span></span><br><span class="line"><span class="attr">runtime:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">python</span></span><br><span class="line">  <span class="attr">options:</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">venv</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">A</span> <span class="string">minimal</span> <span class="string">AWS</span> <span class="string">Python</span> <span class="string">Pulumi</span> <span class="string">program</span></span><br></pre></td></tr></table></figure><p>In the above configuration, we have set the project name as <code>my-project</code>, the runtime as <code>python</code> and the virtualenv as <code>venv</code>. The description is a brief description of the project.</p><h2 id="Create-a-new-stack"><a href="#Create-a-new-stack" class="headerlink" title="Create a new stack"></a>Create a new stack</h2><p>To create a new stack, you can use the <code>pulumi stack init</code> command. Below command is creating a new stack with the name <code>dev</code>.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack init dev</span><br></pre></td></tr></table></figure><p>Once you created the stack, the pululmi will generate a file named <code>Pulumi.dev.yaml</code> in your project folder. You can select it using the <code>pulumi stack select</code> command.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack select dev</span><br></pre></td></tr></table></figure><h2 id="Configure-the-stack"><a href="#Configure-the-stack" class="headerlink" title="Configure the stack"></a>Configure the stack</h2><p>The <code>Pulumi.dev.yaml</code> file is the configuration file for the stack.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">encryptionsalt:</span> <span class="string">v1:6YTR30z2X9tM=:v1:+fJN/nMOdJM+XjeZ:P7V9XPB9GHKE/dBuXX1uOCNGwgQztre==</span></span><br><span class="line"><span class="attr">config:</span> </span><br><span class="line">  <span class="attr">aws:region:</span> <span class="string">us-west-2</span></span><br><span class="line">  <span class="attr">aws:profile:</span> <span class="string">profile-account-1</span></span><br></pre></td></tr></table></figure><p>In above configuration, we have set the encryption salt (this is generated), and the AWS region and profile. You can add more configuration as per your requirement.</p><h2 id="Create-a-new-resource"><a href="#Create-a-new-resource" class="headerlink" title="Create a new resource"></a>Create a new resource</h2><p>To create a new resource, such as s3 bucket, you can write python code in the <code>main.py</code> file. Below is the code to create a new s3 bucket.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">bucket = aws.s3.Bucket(<span class="string">&quot;my-bucket&quot;</span>)</span><br></pre></td></tr></table></figure><p>In the above code, we have imported the <code>aws</code> module and created a new s3 bucket resource. The <code>Bucket</code> function creates a new s3 bucket with the name <code>my-bucket</code>.</p><h2 id="Preview-the-changes"><a href="#Preview-the-changes" class="headerlink" title="Preview the changes"></a>Preview the changes</h2><p>To preview the changes, you can use the <code>pulumi preview</code> command. This command will show the changes that will be applied to the infrastructure.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi preview</span><br></pre></td></tr></table></figure><p>Below is the project currently I’m working on for <code>pululmi preview</code> showcase.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-preview.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-preview.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Preview"/></div><span class="image-caption">Pulumi Preview</span></div><p>In above screenshot, you can see the changes that will be applied to the infrastructure. Including <code>update</code>, <code>create</code> and <code>delete</code> resources listed. You can also use the <code>--diff</code> option to show the difference between the current state and the desired state.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi preview --diff</span><br></pre></td></tr></table></figure><h2 id="Deploy-the-infrastructure"><a href="#Deploy-the-infrastructure" class="headerlink" title="Deploy the infrastructure"></a>Deploy the infrastructure</h2><p>To deploy the infrastructure, you can use the <code>pulumi up</code> command. This command will deploy the infrastructure as per the configuration in the <code>Pulumi.yaml</code> file.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi up</span><br></pre></td></tr></table></figure><p>This will deploy the infrastructure and show the output.</p><h2 id="Check-the-status-of-the-infrastructure"><a href="#Check-the-status-of-the-infrastructure" class="headerlink" title="Check the status of the infrastructure"></a>Check the status of the infrastructure</h2><p>To check the status of the infrastructure, you can use the <code>pulumi stack</code> command. This command will show the status of the infrastructure.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack</span><br></pre></td></tr></table></figure><p>This will show the status of the infrastructure. Below is the output of the <code>pulumi stack</code> command of one project I’m working.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-stack.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-stack.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Stack"/></div><span class="image-caption">Pulumi Stack</span></div><h2 id="Destroy-the-infrastructure"><a href="#Destroy-the-infrastructure" class="headerlink" title="Destroy the infrastructure"></a>Destroy the infrastructure</h2><p>To destroy the infrastructure, you can use the <code>pulumi destroy</code> command. This command will destroy the infrastructure as per the configuration in the <code>Pulumi.yaml</code> file.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi destroy</span><br></pre></td></tr></table></figure><p>This will destroy the infrastructure. Please be aware that this command will destroy all the resources in the stack. It’s dangerous to use this command, so use it with caution. You should know what you’re doing before using this command.</p><p>There are much more features of Pulumi, but I hope this article will give you a good idea about Pulumi.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Pulumi is a powerful IaC tool that manages the cloud infrastructure. It is easy to use and has a simple and intuitive interface. It supports a wide range of cloud providers, including AWS, Azure, GCP, Kubernetes, Docker, and more. It is also easy to integrate with CI&#x2F;CD pipeline.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;To manage the application cloud infrastructure more efficiently, we can use the &lt;code&gt;Terraform&lt;/code&gt; for &lt;code&gt;IaC(Infrastructure as Co</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>为何Redis选择单线程而非多线程架构？</title>
    <link href="https://stonefishy.github.io/2024/01/25/why-redis-choose-single-thread/"/>
    <id>https://stonefishy.github.io/2024/01/25/why-redis-choose-single-thread/</id>
    <published>2024-01-25T23:23:18.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>在现代的互联网应用中，数据存储和访问速度是至关重要的。Redis，作为一款高性能的内存数据库，以其快速的读写速度和灵活的数据结构而闻名。然而，令人惊奇的是，<code>Redis采用了单线程的执行模型</code>，而不是一些其他数据库采用的多线程或多进程模型。本文将深入探讨Redis为何选择这种看似不合理的设计决策，以及这个决策背后的技术原理。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/redis/redis-logo.webp" class="lazyload placeholder" data-srcset="/assets/images/redis/redis-logo.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Redis" style="width:600px;"/></div><span class="image-caption">Redis</span></div><h3 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h3><p><code>Redis</code>是一款基于内存的数据存储系统，它支持多种数据结构，如字符串、哈希表、列表、集合等。由于数据完全存储在内存中，Redis能够提供极高的读写速度，使其成为许多应用的首选数据库。</p><p>然而，令人惊讶的是，Redis在设计时选择了单线程执行模型，与其他一些数据库系统采用的多线程或多进程模型形成鲜明对比。这个决策引起了许多人的好奇，接下来我们将深入探讨Redis为何做出这一选择。</p><h3 id="为何选择单线程？"><a href="#为何选择单线程？" class="headerlink" title="为何选择单线程？"></a>为何选择单线程？</h3><h4 id="1-简单性与可维护性"><a href="#1-简单性与可维护性" class="headerlink" title="1. 简单性与可维护性"></a>1. 简单性与可维护性</h4><p>Redis的设计哲学之一是保持简单性和可维护性。<code>单线程模型避免了复杂的并发控制和同步机制，使得代码更加清晰和容易维护</code>。在一个单线程的环境中，开发者更容易理解和调试代码，减少了出错的可能性。</p><h4 id="2-避免上下文切换开销"><a href="#2-避免上下文切换开销" class="headerlink" title="2. 避免上下文切换开销"></a>2. 避免上下文切换开销</h4><p>多线程模型中，线程之间的切换会引入上下文切换的开销。而在单线程模型下，这种开销被最小化，因为不存在多线程之间的竞争和切换。这使得Redis能够更有效地利用CPU资源，提高整体性能。</p><h4 id="3-内存访问的局部性"><a href="#3-内存访问的局部性" class="headerlink" title="3. 内存访问的局部性"></a>3. 内存访问的局部性</h4><p>Redis的工作负载通常是内存密集型的，而不是计算密集型的。在这种情况下，单线程模型的优势显而易见。由于Redis数据完全存储在内存中，对于大多数操作而言，CPU主要执行的是内存读写操作。<code>单线程模型避免了多线程之间频繁的共享内存访问</code>，利用了内存访问的局部性，从而提高了性能。</p><h4 id="4-原子性操作简化"><a href="#4-原子性操作简化" class="headerlink" title="4. 原子性操作简化"></a>4. 原子性操作简化</h4><p>Redis通过使用事务和原子性操作来确保数据的一致性。<code>在单线程模型下，原子性操作更容易实现，因为不需要考虑多线程之间的竞争条件</code>。这使得Redis能够提供可靠的事务支持，确保数据的完整性。</p><h3 id="单线程模型的挑战与应对"><a href="#单线程模型的挑战与应对" class="headerlink" title="单线程模型的挑战与应对"></a>单线程模型的挑战与应对</h3><h4 id="1-阻塞问题"><a href="#1-阻塞问题" class="headerlink" title="1. 阻塞问题"></a>1. 阻塞问题</h4><p>单线程模型的一个潜在问题是当执行某些阻塞操作时，整个系统会被阻塞。为了解决这个问题，Redis采用了非阻塞的I&#x2F;O模型。<code>通过使用异步非阻塞的网络I/O，Redis能够在等待外部操作完成的同时继续处理其他请求，从而提高系统的并发性</code>。<br><img src="/assets/images/redis/redis-io-multiplexing-2.webp" class="lazyload placeholder" data-srcset="/assets/images/redis/redis-io-multiplexing-2.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h4 id="2-多核利用问题"><a href="#2-多核利用问题" class="headerlink" title="2. 多核利用问题"></a>2. 多核利用问题</h4><p>单线程模型似乎不能充分利用多核处理器的优势。为了解决这个问题，Redis引入了多个实例的概念。通过运行多个Redis实例，每个实例在单独的线程中运行，从而利用多核处理器的优势。这种方式在保持简单性的同时，使得Redis能够在多核系统中发挥更大的性能优势。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>Redis选择单线程而非多线程的设计决策并非出于偶然，而是经过深思熟虑的结果。在保持简单性、可维护性的同时，单线程模型通过避免上下文切换开销、利用内存访问的局部性等优势，实现了出色的性能。同时，通过采用非阻塞I&#x2F;O和多实例的策略，成功应对了单线程模型可能遇到的阻塞和多核利用的问题。</p><p>总体而言，Redis的设计决策展现了对性能和可维护性的平衡考虑，使得它成为一个在许多高性能应用场景中备受青睐的内存数据库。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在现代的互联网应用中，数据存储和访问速度是至关重要的。Redis，作为一款高性能的内存数据库，以其快速的读写速度和灵活的数据结构而闻名。然而，令人惊奇的是，&lt;code&gt;Redis采用了单线程的执行模型&lt;/code&gt;，而不是一些其他数据库采用的多线程或多进程模型。本文将深入探</summary>
      
    
    
    
    <category term="中间件" scheme="https://stonefishy.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://stonefishy.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis单线程之速度之谜解析</title>
    <link href="https://stonefishy.github.io/2024/01/22/redis-single-thread-speed/"/>
    <id>https://stonefishy.github.io/2024/01/22/redis-single-thread-speed/</id>
    <published>2024-01-22T23:20:29.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>在数据库领域中，多线程通常被认为是提高性能的关键。然而，<code>Redis</code>却是一个独特的存在，它以单线程的方式迅猛地处理各种请求，展现出惊人的速度和效率。本文将深入探讨Redis单线程模型的奥秘以及它如何在高并发环境下保持出色性能。</p><h3 id="Redis的单线程模型"><a href="#Redis的单线程模型" class="headerlink" title="Redis的单线程模型"></a>Redis的单线程模型</h3><p>Redis之所以被称为单线程，是因为它在处理客户端请求时采用了<code>单线程的事件循环机制</code>。这意味着Redis一次只能处理一个操作，例如读取或写入，而不是同时执行多个操作。然而，这并不妨碍Redis在实际应用中表现出色。</p><h3 id="事件驱动与异步非阻塞"><a href="#事件驱动与异步非阻塞" class="headerlink" title="事件驱动与异步非阻塞"></a>事件驱动与异步非阻塞</h3><p>Redis的单线程模型并不意味着它会阻塞在某个请求上，相反，它采用了<code>事件驱动</code>和<code>异步非阻塞</code>的方式。通过使用<code>I/O多路复用机制</code>，Redis能够在等待一个操作完成的同时继续处理其他请求。这种设计使得Redis能够充分利用系统资源，高效地响应大量并发请求。<br><img src="/assets/images/redis/redis-io-multiplexing.webp" class="lazyload placeholder" data-srcset="/assets/images/redis/redis-io-multiplexing.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Redis I/O Multiplexing"></p><h3 id="内存数据库与快速访问"><a href="#内存数据库与快速访问" class="headerlink" title="内存数据库与快速访问"></a>内存数据库与快速访问</h3><p>Redis将数据存储在内存中，这是其高速读写的关键。内存的快速访问速度远远超过了磁盘访问速度，使得Redis能够在瞬间完成诸如读取、写入等操作。此外，Redis通过使用数据结构的方式，如哈希表和有序集合，进一步提高了数据的访问效率。</p><h3 id="优秀的持久化机制"><a href="#优秀的持久化机制" class="headerlink" title="优秀的持久化机制"></a>优秀的持久化机制</h3><p>尽管Redis主要是内存数据库，但它也提供了持久化的机制，确保数据不会因服务器重启而丢失。通过将数据异步写入磁盘，Redis在保持高性能的同时，也具备了可靠的数据持久性，使其在关键业务场景中得以广泛应用。用户可以根据需求选择使用RDB快照或AOF日志来实现持久化。</p><h3 id="高级别的优化策略"><a href="#高级别的优化策略" class="headerlink" title="高级别的优化策略"></a>高级别的优化策略</h3><p>Redis通过采用多种高级优化策略，进一步提升了性能。例如，通过使用<code>管道技术</code>可以批量执行多个命令，减少通信开销。此外，Redis还实现了虚拟内存、集群模式等多种机制，为用户提供了灵活而强大的工具。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>尽管Redis采用了单线程模型，但其出色的性能和高效的设计使得它成为一个备受欢迎的数据库解决方案。通过<strong>事件驱动</strong>、<strong>异步非阻塞</strong>、<strong>内存数据库</strong>等多种技术手段的巧妙结合，Redis成功地解决了单线程模型可能面临的性能瓶颈，展现出强大的潜力和广泛的应用前景。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在数据库领域中，多线程通常被认为是提高性能的关键。然而，&lt;code&gt;Redis&lt;/code&gt;却是一个独特的存在，它以单线程的方式迅猛地处理各种请求，展现出惊人的速度和效率。本文将深入探讨Redis单线程模型的奥秘以及它如何在高并发环境下保持出色性能。&lt;/p&gt;
&lt;h3 id=</summary>
      
    
    
    
    <category term="中间件" scheme="https://stonefishy.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://stonefishy.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>构建JavaScript生成器：探索无穷可能的世界</title>
    <link href="https://stonefishy.github.io/2024/01/19/javascript-generator-powerful/"/>
    <id>https://stonefishy.github.io/2024/01/19/javascript-generator-powerful/</id>
    <published>2024-01-19T21:30:44.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>JavaScript作为一种强大而灵活的编程语言，为开发者提供了丰富的工具和功能。其中，生成器（<code>Generators</code>）是一项引人注目的特性，它们可以帮助我们在编写异步代码时更加轻松地管理流程和状态。本文将深入探讨JavaScript生成器的基本概念，并提供一些实用的代码示例，让我们一同踏入生成器的神奇世界。</p><h3 id="生成器是什么？"><a href="#生成器是什么？" class="headerlink" title="生成器是什么？"></a>生成器是什么？</h3><p>生成器是一种特殊类型的函数，它允许我们在需要时暂停和恢复执行。与普通函数不同，生成器的执行可以在每次暂停时保留其状态，这使得编写异步代码变得更加直观和可读。</p><p>要创建一个生成器，我们使用<code>function*</code>关键字，并在函数体内使用<code>yield</code>语句来指示暂停执行。以下是一个简单的生成器示例：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span>* <span class="title function_">simpleGenerator</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">yield</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">yield</span> <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">yield</span> <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> generator = <span class="title function_">simpleGenerator</span>();</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(generator.<span class="title function_">next</span>()); <span class="comment">// 输出: &#123; value: 1, done: false &#125;</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(generator.<span class="title function_">next</span>()); <span class="comment">// 输出: &#123; value: 2, done: false &#125;</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(generator.<span class="title function_">next</span>()); <span class="comment">// 输出: &#123; value: 3, done: false &#125;</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(generator.<span class="title function_">next</span>()); <span class="comment">// 输出: &#123; value: undefined, done: true &#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在上述示例中，我们创建了一个名为simpleGenerator的生成器，它依次产生数字1、2和3。每次调用generator.next()时，生成器会从上一次暂停的地方继续执行，直到遇到下一个yield语句或函数结束。</p><h3 id="使用生成器处理异步任务"><a href="#使用生成器处理异步任务" class="headerlink" title="使用生成器处理异步任务"></a>使用生成器处理异步任务</h3><p>生成器的真正威力体现在处理异步任务时。通过生成器和<code>yield</code>语句，我们可以以同步的方式编写异步代码，使其更易于理解和维护。以下是一个简单的异步生成器示例：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">fetchData</span>(<span class="params">url</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="title function_">resolve</span>(<span class="string">`Data from <span class="subst">$&#123;url&#125;</span>`</span>);</span><br><span class="line">    &#125;, <span class="number">1000</span>);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span>* <span class="title function_">asyncGenerator</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> data1 = <span class="keyword">yield</span> <span class="title function_">fetchData</span>(<span class="string">&#x27;https://api.example.com/data1&#x27;</span>);</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(data1);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> data2 = <span class="keyword">yield</span> <span class="title function_">fetchData</span>(<span class="string">&#x27;https://api.example.com/data2&#x27;</span>);</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(data2);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 更多异步任务...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">runAsyncGenerator</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> generator = <span class="title function_">asyncGenerator</span>();</span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">handleNext</span> = (<span class="params">result</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">const</span> &#123; value, done &#125; = generator.<span class="title function_">next</span>(result);</span><br><span class="line">    <span class="keyword">if</span> (!done) &#123;</span><br><span class="line">      value.<span class="title function_">then</span>(handleNext);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="title function_">handleNext</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">runAsyncGenerator</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出：Data from https://api.example.com/data1</span></span><br><span class="line"><span class="comment">// 输出：Data from https://api.example.com/data2</span></span><br></pre></td></tr></table></figure><p>在上述示例中，asyncGenerator是一个异步生成器，通过fetchData函数模拟异步数据获取。runAsyncGenerator函数负责启动异步生成器，并在每次生成器暂停时处理Promise的解析。</p><h3 id="生成器的错误处理"><a href="#生成器的错误处理" class="headerlink" title="生成器的错误处理"></a>生成器的错误处理</h3><p>生成器也可以用于更好地处理错误。通过在生成器内部使用<code>try...catch</code>语句，我们可以捕获并处理异步任务中的错误：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">fetchData</span>(<span class="params">url</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="title function_">reject</span>(<span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">`Error from <span class="subst">$&#123;url&#125;</span>`</span>));</span><br><span class="line">    &#125;, <span class="number">1000</span>);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span>* <span class="title function_">errorHandlingGenerator</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> result = <span class="keyword">yield</span> <span class="title function_">fetchData</span>(<span class="string">&#x27;https://api.example.com&#x27;</span>);</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(result);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&#x27;Error:&#x27;</span>, error.<span class="property">message</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">runErrorHandlingGenerator</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> generator = <span class="title function_">errorHandlingGenerator</span>();</span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">handleNext</span> = (<span class="params">result</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">const</span> &#123; value, done &#125; = generator.<span class="title function_">next</span>(result);</span><br><span class="line">      <span class="keyword">if</span> (!done) &#123;</span><br><span class="line">        value.<span class="title function_">then</span>(handleNext).<span class="title function_">catch</span>(<span class="function">(<span class="params">error</span>) =&gt;</span> generator.<span class="keyword">throw</span>(error));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">      generator.<span class="keyword">throw</span>(error);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="title function_">handleNext</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">runErrorHandlingGenerator</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出： Error: error from https://api.example.com</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在上述示例中，errorHandlingGenerator演示了如何在生成器内捕获异步任务的错误。runErrorHandlingGenerator函数用于启动生成器，并通过catch语句处理生成器内部的错误。</p><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>JavaScript生成器是一项强大而灵活的功能，为异步编程带来了新的范式。通过结合<code>生成器</code>和<code>yield</code>语句，我们可以更清晰地表达代码的流程，并更容易地处理异步任务和错误。在实际项目中，生成器是一个值得深入研究和应用的工具，它为我们打开了无穷可能的编程世界。让我们在代码的海洋中畅游，发现生成器为我们带来的新奇和便利吧！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;JavaScript作为一种强大而灵活的编程语言，为开发者提供了丰富的工具和功能。其中，生成器（&lt;code&gt;Generators&lt;/code&gt;）是一项引人注目的特性，它们可以帮助我们在编写异步代码时更加轻松地管理流程和状态。本文将深入探讨JavaScript生成器的基本概念</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>深入理解ES6中的Symbol类型</title>
    <link href="https://stonefishy.github.io/2024/01/03/understand-es6-symbol/"/>
    <id>https://stonefishy.github.io/2024/01/03/understand-es6-symbol/</id>
    <published>2024-01-03T19:55:00.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>在ES6（ECMAScript 2015）中引入了一种新的基本数据类型——<code>Symbol</code>。Symbol类型的引入丰富了JavaScript语言，为开发者提供了一种独一无二的标识符。本文将深入探讨Symbol的特性、用途以及代码示例。</p><h3 id="1-Symbol的创建"><a href="#1-Symbol的创建" class="headerlink" title="1. Symbol的创建"></a>1. Symbol的创建</h3><p>Symbol的创建是通过调用全局的Symbol函数实现的。Symbol函数接受一个可选的描述参数，该参数用于标识Symbol的用途，但不会影响Symbol的唯一性。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个没有描述的Symbol</span></span><br><span class="line"><span class="keyword">const</span> symbol1 = <span class="title class_">Symbol</span>();</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="keyword">typeof</span> symbol1); <span class="comment">// 输出: symbol</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个带有描述的Symbol</span></span><br><span class="line"><span class="keyword">const</span> symbol2 = <span class="title class_">Symbol</span>(<span class="string">&#x27;mySymbol&#x27;</span>);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(symbol2.<span class="title function_">toString</span>()); <span class="comment">// 输出: Symbol(mySymbol)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-Symbol的唯一性"><a href="#2-Symbol的唯一性" class="headerlink" title="2. Symbol的唯一性"></a>2. Symbol的唯一性</h3><p>Symbol是唯一的，即使描述相同，它们也是不同的。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> symbol1 = <span class="title class_">Symbol</span>(<span class="string">&#x27;mySymbol&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> symbol2 = <span class="title class_">Symbol</span>(<span class="string">&#x27;mySymbol&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(symbol1 === symbol2); <span class="comment">// 输出: false</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-Symbol作为对象属性名"><a href="#3-Symbol作为对象属性名" class="headerlink" title="3. Symbol作为对象属性名"></a>3. Symbol作为对象属性名</h3><p>使用Symbol作为对象属性名可以防止属性名冲突，提高代码的健壮性。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> mySymbol = <span class="title class_">Symbol</span>(<span class="string">&#x27;mySymbol&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> obj = &#123;</span><br><span class="line">  [mySymbol]: <span class="string">&#x27;Hello Symbol!&#x27;</span>,</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;John&#x27;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(obj[mySymbol]); <span class="comment">// 输出: Hello Symbol!</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(obj.<span class="property">name</span>); <span class="comment">// 输出: John</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-内置Symbol"><a href="#4-内置Symbol" class="headerlink" title="4. 内置Symbol"></a>4. 内置Symbol</h3><p>ES6引入了一些内置的Symbol，它们在特定的上下文中有着重要的作用。</p><h4 id="Symbol-iterator：-用于定义对象的默认迭代器。"><a href="#Symbol-iterator：-用于定义对象的默认迭代器。" class="headerlink" title="Symbol.iterator： 用于定义对象的默认迭代器。"></a>Symbol.iterator： 用于定义对象的默认迭代器。</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> myIterable = &#123;</span><br><span class="line">  [<span class="title class_">Symbol</span>.<span class="property">iterator</span>]: <span class="keyword">function</span>* () &#123;</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">3</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> value <span class="keyword">of</span> myIterable) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(value);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出:</span></span><br><span class="line"><span class="comment">// 1</span></span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line"><span class="comment">// 3</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Symbol-for和Symbol-keyFor：-用于创建和检索全局Symbol注册表中的Symbol。"><a href="#Symbol-for和Symbol-keyFor：-用于创建和检索全局Symbol注册表中的Symbol。" class="headerlink" title="Symbol.for和Symbol.keyFor： 用于创建和检索全局Symbol注册表中的Symbol。"></a>Symbol.for和Symbol.keyFor： 用于创建和检索全局Symbol注册表中的Symbol。</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> globalSymbol = <span class="title class_">Symbol</span>.<span class="title function_">for</span>(<span class="string">&#x27;globalSymbol&#x27;</span>); <span class="comment">//注册到全局Symbol表</span></span><br><span class="line"><span class="keyword">const</span> localSymbol = <span class="title class_">Symbol</span>(<span class="string">&#x27;localSymbol&#x27;</span>); <span class="comment">// 未注册到全局Symbo表</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="title class_">Symbol</span>.<span class="title function_">keyFor</span>(globalSymbol)); <span class="comment">// 输出: globalSymbol</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="title class_">Symbol</span>.<span class="title function_">keyFor</span>(localSymbol)); <span class="comment">// 输出: undefined</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="5-使用Symbol来定义常量"><a href="#5-使用Symbol来定义常量" class="headerlink" title="5. 使用Symbol来定义常量"></a>5. 使用Symbol来定义常量</h3><p>使用Symbol来定义常量可以有效地避免命名冲突。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="variable constant_">COLOR_RED</span> = <span class="title class_">Symbol</span>(<span class="string">&#x27;Red&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> <span class="variable constant_">COLOR_GREEN</span> = <span class="title class_">Symbol</span>(<span class="string">&#x27;Green&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">printColor</span>(<span class="params">color</span>) &#123;</span><br><span class="line">  <span class="keyword">switch</span> (color) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="attr">COLOR_RED</span>:</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;红色&#x27;</span>);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="attr">COLOR_GREEN</span>:</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;绿色&#x27;</span>);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="attr">default</span>:</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;未知颜色&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">printColor</span>(<span class="variable constant_">COLOR_RED</span>); <span class="comment">// 输出: 红色</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>Symbol是一项强大而灵活的特性，它为JavaScript引入了一种全新的数据类型，提高了代码的安全性和可读性。在实际开发中，合理运用Symbol能够使代码更具表达力和扩展性。希望本文能够帮助你更深入地理解和应用ES6中的Symbol类型。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在ES6（ECMAScript 2015）中引入了一种新的基本数据类型——&lt;code&gt;Symbol&lt;/code&gt;。Symbol类型的引入丰富了JavaScript语言，为开发者提供了一种独一无二的标识符。本文将深入探讨Symbol的特性、用途以及代码示例。&lt;/p&gt;
&lt;h3 </summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>What is Bixby Capsule？How to develop it?</title>
    <link href="https://stonefishy.github.io/2023/09/10/what-is-bixby-capsule/"/>
    <id>https://stonefishy.github.io/2023/09/10/what-is-bixby-capsule/</id>
    <published>2023-09-10T20:24:58.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/assets/images/bixby/bixby.webp" class="lazyload placeholder" data-srcset="/assets/images/bixby/bixby.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Bixby Capsule"></p><h2 class="bamboo-h " id="导言bzqwpchlabc">导言</h2><br/><p>在今天的数字时代，虚拟助手已经成为我们日常生活的一部分。Bixby，三星电子开发的人工智能助手，是其中一个备受欢迎的助手之一。<code>Bixby Capsule</code> 是扩展 Bixby 功能的关键组成部分，本文将介绍什么是 Bixby Capsule、它的工作原理以及如何开发自己的 Capsule。</p><h2 class="bamboo-h " id="什么是 Bixby Capsule？6lnrzcpoaik">什么是 Bixby Capsule？</h2><br/><p>Bixby Capsule 是一个为 Bixby 助手创建自定义功能和技能的容器。它允许开发者创建、部署和共享特定领域的虚拟助手应用程序，使用户能够通过语音和文本与虚拟助手进行交互。Capsule 的核心目标是扩展 Bixby 的能力，使其能够执行特定领域的任务，如设定闹钟、预订餐厅、查询天气、播放音乐等。</p><h2 class="bamboo-h " id="Bixby Capsule 的工作原理24zj5vfftpz">Bixby Capsule 的工作原理</h2><br/><p>了解 Bixby Capsule 的工作原理对于开发者非常重要。下面是 Bixby Capsule 的工作原理的简要概述：</p><p><strong>语音输入或文本输入</strong>：<br>用户通过语音或文本与 Bixby 进行交互，提出请求或问题。</p><p><strong>语音识别和自然语言处理</strong>：<br>Bixby 使用语音识别技术将用户的语音转化为文本，然后使用自然语言处理（NLP）技术理解用户的意图和需求。</p><p><strong>Capsule 匹配</strong>：<br>Bixby 确定用户的请求与哪个 Capsule 最匹配，这是通过匹配用户的意图与 Capsule 的功能来实现的。</p><p><strong>Capsule 交互</strong>：<br>一旦确定了匹配的 Capsule，Bixby 与该 Capsule 进行交互，将用户的请求传递给 Capsule。</p><p><strong>Capsule 执行</strong>：<br>Capsule 接收用户的请求并执行相关操作，可能需要与外部数据源或服务进行交互以获取信息或执行任务。</p><p><strong>响应用户</strong>：<br>Capsule 返回结果给 Bixby，然后 Bixby 将结果呈现给用户，通常以语音或文本形式。</p><h2 class="bamboo-h " id="如何开发 Bixby Capsule？1fszu7ggpzo">如何开发 Bixby Capsule？</h2><br/><p>现在让我们来看看如何开发自己的 Bixby Capsule。以下是一个简要的步骤：</p><h3 id="步骤-1：准备开发环境"><a href="#步骤-1：准备开发环境" class="headerlink" title="步骤 1：准备开发环境"></a>步骤 1：准备开发环境</h3><p>在开始开发之前，您需要准备好开发环境。这包括以下步骤：</p><h4 id="1-1-安装-Bixby-开发工具"><a href="#1-1-安装-Bixby-开发工具" class="headerlink" title="1.1 安装 Bixby 开发工具"></a>1.1 安装 Bixby 开发工具</h4><p>Bixby 开发工具包括 Bixby IDE（集成开发环境）和 Bixby CLI（命令行工具）。可以从 Bixby Developer Center 的官方网站上下载和安装这些工具。确保您的开发环境设置正确。</p><h4 id="1-2-注册-Bixby-开发者账户"><a href="#1-2-注册-Bixby-开发者账户" class="headerlink" title="1.2 注册 Bixby 开发者账户"></a>1.2 注册 Bixby 开发者账户</h4><p>在开始之前，您需要在 Bixby Developer Center 上注册一个开发者账户。这个账户将用于创建、管理和部署 Capsules。</p><h3 id="步骤-2：创建-Capsule"><a href="#步骤-2：创建-Capsule" class="headerlink" title="步骤 2：创建 Capsule"></a>步骤 2：创建 Capsule</h3><p>现在，让我们创建一个新的 Capsule：</p><h4 id="2-1-使用-Bixby-IDE-创建-Capsule"><a href="#2-1-使用-Bixby-IDE-创建-Capsule" class="headerlink" title="2.1 使用 Bixby IDE 创建 Capsule"></a>2.1 使用 Bixby IDE 创建 Capsule</h4><ol><li>打开 Bixby IDE。</li><li>在 IDE 中选择 “File” &gt; “New” &gt; “Bixby Capsule”。</li><li>输入 Capsule 的名称和描述，并选择 Capsule 的类型（例如，”自定义” 或 “Smart Speaker”）。</li><li>点击 “Create” 按钮。</li></ol><h4 id="2-2-定义结构、概念和操作"><a href="#2-2-定义结构、概念和操作" class="headerlink" title="2.2 定义结构、概念和操作"></a>2.2 定义结构、概念和操作</h4><p>在 Capsule 中，您可以定义结构（Structures）、概念（Concepts）和操作（Actions）来表示您的数据和功能：</p><ol><li>在 IDE 中，导航到 models 目录，然后创建一个新的 .bxb 文件。</li><li>在文件中，您可以开始定义结构、概念和操作。例如：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">integer (NumDiceConcept) &#123;</span><br><span class="line">  description (The number of dice to throw.)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">structure (RollResultConcept) &#123;</span><br><span class="line">  description (The result object produced by the RollDice action.)</span><br><span class="line">  property (sum) &#123;</span><br><span class="line">    type (SumConcept)</span><br><span class="line">    min (Required)</span><br><span class="line">    max (One)</span><br><span class="line">  &#125;</span><br><span class="line">  property (roll) &#123;</span><br><span class="line">    description (The list of results for each dice roll.)</span><br><span class="line">    type (RollConcept)</span><br><span class="line">    min (Required)</span><br><span class="line">    max (Many)</span><br><span class="line">  &#125;      </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">action (RollDice) &#123;</span><br><span class="line">  collect&#123;</span><br><span class="line">    input (numDice) &#123;</span><br><span class="line">      type (NumDiceConcept)</span><br><span class="line">      min (Required)</span><br><span class="line">      max (One)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    input (numSides) &#123;</span><br><span class="line">      type (NumSidesConcept)</span><br><span class="line">      min (Required)</span><br><span class="line">      max (One)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; </span><br><span class="line">  output (RollResultConcept)</span><br><span class="line">  type (Calculation)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="步骤-3：设计对话"><a href="#步骤-3：设计对话" class="headerlink" title="步骤 3：设计对话"></a>步骤 3：设计对话</h3><p>使用 Bixby IDE 的对话工具，您可以设计用户与 Capsule 的对话：</p><h4 id="3-1-创建对话文件"><a href="#3-1-创建对话文件" class="headerlink" title="3.1 创建对话文件"></a>3.1 创建对话文件</h4><ol><li>在 IDE 中，导航到 resources&#x2F;dialogs 目录。</li><li>创建一个新的 .dialog 文件，为您的 Capsule 定义一个对话。</li></ol><h4 id="3-2-定义用户输入和回复"><a href="#3-2-定义用户输入和回复" class="headerlink" title="3.2 定义用户输入和回复"></a>3.2 定义用户输入和回复</h4><p>在对话文件中，定义用户输入示例和 Capsule 的回复示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dialog (Result) &#123;</span><br><span class="line">  match &#123;</span><br><span class="line">    BusinessCategory (this) &#123;</span><br><span class="line">      from-property: Business (business)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  template(&quot;#&#123;value(business.name)&#125; has #&#123;joinAs(&#x27;value&#x27;, this)&#125;.&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="步骤-4：测试和调试-Capsule"><a href="#步骤-4：测试和调试-Capsule" class="headerlink" title="步骤 4：测试和调试 Capsule"></a>步骤 4：测试和调试 Capsule</h3><p>在部署之前，确保您对 Capsule 进行了测试和调试：</p><h4 id="4-1-使用模拟器测试"><a href="#4-1-使用模拟器测试" class="headerlink" title="4.1 使用模拟器测试"></a>4.1 使用模拟器测试</h4><p>在 Bixby IDE 中，使用模拟器来模拟用户与 Capsule 的对话，以确保一切正常工作。检查回复是否符合预期。</p><h4 id="4-2-调试"><a href="#4-2-调试" class="headerlink" title="4.2 调试"></a>4.2 调试</h4><p>使用 Bixby IDE 的调试工具来查找和修复潜在问题。您可以设置断点、查看变量的值，并进行单步调试以确保 Capsule 的行为正确。</p><h3 id="步骤-5：部署-Capsule"><a href="#步骤-5：部署-Capsule" class="headerlink" title="步骤 5：部署 Capsule"></a>步骤 5：部署 Capsule</h3><p>一旦您对 Capsule 满意并通过了测试，就可以开始部署它：</p><h4 id="5-1-创建开发版本"><a href="#5-1-创建开发版本" class="headerlink" title="5.1 创建开发版本"></a>5.1 创建开发版本</h4><p>在 Bixby IDE 中，您可以创建一个开发版本的 Capsule，这个版本可以在您的开发环境中使用：</p><ol><li>选择 “Build” &gt; “Create Development Version”。</li><li>确认创建版本并等待完成。</li></ol><h4 id="5-2-提交审核"><a href="#5-2-提交审核" class="headerlink" title="5.2 提交审核"></a>5.2 提交审核</h4><p>如果您计划将 Capsule 分享给其他人或发布到 Bixby Marketplace，您需要提交审核请求：</p><ol><li>在 Bixby Developer Center 上登录。</li><li>在开发者中心中，选择您的 Capsule 项目，然后提交审核请求。</li></ol><h3 id="步骤-6：发布和分享"><a href="#步骤-6：发布和分享" class="headerlink" title="步骤 6：发布和分享"></a>步骤 6：发布和分享</h3><p>一旦审核通过，您可以将 Capsule 发布并分享给其他用户：</p><h4 id="6-1-发布"><a href="#6-1-发布" class="headerlink" title="6.1 发布"></a>6.1 发布</h4><ol><li>在 Bixby Developer Center 上，选择 “发布” 选项。</li><li>输入有关 Capsule 的详细信息，包括名称、描述和图标。</li><li>发布您的 Capsule。</li></ol><h4 id="6-2-分享"><a href="#6-2-分享" class="headerlink" title="6.2 分享"></a>6.2 分享</h4><p>您可以分享您的 Capsule 的链接给其他用户，或者在 Bixby Marketplace 上找到它</p><h2 class="bamboo-h " id="结论4jnzy9f4ofu">结论</h2><br/><p>Bixby Capsule 是一个强大的工具，可以帮助开发者创建自定义虚拟助手应用程序，提供各种功能和技能。了解其工作原理以及按照上述步骤进行开发，将使您能够构建出令人印象深刻的 Bixby Capsules，改善用户体验，扩展 Bixby 的功能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/assets/images/bixby/bixby.webp&quot; class=&quot;lazyload placeholder&quot; data-srcset=&quot;/assets/images/bixby/bixby.webp&quot; srcset=&quot;https://pic</summary>
      
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Bixby" scheme="https://stonefishy.github.io/tags/Bixby/"/>
    
  </entry>
  
  <entry>
    <title>AWS Glue DataBrew - 简化数据准备的利器</title>
    <link href="https://stonefishy.github.io/2023/09/05/aws-glue-databrew-data-preparation-tool/"/>
    <id>https://stonefishy.github.io/2023/09/05/aws-glue-databrew-data-preparation-tool/</id>
    <published>2023-09-05T23:21:33.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>数据准备是数据分析和机器学习的关键步骤之一。<code>AWS Glue DataBrew</code> 是 Amazon Web Services（AWS）提供的一项强大工具，旨在帮助数据工程师、数据分析师和数据科学家轻松地准备数据以进行分析、报告和机器学习。本文将深入探讨 AWS Glue DataBrew 的特点、优势、使用场景和如何入门。<br><img src="/assets/images/aws/aws-glue-databrew.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-databrew.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue DataBrew"></p><h2 class="bamboo-h " id="AWS Glue DataBrew 简介1iotxxq6tlr">AWS Glue DataBrew 简介</h2><br/><p>AWS Glue DataBrew 是一项全托管的数据准备服务，它通过可视化界面和自动化工具简化了数据清理、转换和准备的过程。以下是 AWS Glue DataBrew 的一些关键特点：</p><h4 id="可视化数据准备"><a href="#可视化数据准备" class="headerlink" title="可视化数据准备"></a>可视化数据准备</h4><p>DataBrew 提供了直观的用户界面，使用户能够轻松地探索、清理和转换数据，而无需编写复杂的代码。</p><h4 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h4><p>您可以通过数据探索功能快速了解数据的结构、内容和质量，以便更好地理解数据。</p><h4 id="自动数据规范化"><a href="#自动数据规范化" class="headerlink" title="自动数据规范化"></a>自动数据规范化</h4><p>DataBrew 自动检测数据类型和结构，并提供数据规范化建议，以确保数据在分析过程中的一致性。</p><h4 id="多源数据支持"><a href="#多源数据支持" class="headerlink" title="多源数据支持"></a>多源数据支持</h4><p>DataBrew 可以连接到多种数据源，包括数据湖、数据仓库、数据库、云存储和 API。</p><h4 id="数据转换和清洗"><a href="#数据转换和清洗" class="headerlink" title="数据转换和清洗"></a>数据转换和清洗</h4><p>您可以使用 DataBrew 进行各种数据转换和清洗操作，如删除重复数据、填充缺失值、合并列等。</p><h4 id="工作流程自动化"><a href="#工作流程自动化" class="headerlink" title="工作流程自动化"></a>工作流程自动化</h4><p>DataBrew 支持创建数据准备工作流程，以自动执行多个数据准备任务，提高效率。</p><h4 id="数据监控和审计"><a href="#数据监控和审计" class="headerlink" title="数据监控和审计"></a>数据监控和审计</h4><p>DataBrew 提供数据监控和审计功能，以跟踪数据准备操作，确保数据质量和安全性。</p><h2 class="bamboo-h " id="AWS Glue DataBrew 的优势87zpcy5mlz0">AWS Glue DataBrew 的优势</h2><br/><p>为什么要选择 AWS Glue DataBrew 作为数据准备工具？以下是它的一些显著优势：</p><h4 id="降低技术门槛"><a href="#降低技术门槛" class="headerlink" title="降低技术门槛"></a>降低技术门槛</h4><p>DataBrew 的可视化界面使数据准备过程对于不擅长编程的用户也变得更加可行，降低了技术门槛。</p><h4 id="节省时间"><a href="#节省时间" class="headerlink" title="节省时间"></a>节省时间</h4><p>自动化功能和预建的数据转换操作可以大幅节省数据准备的时间，使用户能够更快地获得洞察。</p><h4 id="改进数据质量"><a href="#改进数据质量" class="headerlink" title="改进数据质量"></a>改进数据质量</h4><p>DataBrew 的数据探索和质量评估工具有助于发现和解决数据质量问题，提高数据分析的可靠性。</p><h4 id="与-AWS-生态系统集成"><a href="#与-AWS-生态系统集成" class="headerlink" title="与 AWS 生态系统集成"></a>与 AWS 生态系统集成</h4><p>DataBrew 与其他 AWS 服务集成，可无缝集成到您的数据工作流程中，如 AWS Glue、S3、Redshift 等。</p><h2 class="bamboo-h " id="AWS Glue DataBrew 的使用场景1whhydqhtox">AWS Glue DataBrew 的使用场景</h2><br/><p>AWS Glue DataBrew 适用于多种使用场景，包括但不限于：</p><h4 id="数据清理和规范化"><a href="#数据清理和规范化" class="headerlink" title="数据清理和规范化"></a>数据清理和规范化</h4><p>将原始数据清理并规范化，以便进行分析和报告。</p><h4 id="数据探索和可视化"><a href="#数据探索和可视化" class="headerlink" title="数据探索和可视化"></a>数据探索和可视化</h4><p>通过数据探索功能可视化数据，以便更好地了解数据的特点。</p><h4 id="缺失数据处理"><a href="#缺失数据处理" class="headerlink" title="缺失数据处理"></a>缺失数据处理</h4><p>填充缺失数据或识别缺失数据的模式。</p><h4 id="数据合并和分割"><a href="#数据合并和分割" class="headerlink" title="数据合并和分割"></a>数据合并和分割</h4><p>合并不同来源的数据或拆分包含多个值的列。</p><h4 id="数据质量监控"><a href="#数据质量监控" class="headerlink" title="数据质量监控"></a>数据质量监控</h4><p>持续监控数据质量，以及时发现问题并采取纠正措施。</p><h2 class="bamboo-h " id="入门 AWS Glue DataBrew1zwf7a9gx5f">入门 AWS Glue DataBrew</h2><br/><p>要开始使用 AWS Glue DataBrew，您可以按照以下步骤操作：</p><ol><li>登录 AWS 控制台：使用您的 AWS 帐户登录 AWS 管理控制台。</li><li>导航到 AWS Glue DataBrew：在 AWS 控制台中，导航到 DataBrew 服务页面。</li><li>创建项目：创建一个新项目或选择现有项目，以开始数据准备工作。</li><li>导入数据：将您要准备的数据导入项目。</li><li>使用 DataBrew：在 DataBrew 的可视化界面中探索、清理和转换数据。</li><li>保存和导出数据：完成数据准备后，您可以将数据保存并导出到其他 AWS 服务或应用程序中。</li></ol><h2 class="bamboo-h " id="总结245kfs8czgp">总结</h2><br/><p>AWS Glue DataBrew 是一项强大的数据准备工具，它通过可视化界面和自动化功能使数据准备变得更加容易和高效。无论您是数据工程师、数据分析师还是数据科学家，DataBrew 都可以帮助您加速数据分析的过程，从原始数据中提取有价值的信息。开始使用 DataBrew，并体验数据准备的全新方式！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;数据准备是数据分析和机器学习的关键步骤之一。&lt;code&gt;AWS Glue DataBrew&lt;/code&gt; 是 Amazon Web Services（AWS）提供的一项强大工具，旨在帮助数据工程师、数据分析师和数据科学家轻松地准备数据以进行分析、报告和机器学习。本文将深入探</summary>
      
    
    
    
    <category term="大数据" scheme="https://stonefishy.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="大数据" scheme="https://stonefishy.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>How to install additional msi components.</title>
    <link href="https://stonefishy.github.io/2023/05/25/how-to-install-additional-msi-components/"/>
    <id>https://stonefishy.github.io/2023/05/25/how-to-install-additional-msi-components/</id>
    <published>2023-05-25T17:35:28.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I had the opportunity to work on a project that requires to build a Msi Installer which contains multiple components. The project was to install these components on a Windows machine. To build this Msi Installer, I used <code>WiX toolset</code>. It’s a powerful tool that allows you to create complex installers with a high degree of flexibility. But here I’m not going to go into the details of how to create a Msi Installer using WiX toolset. Instead, I’ll focus on how to use <code>msiexec</code> tool to install additional components of a Windows MSI package.</p><h2 id="Understanding-msiexec"><a href="#Understanding-msiexec" class="headerlink" title="Understanding msiexec"></a>Understanding <code>msiexec</code></h2><p><code>msiexec</code> is a command-line utility that allows you to install, modify, or uninstall software that comes in the form of an MSI package. MSI (Microsoft Installer) packages are commonly used for software distribution because they offer a standardized way to handle installations, including dependencies and custom actions.</p><h2 id="Windows-Installer-Properties"><a href="#Windows-Installer-Properties" class="headerlink" title="Windows Installer Properties"></a>Windows Installer Properties</h2><p>The Windows Installer contains several properties that can be set to customize the installation process. These properties is defined in list categories.</p><ul><li>Component Location Properties</li><li>Configuration Properties</li><li>Date, Time Properties</li><li>Feature Installation Options Properties</li><li>Hardware Properties</li><li>Installation Status Properties</li><li>Operating System Properties</li><li>Product Information Properties</li><li>Summary Information Update Properties</li><li>System Folder Properties</li><li>User Information Properties</li></ul><p>For more details, please refer to the official documentation of Windows Installer. <a href="https://learn.microsoft.com/en-us/windows/win32/msi/property-reference">https://learn.microsoft.com/en-us/windows/win32/msi/property-reference</a></p><h2 id="The-ADDLOCAL-Option"><a href="#The-ADDLOCAL-Option" class="headerlink" title="The ADDLOCAL Option"></a>The <code>ADDLOCAL</code> Option</h2><p>One of the most useful options when using msiexec is <code>ADDLOCAL</code>. This option allows you to specify which features or components of the MSI package you want to install. Here’s the basic syntax:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msiexec /i &lt;path_to_msi_file&gt; ADDLOCAL=&lt;component1&gt;[,&lt;component2&gt;,...]</span><br></pre></td></tr></table></figure><p>This works in a scenario, some feature components of msi package already installed, and you can use this property to install additional component.</p><h2 id="Example-Scenario"><a href="#Example-Scenario" class="headerlink" title="Example Scenario"></a>Example Scenario</h2><p>Let’s say you have an MSI package named example.msi that contains several components, including FeatureA, FeatureB, and FeatureC. If you only need FeatureA and FeatureB, you can use the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msiexec /i &quot;C:\path\to\example.msi&quot; ADDLOCAL=FeatureA,FeatureB</span><br></pre></td></tr></table></figure><p>This command will install only the specified components, saving you time and disk space.</p><h2 id="Combining-with-Other-Options"><a href="#Combining-with-Other-Options" class="headerlink" title="Combining with Other Options"></a>Combining with Other Options</h2><p>msiexec offers a variety of other options that you can combine with <code>ADDLOCAL</code> to customize your installation further. For instance, you can use the <code>/passive</code> option for a passive installation, which means the installation will run with minimal user interaction:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msiexec /i &quot;C:\path\to\example.msi&quot; ADDLOCAL=FeatureA /passive</span><br></pre></td></tr></table></figure><p>This is particularly useful for automated installations or when you want to avoid user prompts.</p><h3 id="Important-Considerations"><a href="#Important-Considerations" class="headerlink" title="Important Considerations"></a>Important Considerations</h3><ol><li><p><code>Component Names</code>: Ensure that the component names are exactly as specified in the MSI package. These names can usually be found in the documentation provided with the MSI package or by inspecting the package with a tool like <code>Orca</code>.</p></li><li><p><code>All Components</code>: If you need to install all components, you can omit the <code>ADDLOCAL=ALL</code> option to install everything:</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msiexec /i &quot;C:\path\to\example.msi&quot; ADDLOCAL=ALL</span><br></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Using <code>msiexec</code> with the <code>ADDLOCAL</code> option is a powerful way to manage MSI installations, allowing you to install only the components you need. This not only saves time but also ensures that your system remains clutter-free with unnecessary software. Whether you’re a system administrator, a developer, or simply someone who likes to keep their system lean, mastering msiexec is a valuable skill.</p><p>By following the examples and tips provided in this blog post, you’ll be well on your way to becoming an expert in MSI installations. Happy installing!</p><h2 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h2><ul><li>Windows Instalelr: <a href="https://learn.microsoft.com/en-us/windows/win32/msi/windows-installer-portal">https://learn.microsoft.com/en-us/windows/win32/msi/windows-installer-portal</a></li><li>Windows Installer Property Reference: <a href="https://docs.microsoft.com/en-us/windows/win32/msi/property-reference">https://docs.microsoft.com/en-us/windows/win32/msi/property-reference</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently, I had the opportunity to work on a project that requires to build a Msi Installer which contains multiple components. The proje</summary>
      
    
    
    
    
    <category term="Msi" scheme="https://stonefishy.github.io/tags/Msi/"/>
    
    <category term="Wix" scheme="https://stonefishy.github.io/tags/Wix/"/>
    
    <category term="Installer" scheme="https://stonefishy.github.io/tags/Installer/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Sentiment Analysis - Load Raw Dataset</title>
    <link href="https://stonefishy.github.io/2023/02/14/machine-learning-sentiment-analysis-load-raw-dataset/"/>
    <id>https://stonefishy.github.io/2023/02/14/machine-learning-sentiment-analysis-load-raw-dataset/</id>
    <published>2023-02-14T09:42:45.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, the <code>ChatGPT</code> is very hot in the NLP community. It is a transformer-based language model that can generate human-like conversations. It attracts me to learn about Machine Learning to build a AI model. In this blog, I will talk about how to build a Sentiment Analysis model, the topic will be separated into several blogs, including Load raw dataset,Text Vectorization, Model Training, and Model Evaluation, Model Testing.</p><h2 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a>Sentiment Analysis</h2><p>Sentiment Analysis is a natural language processing (NLP) task that involves classifying the sentiment of a given text into one of the predefined categories such as positive, negative, or neutral. The goal of sentiment analysis is to understand the attitude or opinion of the writer towards a particular topic or product.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/sentiment-analysis.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/sentiment-analysis.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Sentiment Analysis" style="width:600px;"/></div><span class="image-caption">Sentiment Analysis</span></div><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>To build and train a sentiment analysis model, we need a dataset. The dataset used in this blog is the <code>IMDB movie review dataset</code>. You can find this dataset more information in previous blogs. It contains 50,000 movie reviews labeled as <code>positive</code> or <code>negative</code>. The dataset is split into 25,000 reviews for training and 25,000 reviews for testing.</p><p>After downloading the dataset, unzip the file and put it in a directory named <code>dataset</code>. The directory structure should look like this:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataset</span><br><span class="line">├── test</span><br><span class="line">│   ├── neg</span><br><span class="line">│   └── pos</span><br><span class="line">└── train</span><br><span class="line">    ├── neg</span><br><span class="line">    └── pos</span><br></pre></td></tr></table></figure><h2 id="Loading-the-Raw-Data"><a href="#Loading-the-Raw-Data" class="headerlink" title="Loading the Raw Data"></a>Loading the Raw Data</h2><p>We will load the raw data using <code>tensorflow</code> and <code>keras</code> libraries. The <code>text_dataset_from_directory</code> function is used to load the dataset. The function takes the directory path, batch size, validation split, subset, and seed as input parameters. </p><p>The <code>validation_split</code> parameter is used to split the dataset into training and validation sets. For example, if the <code>validation_split</code> is set to 0.2, 20% of the data will be used for validation.</p><p>The <code>subset</code> parameter is used to specify which subset of the data to load. <code>training</code> value is used to load only the training data. <code>validation</code> value is used to load only the validation data. The <code>seed</code> parameter is used to ensure reproducibility.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_raw_train_dataset</span>():</span><br><span class="line">    <span class="keyword">return</span> tf.keras.utils.text_dataset_from_directory(</span><br><span class="line">        config.ds_train_dir,</span><br><span class="line">        batch_size=config.ds_batch_size, <span class="comment"># batch size</span></span><br><span class="line">        validation_split=config.validate_split, <span class="comment"># 10% of data will be used for validation</span></span><br><span class="line">        subset=<span class="string">&#x27;training&#x27;</span>, <span class="comment"># only training data will be used</span></span><br><span class="line">        seed=config.ds_batch_seed) <span class="comment"># to ensure reproducibility</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_raw_validation_dataset</span>():</span><br><span class="line">    <span class="keyword">return</span> tf.keras.utils.text_dataset_from_directory(</span><br><span class="line">        config.ds_train_dir,</span><br><span class="line">        batch_size=config.ds_batch_size,</span><br><span class="line">        validation_split=config.validate_split,</span><br><span class="line">        subset=<span class="string">&#x27;validation&#x27;</span>,</span><br><span class="line">        seed=config.ds_batch_seed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_raw_test_dataset</span>():</span><br><span class="line">    <span class="keyword">return</span> tf.keras.utils.text_dataset_from_directory(</span><br><span class="line">        config.ds_test_dir,</span><br><span class="line">        batch_size=config.ds_batch_size)</span><br></pre></td></tr></table></figure><p>In above code, there are three functions defined to load the raw data. The <code>load_raw_train_dataset</code> function is used to load the training data, the <code>load_raw_validation_dataset</code> function is used to load the validation data, and the <code>load_raw_test_dataset</code> function is used to load the test data.</p><p>For the <code>config.py</code> file, we will define the following parameters for above raw data loading functions.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dataset directory for training</span></span><br><span class="line">ds_train_dir = <span class="string">&quot;dataset/train&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset directory for testing</span></span><br><span class="line">ds_test_dir = <span class="string">&quot;dataset/test&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch size for training and testing</span></span><br><span class="line">ds_batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># random seed for shuffling the data</span></span><br><span class="line">ds_batch_seed = <span class="number">36</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 10% of data will be used for validation</span></span><br><span class="line">validate_split = <span class="number">0.1</span></span><br></pre></td></tr></table></figure><p>In above code, we are loading the raw data from the <code>dataset/train</code> and <code>dataset/test</code> directories. The <code>batch_size</code> parameter is set to 32, which means that the data will be loaded in batches of 32. The <code>validation_split</code> parameter is set to 0.1, which means that 10% of the data will be used for validation. The <code>subset</code> parameter is set to <code>training</code> to load only the training data, <code>validation</code> to load only the validation data. The <code>seed</code> parameter is set to 36 to ensure reproducibility.</p><p>So for now, we have loaded the raw data, in the next blog, we will talk about text vectorization which is the process of converting text into numerical form that can be used for training and testing the model.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently, the &lt;code&gt;ChatGPT&lt;/code&gt; is very hot in the NLP community. It is a transformer-based language model that can generate human-lik</summary>
      
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Keras" scheme="https://stonefishy.github.io/tags/Keras/"/>
    
    <category term="NLP" scheme="https://stonefishy.github.io/tags/NLP/"/>
    
    <category term="Tensorflow" scheme="https://stonefishy.github.io/tags/Tensorflow/"/>
    
    <category term="Sentiment Analysis" scheme="https://stonefishy.github.io/tags/Sentiment-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>The Pile - A Comprehensive Dataset for Training NLP Models</title>
    <link href="https://stonefishy.github.io/2023/02/01/the-pile-a-comprehensive-dataset-for-training-nlp-models/"/>
    <id>https://stonefishy.github.io/2023/02/01/the-pile-a-comprehensive-dataset-for-training-nlp-models/</id>
    <published>2023-02-01T10:54:23.000Z</published>
    <updated>2024-07-09T03:29:33.958Z</updated>
    
    <content type="html"><![CDATA[<p>In the rapidly evolving field of natural language processing (NLP), the quality and diversity of training data are crucial for developing robust and capable models. One of the most significant contributions to this area is <code>The Pile</code>, an open-source, large-scale dataset curated by EleutherAI. This blog post will delve into what The Pile is, its components, and how you can use it to train your own NLP models.</p><h2 id="What-is-The-Pile"><a href="#What-is-The-Pile" class="headerlink" title="What is The Pile?"></a>What is The Pile?</h2><p>The Pile is a massive dataset designed specifically for training NLP models. It comprises approximately <code>825 gigabytes</code> of text data collected from a wide array of sources to ensure diversity and richness in language representation. Created by EleutherAI, The Pile aims to provide researchers and developers with a <code>high-quality</code>, <code>comprehensive</code> dataset that can support the development of state-of-the-art NLP models.</p><h2 id="Components-of-The-Pile"><a href="#Components-of-The-Pile" class="headerlink" title="Components of The Pile"></a>Components of The Pile</h2><p>The Pile is composed of a variety of sub-datasets, each contributing unique content to the overall collection. Here are some of the key components:</p><ul><li><code>Wikipedia</code>: A snapshot of English Wikipedia, providing a wealth of general knowledge across numerous domains. It contains approximately 1.5 billion words in plain text format.</li><li><code>Books3</code>: A collection of books from various genres and disciplines, offering rich and diverse narrative styles. It contains approximately 196,640 books in plain text format.</li><li><code>PubMed Central</code>: Biomedical literature providing specialized scientific text. PubMed Central® (PMC) is a free full-text archive of biomedical and life sciences journal literature at the U.S. National Institutes of Health’s National Library of Medicine (NIH&#x2F;NLM)</li><li><code>StackExchange</code>: Q&amp;A data from StackExchange sites, capturing technical discussions and community knowledge. StackExchange is a question-and-answer website for programmers, data scientists, and other professionals.</li><li><code>GitHub</code>: Code repositories from GitHub, including source code and associated documentation. GitHub is a popular platform for hosting software development projects.</li><li><code>ArXiv</code>: Scientific papers from the ArXiv preprint server, covering a broad range of academic research. ArXiv is a free distribution service and an open-access archive for nearly 2.4 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics</li></ul><p>The Pile not only contains above datasets, it also includes like <code>YoutubeSubtitles</code>, <code>Freelaw</code> and <code>HackerNews</code> etc. These components ensure that The Pile covers a broad spectrum of human knowledge and language use, making it an invaluable resource for training versatile NLP models.</p><p>You can access the full list of components and their sizes on the official EleutherAI github repo here: <a href="https://github.com/EleutherAI/the-pile?tab=readme-ov-file">https://github.com/EleutherAI/the-pile?tab=readme-ov-file</a></p><h2 id="Why-Use-The-Pile"><a href="#Why-Use-The-Pile" class="headerlink" title="Why Use The Pile?"></a>Why Use The Pile?</h2><ul><li><code>Diversity</code>: With text from multiple domains and styles, The Pile helps create models that generalize well across different contexts.</li><li><code>Size</code>: At 825 gigabytes, The Pile provides a substantial amount of data, which is vital for training large-scale NLP models.</li><li><code>Quality</code>: Curated with care, The Pile filters out low-quality content, ensuring that the data used for training is valuable and relevant.</li><li><code>Open Source</code>: The Pile is freely available, supporting open research and development in the NLP community.</li></ul><h2 id="How-to-Use-The-Pile"><a href="#How-to-Use-The-Pile" class="headerlink" title="How to Use The Pile"></a>How to Use The Pile</h2><p>Using The Pile for training NLP models involves several steps, from acquiring the dataset to preprocessing it for model training. Here’s a step-by-step guide:</p><h3 id="Acquire-the-Dataset"><a href="#Acquire-the-Dataset" class="headerlink" title="Acquire the Dataset"></a>Acquire the Dataset</h3><p>You can download The Pile from the official EleutherAI repository. Ensure you have sufficient storage and bandwidth to handle the dataset’s size.</p><h3 id="Set-Up-Your-Environment"><a href="#Set-Up-Your-Environment" class="headerlink" title="Set Up Your Environment"></a>Set Up Your Environment</h3><p>Ensure you have a robust computing environment set up, ideally with access to powerful GPUs if you’re training large models. Popular frameworks like PyTorch or TensorFlow are suitable for this task.</p><h3 id="Preprocess-the-Data"><a href="#Preprocess-the-Data" class="headerlink" title="Preprocess the Data"></a>Preprocess the Data</h3><p>Depending on your specific use case, you might need to preprocess the data. This could involve tokenization, normalization, or formatting the text to match the input requirements of your chosen model. Libraries like Hugging Face’s Tokenizers can be very helpful here.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2Tokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(<span class="string">&#x27;gpt2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer.encode(text, return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="Load-the-Data"><a href="#Load-the-Data" class="headerlink" title="Load the Data"></a>Load the Data</h3><p>Use data loading utilities to efficiently feed the data into your training pipeline. If you’re using <code>PyTorch</code>, <code>DataLoader</code> can help manage batching and shuffling.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, texts</span>):</span><br><span class="line">        self.texts = texts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.texts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> preprocess(self.texts[idx])</span><br><span class="line"></span><br><span class="line">texts = [...]  <span class="comment"># Load your text data here</span></span><br><span class="line">dataset = TextDataset(texts)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">8</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="Train-Your-Model"><a href="#Train-Your-Model" class="headerlink" title="Train Your Model"></a>Train Your Model</h3><p>Set up your NLP model and start the training process. Ensure you monitor the training metrics to adjust hyperparameters as needed.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, Trainer, TrainingArguments</span><br><span class="line"></span><br><span class="line">model = GPT2LMHeadModel.from_pretrained(<span class="string">&#x27;gpt2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&#x27;./results&#x27;</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    save_steps=<span class="number">10_000</span>,</span><br><span class="line">    save_total_limit=<span class="number">2</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=dataset,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><h3 id="Evaluate-and-Fine-tune"><a href="#Evaluate-and-Fine-tune" class="headerlink" title="Evaluate and Fine-tune"></a>Evaluate and Fine-tune</h3><p>After initial training, evaluate your model on validation data and fine-tune as necessary. This could involve additional training on specific subsets of The Pile or other datasets to enhance performance on particular tasks.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The Pile represents a monumental step forward in the availability of high-quality, diverse datasets for NLP research. By leveraging The Pile, you can train more robust and generalizable language models, pushing the boundaries of what NLP systems can achieve. Whether you’re an academic researcher or an industry practitioner, The Pile offers a valuable resource to support your work in developing cutting-edge NLP technologies.</p><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links"></a>Reference Links</h2><ul><li><a href="https://pile.eleuther.ai/">https://pile.eleuther.ai/</a></li><li><a href="https://github.com/EleutherAI/the-pile?tab=readme-ov-file">https://github.com/EleutherAI/the-pile?tab=readme-ov-file</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the rapidly evolving field of natural language processing (NLP), the quality and diversity of training data are crucial for developing</summary>
      
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://stonefishy.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>A Large Movie Review Dataset for Binary Sementic Analysis</title>
    <link href="https://stonefishy.github.io/2023/01/11/a-large-movie-review-dataset-for-binary-sementic-analysis/"/>
    <id>https://stonefishy.github.io/2023/01/11/a-large-movie-review-dataset-for-binary-sementic-analysis/</id>
    <published>2023-01-11T16:14:32.000Z</published>
    <updated>2024-07-09T03:29:33.954Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this article, we will discuss about a large movie review dataset for <code>binary semantic analysis</code>. It is extracted from IMDb(<a href="https://www.imdb.com/">https://www.imdb.com/</a>) movie sites and handled by <code>Stanford</code> university. The dataset contains 50,000 movie reviews labeled as positive or negative. It is divided into training and testing sets with 25,000 and 25,000 movie reviews respectively. It is labeled as positive or negative based on the sentiment of the review. It also include an additional 50,000 unlabeled documents for unsupervised learning. </p><h2 id="Dataset-Information"><a href="#Dataset-Information" class="headerlink" title="Dataset Information"></a>Dataset Information</h2><h4 id="Positive-Reviews"><a href="#Positive-Reviews" class="headerlink" title="Positive Reviews"></a>Positive Reviews</h4><p>The positive reviews contains 25000 movie reviews labeled as positive. A positive review has a score &gt;&#x3D; 7 out of 10. The positive reviews are mostly positive and entertaining. The reviews are mostly written in the positive tone. In the <code>aclImdb\train\pos</code> directory, the suffix number of files all <code>&gt;= 7</code>. Example file name like <code>10_8.txt</code> which means star rating <code>8/10</code> from IMDb.</p><h4 id="Negative-Reviews"><a href="#Negative-Reviews" class="headerlink" title="Negative Reviews"></a>Negative Reviews</h4><p>The negative reviews contains 25000 movie reviews labeled as negative. A negative review has a score <code>&lt;= 4</code> out of 10. The negative reviews are mostly negative and sad. The reviews are mostly written in the negative tone. In the <code>aclImdb\train\neg</code> directory, the suffix number of files all <code>&lt;= 4</code>. Example file name like <code>10_3.txt</code> which means star rating <code>3/10</code> from IMDb.</p><p>The reviews with more neutral ratings are not included in the train&#x2F;test sets.</p><h4 id="Unlabeled-Reviews"><a href="#Unlabeled-Reviews" class="headerlink" title="Unlabeled Reviews"></a>Unlabeled Reviews</h4><p>The unlabeled reviews contains 50000 movie reviews that are not labeled as positive or negative. These reviews are used for unsupervised learning. In the <code>aclImdb\train\unsup</code> directory, these reviews are not labeled as positive or negative, the suffix number of files all are <code>0</code> which means the score. Example file name like <code>10_0.txt</code>.</p><h4 id="Test-dataset-reviews"><a href="#Test-dataset-reviews" class="headerlink" title="Test dataset reviews"></a>Test dataset reviews</h4><p>The test reviews contains 25000 movie reviews. These reviews are used for evaluating the performance of the model. In the <code>aclImdb\test</code> directory, it contains <code>pos</code> and <code>neg</code> directories with the same structure as the <code>train</code> directory.</p><h4 id="Tokenized-BoW"><a href="#Tokenized-BoW" class="headerlink" title="Tokenized BoW"></a>Tokenized BoW</h4><p>In addition to the review text files, there is a already-tokenized bag of words (BoW) features that were used in <code>Standford</code> experiments. These are stored in .feat files in the train&#x2F;test directories. Each .feat file is in LIBSVM format, an ascii sparse-vector format for labeled data. The feature indices in these files start from 0, and the text tokens corresponding to a feature index is found in [imdb.vocab]. So a line with 0:7 in a .feat file means the first word in <a href="the">imdb.vocab</a> appears 7 times in that review.</p><h2 id="Download-the-Dataset"><a href="#Download-the-Dataset" class="headerlink" title="Download the Dataset"></a>Download the Dataset</h2><p>The complete dataset can be downloaded from the following link: <a href="https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz">https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz</a>. Once you download and unzip it, you can see the major dataset structure as shown below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">aclImdb</span><br><span class="line">├── README</span><br><span class="line">├── imdb.vocab </span><br><span class="line">├── test</span><br><span class="line">│   ├── neg</span><br><span class="line">│   │   ├── 2_1.txt</span><br><span class="line">│   └── pos</span><br><span class="line">│   │   ├── 3_8.txt</span><br><span class="line">├── train</span><br><span class="line">│   ├── neg</span><br><span class="line">│   │   ├── 12_1.txt</span><br><span class="line">│   ├── pos</span><br><span class="line">│   │   ├── 4_8.txt</span><br><span class="line">│   └── unsup</span><br><span class="line">│   │   ├── 10_0.txt</span><br></pre></td></tr></table></figure><p>In the <code>.txt</code> file, the text content is review of the movie.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this article, we will discu</summary>
      
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Keras" scheme="https://stonefishy.github.io/tags/Keras/"/>
    
    <category term="TensorFlow" scheme="https://stonefishy.github.io/tags/TensorFlow/"/>
    
    <category term="Dataset" scheme="https://stonefishy.github.io/tags/Dataset/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Tensorflow for Machine Learning</title>
    <link href="https://stonefishy.github.io/2023/01/02/understanding-tensorflow-for-machine-learning/"/>
    <id>https://stonefishy.github.io/2023/01/02/understanding-tensorflow-for-machine-learning/</id>
    <published>2023-01-02T15:26:26.000Z</published>
    <updated>2024-07-09T03:29:33.954Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction-to-TensorFlow"><a href="#Introduction-to-TensorFlow" class="headerlink" title="Introduction to TensorFlow"></a>Introduction to TensorFlow</h2><p><code>TensorFlow</code> is an open-source machine learning framework developed by <code>Google</code>. It is designed to facilitate the creation and deployment of <code>machine learning</code> models, from simple linear regression to complex deep neural networks. TensorFlow provides a comprehensive ecosystem of tools, libraries, and community resources that allow researchers and developers to build and train ML models efficiently.</p><h2 id="Core-Concepts"><a href="#Core-Concepts" class="headerlink" title="Core Concepts"></a>Core Concepts</h2><h3 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h3><p>At the heart of TensorFlow is the concept of a <code>tensor(张量)</code>. A tensor is a generalization of vectors and matrices to potentially higher dimensions. In TensorFlow, tensors are multi-dimensional arrays with a uniform type (<code>dtype</code>). Tensors are the primary data structure used in TensorFlow operations.</p><h3 id="Graphs-and-Sessions"><a href="#Graphs-and-Sessions" class="headerlink" title="Graphs and Sessions"></a>Graphs and Sessions</h3><p>TensorFlow uses a <code>dataflow graph(数据流图)</code> to represent the computations required for a machine learning model. The <code>graph</code> consists of nodes <code>(operations)(操作)</code> and edges <code>(tensors)(张量)</code>. Each node in the graph represents an operation, and the edges represent the tensors that flow between these operations.</p><p>To execute the graph, TensorFlow uses sessions. A <code>session</code> encapsulates the environment in which the operations in the graph are executed to produce tensors.</p><h3 id="Variables-and-Placeholders"><a href="#Variables-and-Placeholders" class="headerlink" title="Variables and Placeholders"></a>Variables and Placeholders</h3><ul><li><strong>Variables</strong>: These are used to hold and update parameters during the training process. Variables are in-memory buffers containing tensors.</li><li><strong>Placeholders</strong>: These are used to feed data into the graph. They allow you to pass data into the graph at runtime without initializing them with a value.</li></ul><h2 id="Building-a-Model"><a href="#Building-a-Model" class="headerlink" title="Building a Model"></a>Building a Model</h2><h3 id="Defining-the-Graph"><a href="#Defining-the-Graph" class="headerlink" title="Defining the Graph"></a>Defining the Graph</h3><p>To build a model, you first define the <code>computational graph(计算图)</code>. This involves creating the necessary operations and connecting them with tensors. For example, to create a simple linear regression model, you might define the following operations:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Placeholders for input and output data</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, n_features], name=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">1</span>], name=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Variables for weights and bias</span></span><br><span class="line">w = tf.Variable(tf.zeros([n_features, <span class="number">1</span>]), name=<span class="string">&#x27;weights&#x27;</span>)</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]), name=<span class="string">&#x27;bias&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model: y = Wx + b</span></span><br><span class="line">y_pred = tf.matmul(x, w) + b</span><br></pre></td></tr></table></figure><h3 id="Loss-Function-and-Optimizer"><a href="#Loss-Function-and-Optimizer" class="headerlink" title="Loss Function and Optimizer"></a>Loss Function and Optimizer</h3><p>Next, you need to define a <code>loss function(损失函数)</code> to measure how well the model’s predictions match the actual data. Common loss functions include <code>mean squared error(均方误差) for regression problems(回归问题)</code> and <code>cross-entropy(交叉熵) for classification problems(分类问题)</code>.</p><p>You also need to choose an <code>optimizer</code> to minimize the loss function. TensorFlow provides several optimizers, such as <code>GradientDescentOptimizer(梯度下降优化器)</code>, <code>AdamOptimizer(自适应矩阵估计优化器)</code>, <code>AdagradOptimizer</code>, and <code>RMSPropOptimizer</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mean squared error loss function</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y_pred - y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gradient descent optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)</span><br></pre></td></tr></table></figure><h2 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h2><p>To train the model, you need to run the session and feed the data into the placeholders. The optimizer will adjust the variables to minimize the loss.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Initialize variables</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Training loop</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        _, loss_value = sess.run([optimizer, loss], feed_dict=&#123;x: train_x, y: train_y&#125;)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>, Loss: <span class="subst">&#123;loss_value&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><p>Once the model is trained, you can deploy it for inference. TensorFlow provides several tools for model deployment, including <code>TensorFlow Serving</code>, <code>TensorFlow Lite for mobile and embedded devices</code>, and <code>TensorFlow.js for web applications</code>.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>TensorFlow is a powerful and flexible framework for building and deploying machine learning models. By understanding its core concepts and tools, you can efficiently develop and train models for a wide range of applications.</p><p>For more details, please refer to the official TensorFlow documentation: <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction-to-TensorFlow&quot;&gt;&lt;a href=&quot;#Introduction-to-TensorFlow&quot; class=&quot;headerlink&quot; title=&quot;Introduction to TensorFlow&quot;&gt;&lt;/a&gt;Introduc</summary>
      
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Keras" scheme="https://stonefishy.github.io/tags/Keras/"/>
    
    <category term="TensorFlow" scheme="https://stonefishy.github.io/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>AWS Auto Scaling Group - 实现弹性自动扩展的技术指南</title>
    <link href="https://stonefishy.github.io/2022/11/15/aws-auto-scaling-group/"/>
    <id>https://stonefishy.github.io/2022/11/15/aws-auto-scaling-group/</id>
    <published>2022-11-15T22:27:54.000Z</published>
    <updated>2024-07-09T03:29:33.954Z</updated>
    
    <content type="html"><![CDATA[<p>在Cloud领域，弹性自动扩展是确保应用程序高可用性和性能的关键组成部分。<code>AWS Auto Scaling Group（ASG）</code>是Amazon Web Services（AWS）提供的一项强大服务，可帮助您自动扩展和管理应用程序的资源，以适应不断变化的工作负载需求。本文将深入探讨AWS Auto Scaling Group的技术细节，包括其核心概念、配置选项、最佳实践和实际应用场景。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-asg-capacity.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-asg-capacity.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Auto Scaling Group" style="width:600px;"/></div><span class="image-caption">AWS Auto Scaling Group</span></div><h3 id="理解-AWS-Auto-Scaling-Group（ASG）"><a href="#理解-AWS-Auto-Scaling-Group（ASG）" class="headerlink" title="理解 AWS Auto Scaling Group（ASG）"></a>理解 AWS Auto Scaling Group（ASG）</h3><ul><li><strong>什么是Auto Scaling Group？</strong></li></ul><p>AWS Auto Scaling Group（ASG）是一项AWS服务，允许您自动增加或减少应用程序实例的数量，以满足流量波动。ASG基于一组规则来动态调整实例的数量，确保应用程序具有所需的容量，并提供高可用性。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-asg-elb.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-asg-elb.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Auto Scaling Group in AWS with Load Balancer" style="width:600px;"/></div><span class="image-caption">Auto Scaling Group in AWS with Load Balancer</span></div><ul><li><strong>ASG的工作原理</strong></li></ul><p>ASG通过监控配置的指标，例如CPU利用率或请求率，来确定是否需要调整实例数量。它可以自动启动新实例以应对高负载，或者停止不再需要的实例以节省成本。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-asg-cloudwatch.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-asg-cloudwatch.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Auto Scaling in AWS with Cloud Watch Alarm" style="width:600px;"/></div><span class="image-caption">Auto Scaling in AWS with Cloud Watch Alarm</span></div><ul><li><strong>ASG的优势</strong></li></ul><p>ASG的优势包括自动化扩展、高可用性、成本效益以及应对不断变化的需求。它可以确保应用程序始终具备所需的性能，并且无需手动干预。</p><h3 id="Auto-Scaling-Group的关键组件"><a href="#Auto-Scaling-Group的关键组件" class="headerlink" title="Auto Scaling Group的关键组件"></a>Auto Scaling Group的关键组件</h3><ul><li><strong>启动配置（Launch Configuration）</strong></li></ul><p>启动配置定义了ASG启动新实例时使用的AMI、实例类型、安全组等参数。它充当了创建实例的蓝图。</p><ul><li><strong>自动扩展策略（Auto Scaling Policies）</strong></li></ul><p>自动扩展策略是ASG的核心。它们定义了何时以及如何扩展或缩减实例数量，基于监控指标和阈值的触发条件。</p><ul><li><strong>健康检查（Health Checks）</strong></li></ul><p>健康检查用于监控实例的健康状态。ASG可以自动替换失败或不健康的实例，确保应用程序的稳定性。</p><h3 id="Auto-Scaling-Group的配置选项"><a href="#Auto-Scaling-Group的配置选项" class="headerlink" title="Auto Scaling Group的配置选项"></a>Auto Scaling Group的配置选项</h3><ul><li><strong>期望容量与最小&#x2F;最大大小</strong></li></ul><p>期望容量是您希望ASG维护的实例数量，而最小和最大大小则定义了ASG可以自动扩展或缩减的范围。</p><ul><li><strong>使用负载均衡器</strong></li></ul><p>如果您使用负载均衡器（如AWS ELB），ASG可以与之集成，确保新实例被平衡地分配到负载均衡器后端。</p><ul><li><strong>实例类型与AMI选择</strong></li></ul><p>选择适当的实例类型和AMI对性能和成本至关重要。ASG允许您在启动配置中定义这些选项，以便根据需求选择。</p><ul><li><strong>自动扩展策略：手动、定时和动态</strong></li></ul><p>ASG支持多种自动扩展策略。您可以手动设置扩展策略，定时触发扩展，或根据动态触发条件自动调整容量。</p><h3 id="高级ASG功能"><a href="#高级ASG功能" class="headerlink" title="高级ASG功能"></a>高级ASG功能</h3><ul><li><strong>生命周期挂钩（Lifecycle Hooks）</strong></li></ul><p>生命周期挂钩允许您执行自定义操作，例如在实例启动或终止时发送通知或运行脚本。</p><ul><li><strong>实例终止策略（Instance Termination Policies）</strong></li></ul><p>终止策略定义了ASG在需要缩减容量时应如何选择要终止的实例。您可以自定义终止策略以满足特定需求。</p><ul><li><strong>预测性自动扩展（Predictive Scaling）</strong></li></ul><p>预测性自动扩展使用机器学习来预测将来的负载，并相应地调整实例数量，以减少资源浪费和成本。</p><ul><li><strong>混合实例策略（Mixed Instances Policy）</strong></li></ul><p>混合实例策略允许ASG使用多种实例类型，包括On-Demand和Spot实例，以提高成本效益。</p><ul><li><strong>在ASG中使用Spot实例</strong></li></ul><p>Spot实例是成本较低但可中断的实例类型。ASG可以使用Spot实例来降低成本，同时仍保持可用性。</p><h3 id="配置AWS-Auto-Scaling-Group"><a href="#配置AWS-Auto-Scaling-Group" class="headerlink" title="配置AWS Auto Scaling Group"></a>配置AWS Auto Scaling Group</h3><ul><li><strong>创建 Auto Scaling Group</strong></li></ul><p>在AWS控制台中创建Auto Scaling Group（ASG）是一项简单但重要的任务。首先，登录到AWS管理控制台，然后遵循以下步骤：</p><ol><li>导航到Auto Scaling控制台。</li><li>单击“创建Auto Scaling组”。</li><li>指定ASG的名称和描述。</li><li>选择要使用的启动配置。启动配置定义了新实例的配置，包括AMI、实例类型、安全组等。</li><li>设置期望容量。这是您希望ASG维护的实例数量。</li><li>选择最小和最大大小。最小大小是ASG可以缩减到的最小实例数，最大大小是ASG可以扩展到的最大实例数。</li><li>选择要使用的VPC。</li><li>配置负载均衡（如果需要）。您可以选择将ASG与负载均衡器相关联，以分配流量。</li><li>配置健康检查以确保实例的健康状态。</li><li>设置通知，以便在ASG执行自动扩展时接收通知。</li><li>审查和创建ASG。</li></ol><ul><li><strong>定义启动配置</strong></li></ul><p>启动配置是ASG创建新实例时使用的模板。您可以在创建ASG时选择现有的启动配置或创建新的。启动配置包括以下关键选项：</p><ol><li>AMI（Amazon Machine Image）：选择适合您应用程序的AMI。这是新实例的操作系统和应用程序基础。</li><li>实例类型：选择实例的规格，以满足性能和资源需求。</li><li>安全组：定义实例的网络访问策略，确保适当的安全性。</li><li>存储卷：定义实例的根卷和附加卷。</li><li>用户数据：可选项，允许您提供启动脚本或其他自定义配置。</li></ol><ul><li><strong>配置自动扩展策略</strong></li></ul><p>自动扩展策略定义了ASG何时以及如何调整实例数量。在ASG中，您可以配置以下类型的策略：</p><ol><li>目标跟踪策略：设置CPU利用率、网络流量等指标的目标值。ASG将自动增加或减少实例以维持目标。</li><li>简单缩放策略：基于CloudWatch指标（如CPU利用率）的阈值进行自动缩放。</li><li>定时扩展策略：按计划定期增加或减少实例数量。适用于按时间表的工作负载。</li></ol><ul><li><strong>关联负载均衡器</strong></li></ul><p>如果您的应用程序需要负载均衡，您可以将ASG与AWS Elastic Load Balancer（ELB）相关联。这样，ASG将自动将新实例注册到负载均衡器，确保流量平衡。</p><ul><li><strong>设置健康检查</strong></li></ul><p>健康检查是确保实例健康的关键。您可以定义HTTP、TCP或自定义健康检查来监控实例。如果实例标记为不健康，ASG将自动替换它们。</p><h3 id="实际应用场景"><a href="#实际应用场景" class="headerlink" title="实际应用场景"></a>实际应用场景</h3><p>AWS Auto Scaling Group（ASG）在各种应用场景中都具有广泛的用途，以下是一些常见的应用场景：</p><ul><li><strong>Web应用程序</strong></li></ul><p>Web应用程序通常会面临不断变化的流量。ASG可帮助您根据实际请求量自动扩展或缩减实例数量，以确保用户始终获得稳定的性能。在这种情况下，您可以根据请求率、CPU利用率或其他性能指标来配置自动扩展策略。</p><ul><li><strong>微服务架构</strong></li></ul><p>微服务架构将应用程序拆分成多个微小的服务，每个服务都可以独立扩展。ASG为每个微服务提供弹性，使您能够根据每个服务的负载需求来动态调整实例数量。这有助于确保整体系统的高可用性和性能。</p><ul><li><strong>批处理处理</strong></li></ul><p>对于需要处理大量数据或批量作业的场景，ASG可以帮助您实现自动化的扩展和缩减。您可以根据作业队列的长度、处理速度等指标来配置自动扩展策略，以确保作业能够及时完成。</p><ul><li><strong>数据分析</strong></li></ul><p>数据分析工作负载通常需要大量计算资源，但其负载可能在不同时间段内变化。ASG允许您根据数据分析工作负载的需求来动态调整实例数量。这意味着您可以在数据处理高峰期扩展实例数量，并在需求下降时自动缩减容量，以优化成本。</p><ul><li><strong>电子商务平台</strong></li></ul><p>电子商务平台在特定时间段内可能会面临季节性高峰，如假日购物季。使用ASG，您可以根据销售活动的预期来调整实例数量，以应对潜在的流量增加。这有助于确保用户在高峰期间获得无缝的购物体验。</p><ul><li><strong>游戏服务器</strong></li></ul><p>在线游戏通常会有大量玩家同时在线，因此需要具备高度可扩展性。ASG可以根据游戏服务器的负载情况来自动扩展或缩减实例数量，以满足玩家需求。这有助于确保游戏的稳定性和响应速度。</p><ul><li><strong>科学计算</strong></li></ul><p>科学计算工作负载需要大量计算资源来执行复杂的计算任务，例如模拟、数据分析和渲染。ASG可以帮助科学研究团队在需要时获得额外的计算能力，以加速研究进程。</p><p>这些是一些常见的实际应用场景，ASG的灵活性和自动化特性使其成为各种工作负载的理想选择。根据您的特定需求，您可以调整自动扩展策略和配置，以满足不同应用程序的要求。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>AWS Auto Scaling Group（ASG）是Cloud中实现弹性自动扩展的重要工具，它使您能够根据需求自动调整资源，同时优化资源使用和成本。通过深入了解ASG的核心概念、配置选项、最佳实践以及实际应用场景，您将能够构建可扩展和具有适应性的云基础架构，以应对不断变化的应用程序和服务需求。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在Cloud领域，弹性自动扩展是确保应用程序高可用性和性能的关键组成部分。&lt;code&gt;AWS Auto Scaling Group（ASG）&lt;/code&gt;是Amazon Web Services（AWS）提供的一项强大服务，可帮助您自动扩展和管理应用程序的资源，以适应不断变</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Load Balancer: CLB, ALB, NLB and GWLB</title>
    <link href="https://stonefishy.github.io/2022/10/21/elastic-load-balancer-clb-alb-nlb-and-gwlb/"/>
    <id>https://stonefishy.github.io/2022/10/21/elastic-load-balancer-clb-alb-nlb-and-gwlb/</id>
    <published>2022-10-21T20:23:06.000Z</published>
    <updated>2024-07-09T03:29:33.954Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Classic-Load-Balancers-v1"><a href="#Classic-Load-Balancers-v1" class="headerlink" title="Classic Load Balancers (v1)"></a>Classic Load Balancers (v1)</h2><p><strong>Supports TCP (Layer 4), HTTP &amp; HTTPS (Layer 7)</strong></p><p><strong>Health checks are TCP or HTTP based</strong></p><p><strong>Fixed hostname XXX.region.elb.amazonaws.com</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-clb.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-clb.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Classic Load Balancer" style="width:600px;"/></div><span class="image-caption">AWS Classic Load Balancer</span></div><h2 id="Application-Load-Balancer-v2"><a href="#Application-Load-Balancer-v2" class="headerlink" title="Application Load Balancer (v2)"></a>Application Load Balancer (v2)</h2><p><strong>Application  load balancers is Layer 7 (HTTP)</strong></p><p><strong>Load balancing to multiple HTTP applications across machines (target groups)</strong></p><p><strong>Load balancing to multiple applications on the same machine (ex: containers)</strong></p><p><strong>Support for HTTP&#x2F;2 and WebSocket</strong></p><p><strong>Supports redirects (from HTTP to HTTPS for example)</strong></p><p><strong>Routing tables to different target groups:</strong></p><ol><li>Routing base on path in URL (example.com&#x2F;<strong>users</strong> &amp; example.com&#x2F;<strong>posts</strong>)</li><li>Routing base on hostname in URL (<strong>one</strong>.example.com &amp; <strong>other</strong>.example.com)</li><li>Routing base on Query String, Headers (example.com&#x2F;users?<strong>id&#x3D;123&amp;order&#x3D;false</strong>)</li></ol><span class='pbg danger'>ALB are a great fit for micro services & container-based application (example: Docker & Amazon ECS)</span><p>Has a port mapping feature to redirect to a dynamic port in ECS<br>In comparison, we’d need multiple Classic Load Balancer per application</p><h3 id="ALB-v2-HTTP-Based-Traffic"><a href="#ALB-v2-HTTP-Based-Traffic" class="headerlink" title="ALB (v2) HTTP Based Traffic"></a>ALB (v2) HTTP Based Traffic</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-alb-traffic.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-alb-traffic.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Application Load Balancer Traffic" style="width:600px;"/></div><span class="image-caption">AWS Application Load Balancer Traffic</span></div><h3 id="ALB-v2-Target-Groups"><a href="#ALB-v2-Target-Groups" class="headerlink" title="ALB (v2) Target Groups"></a>ALB (v2) Target Groups</h3><p><strong>EC2 instances (can be managed by an Auto Scaling Group) - HTTP</strong></p><p><strong>ECS tasks (managed by ECS itself) - HTTP</strong></p><p><strong>Lambda functions - HTTP request is translated into a JSON event</strong></p><p><strong>IP Addresses - must be private IPs</strong></p><p><strong>ALB can route to multiple target groups</strong></p><p><strong>Health checks are at the target group level</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-alb-targetgroup.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-alb-targetgroup.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS ALB Query Strings/Parameters Routing" style="width:600px;"/></div><span class="image-caption">AWS ALB Query Strings/Parameters Routing</span></div><h2 id="Network-Load-Balancer-v2"><a href="#Network-Load-Balancer-v2" class="headerlink" title="Network Load Balancer (v2)"></a>Network Load Balancer (v2)</h2><p><strong>Network load balancers (Layer 4) allow to:</strong></p><ol><li>Forward TCP &amp; UDP traffic to your instances</li><li>Handle millions of request per seconds</li><li>Less latency ~ 100ms (vs 400 ms for ALB)</li></ol><p><strong>NLB has one static IP per AZ, and supports assigning Elastic IP(helpful for whitelisting specific IP)</strong></p><p><strong>NLB are used for extreme performance, TCP or UDP traffic</strong></p><p><strong>Not included in the AWS free tier</strong></p><h3 id="Network-Load-Balancer-v2-TCP-Layer-4-Based-Traffic"><a href="#Network-Load-Balancer-v2-TCP-Layer-4-Based-Traffic" class="headerlink" title="Network Load Balancer (v2) TCP (Layer 4) Based Traffic"></a>Network Load Balancer (v2) TCP (Layer 4) Based Traffic</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-nlb-traffic.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-nlb-traffic.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS NLB TCP Based Traffic" style="width:600px;"/></div><span class="image-caption">AWS NLB TCP Based Traffic</span></div><h3 id="Network-Load-Balancer-Target-Groups"><a href="#Network-Load-Balancer-Target-Groups" class="headerlink" title="Network Load Balancer - Target Groups"></a>Network Load Balancer - Target Groups</h3><p><strong>EC2 instances</strong></p><p><strong>IP Addresses - must be private IPs</strong></p><p><strong>Application Load Balancer</strong></p><p><strong>Health Checks support the TCP, HTTP and HTTPS protocols</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-nlb-targetgroup.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-nlb-targetgroup.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Network Load Balancer Target Group" style="width:600px;"/></div><span class="image-caption">AWS Network Load Balancer Target Group</span></div><h2 id="Gateway-Load-Balancer"><a href="#Gateway-Load-Balancer" class="headerlink" title="Gateway Load Balancer"></a>Gateway Load Balancer</h2><p><strong>Deploy, scale, and manage a fleet of 3rd party network virtual applications in AWS Example: Firewalls, Intrusion Detection and Prevention Systems, Deep Packet Inspect Inspection Systems, payload manipulation, …</strong></p><p><strong>Operates at Layer 3 (Network Layer) - IP Packages</strong></p><p><strong>Combines the following fuctions:</strong></p><ol><li>Transparent Network Gateway - single entry&#x2F;exit for all traffic</li><li>Load Balancer - distributes traffic to your virtual applications</li><li>Uses the GENEVE protocol on port 6081</li></ol><h3 id="Gateway-Load-Balancer-Network-Layer-Layer-3-Based-Traffic"><a href="#Gateway-Load-Balancer-Network-Layer-Layer-3-Based-Traffic" class="headerlink" title="Gateway Load Balancer Network Layer (Layer 3) Based Traffic"></a>Gateway Load Balancer Network Layer (Layer 3) Based Traffic</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-gwlb.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-gwlb.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Gateway Load Balancer Traffic" style="height:500px;"/></div><span class="image-caption">AWS Gateway Load Balancer Traffic</span></div>  <h3 id="Gateway-Load-Balancer-Target-Group"><a href="#Gateway-Load-Balancer-Target-Group" class="headerlink" title="Gateway Load Balancer - Target Group"></a>Gateway Load Balancer - Target Group</h3><p><strong>EC2 instances</strong></p><p><strong>IP Addresses - must be private IPs</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-elb-gwlb-targetgroup.webp" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-elb-gwlb-targetgroup.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Gateway Load Balancer Target Group" style="width:600px;"/></div><span class="image-caption">AWS Gateway Load Balancer Target Group</span></div>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Classic-Load-Balancers-v1&quot;&gt;&lt;a href=&quot;#Classic-Load-Balancers-v1&quot; class=&quot;headerlink&quot; title=&quot;Classic Load Balancers (v1)&quot;&gt;&lt;/a&gt;Classic L</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
  </entry>
  
</feed>
