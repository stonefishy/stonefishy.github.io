<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andrewsy&#39;s Space</title>
  
  
  <link href="https://stonefishy.github.io/atom.xml" rel="self"/>
  
  <link href="https://stonefishy.github.io/"/>
  <updated>2024-11-15T06:39:09.202Z</updated>
  <id>https://stonefishy.github.io/</id>
  
  <author>
    <name>Andrewsy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>详解数据分析中的方差，标准差和异常值的使用</title>
    <link href="https://stonefishy.github.io/2024/11/15/data-analysis-standard-deviation-variance-outliers/"/>
    <id>https://stonefishy.github.io/2024/11/15/data-analysis-standard-deviation-variance-outliers/</id>
    <published>2024-11-15T11:22:27.000Z</published>
    <updated>2024-11-15T06:39:09.202Z</updated>
    
    <content type="html"><![CDATA[<p>在数据分析中，<code>方差（Variance）</code>、<code>标准差（Standard Deviation）</code>和<code>异常值（Outliers）</code>是分析数据分布和变异性的重要统计工具。理解这些概念，并能够有效地应用它们，对于<code>数据清洗</code>、探索性数据分析（EDA）以及<code>构建准确的预测模型</code>至关重要。</p><h2 id="方差（Variance）"><a href="#方差（Variance）" class="headerlink" title="方差（Variance）"></a>方差（Variance）</h2><p>方差是反映数据集中各数据点与数据均值之间差异的一个重要指标。它的大小可以用来衡量数据的离散程度。具体来说，方差越大，数据的变动越大，反之则越小。</p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.798ex;" xmlns="http://www.w3.org/2000/svg" width="28.177ex" height="2.755ex" role="img" focusable="false" viewBox="0 -864.9 12454.1 1217.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-2-TEX-N-56" d="M114 620Q113 621 110 624T107 627T103 630T98 632T91 634T80 635T67 636T48 637H19V683H28Q46 680 152 680Q273 680 294 683H305V637H284Q223 634 223 620Q223 618 313 372T404 126L490 358Q575 588 575 597Q575 616 554 626T508 637H503V683H512Q527 680 627 680Q718 680 724 683H730V637H723Q648 637 627 596Q627 595 515 291T401 -14Q396 -22 382 -22H374H367Q353 -22 348 -14Q346 -12 231 303Q114 617 114 620Z"></path><path id="MJX-2-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-2-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-2-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-2-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-2-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJX-2-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-2-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-2-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-2-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-2-TEX-SO-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path id="MJX-2-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-2-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-2-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-2-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-2-TEX-I-1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path id="MJX-2-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-2-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><use data-c="56" xlink:href="#MJX-2-TEX-N-56"></use><use data-c="61" xlink:href="#MJX-2-TEX-N-61" transform="translate(750,0)"></use><use data-c="72" xlink:href="#MJX-2-TEX-N-72" transform="translate(1250,0)"></use><use data-c="69" xlink:href="#MJX-2-TEX-N-69" transform="translate(1642,0)"></use><use data-c="61" xlink:href="#MJX-2-TEX-N-61" transform="translate(1920,0)"></use><use data-c="6E" xlink:href="#MJX-2-TEX-N-6E" transform="translate(2420,0)"></use><use data-c="63" xlink:href="#MJX-2-TEX-N-63" transform="translate(2976,0)"></use><use data-c="65" xlink:href="#MJX-2-TEX-N-65" transform="translate(3420,0)"></use></g><g data-mml-node="mo" transform="translate(4141.8,0)"><use data-c="3D" xlink:href="#MJX-2-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(5197.6,0)"><g data-mml-node="mn" transform="translate(255.4,394) scale(0.707)"><use data-c="31" xlink:href="#MJX-2-TEX-N-31"></use></g><g data-mml-node="mi" transform="translate(220,-345) scale(0.707)"><use data-c="1D45B" xlink:href="#MJX-2-TEX-I-1D45B"></use></g><rect width="624.3" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(6228.5,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-2-TEX-SO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-2-TEX-I-1D45B"></use></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-2-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="3D" xlink:href="#MJX-2-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1123,0)"><use data-c="31" xlink:href="#MJX-2-TEX-N-31"></use></g></g></g><g data-mml-node="mo" transform="translate(8515.1,0)"><use data-c="28" xlink:href="#MJX-2-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(8904.1,0)"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-2-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-2-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(10025.3,0)"><use data-c="2212" xlink:href="#MJX-2-TEX-N-2212"></use></g><g data-mml-node="mi" transform="translate(11025.5,0)"><use data-c="1D707" xlink:href="#MJX-2-TEX-I-1D707"></use></g><g data-mml-node="msup" transform="translate(11628.5,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-2-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-2-TEX-N-32"></use></g></g></g></g></svg></mjx-container><blockquote><p><code>x_i</code>为数据集中的每个数据点，<br><code>μ</code> 为数据集的均值，<br><code>n</code> 为数据的总个数。<br>方差就是所有数据点与均值的差值的平方的平均值。</p></blockquote><p>方差计算时，我们将每个数据点与均值的差值进行平方，然后求平均。方差的单位是原始数据单位的平方，因此有时它的解释意义不如标准差直观。</p><h2 id="标准差（Standard-Deviation）"><a href="#标准差（Standard-Deviation）" class="headerlink" title="标准差（Standard Deviation）"></a>标准差（Standard Deviation）</h2><p>标准差是方差的平方根。与方差不同，标准差的单位与原始数据相同，因此更易于理解。标准差越大，说明数据的波动性越大；标准差越小，则说明数据较为集中。</p><p>标准差的计算公式为：</p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.231ex;" xmlns="http://www.w3.org/2000/svg" width="32.902ex" height="2.398ex" role="img" focusable="false" viewBox="0 -958 14542.6 1060" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path id="MJX-1-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-1-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-1-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-1-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJX-1-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-1-TEX-N-20" d=""></path><path id="MJX-1-TEX-N-44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z"></path><path id="MJX-1-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-1-TEX-N-76" d="M338 431Q344 429 422 429Q479 429 503 431H508V385H497Q439 381 423 345Q421 341 356 172T288 -2Q283 -11 263 -11Q244 -11 239 -2Q99 359 98 364Q93 378 82 381T43 385H19V431H25L33 430Q41 430 53 430T79 430T104 429T122 428Q217 428 232 431H240V385H226Q187 384 184 370Q184 366 235 234L286 102L377 341V349Q377 363 367 372T349 383T335 385H331V431H338Z"></path><path id="MJX-1-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-1-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-N-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path><path id="MJX-1-TEX-N-56" d="M114 620Q113 621 110 624T107 627T103 630T98 632T91 634T80 635T67 636T48 637H19V683H28Q46 680 152 680Q273 680 294 683H305V637H284Q223 634 223 620Q223 618 313 372T404 126L490 358Q575 588 575 597Q575 616 554 626T508 637H503V683H512Q527 680 627 680Q718 680 724 683H730V637H723Q648 637 627 596Q627 595 515 291T401 -14Q396 -22 382 -22H374H367Q353 -22 348 -14Q346 -12 231 303Q114 617 114 620Z"></path><path id="MJX-1-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><use data-c="53" xlink:href="#MJX-1-TEX-N-53"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(556,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(945,0)"></use><use data-c="6E" xlink:href="#MJX-1-TEX-N-6E" transform="translate(1445,0)"></use><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(2001,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(2557,0)"></use><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(3057,0)"></use><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(3449,0)"></use><use data-c="20" xlink:href="#MJX-1-TEX-N-20" transform="translate(4005,0)"></use><use data-c="44" xlink:href="#MJX-1-TEX-N-44" transform="translate(4255,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(5019,0)"></use><use data-c="76" xlink:href="#MJX-1-TEX-N-76" transform="translate(5463,0)"></use><use data-c="69" xlink:href="#MJX-1-TEX-N-69" transform="translate(5991,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(6269,0)"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(6769,0)"></use><use data-c="69" xlink:href="#MJX-1-TEX-N-69" transform="translate(7158,0)"></use><use data-c="6F" xlink:href="#MJX-1-TEX-N-6F" transform="translate(7436,0)"></use><use data-c="6E" xlink:href="#MJX-1-TEX-N-6E" transform="translate(7936,0)"></use></g><g data-mml-node="mo" transform="translate(8769.8,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="msqrt" transform="translate(9825.6,0)"><g transform="translate(853,0)"><g data-mml-node="mtext"><use data-c="56" xlink:href="#MJX-1-TEX-N-56"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(750,0)"></use><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(1250,0)"></use><use data-c="69" xlink:href="#MJX-1-TEX-N-69" transform="translate(1642,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(1920,0)"></use><use data-c="6E" xlink:href="#MJX-1-TEX-N-6E" transform="translate(2420,0)"></use><use data-c="63" xlink:href="#MJX-1-TEX-N-63" transform="translate(2976,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(3420,0)"></use></g></g><g data-mml-node="mo" transform="translate(0,98)"><use data-c="221A" xlink:href="#MJX-1-TEX-N-221A"></use></g><rect width="3864" height="60" x="853" y="838"></rect></g></g></g></svg></mjx-container><blockquote><p>方差的平方根即为标准差。</p></blockquote><h3 id="标准差与方差的关系"><a href="#标准差与方差的关系" class="headerlink" title="标准差与方差的关系"></a>标准差与方差的关系</h3><p>标准差和方差都用来描述数据的离散程度。标准差比方差更常用，因为它的单位与数据本身一致，解释起来更加直观。</p><h2 id="异常值（Outliers）"><a href="#异常值（Outliers）" class="headerlink" title="异常值（Outliers）"></a>异常值（Outliers）</h2><p>异常值是指在数据集中远离其他数据点的值。异常值的存在往往是由于数据录入错误、测量误差，或者数据本身存在极端波动。异常值会影响数据的分布，进而影响数据分析结果，尤其是均值、方差和标准差等统计量。</p><h3 id="如何识别异常值"><a href="#如何识别异常值" class="headerlink" title="如何识别异常值"></a>如何识别异常值</h3><p>常用的异常值检测方法有：</p><p><strong>箱线图法（Boxplot）</strong>：通过计算四分位数和四分位距（IQR）来识别异常值。通常，位于Q1 - 1.5 * IQR 或 Q3 + 1.5 * IQR之外的数据点被认为是异常值。<br><strong>Z-score法</strong>：通过计算数据点与均值的标准差倍数来判断数据点是否为异常值。<span class='pbg danger'>一般认为，Z-score超过3或小于-3的数据为异常值。</span></p><h3 id="异常值的处理"><a href="#异常值的处理" class="headerlink" title="异常值的处理"></a>异常值的处理</h3><p>在数据分析中，我们通常会在数据预处理阶段识别并处理异常值。常见的处理方法包括：</p><ul><li>删除异常值：直接从数据集中删除异常值。</li><li>替换异常值：用均值、中位数等替代异常值。</li><li>保留异常值：在某些情况下，异常值可能包含重要信息，因此也可以选择保留异常值。</li></ul><h2 id="举个列子"><a href="#举个列子" class="headerlink" title="举个列子"></a>举个列子</h2><p>假设我们有一个包含学生成绩的数据集，其中有一个异常值（200）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据集：一组学生成绩，其中包括异常值200</span></span><br><span class="line">data = [<span class="number">80</span>, <span class="number">85</span>, <span class="number">90</span>, <span class="number">92</span>, <span class="number">85</span>, <span class="number">88</span>, <span class="number">75</span>, <span class="number">78</span>, <span class="number">92</span>, <span class="number">95</span>, <span class="number">100</span>, <span class="number">85</span>, <span class="number">92</span>, <span class="number">88</span>, <span class="number">85</span>, <span class="number">200</span>]</span><br></pre></td></tr></table></figure><h2 id="计算方差和标准差"><a href="#计算方差和标准差" class="headerlink" title="计算方差和标准差"></a>计算方差和标准差</h2><p>我们使用<code>NumPy</code>来计算数据的方差和标准差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算方差</span></span><br><span class="line">variance_value = np.var(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;方差 (Variance): <span class="subst">&#123;variance_value&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算标准差</span></span><br><span class="line">std_dev_value = np.std(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;标准差 (Standard Deviation): <span class="subst">&#123;std_dev_value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">方差 (Variance): 781.734375</span><br><span class="line">标准差 (Standard Deviation): 27.959513139538036</span><br></pre></td></tr></table></figure><p>从输出可以看到，这组数据的方差为781.73，标准差为27.95，这表明数据的离散程度相对较高。特别是最后的异常值（200）对标准差的影响很大。</p><h3 id="异常值检测与处理"><a href="#异常值检测与处理" class="headerlink" title="异常值检测与处理"></a>异常值检测与处理</h3><h4 id="使用Z-score检测异常值"><a href="#使用Z-score检测异常值" class="headerlink" title="使用Z-score检测异常值"></a>使用Z-score检测异常值</h4><p>我们使用Z-score来检测数据中的异常值。如果Z-score大于3或小于-3，则该数据点被认为是异常值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算Z-score</span></span><br><span class="line">z_scores = stats.zscore(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Z-scores: <span class="subst">&#123;z_scores&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测异常值</span></span><br><span class="line">outliers = [data[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)) <span class="keyword">if</span> np.<span class="built_in">abs</span>(z_scores[i]) &gt; <span class="number">3</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到的异常值: <span class="subst">&#123;outliers&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>使用<code>scipy</code>的<code>stats</code>模块可以计算Z-score。输出结果中，Z-score大于3的异常值是200。</p><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Z-scores: [-0.51413628 -0.33530627 -0.15647626 -0.08494425 -0.33530627 -0.22800826</span><br><span class="line"> -0.69296629 -0.58566828 -0.08494425  0.02235375  0.20118376 -0.33530627</span><br><span class="line"> -0.08494425 -0.22800826 -0.33530627  3.77778395]</span><br><span class="line">检测到的异常值: [200]</span><br></pre></td></tr></table></figure><p>从输出结果中可以看出，Z-score大于3的异常值是200。这是由于200与其他数据点的差异过大，Z-score值为9.39，远远超过了3。</p><h4 id="使用箱线图检测异常值"><a href="#使用箱线图检测异常值" class="headerlink" title="使用箱线图检测异常值"></a>使用箱线图检测异常值</h4><p>我们可以绘制箱线图来可视化数据并检测异常值。可以使用<code>matplotlib</code>库绘制箱线图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制箱线图</span></span><br><span class="line">plt.boxplot(data)</span><br><span class="line">plt.title(<span class="string">&quot;Boxplot Chart&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/data-analysis/outlier-boxplot.png" class="lazyload placeholder" data-srcset="/assets/images/data-analysis/outlier-boxplot.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="箱线图" style="width:500px;"/></div><span class="image-caption">箱线图</span></div><p>从箱线图中，200的值处于箱体外，因此被视为异常值。</p><h3 id="处理异常值"><a href="#处理异常值" class="headerlink" title="处理异常值"></a>处理异常值</h3><p>在实际分析中，我们可以选择处理异常值。以下是几种常见的方法：</p><h4 id="删除异常值"><a href="#删除异常值" class="headerlink" title="删除异常值"></a>删除异常值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除异常值（Z-score大于3的点）</span></span><br><span class="line">cleaned_data = [data[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)) <span class="keyword">if</span> np.<span class="built_in">abs</span>(z_scores[i]) &lt;= <span class="number">3</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;删除异常值后的数据: <span class="subst">&#123;cleaned_data&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">删除异常值后的数据: [80, 85, 90, 92, 85, 88, 75, 78, 92, 95, 100, 85, 92, 88, 85]</span><br></pre></td></tr></table></figure><h4 id="替换异常值"><a href="#替换异常值" class="headerlink" title="替换异常值"></a>替换异常值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 替换异常值为中位数</span></span><br><span class="line">median_value = np.median(data)</span><br><span class="line">cleaned_data_with_median = [median_value <span class="keyword">if</span> np.<span class="built_in">abs</span>(z_scores[i]) &gt; <span class="number">3</span> <span class="keyword">else</span> data[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data))]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;替换异常值后的数据: <span class="subst">&#123;cleaned_data_with_median&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">替换异常值后的数据: [80, 85, 90, 92, 85, 88, 75, 78, 92, 95, 100, 85, 92, 88, 85, 88.0]</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>方差和标准差是用于衡量数据离散程度的基本统计量。方差的单位为原始数据单位的平方，而标准差则直接以原始单位表示，更容易解释。</li><li>异常值是指那些在数据中与其他数据点差异较大的值，它们可能影响统计分析的结果。在数据清洗阶段，识别和处理异常值是至关重要的一步。</li></ul><p>在Python中，我们可以利用<code>NumPy</code>、<code>SciPy</code>和<code>Matplotlib</code>等库来计算方差、标准差，识别异常值，并根据需要处理异常值。通过掌握这些基本概念和技术，我们数据分析师可以更有效地理解数据的分布特征，发现数据中的潜在问题，做出更加精准的数据分析。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在数据分析中，&lt;code&gt;方差（Variance）&lt;/code&gt;、&lt;code&gt;标准差（Standard Deviation）&lt;/code&gt;和&lt;code&gt;异常值（Outliers）&lt;/code&gt;是分析数据分布和变异性的重要统计工具。理解这些概念，并能够有效地应用它们，对于&lt;c</summary>
      
    
    
    
    <category term="Data Analysis" scheme="https://stonefishy.github.io/categories/Data-Analysis/"/>
    
    
    <category term="Data Analysis" scheme="https://stonefishy.github.io/tags/Data-Analysis/"/>
    
    <category term="Math" scheme="https://stonefishy.github.io/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to LangChain: Make AI Smarter and Easier to use</title>
    <link href="https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/"/>
    <id>https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/</id>
    <published>2024-11-12T13:49:12.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-image.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-image.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:600px;"/></div></div><p>Have you ever wondered how some apps and websites can have conversations with you, answer your questions? Many of these apps use <code>artificial intelligence (AI)</code>, like the chatbot you might use to ask questions or get advice. But creating these smart systems can be tricky. This is where a tool called <code>LangChain</code> comes in to help!</p><p><code>LangChain</code> is a framework that makes it easier for developers to build applications that use <code>AI models</code>, like chatbots or smart helpers. In this blog, we’re going to explain what LangChain is, how it works, and why it’s useful for making AI apps.</p><h2 id="What-is-LangChain"><a href="#What-is-LangChain" class="headerlink" title="What is LangChain?"></a>What is LangChain?</h2><p>LangChain is a tool for developers that helps them build applications using <code>large language models (LLMs)</code>—the same kind of AI that powers chatbots, writing assistants, and more. LLMs can understand and generate text in a way that sounds like a real person. However, using these models to make powerful apps can be complicated. LangChain makes it easier by offering ready-made building blocks to connect these models to other tools, data, and even databases.</p><p>Think of LangChain like a set of Lego blocks that you can use to build cool things with AI. It saves developers time by giving them ready-made pieces to use, rather than having to create everything from scratch.</p><h2 id="Features-of-LangChain"><a href="#Features-of-LangChain" class="headerlink" title="Features of LangChain"></a>Features of LangChain</h2><p>Let’s break down some of the cool features LangChain offers and how they help developers make smarter apps.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-features.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-features.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="LangChain Features"/></div><span class="image-caption">LangChain Features</span></div><ol><li><p><strong>Chains</strong>: Putting Multiple Steps Together<br>Imagine you have a robot that can help with math homework. The robot might need to do multiple things to solve a problem. First, it could look up the math formula, then solve the problem, and finally explain the answer. In LangChain, these steps are called chains.</p><blockquote><p>A chain is a sequence of actions where each step depends on the previous one. For example, you could create a chain where:</p><p>First, the app asks the AI to pull data from a website.<br>Then, it uses that data to answer a question.<br>Finally, it summarizes the answer for the user.</p></blockquote></li><li><p><strong>Prompt Management</strong>: Talking to AI the Right Way<br>When you talk to an AI, how you ask your question or give your instruction is really important. That’s called a prompt. LangChain helps developers make the best prompts by letting them create templates. These templates let developers easily change certain parts of the prompt without having to rewrite it every time.</p><blockquote><p>For example, if you wanted to ask the AI to summarize a story, you could have a prompt like this:</p><p>“Please summarize the following story: {story}”</p><p>In this template, {story} is a placeholder that can be replaced with any story you want the AI to summarize.</p></blockquote></li><li><p><strong>Agents</strong>: Letting AI Decide What to Do Next<br>Sometimes, a smart system needs to decide what to do next based on the information it gets. For example, if you ask an AI about the weather, it might decide to pull the latest weather data from the internet. This decision-making is done by agents.</p><blockquote><p>An agent is like a helper that looks at the information it gets and chooses the best action. LangChain helps developers build agents that can make these decisions automatically.</p></blockquote></li><li><p><strong>Memory</strong>: Remembering What Happened Before<br>Have you ever talked to a chatbot and then later felt like it forgot what you said earlier? That can make a conversation feel weird. <code>LangChain helps solve this problem by letting the AI remember what was said earlier in the conversation</code>. This feature is called memory.</p><blockquote><p>or example, if you ask a chatbot for homework help and then ask a follow-up question, LangChain can help the AI remember the first question and give a more useful answer based on that memory.</p></blockquote></li><li><p><strong>Integrations</strong>: Connecting to Other Tools and Websites<br>Sometimes, an AI app needs to talk to other systems to get more information. <span class='pbg success'>LangChain makes this easy by letting developers connect their AI app to other tools</span> This is like having a personal assistant that not only talks to you but also has access to tons of information online.</p><blockquote><p>For example, an AI app could pull up the latest sports scores, or check the weather for you, using real-time data from the internet.</p></blockquote></li><li><p><strong>Retrieval-Augmented Generation (RAG)</strong>: Getting Smarter Answers<br>LangChain also lets AI search for information in real-time. This is called retrieval-augmented generation (RAG). It allows the AI to look up the latest data, like news stories or facts, and use that information to create smarter answers.</p><blockquote><p>For example, if you ask about the latest trends in video games, the AI can search the web for the most up-to-date information and then explain it to you.</p></blockquote></li></ol><h2 id="Why-Do-Developers-Use-LangChain"><a href="#Why-Do-Developers-Use-LangChain" class="headerlink" title="Why Do Developers Use LangChain?"></a>Why Do Developers Use LangChain?</h2><p>There are several reasons why developers might want to use LangChain:</p><ol><li><p>Makes It Easier to Build AI Apps<br>Instead of starting from scratch, LangChain gives developers tools that speed up the process of creating AI apps. Developers can use LangChain’s building blocks to create powerful applications without needing to write everything by hand.</p></li><li><p>It’s Flexible<br>LangChain can be used for a wide variety of apps. Whether you want to build a chatbot, a smart search engine, or an app that helps you study, LangChain has tools that make it easier to put everything together.</p></li><li><p>Saves Time<br>Developers don’t have to spend a lot of time figuring out how to make an AI model work with a database or how to chain steps together. LangChain does much of the heavy lifting, so developers can focus on the fun and creative parts of building their apps.</p></li><li><p>It’s <code>Open-Source</code><br>LangChain is free for anyone to use and improve. It’s open-source, which means developers from all over the world can contribute to making it better. If you’re learning to code or want to help improve the tool, you can!</p></li></ol><h2 id="Real-World-Examples-of-LangChain"><a href="#Real-World-Examples-of-LangChain" class="headerlink" title="Real-World Examples of LangChain"></a>Real-World Examples of LangChain</h2><p>LangChain is already being used in many cool ways. Here are a few examples:</p><ol><li><p>Chatbots<br>Developers can use LangChain to build chatbots that remember previous conversations and can talk to you like a real person. For example, you could create a chatbot to help you study for a test, and it would remember what you’ve learned so far.</p></li><li><p>Smart Assistants<br>LangChain can help build systems that pull information from the internet and use AI to explain things in simple terms. For example, if you’re stuck on a science problem, an AI could look up the topic online and explain it to you in a way you understand.</p></li><li><p>Automated Content Creation<br>Some apps use LangChain to automatically write articles or summaries. For example, a news website could use LangChain to summarize long articles or pull out the key points from reports, saving readers time.</p></li><li><p>Personalized Search Engines<br>LangChain can be used to build search engines that don’t just give you a list of links but also summarize the best results for you. This could help you find the exact answer you need faster.</p></li></ol><h2 id="How-to-Get-Started-with-LangChain"><a href="#How-to-Get-Started-with-LangChain" class="headerlink" title="How to Get Started with LangChain"></a>How to Get Started with LangChain</h2><p>If you’re excited to try out LangChain, here’s how you can get started:</p><ol><li>Install Python: LangChain works with Python, a programming language that’s great for beginners.</li><li>Install LangChain: You can install LangChain by running the command <code>pip install langchain</code> in Python.</li><li>Start Building: Once LangChain is installed, you can start building your own AI-powered applications! LangChain has tutorials and guides to help you learn how to use it.</li></ol><p>For more information, check out the LangChain documentation at <a href="https://python.langchain.com/docs/introduction/">https://python.langchain.com/docs/introduction/</a></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>LangChain is a super helpful tool for developers who want to build cool apps powered by AI. It makes it easier to connect different parts of an app, like databases or the web, with a language model that can understand and generate text. Whether it’s helping with homework, answering questions, or building a chatbot, LangChain is a great way to build smarter, more interactive applications.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/langchain-image.png&quot; class=&quot;lazylo</summary>
      
    
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
  </entry>
  
  <entry>
    <title>What is Prompt Engineering? Best Practices and Examples</title>
    <link href="https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/"/>
    <id>https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/</id>
    <published>2024-11-05T14:08:09.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophisticated, a new role has emerged in the AI ecosystem: <code>the Prompt Engineer</code>. The term might sound technical or niche, but it’s actually pivotal to leveraging AI models effectively. Whether you’re interacting with AI in your personal or professional life, the quality of the interaction largely depends on how well the prompt is designed. This article will explore what a prompt engineer does, the best practices for writing effective prompts, and provide examples comparing outputs with and without a prompt engineer’s expertise.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineering.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineering.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><h2 id="What-is-a-Prompt-Engineer"><a href="#What-is-a-Prompt-Engineer" class="headerlink" title="What is a Prompt Engineer?"></a>What is a Prompt Engineer?</h2><p><em>A Prompt Engineer is someone who specializes in crafting, refining, and optimizing prompts to ensure that AI models respond with the most relevant,accurate,and actionable information.</em> The role requires a blend of creativity, technical understanding, and knowledge of the AI’s underlying model architecture.</p><p>In essence, the prompt engineer’s job is to “speak” the language of the AI model. Since AI models like <code>GPT-3</code> or <code>GPT-4</code> don’t “think” like humans, their responses depend heavily on how the question or task is framed. A prompt engineer ensures that the right context, constraints, and phrasing are in place to guide the model toward producing the most useful responses.</p><h2 id="Why-is-Prompt-Engineering-Important"><a href="#Why-is-Prompt-Engineering-Important" class="headerlink" title="Why is Prompt Engineering Important?"></a>Why is Prompt Engineering Important?</h2><p>While AI models are capable of generating human-like text and performing complex tasks, their outputs are highly sensitive to the structure of the prompt. The same AI model could provide vastly different answers depending on the way a question is asked. Prompt engineers understand this sensitivity and use it to maximize the effectiveness of the interaction with AI.</p><p>Here are some reasons why prompt engineering is important:</p><p><strong>Maximizing output quality</strong>: Well-designed prompts improve the accuracy, relevance, and clarity of responses.<br><strong>Reducing errors</strong>: By properly framing a prompt, prompt engineers can help reduce misunderstandings or irrelevant responses.<br><strong>Efficiency</strong>: Instead of relying on trial and error to get useful responses, prompt engineers streamline the interaction process, saving time and resources.<br><strong>Contextuality</strong>: A good prompt will provide the necessary context for the model, ensuring that the response is in line with the user’s expectations.</p><h2 id="The-Path-of-a-Prompt-Engineer"><a href="#The-Path-of-a-Prompt-Engineer" class="headerlink" title="The Path of a Prompt Engineer"></a>The Path of a Prompt Engineer</h2><p>The process that a prompt engineer follows to ensure optimal results involves several stages. Each stage builds upon the last, leading to an iterative cycle that refines both the prompt and the AI’s output. Here’s a breakdown of the typical path of a prompt engineer:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineer-path.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineer-path.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="The Path of a Prompt Engineer" style="width:800px;"/></div><span class="image-caption">The Path of a Prompt Engineer</span></div><h3 id="1-Task-Understanding"><a href="#1-Task-Understanding" class="headerlink" title="1.Task Understanding:"></a>1.Task Understanding:</h3><p>Before crafting any prompt, the first step is to fully understand the task at hand. This involves clarifying the user’s goal, determining the desired output format, and understanding the nuances of the request. A deep understanding of the problem ensures that the prompt engineer can craft a question or instruction that addresses all necessary aspects.</p><blockquote><p>Example: If the task is to generate a poem, the prompt engineer will need to understand the tone, style, and subject matter required.</p></blockquote><h3 id="2-Crafting-Prompts"><a href="#2-Crafting-Prompts" class="headerlink" title="2.Crafting Prompts:"></a>2.Crafting Prompts:</h3><p>The next step is to craft the prompt. This involves framing the task clearly, with enough specificity to guide the AI toward the desired output. Crafting an effective prompt is not about asking a single question, but about <em>providing the model with the right context, constraints, and direction</em>.</p><blockquote><p>Example: Instead of asking, “Write a poem,” a more specific prompt might be, “Write a rhyming poem about the beauty of autumn, focusing on imagery and feelings of nostalgia.”</p></blockquote><h3 id="3-Prompt-Alignment"><a href="#3-Prompt-Alignment" class="headerlink" title="3.Prompt Alignment:"></a>3.Prompt Alignment:</h3><p>At this stage, the prompt must be aligned with the intended outcome. This means considering the AI model’s strengths and limitations and ensuring that the prompt leads the AI to produce a response that fits the desired format, tone, and depth. The prompt should ensure the model understands the context of the task, as well as any constraints or preferences that need to be respected.</p><blockquote><p>Example: For a technical article, aligning the prompt would involve ensuring the language model knows to prioritize clarity, accuracy, and technical precision.</p></blockquote><h3 id="4-Optimizing-Prompt"><a href="#4-Optimizing-Prompt" class="headerlink" title="4.Optimizing Prompt:"></a>4.Optimizing Prompt:</h3><p>After alignment, the prompt may need further refinement. This step involves fine-tuning the wording, simplifying complex instructions, or narrowing down the scope to ensure that the prompt is as effective as possible. <em>Optimization often involves making the prompt more specific and reducing ambiguity.</em></p><blockquote><p>Example: “Write a 300-word summary of the research paper on AI ethics, emphasizing the ethical dilemmas and implications for technology companies.” This version is more optimized than a broad, vague instruction.</p></blockquote><h3 id="5-AI-Model-Processing"><a href="#5-AI-Model-Processing" class="headerlink" title="5.AI Model Processing:"></a>5.AI Model Processing:</h3><p>Once the optimized prompt is provided, the AI model processes it and generates a response. This is where the model applies its underlying machine learning architecture, leveraging its training data to formulate a response.</p><blockquote><p>Example: The AI will analyze the prompt, consider patterns in its training data, and produce a response based on its understanding of the language and context.</p></blockquote><h3 id="6-Generating-Output"><a href="#6-Generating-Output" class="headerlink" title="6.Generating Output:"></a>6.Generating Output:</h3><p>The AI model generates the initial output based on the prompt. Depending on the AI model’s capabilities, this output may vary in length, style, accuracy, or even relevance to the task.</p><blockquote><p>Example: If the task was to summarize a paper, the output might include key findings, conclusions, and references to methodology.</p></blockquote><h3 id="7-Output-Refinement"><a href="#7-Output-Refinement" class="headerlink" title="7.Output Refinement:"></a>7.Output Refinement:</h3><p>Once the output is generated, prompt engineers review and refine it. This may involve removing irrelevant information, adjusting tone, adding details, or improving clarity. In some cases, the output might need to be restructured to fit the desired format.</p><blockquote><p>Example: If the AI’s response contains tangential information or lacks clarity, the prompt engineer would reword it or fine-tune the output to better align with the user’s expectations.</p></blockquote><h3 id="8-Iterative-Improvement"><a href="#8-Iterative-Improvement" class="headerlink" title="8.Iterative Improvement:"></a>8.Iterative Improvement:</h3><p>Finally, the process of prompt engineering is iterative. After refining the output, prompt engineers analyze the effectiveness of the response and assess how the prompt can be improved for future tasks. This leads to continuous improvement, ensuring that future prompts are even more optimized, concise, and aligned with user needs.</p><blockquote><p>Example: The engineer might adjust the prompt for the next interaction to ensure more relevant details or a more focused response.</p></blockquote><h2 id="Key-Skills-and-Tools-of-a-Prompt-Engineer"><a href="#Key-Skills-and-Tools-of-a-Prompt-Engineer" class="headerlink" title="Key Skills and Tools of a Prompt Engineer"></a>Key Skills and Tools of a Prompt Engineer</h2><p>Prompt engineering requires a variety of skills:</p><p><strong>Understanding of Language Models</strong>:<br>A prompt engineer should have a deep understanding of how LLMs like GPT process language. Knowing their strengths and weaknesses allows for better prompt design.</p><p><strong>Communication Skills</strong>:<br>Effective communication is critical, as prompt engineers must be able to convey complex instructions in a way that the model can interpret clearly.</p><p><strong>Creativity and Experimentation</strong>:<br>Crafting effective prompts often requires trial and error, testing different phrasings and structures to see what works best.</p><p><strong>Analytical Thinking</strong>:<br>Understanding how different types of inputs influence the model’s outputs and iterating to improve results.</p><p>In addition to these skills, prompt engineers also use tools to test and refine their prompts. For instance, platforms like OpenAI’s Playground allow users to experiment with various prompts in real-time, while more advanced professionals might leverage APIs to automate or scale their prompt engineering work.</p><h2 id="Best-Practices-for-Prompt-Engineering"><a href="#Best-Practices-for-Prompt-Engineering" class="headerlink" title="Best Practices for Prompt Engineering"></a>Best Practices for Prompt Engineering</h2><p>There are several strategies that a prompt engineer can employ to get the most out of a language model. Below are some of the best practices:</p><ol><li><p><strong>Be Specific and Clear</strong>: Ambiguous prompts can confuse AI models, leading to vague or incorrect responses. Make sure the prompt is clear and as specific as possible.</p><blockquote><p>Example: Instead of asking, “Tell me about AI,” a more specific prompt would be, “Can you explain the difference between supervised and unsupervised learning in AI?”</p></blockquote></li><li><p><strong>Use Context Effectively</strong>: Providing context can guide the model to better understand the desired output.</p><blockquote><p>Example: Instead of saying, “Write a poem,” say, “Write a rhyming poem about the beauty of autumn with a melancholic tone.”</p></blockquote></li><li><p><strong>Limit the Scope</strong>: Sometimes, less is more. Limit the scope of the prompt to avoid overwhelming the model with too much information or too many instructions.</p><blockquote><p>Example: Instead of “Write an article about the importance of artificial intelligence in modern business, covering all aspects of AI from machine learning to natural language processing,” you could say, “Write a short article explaining the importance of AI in customer service.”</p></blockquote></li><li><p><strong>Test and Iterate</strong>: A prompt engineer should test various iterations of a prompt to identify the most effective structure.</p></li><li><p><strong>Give Examples</strong>: For tasks requiring specific output formats, include an example to guide the model.</p><blockquote><p>Example: If you want a bulleted list, you could say, “List the steps in a process to build a website. For example: Step 1: Plan the layout.”</p></blockquote></li><li><p><strong>Use Temperature and Max Tokens</strong>: Some models allow you to adjust the <code>temperature (which controls randomness)</code> and the <code>max tokens (which sets a character limit)</code> to control the output. These can be adjusted to fine-tune the model’s output.</p></li></ol><h2 id="Comparing-with-and-without-Prompt-Engineering"><a href="#Comparing-with-and-without-Prompt-Engineering" class="headerlink" title="Comparing with and without Prompt Engineering"></a>Comparing with and without Prompt Engineering</h2><p>Now let’s look at some concrete examples of how a well-crafted prompt versus a poorly constructed one can affect the outcome.</p><h3 id="Example-1-Writing-a-Research-Summary"><a href="#Example-1-Writing-a-Research-Summary" class="headerlink" title="Example 1: Writing a Research Summary"></a>Example 1: Writing a Research Summary</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize this research paper.”</p><p>The AI may generate a generic or overly simplistic summary, without capturing the key aspects of the paper, such as methodology, results, and conclusions.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize the research paper titled ‘Exploring AI Ethics in Autonomous Vehicles.’ Focus on the methodology, key findings, and implications for policy. Keep the summary under 200 words.”</p><p>The AI’s response will be more targeted, concise, and aligned with the user’s expectations, providing a detailed summary that addresses the core aspects of the paper.</p><h3 id="Example-2-Writing-a-Creative-Story"><a href="#Example-2-Writing-a-Creative-Story" class="headerlink" title="Example 2: Writing a Creative Story"></a>Example 2: Writing a Creative Story</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a story.”</p><p>The story might lack direction, coherence, or creativity, leading to a generic or even nonsensical narrative.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a short story set in a post-apocalyptic world where humans are living on Mars. The protagonist is a scientist struggling with the ethical implications of using artificial intelligence to terraform the planet. Make the tone introspective and thought-provoking.”</p><p>The story produced will be richer, more engaging, and aligned with the specific context and themes the user wanted.</p><h3 id="Example-3-Asking-for-Code"><a href="#Example-3-Asking-for-Code" class="headerlink" title="Example 3: Asking for Code"></a>Example 3: Asking for Code</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function.”</p><p>The AI may generate a simple function, but it may not meet the user’s needs or lack important features such as error handling or optimization.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function to validate an email address using regular expressions. The function should return True if the email is valid and False if it is invalid. It should also handle common edge cases such as missing domain names or incorrect characters.”</p><p>The AI’s response will be much more precise, including the correct implementation, error handling, and edge case considerations.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In the world of AI, a <code>Prompt Engineer</code> plays a critical role in ensuring that AI models deliver optimal results. The expertise of prompt engineers can dramatically influence the quality, relevance, and accuracy of responses from language models like <code>GPT-4</code>. By following best practices—such as being specific, providing context, testing different iterations, and using examples—they can significantly improve the interaction between humans and AI.</p><p>As AI continues to evolve, the role of prompt engineering will become even more important, helping users and businesses unlock the full potential of artificial intelligence. Whether it’s writing, problem-solving, or complex technical tasks, the way we interact with AI will increasingly depend on how well we craft our prompts.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophis</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
    <category term="GPT-3" scheme="https://stonefishy.github.io/tags/GPT-3/"/>
    
    <category term="Prompt Engineering" scheme="https://stonefishy.github.io/tags/Prompt-Engineering/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Azure OpenAI GPT-4 API Chat Role Usage</title>
    <link href="https://stonefishy.github.io/2024/11/01/understanding-the-azure-openai-gpt-4-api-role/"/>
    <id>https://stonefishy.github.io/2024/11/01/understanding-the-azure-openai-gpt-4-api-role/</id>
    <published>2024-11-01T10:34:01.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p><code>Azure OpenAI</code> is a service provided by Microsoft that integrates OpenAI’s advanced language models into the Azure cloud platform. It allows developers to access and use OpenAI’s capabilities, such as natural language processing, code generation, and more, through Azure’s infrastructure.</p><p>Recently, we have deployed our first version of the OpenAI <code>GPT-4</code> model into the Azure cloud platform. This model is a powerful natural language model that can generate text based on a given prompt.</p><h2 id="What-is-GPT-4"><a href="#What-is-GPT-4" class="headerlink" title="What is GPT-4?"></a>What is GPT-4?</h2><p><code>GPT-4</code> is a transformer-based language model that was developed by OpenAI. It is a powerful language model that can generate text based on a given prompt. It has been trained on a large dataset of text and can generate coherent and engaging text that is often considered to be the next big thing in language models.</p><h2 id="How-can-I-use-the-GPT-4-API"><a href="#How-can-I-use-the-GPT-4-API" class="headerlink" title="How can I use the GPT-4 API?"></a>How can I use the GPT-4 API?</h2><p>To use the GPT-4 API, you need to follow these steps:</p><ol><li>Create an Azure account.</li><li>Create a resource group.</li><li>Create a new OpenAI resource.</li><li>Generate an API key.</li><li>Use the API key to make API requests.</li></ol><h3 id="1-Create-an-Azure-account"><a href="#1-Create-an-Azure-account" class="headerlink" title="1. Create an Azure account"></a>1. Create an Azure account</h3><p>To use the GPT-4 API, you need to have an Azure account. If you don’t have one, you can create one for free by following the steps in the <a href="https://azure.microsoft.com/en-us/free/">Azure sign-up page</a>.</p><h3 id="2-Create-a-resource-group"><a href="#2-Create-a-resource-group" class="headerlink" title="2. Create a resource group"></a>2. Create a resource group</h3><p>Create a resource group to organize your Azure resources. To create a new resource group, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>Resource groups</code> option in the left-hand menu.</li><li>Click on the <code>+ Create</code> button.</li><li>Enter a name for your resource group and select your subscription.</li><li>Click on the <code>Review + create</code> button.</li></ol><h3 id="3-Create-a-new-OpenAI-resource"><a href="#3-Create-a-new-OpenAI-resource" class="headerlink" title="3. Create a new OpenAI resource"></a>3. Create a new OpenAI resource</h3><p>To create a new OpenAI resource, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>Create a resource</code> button.</li><li>Search for <code>OpenAI</code> in the search bar.</li><li>Click on the <code>OpenAI</code> resource.</li><li>Click on the <code>Create</code> button.</li><li>Enter a name for your OpenAI resource and select your subscription.</li><li>Select the resource group you created earlier.</li><li>Select the pricing tier.</li><li>Click on the <code>Create</code> button.</li></ol><h3 id="4-Generate-an-API-key"><a href="#4-Generate-an-API-key" class="headerlink" title="4. Generate an API key"></a>4. Generate an API key</h3><p>To generate an API key, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>All resources</code> option in the left-hand menu.</li><li>Search for your OpenAI resource.</li><li>Click on the resource.</li><li>Click on the <code>Show access keys</code> button.</li><li>Copy the <code>Key 1</code> value.</li></ol><h3 id="5-Use-the-API-key-to-make-API-requests"><a href="#5-Use-the-API-key-to-make-API-requests" class="headerlink" title="5. Use the API key to make API requests"></a>5. Use the API key to make API requests</h3><p>To make API requests, we need to include the API key in the request headers. Here’s an example of how to make a request to the GPT-4 API with REST styles. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="variable">$AZURE_OPENAI_ENDPOINT</span>/openai/deployments/gpt-4o/chat/completions?api-version=2023-07-01-preview \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;api-key: <span class="variable">$AZURE_OPENAI_API_KEY</span>&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;&quot;messages&quot;:[&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;There are 5 classifications: Suggestion, Meanless, Compliment, Complaint, Please provide a classification for user input.&quot;&#125;,&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Does Azure OpenAI support customer managed keys?&quot;&#125;,&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;A classification word&quot;&#125;,&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;its great and easy to use&quot;&#125;]&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>Place your API key and endpoint in the appropriate variables, and update which deployments model (gpt-4, gpt-4o or other models) and model version of your endpoint is using.</p><p>The Azure OpenAI also supports multiple programming languages, including <code>Python</code>, <code>JavaScript</code>, and <code>C#</code>. You can use the API to generate text in your preferred programming language.</p><h2 id="GPT-4-Chat-Roles"><a href="#GPT-4-Chat-Roles" class="headerlink" title="GPT-4 Chat Roles"></a>GPT-4 Chat Roles</h2><p>In above message parameter, you may notice thata there are three roles: <code>system</code>, <code>user</code>, and <code>assistant</code>. The GPT-4 API supports three chat roles. Let digger deeper into each role:</p><p><strong>System</strong>: This role sets the context or guidelines for the conversation. It’s where you can specify instructions or constraints for how the assistant should behave throughout the interaction.</p><p><strong>User</strong>: This role represents the input from the person interacting with the model. Any questions or prompts posed by the user fall under this role.</p><p><strong>Assistant</strong>: This role is for the model’s responses. It contains the output generated by the assistant based on the user input and the context provided by the system.</p><p>In another word. The <code>system</code> role sets the context, the <code>user</code> role represents the input, and the <code>assistant</code> role contains the output.</p><blockquote><p>Use system to define the conversation’s tone, behavior, or rules.<br>Use user for all queries or statements made by the person.<br>Use assistant for the model’s replies.</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Let’s say we want to classify the product feedback classification as <code>Suggestion</code>, <code>Meanless</code>, <code>Compliment</code>, <code>Complaint</code>, or <code>Others</code>. We can use the GPT-4 API to generate text based on the given prompt and classify the feedback.</p><p>First, we define the context or guidelines to let the assistant know what result we want to achieve. Given below content to the <code>system</code> role.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;There are 5 classifications: Suggestion, Meanless, Compliment, Complaint, Please provide a classification for user input.&quot;&#125;,</span><br></pre></td></tr></table></figure><p>And, we only the <code>OpenAI</code> to reply me the classification word when user input is provided. So we define the <code>assistant</code> role as <code>classification word</code>.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;A classification word&quot;&#125;</span><br></pre></td></tr></table></figure><p>Now, we can ask the user to provide the feedback and provide the <code>user</code> role.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;its great and easy to use&quot;&#125;</span><br></pre></td></tr></table></figure><p>After the conversation, the <code>assistant</code> role will provide the classification word as <code>Compliment</code>. You will notice that there is a piece of json indicates the <code>assistant</code> role content value in the response. The OpenAI gpt-4o model knows “its great and easy to use” is a “Compliment” and provides the classification word as “Compliment”.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Compliment&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/openai-chat-role-api-usage-example-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/openai-chat-role-api-usage-example-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Classification - its great and easy to use" style="width:800px;"/></div><span class="image-caption">Classification - its great and easy to use</span></div><p>Let’s try another user input.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I&#x27;m in your walls&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/openai-chat-role-api-usage-example-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/openai-chat-role-api-usage-example-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Classification - I'm in your walls" style="width:800px;"/></div><span class="image-caption">Classification - I'm in your walls</span></div><p>The <code>assistant</code> role will provide the classification word as <code>Meanless</code>. Because this input is not meanful for any product feedback.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article, we have explored the role of the Azure OpenAI GPT-4 API and how it can be used to generate text. We have also learned about the chat roles and how to use them to classify the product feedback.</p>]]></content>
    
    
    <summary type="html">In this article, we will explore the role of the Azure OpenAI GPT-4 API and how it can be used to generate text.</summary>
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
  </entry>
  
  <entry>
    <title>Data Analysis Chart by Generative AI</title>
    <link href="https://stonefishy.github.io/2024/10/29/data-analysis-chart-by-generative-ai/"/>
    <id>https://stonefishy.github.io/2024/10/29/data-analysis-chart-by-generative-ai/</id>
    <published>2024-10-29T14:18:48.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>In data analysis, we often need to create charts to visualize the data by using BI tools, such as <code>Tableau</code>, <code>Power BI</code>, <code>AWS Quicksight</code>, or <code>Qlik Sense</code>. These tools allow us to create interactive and visually appealing charts, which can help us to identify patterns and trends in the data.</p><h2 id="General-Solution-Architecture-for-Data-Analysis-BI-Chart"><a href="#General-Solution-Architecture-for-Data-Analysis-BI-Chart" class="headerlink" title="General Solution Architecture for Data Analysis BI Chart"></a>General Solution Architecture for Data Analysis BI Chart</h2><p>The general data analysis BI chart solution architecture like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-general-arch.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-general-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="General Solution Architecture for Data Analysis BI Chart" style="width:800px;"/></div><span class="image-caption">General Solution Architecture for Data Analysis BI Chart</span></div>.<p>Usually, the engieering create business chart by using BI tools after data is ETL proceseed. If the business want to see the data distribution chart, they need to ask the data engineer to create the chart. The data engineer will create the chart using BI tools and share it with the business. This may take some time and effort.</p><h2 id="Solution-Architecture-for-Data-Analysis-BI-Chart-by-Generative-AI"><a href="#Solution-Architecture-for-Data-Analysis-BI-Chart-by-Generative-AI" class="headerlink" title="Solution Architecture for Data Analysis BI Chart by Generative AI"></a>Solution Architecture for Data Analysis BI Chart by Generative AI</h2><p>Think about the scenario where the business want to see the data distribution chart without the data engineer’s help. How can we create the chart without the data engineer’s help?</p><p>One way to create the data distribution chart without the data engineer’s help is to use a generative AI model. The business just need to describe what the data they want to see and want to display as which chart type. The generative AI application will create the chart for them.</p><p>The core important thing we need to let the GenAI to understand user’s natural language and generate the information which application can be use. The solution architecture like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-AI-arch.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-AI-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AI Solution Architecture for Data Analysis BI Chart" style="width:800px;"/></div><span class="image-caption">AI Solution Architecture for Data Analysis BI Chart</span></div>.<p>The AI application will take the user’s natural language as input and generate the chart for them. The AI application will use the following steps to generate the chart:</p><ol><li>Understand the user’s natural language and generate the chart title, chart type and chart related sql.</li><li>Connect to the database or dataset and execute the chart related sql to get the data.</li><li>Use the data to create the chart using the chart type.</li></ol><p>The AI model could be <code>ChatGPT</code>, <code>OpenAI</code> or <code>Claude</code> model. The AI model will generate the chart related sql, chart type and chart title based on the user’s natural language. The AI model will use the chart type to create the chart.</p><p>For example, if the user’s natural language is “Show the distribution of the sales by product category”, the AI application will generate the chart title as “Sales Distribution by Product Category” and chart type as “Bar Chart”. The AI application will execute the following sql to get the data:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> product_category, <span class="built_in">SUM</span>(sales) <span class="keyword">as</span> total_sales</span><br><span class="line"><span class="keyword">FROM</span> sales_data</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> product_category</span><br></pre></td></tr></table></figure><p>Below is a demo to generate the chart for the user’s natural language base on testing sample data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>User input natural language: </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;I want to see the distribution of all product categories with duplicate devices removed, and exclude the empty category, please display it in a pie chart.&quot;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-1a.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-1a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>The AI model response below base on the user’s natural language and prompts.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    &#x27;sql&#x27;<span class="punctuation">:</span> <span class="string">&quot;SELECT category, COUNT(DISTINCT macaddress) as device_count FROM device_demo_data WHERE category != &#x27;&#x27; GROUP BY category ORDER BY device_count DESC&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    &#x27;chart&#x27;<span class="punctuation">:</span> &#x27;pie&#x27;<span class="punctuation">,</span> </span><br><span class="line">    &#x27;title&#x27;<span class="punctuation">:</span> &#x27;Distribution of Unique Devices by Product Category&#x27;</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>There is a question, how the AI model know to generate this data format for us? Actually it is because we provide the prompts to the AI model. The prompts will guide the AI model to generate the chart related sql, chart type and chart title. Below is sample prompts:</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">You are a data analyst. Below is the table structure information about devices reported data. I will ask you questions, and then please generate the json data format &#123;&#x27;sql&#x27;:&#x27;&#x27;,&#x27;chart&#x27;:&#x27;table&#x27;,&#x27;title&#x27;:&#x27;&#x27;&#125; based on the questions I asked. </span><br><span class="line">Emphasize: I only need this json data format. The &#x27;sql&#x27; value is used by AWS Athena to query and generate the chart data. </span><br><span class="line">The &#x27;chart&#x27; value is the chart type, &#x27;numeric&#x27; represents a just a number, &#x27;table&#x27; represents a table chart, &#x27;pie&#x27; represents a pie chart, &#x27;bar&#x27; represents a bar chart, &#x27;line&#x27; represents a line chart. </span><br><span class="line">The &#x27;title&#x27; value is the chart title. Please remember, I only need the json string format data, don&#x27;t need other sentence.</span><br><span class="line">CREATE EXTERNAL TABLE `device_demo_data`(</span><br><span class="line">  `macaddress` string COMMENT &#x27;设备mac地址 / The device macaddress&#x27;, </span><br><span class="line">  `productname` string COMMENT &#x27;设备产品名称 / The device product name&#x27;, </span><br><span class="line">  `category` string COMMENT &#x27;设备产品的分类 / The device product category&#x27;, </span><br><span class="line">  `country` string COMMENT &#x27;设备所在的国家 / The country where the device is located&#x27;, </span><br><span class="line">  `region` string COMMENT &#x27;设备上传数据所在的区域 / The region where the device data is reported&#x27;, </span><br><span class="line">  `default_region` string COMMENT &#x27;设备出厂设置的默认区域 / The default region set by the device&#x27;, </span><br><span class="line">  `oneosversion` string COMMENT &#x27;设备OneOS的版本号 / The OneOS version of the device&#x27;, </span><br><span class="line">  `firmwareversion` string COMMENT &#x27;设备的固件版本号 / The firmware version of the device&#x27;, </span><br><span class="line">  `officialversion` string COMMENT &#x27;设备是否是官方的发布版本，1为官方版本， 0为非官方版本 / Whether the device is an official release, 1 for official version, 0 for non-official version&#x27;, </span><br><span class="line">  `createtime` string COMMENT &#x27;设备上报数据的日期, 数据类型是字符串，日期格式是2024-09-01，表示2024年9月1日 / The date when the device reported data, the data type is string, the date format is 2024-09-01, which means September 1, 2024&#x27;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>We tell AI model the data schema and each field means, and indicate only need the json format response with specific field. Once the AI model generate the response, we can use it to create the chart for the user’s natural language.</p><p>We can also generate the line chart base on time line.</p><p>User input natural language: </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">How many distinct devices reported every week, exclude the empty date, display the data in line graph</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>For the front-end UI to display the chart, we can use some chart library like <code>Echarts</code>, <code>Hightcharts</code>, <code>D3.js</code> or <code>Chart.js</code>. The front-end UI display the chart base on chart type and the data which queried by SQL.</p><p>All these generated charts can be added into dashboard.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-dashboard.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-dashboard.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<h2 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h2><p>As you can see, the AI solution architecture is a new way to create BI chart. However, it still has some limitations. It can not generate the complex chart which like some BI tools advanced chart fucntionality. But it is still a good start to create the chart for business users.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In data analysis, we often need to create charts to visualize the data by using BI tools, such as &lt;code&gt;Tableau&lt;/code&gt;, &lt;code&gt;Power BI&lt;/c</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>The Intelligent SQL Generator base on Spring AI with AWS Bedrock</title>
    <link href="https://stonefishy.github.io/2024/10/23/intelligent-sql-generator-base-on-spring-ai-with-aws-bedrock/"/>
    <id>https://stonefishy.github.io/2024/10/23/intelligent-sql-generator-base-on-spring-ai-with-aws-bedrock/</id>
    <published>2024-10-23T15:01:12.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>The generative AI is a type of artificial intelligence (AI) that can learn from data and generate new data. In this article, we will discuss how to build an intelligent SQL generator using <code>Spring AI</code> and <code>AWS Bedrock</code>. For example, the application able to provide the data sql to us after we input the natural language questions, and we can query the data by using the sql, even display the chart base on data queried.</p><h2 id="Spring-AI"><a href="#Spring-AI" class="headerlink" title="Spring AI"></a>Spring AI</h2><p>The <code>Spring AI</code> is a project of <code>Spring</code>. It support for all major AI Model providers such as <code>Anthropic</code>, <code>OpenAI</code>, <code>Microsoft</code>, <code>Amazon</code>, <code>Google</code>, and <code>Ollama</code>. Model type supports such as <code>Chart Completion</code>, <code>Text to Image</code>, <code>Text to Speech</code>, <code>Translation</code>, <code>Audio Transcription</code> and so on. It make it easy to integrate AI models into the application.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/spring-ai.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/spring-ai.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Spring AI" style="width:500px;"/></div><span class="image-caption">Spring AI</span></div><h2 id="AWS-Bedrock"><a href="#AWS-Bedrock" class="headerlink" title="AWS Bedrock"></a>AWS Bedrock</h2><p>Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case. It contains <code>Anthropic</code> (<code>Claude</code>), <code>Meta</code> (<code>Llama</code>) and <code>Stability AI</code> models. In this blog, we will use <code>Claude</code> AI model of <code>Anthropic</code> to build our intelligent SQL generator.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-ai.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-ai.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock" style="width:600px;"/></div><span class="image-caption">AWS Bedrock</span></div><h2 id="Building-Intelligent-SQL-Generator"><a href="#Building-Intelligent-SQL-Generator" class="headerlink" title="Building Intelligent SQL Generator"></a>Building Intelligent SQL Generator</h2><p>Assuming we’re data analyzer, we have product_sales, products and customers three tables data in mysql. And we want to query the data by input natural language instead of write specific SQL manually. We can use AI to understand user natural langauge to generate the SQL base on table schemas. Let’s get start. </p><h3 id="Create-a-new-Spring-Boot-project"><a href="#Create-a-new-Spring-Boot-project" class="headerlink" title="Create a new Spring Boot project"></a>Create a new Spring Boot project</h3><p>Create a <code>Spring Boot</code> project with restful api, add the following dependencies in maven <code>pom.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.ai<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-ai-bedrock-ai-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The <code>spring-ai-bedrock-ai-spring-boot-starter</code> is library that provides integration with <code>AWS Bedrock</code> models in <code>Spring AI</code>.</p><h3 id="Configure-AWS-Bedrock-configuraitons"><a href="#Configure-AWS-Bedrock-configuraitons" class="headerlink" title="Configure AWS Bedrock configuraitons"></a>Configure AWS Bedrock configuraitons</h3><p>In application.properties, configur below configurations.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=spring-ai-datasql</span><br><span class="line">spring.ai.bedrock.aws.region=us-east-1</span><br><span class="line">spring.ai.bedrock.aws.timeout=5m</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.enabled=true</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.options.max-tokens=4000</span><br><span class="line"></span><br><span class="line"># config below AWS credential key, configure it in Java environments or System environments</span><br><span class="line">spring.ai.bedrock.aws.access-key=$&#123;AWS_ACCESS_KEY_ID&#125;</span><br><span class="line">spring.ai.bedrock.aws.secret-key=$&#123;AWS_SECRET_ACCESS_KEY&#125;</span><br></pre></td></tr></table></figure><h3 id="Prepare-prompts-for-AI"><a href="#Prepare-prompts-for-AI" class="headerlink" title="Prepare prompts for AI"></a>Prepare prompts for AI</h3><p>Since we only need AI to generate the SQL base on mysql table schema. So we need prepare prompts to <code>AI</code> to fully understand our requirements. Below is <code>prompts.txt</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">There are 3 mysql tables schema product_sales, products, customers.</span><br><span class="line">CREATE TABLE product_sales (</span><br><span class="line">    sale_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    product_id INT NOT NULL,</span><br><span class="line">    sale_date DATETIME DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">    price DECIMAL(10, 2) NOT NULL,</span><br><span class="line">    customer_id INT,</span><br><span class="line">    region VARCHAR(100),</span><br><span class="line">    FOREIGN KEY (product_id) REFERENCES products(product_id),</span><br><span class="line">    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE products (</span><br><span class="line">    product_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    product_name VARCHAR(100),</span><br><span class="line">    product_category VARCHAR(100)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE customers (</span><br><span class="line">    customer_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    customer_name VARCHAR(100)</span><br><span class="line">);</span><br><span class="line">I will ask you question, please base on table schema to generate the SQL text in single line, please note I only need full correct sql text, do not</span><br><span class="line">need other text or any other characters.</span><br></pre></td></tr></table></figure><p>In above prompts, you can see it tells AI we only need SQL text base on the 3 mysql table schemas.</p><h3 id="Core-Code"><a href="#Core-Code" class="headerlink" title="Core Code"></a>Core Code</h3><p>Create a restful controller and pass the prompts and user input message to AI model.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spring.ai.datasql.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.ai.bedrock.anthropic3.BedrockAnthropic3ChatModel;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.*;</span><br><span class="line"><span class="keyword">import</span> spring.ai.datasql.service.PromptService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SQLGenController</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BedrockAnthropic3ChatModel chatModel;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> PromptService prompts;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SQLGenController</span><span class="params">(BedrockAnthropic3ChatModel chatModel)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.chatModel = chatModel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/ai/sql&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Map <span class="title function_">generate</span><span class="params">(<span class="meta">@RequestBody</span> String message)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">newMsg</span> <span class="operator">=</span> prompts.getContent() + message;</span><br><span class="line">        <span class="keyword">return</span> Map.of(<span class="string">&quot;sql&quot;</span>, chatModel.call(newMsg));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, we inject <code>BedrockAnthropic3ChatModel</code> which is <code>Anthropic</code> model of <code>AWS Bedrock</code> provided by <code>Spring AI</code>. We also inject <code>PromptService</code> which is a service to read prompts.<br>In <code>generate</code> method, we read prompts from <code>PromptService</code> and append user input message to it. Then we call <code>chatModel.call</code> method to generate the SQL text.</p><p>Code of <code>PromptService</code> to read prompts from file.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spring.ai.datasql.service;</span><br><span class="line"><span class="keyword">import</span> jakarta.annotation.PostConstruct;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Files;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Paths;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PromptService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;classpath:prompts.txt&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> org.springframework.core.io.Resource resource;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String fileContent;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        fileContent = <span class="keyword">new</span> <span class="title class_">String</span>(Files.readAllBytes(Paths.get(resource.getURI())));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getContent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fileContent;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Run-the-application"><a href="#Run-the-application" class="headerlink" title="Run the application"></a>Run the application</h3><p>Run the application and test the API by sending a request with user input message. We may encounter below errors.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-model-can-not-access.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-model-can-not-access.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock Model can not access"/></div><span class="image-caption">AWS Bedrock Model can not access</span></div><p>This is because the <code>spring.ai.bedrock.anthropic3.chat.model</code> in  current Spring AI version default value is <code>anthropic.claude-3-sonnet-20240229-v1:0</code>. Let’s check the anthropic available Claude models in AWS Bedrock. Here we use <code>Claude 3.5</code> AI model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-claude-model-id.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-claude-model-id.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock Anthropic Claude Model Id"/></div><span class="image-caption">AWS Bedrock Anthropic Claude Model Id</span></div><p>Copy this model id and update the <code>spring.ai.bedrock.anthropic3.chat.model</code> in <code>application.properties</code> file. The fully updated <code>application.properties</code> file should be like below.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=spring-ai-datasql</span><br><span class="line">spring.ai.bedrock.aws.region=us-east-1</span><br><span class="line">spring.ai.bedrock.aws.timeout=5m</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.enabled=true</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.options.max-tokens=4000</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.model=anthropic.claude-3-5-sonnet-20240620-v1:0</span><br><span class="line"></span><br><span class="line"># config below AWS credential key, it also can be configure in Java environments or System environments</span><br><span class="line">spring.ai.bedrock.aws.access-key=$&#123;AWS_ACCESS_KEY_ID&#125;</span><br><span class="line">spring.ai.bedrock.aws.secret-key=$&#123;AWS_SECRET_ACCESS_KEY&#125;</span><br></pre></td></tr></table></figure><p>Now, we can run the application and test the API.</p><h4 id="Test-Example-1"><a href="#Test-Example-1" class="headerlink" title="Test Example 1"></a>Test Example 1</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">What&#x27;s the total prices of product sales ?</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><p>The response will be like below.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(price) <span class="keyword">FROM</span> product_sales;</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>The <code>AI</code> model can generate the SQL text base on user input message.</p><h4 id="Test-Example-2"><a href="#Test-Example-2" class="headerlink" title="Test Example 2"></a>Test Example 2</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">How many customers by our products? I only need unique customers.</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id) <span class="keyword">FROM</span> product_sales</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-3"><a href="#Test-Example-3" class="headerlink" title="Test Example 3"></a>Test Example 3</h4><p><strong>Input:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I want to see the total sales prices for each product categories.</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> product_category, <span class="built_in">SUM</span>(price) <span class="keyword">AS</span> total_sales <span class="keyword">FROM</span> product_sales <span class="keyword">JOIN</span> products <span class="keyword">ON</span> product_sales.product_id <span class="operator">=</span> products.product_id <span class="keyword">GROUP</span> <span class="keyword">BY</span> product_category;</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-4"><a href="#Test-Example-4" class="headerlink" title="Test Example 4"></a>Test Example 4</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please show me all sales data which contains price, sales date, customer name and product name and product categories</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ps.price, ps.sale_date, c.customer_name, p.product_name, p.product_category <span class="keyword">FROM</span> product_sales ps <span class="keyword">JOIN</span> products p <span class="keyword">ON</span> ps.product_id <span class="operator">=</span> p.product_id <span class="keyword">JOIN</span> customers c <span class="keyword">ON</span> ps.customer_id <span class="operator">=</span> c.customer_id</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-4.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-5"><a href="#Test-Example-5" class="headerlink" title="Test Example 5"></a>Test Example 5</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please show total sales prices of each product category on 2nd quarter this year</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> p.product_category, <span class="built_in">SUM</span>(ps.price) <span class="keyword">AS</span> total_sales <span class="keyword">FROM</span> product_sales ps <span class="keyword">JOIN</span> products p <span class="keyword">ON</span> ps.product_id <span class="operator">=</span> p.product_id <span class="keyword">WHERE</span> <span class="keyword">YEAR</span>(ps.sale_date) <span class="operator">=</span> <span class="keyword">YEAR</span>(CURDATE()) <span class="keyword">AND</span> QUARTER(ps.sale_date) <span class="operator">=</span> <span class="number">2</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> p.product_category</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-5.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>As you can see the <code>AI</code> model can generate the SQL text base on user input message. Base on this function, we can download the data from mysql or display the chart base on data queried. It’s good for business analyst to query the data by natural language.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The generative AI is a type of artificial intelligence (AI) that can learn from data and generate new data. In this article, we will disc</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
    <category term="Spring AI" scheme="https://stonefishy.github.io/tags/Spring-AI/"/>
    
  </entry>
  
  <entry>
    <title>The useEffect of React Runs Twice in Development Mode.</title>
    <link href="https://stonefishy.github.io/2024/10/16/the-useeffect-of-react-runs-twice-in-development-mode/"/>
    <id>https://stonefishy.github.io/2024/10/16/the-useeffect-of-react-runs-twice-in-development-mode/</id>
    <published>2024-10-16T16:23:44.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>Have you noticed that your <code>useEffect</code> hook of <code>React</code> runs twice when the page first loads in development mode? This occurs because since <code>React 18</code>, it can be confusing, especially for new developers. Let’s explore why this happens and what it means.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-hook-useEffect.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-hook-useEffect.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React Hook useEffect" style="width:800px;"/></div><span class="image-caption">React Hook useEffect</span></div><h2 id="What-is-useEffect"><a href="#What-is-useEffect" class="headerlink" title="What is useEffect?"></a>What is <code>useEffect</code>?</h2><p><code>useEffect</code> is a hook that allows you to perform side effects in your components. Side effects can be things like <strong>fetching data</strong>, <strong>subscribing to events</strong>, or <strong>changing the DOM</strong>. This hook takes two arguments:</p><ol><li>A function to run your side effect.</li><li>An optional array of dependencies that tells React when to run the effect again.</li></ol><p>Here’s a simple example of useEffect in action:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; useEffect, useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">ExampleComponent</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Effect has been executed&#x27;</span>);</span><br><span class="line">    <span class="comment">// Side effect logic here</span></span><br><span class="line">  &#125;, [count]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">p</span>&gt;</span>You clicked &#123;count&#125; times<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;()</span> =&gt;</span> setCount(count + 1)&#125;&gt;Click me<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, the log ‘Effect has been executed’ will be printed to the console twice when the component is first render on development mode.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-useEffect-runs-twice.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-useEffect-runs-twice.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React useEffect runs twice in development mode"/></div><span class="image-caption">React useEffect runs twice in development mode</span></div><h2 id="Why-Does-useEffect-Run-Twice-in-Development-Mode"><a href="#Why-Does-useEffect-Run-Twice-in-Development-Mode" class="headerlink" title="Why Does useEffect Run Twice in Development Mode?"></a>Why Does useEffect Run Twice in Development Mode?</h2><p>When you run your React app in development mode, you might see that the useEffect runs twice when the component loads for the first time. This can be confusing, especially for new developers.</p><h3 id="Reasons-for-the-Double-Execution"><a href="#Reasons-for-the-Double-Execution" class="headerlink" title="Reasons for the Double Execution"></a>Reasons for the Double Execution</h3><p><strong>Strict Mode:</strong> This behavior is part of React’s <code>Strict Mode</code>. It purposely runs certain lifecycle methods and hooks like useEffect twice during development. This helps check if your code can handle side effects correctly.</p><p><strong>Testing Effects:</strong> By running the effect two times, React tests if your side effects can handle being called multiple times without causing bugs. This helps catch problems early.</p><h3 id="What-Happens-in-Production"><a href="#What-Happens-in-Production" class="headerlink" title="What Happens in Production?"></a>What Happens in Production?</h3><span class='pbg danger'>The double call only happens in development mode. When you make your app for production</span><h2 id="How-to-Handle-the-Double-Execution"><a href="#How-to-Handle-the-Double-Execution" class="headerlink" title="How to Handle the Double Execution"></a>How to Handle the Double Execution</h2><p>Here are some tips for dealing with the double execution of useEffect:</p><p><strong>Be Careful with State Updates</strong>: If your effect updates state, make sure it’s safe to run the effect multiple times without causing issues.</p><p><strong>Use Cleanup Functions</strong>: Always return a cleanup function from your useEffect to free up resources and avoid memory issues.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// Your side effect code here</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// Cleanup code here</span></span><br><span class="line">  &#125;;</span><br><span class="line">&#125;, [dependencies]);</span><br></pre></td></tr></table></figure><p><strong>Test Your Effects</strong>: Use the extra invocation to ensure that your effects work correctly.</p><h2 id="Disable-Strict-Mode"><a href="#Disable-Strict-Mode" class="headerlink" title="Disable Strict Mode"></a>Disable Strict Mode</h2><p>It is not recommend this way, but if you want to disable Strict Mode, in <code>React 18</code> you can disable Strict Mode by removing the <code>&lt;React.StrictMode&gt;</code> tag from the return statement in your root component.</p><p>In <code>Next.js</code>, you can disable Strict Mode by setting the following parameter in <code>next.config.js</code>:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">  <span class="attr">reactStrictMode</span>: <span class="literal">false</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><span class='pbg green'>Seeing useEffect run twice in development mode can be surprising</span> Understanding this behavior and preparing your code for it will allow you to use React hooks effectively and build better applications.<p>Even though this might seem confusing at first, it’s an important part of the React development experience. Happy coding!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Have you noticed that your &lt;code&gt;useEffect&lt;/code&gt; hook of &lt;code&gt;React&lt;/code&gt; runs twice when the page first loads in development mode? Th</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>AWS Glue Iceberg tables schema can&#39;t be updated with Pulumi</title>
    <link href="https://stonefishy.github.io/2024/10/09/aws-glue-iceberg-tables-schema-can-t-be-updated-with-pulumi/"/>
    <id>https://stonefishy.github.io/2024/10/09/aws-glue-iceberg-tables-schema-can-t-be-updated-with-pulumi/</id>
    <published>2024-10-09T09:46:22.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>Recently, we’re planing to use <code>Pulumi</code> to manage all current existing <code>AWS Glue Datacatalog</code> tables which are <code>Iceberg</code> format. For the <code>Iceberg</code> tables, I have post a blog before to talk about what is iceberg and what’s feature of it. Here is post link: <a href="https://stonefishy.github.io/2020/05/23/what-is-apache-iceberg/">https://stonefishy.github.io/2020/05/23/what-is-apache-iceberg/</a></p><p>To manage the AWS Glue Iceberg tables with <code>Pulumi</code>, due to our catalog table schemas are continue changes base on requirements. We need to do some technical POC whethere the pulumi can also support to update the iceberg metadata schema as well.</p><h2 id="Create-Glue-Iceberg-Table"><a href="#Create-Glue-Iceberg-Table" class="headerlink" title="Create Glue Iceberg Table"></a>Create Glue Iceberg Table</h2><p>We’re using <code>Pulumi</code> to manage the AWS Cloud Infrastructure. Before create glue table, a glue database is indeed.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_database_test = aws.glue.CatalogDatabase(<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    create_table_default_permissions=[aws.glue.CatalogDatabaseCreateTableDefaultPermissionArgs(</span><br><span class="line">        permissions=[<span class="string">&quot;ALL&quot;</span>],</span><br><span class="line">        principal=aws.glue.CatalogDatabaseCreateTableDefaultPermissionPrincipalArgs(</span><br><span class="line">            data_lake_principal_identifier=<span class="string">&quot;IAM_ALLOWED_PRINCIPALS&quot;</span>,</span><br><span class="line">        ),</span><br><span class="line">    )],</span><br><span class="line">    name=<span class="string">&quot;pulumi_database_test&quot;</span>)</span><br></pre></td></tr></table></figure><p>Above code is to create a glue database named pulumi_database_test. Next Step is to create a glue table with <code>Iceberg</code> format.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_external_table_test = aws.glue.CatalogTable(<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    database_name=<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    storage_descriptor=aws.glue.CatalogTableStorageDescriptorArgs(</span><br><span class="line">        additional_locations=[<span class="string">&quot;s3://xxx/pulumi_external_table_test/data&quot;</span>],</span><br><span class="line">        columns=[</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test1&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test2&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test3&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;boolean&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test4&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ],</span><br><span class="line">        location=<span class="string">&quot;s3://xxx/pulumi_external_table_test&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    table_type=<span class="string">&quot;EXTERNAL_TABLE&quot;</span>,</span><br><span class="line">        open_table_format_input=aws.glue.CatalogTableOpenTableFormatInputArgs(</span><br><span class="line">        iceberg_input=aws.glue.CatalogTableOpenTableFormatInputIcebergInputArgs(</span><br><span class="line">            metadata_operation=<span class="string">&quot;CREATE&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>There is important thing to notice here is that we need to set <code>open_table_format_input</code> with <code>iceberg_input</code> and set <code>metadata_operation</code> as <code>CREATE</code>. This is because we want to create a new Iceberg table with new schema. </p><p>Below is glue iceberg table created screenshot. You can see the 4 fields is added in schema and table format is <code>Apache Iceberg</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-table.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-table.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue Table Schema Created by Pulumi"/></div><span class="image-caption">AWS Glue Table Schema Created by Pulumi</span></div><p>Next, let’s check the important file that is <code>Apache Iceberg</code> metadata file which is located in <code>s3://xxx/pulumi_external_table_test/metadata/</code>.  Download this json file <code>00006-fd122b03-a7aa-42cf-8fec-001535a9fcf5.metadata.json</code> from <code>S3</code>. The 4 fields are defined in metadata json file. That is good. The metadata json is created as well when creating glue table.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-metadata.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-metadata.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue Table Iceberg metadata"/></div><span class="image-caption">AWS Glue Table Iceberg metadata</span></div><h2 id="Insert-new-data-in-Glue-iceberg-table"><a href="#Insert-new-data-in-Glue-iceberg-table" class="headerlink" title="Insert new data in Glue iceberg table"></a>Insert new data in Glue iceberg table</h2><p>Let’s using <code>AWS Athena</code> to insert a test data in the table.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pulumi_database_test.pulumi_external_table_test(test1,test2,test3,test4) <span class="keyword">VALUES</span>(<span class="string">&#x27;1a&#x27;</span>, <span class="string">&#x27;2a&#x27;</span>, <span class="literal">true</span>, <span class="string">&#x27;4a&#x27;</span>)</span><br></pre></td></tr></table></figure><p>The data is insert success and we can use <code>SELECT</code> sql to query the data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-table-query.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-table-query.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Query inserted data in AWS Glue Iceberg table"/></div><span class="image-caption">Query inserted data in AWS Glue Iceberg table</span></div><p>In Iceberg table, we can <code>insert</code>, <code>update</code>, <code>delete</code> data as well.</p><h2 id="Update-Glue-Iceberg-table-schema"><a href="#Update-Glue-Iceberg-table-schema" class="headerlink" title="Update Glue Iceberg table schema"></a>Update Glue Iceberg table schema</h2><p>Let’s add a new field <code>test5</code> in the glue iceberg table base on previous code.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_external_table_test = aws.glue.CatalogTable(<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    database_name=<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    storage_descriptor=aws.glue.CatalogTableStorageDescriptorArgs(</span><br><span class="line">        additional_locations=[<span class="string">&quot;s3://xxx/pulumi_external_table_test/data&quot;</span>],</span><br><span class="line">        columns=[</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test1&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test2&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test3&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;boolean&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test4&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test5&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ],</span><br><span class="line">        location=<span class="string">&quot;s3://xxx/pulumi_external_table_test&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    table_type=<span class="string">&quot;EXTERNAL_TABLE&quot;</span>,</span><br><span class="line">        open_table_format_input=aws.glue.CatalogTableOpenTableFormatInputArgs(</span><br><span class="line">        iceberg_input=aws.glue.CatalogTableOpenTableFormatInputIcebergInputArgs(</span><br><span class="line">            metadata_operation=<span class="string">&quot;CREATE&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Execute <code>pulumi up</code> command to update the glue table schema.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-update-by-pulumi.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-update-by-pulumi.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi update AWS Glue Iceberg table schema"/></div><span class="image-caption">Pulumi update AWS Glue Iceberg table schema</span></div><p>After that, we can check the glue table schema is updated to add a new field <code>test5</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-table-new-field.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-table-new-field.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue iceberg table new field"/></div><span class="image-caption">AWS Glue iceberg table new field</span></div><p>Let’s insert new data in the table with new field <code>test5</code> and run it in <code>AWS Athena</code>.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pulumi_database_test.pulumi_external_table_test(test1,test2,test3,test4,test5) <span class="keyword">VALUES</span>(<span class="string">&#x27;1b&#x27;</span>, <span class="string">&#x27;2b&#x27;</span>, <span class="literal">true</span>, <span class="string">&#x27;4b&#x27;</span>, <span class="string">&#x27;5b&#x27;</span>)</span><br></pre></td></tr></table></figure><p>The Athena execute show below errors:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">COLUMN_NOT_FOUND: Insert column name does not exist in target table: test5. If a data manifest file was generated at &#x27;s3://xxxxxx/4c346103-60d2-45ea-9813-d7060bd5efe9/Unsaved/2024/10/09/37f67a67-4604-43cb-b113-af351c363a51-manifest.csv&#x27;, you may need to manually clean the data from locations specified in the manifest. Athena will not delete data in your account.</span><br><span class="line">This query ran against the &quot;pulumi_database_test&quot; database, unless qualified by the query. Please post the error message on our forum  or contact customer support  with Query Id: 37f67a67-4604-43cb-b113-af351c363a51</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-athena-insert-failed.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-athena-insert-failed.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Athena insert glue iceberg table failed"/></div><span class="image-caption">AWS Athena insert glue iceberg table failed</span></div><p>But when we check the <code>Apache Iceberg</code> metadata file again. The new field <code>test5</code> is not added in the new metadata file. That’s why the insert new data with new field failed.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-metadata-not-updated.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-metadata-not-updated.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue iceberg table metadata not updated"/></div><span class="image-caption">AWS Glue iceberg table metadata not updated</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In Pulumi documentation. The <code>metadata_operation</code> of <code>iceberg_input</code> in <code>open_table_format_input</code> is only support <code>CREATE</code> value. It seems it only can create the iceberg metadata file when glue table created.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-pulumi-doc.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-pulumi-doc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi API Doc"/></div><span class="image-caption">Pulumi API Doc</span></div><p>It seems this is <code>pulumi</code> issue. It is not updating the iceberg metadata file when the glue table schema is updated. I’ve raised a issue to pulumi,  here is issue link: <a href="https://github.com/pulumi/pulumi/issues/17516">https://github.com/pulumi/pulumi/issues/17516</a>. Hope this issue can be fixed soon.</p><p>Mean while, I found there is same issue in <code>Terraform</code> which also can not update the iceberg metadata file when the glue table schema is updated. Terraform issue link here <a href="https://github.com/hashicorp/terraform-provider-aws/issues/36641">https://github.com/hashicorp/terraform-provider-aws/issues/36641</a>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h2&gt;&lt;p&gt;Recently, we’re planing to use &lt;code&gt;Pulumi&lt;/code&gt;</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
  <entry>
    <title>User Survey Feedback Sentiment Analysis Base on AWS Cloud Solution</title>
    <link href="https://stonefishy.github.io/2024/09/19/user-survey-feedback-sentiment-analysis-base-on-aws-cloud-solution/"/>
    <id>https://stonefishy.github.io/2024/09/19/user-survey-feedback-sentiment-analysis-base-on-aws-cloud-solution/</id>
    <published>2024-09-19T14:00:33.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The App Product User Survey Feedback Sentiment Analysis Solution is a cloud-based solution that uses AWS services to analyze user feedback and sentiment of the app product. The solution uses Amazon Comprehend to perform sentiment analysis on the feedback and Amazon S3 to store the data. The solution is designed to be scalable and cost-effective, and can be easily integrated into any app product.</p><p>Basically, our survey feedback file is Excel file that contains the user feedback of app and related application info such as OS verion and app version. The feedback text is different language from global users, so we need to translate the text into English using Amazon Translate.  Besides, the feedback file is generated monthly. So, the solution will extract the feedback data from the Excel file, translate the text into English using Amazon Translate, perform sentiment analysis using Amazon Comprehend, and store the data in Amazon S3. The solution will also provide a dashboard to visualize the sentiment analysis results.</p><p>The <code>Amazon Comprehend</code> is a natural language processing (NLP) service that can analyze text and extract insights such as sentiment, syntax, entities, and key phrases. </p><h2 id="Solution-Architecture"><a href="#Solution-Architecture" class="headerlink" title="Solution Architecture"></a>Solution Architecture</h2><p>Below is the high-level architecture of the solution:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-sentiment-analysis-solution.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-sentiment-analysis-solution.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Sentiment Analysis Solution"/></div><span class="image-caption">AWS Sentiment Analysis Solution</span></div><h3 id="AWS-Services-Used"><a href="#AWS-Services-Used" class="headerlink" title="AWS Services Used"></a>AWS Services Used</h3><p>The solution uses the following AWS services:<br><code>AWS S3</code>: Amazon Simple Storage Service (S3) is a scalable object storage service that can store large amounts of data.<br><code>AWS Lambda</code>: AWS Lambda is a serverless compute service that can run code without provisioning or managing servers.<br><code>AWS Comprehend</code>: Amazon Comprehend is a natural language processing (NLP) service that can analyze text and extract insights such as sentiment, syntax, entities, and key phrases.<br><code>AWS SNS</code>: Amazon Simple Notification Service (SNS) is a messaging service that can be used to send notifications to users.<br><code>AWS Translate</code>: Amazon Translate is a machine translation service that can translate text from one language to another.<br><code>AWS SQS</code>: Amazon Simple Queue Service (SQS) is a messaging service that can be used to store and process large amounts of messages.<br><code>AWS CloudWatch</code>: Amazon CloudWatch is a monitoring service that can be used to monitor the solution and generate metrics.<br><code>AWS Glue</code>: Amazon Glue is a serverless ETL (extract, transform, and load) service that can be used to extract data from the survey feedback file and store it in Amazon S3.<br><code>AWS Athena</code>: Amazon Athena is a serverless data analytics service that can be used to query and analyze data stored in Amazon S3.<br><code>AWS QuickSight</code>: Amazon QuickSight is a business intelligence (BI) service that can be used to create visualizations and dashboards based on the sentiment analysis results.</p><h3 id="Solution-Implementation"><a href="#Solution-Implementation" class="headerlink" title="Solution Implementation"></a>Solution Implementation</h3><p>The solution implementation is divided into the following steps:</p><ol><li>Create an Amazon S3 bucket as raw data bucket to store the survey feedback Excel file.</li><li>Uploaded a survey feedback Excel file to the S3 bucket to trigger the AWS Lambda function.</li><li>AWS Lambda to extract the survey feedback data from the Excel file, translate the text into English using Amazon Translate, sentiment analysis using Amazon Comprehend, and store the data as Parquet format in another Amazon S3 Bucket.</li><li>Create an Amazon SNS topic to notify users by email when the Lambda process data failed.</li><li>Create an Amazon CloudWatch to log the lamdba exeuction logs, generate metrics.</li><li>AWS Glue Crawler to extract the parquet data from the processed amazon S3 bucket and generate a table schema.</li><li>Using Amazon Athena to query the data from the processed Amazon S3 bucket.</li><li>Create an Amazon QuickSight dashboard to visualize the sentiment analysis results.</li></ol><p>The AWS Lambda core function code is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pyarrow <span class="keyword">as</span> pa</span><br><span class="line"><span class="keyword">import</span> pyarrow.parquet <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> urlparse</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">S3_TARGET_BUCKET = os.environ[<span class="string">&#x27;QE_SURVEY_PROCESSED_TARGET_BUCKET&#x27;</span>]</span><br><span class="line">SNS_TOPIC_ARN = os.environ[<span class="string">&#x27;SNS_TOPIC_ARN&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">translate_feedbacks</span>(<span class="params">feedbacks</span>):</span><br><span class="line">    translate = boto3.client(<span class="string">&#x27;translate&#x27;</span>)</span><br><span class="line">    feedbacks_en = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Translate to auto detect language and translate feedback, total <span class="subst">&#123;feedbacks.__len__()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feedback <span class="keyword">in</span> feedbacks:</span><br><span class="line">        response = translate.translate_text(</span><br><span class="line">            Text=feedback,</span><br><span class="line">            SourceLanguageCode=<span class="string">&#x27;auto&#x27;</span>,  <span class="comment"># Detect source language automatically</span></span><br><span class="line">            TargetLanguageCode=<span class="string">&#x27;en&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        feedbacks_en.append(response[<span class="string">&#x27;TranslatedText&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Finished transalate sourceText: <span class="subst">&#123;feedback&#125;</span> to targetText: <span class="subst">&#123;response[<span class="string">&#x27;TranslatedText&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feedbacks_en</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comprehend_sentiment</span>(<span class="params">feedbacks</span>):</span><br><span class="line">    comprehend = boto3.client(<span class="string">&#x27;comprehend&#x27;</span>)</span><br><span class="line">    batch_size = <span class="number">25</span></span><br><span class="line">    all_sentiments = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Comprehend AI to analysis feedback, total <span class="subst">&#123;feedbacks.__len__()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feedbacks), batch_size):</span><br><span class="line">        batch_feedbacks = feedbacks[i:i+batch_size]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Comprehend AI to analysis feedback, batch <span class="subst">&#123;i&#125;</span> - <span class="subst">&#123;i+batch_size&#125;</span>&quot;</span>)</span><br><span class="line">        comprehend_response = comprehend.batch_detect_sentiment(TextList=batch_feedbacks, LanguageCode=<span class="string">&#x27;en&#x27;</span>)</span><br><span class="line">        sentiments = [response[<span class="string">&#x27;Sentiment&#x27;</span>] <span class="keyword">for</span> response <span class="keyword">in</span> comprehend_response[<span class="string">&#x27;ResultList&#x27;</span>]]</span><br><span class="line">        all_sentiments.extend(sentiments)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> all_sentiments</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">    sns_client = boto3.client(<span class="string">&#x27;sns&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    source_bucket = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;bucket&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    source_key = urlparse.unquote_plus(event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;object&#x27;</span>][<span class="string">&#x27;key&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    target_bucket = S3_TARGET_BUCKET</span><br><span class="line">    target_key = <span class="string">f&quot;qe-survey/<span class="subst">&#123;source_key.replace(<span class="string">&#x27;.xlsx&#x27;</span>, <span class="string">&#x27;.parquet&#x27;</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = s3.get_object(Bucket=source_bucket, Key=source_key)</span><br><span class="line">        excel_file = response[<span class="string">&#x27;Body&#x27;</span>].read()</span><br><span class="line">        </span><br><span class="line">        columns = [<span class="string">&#x27;ce_timestamp&#x27;</span>, <span class="string">&#x27;ce_host_id&#x27;</span>, <span class="string">&#x27;ce_host_os&#x27;</span>, <span class="string">&#x27;ce_hw&#x27;</span>, <span class="string">&#x27;ce_fw&#x27;</span>, <span class="string">&#x27;ce_sw&#x27;</span>, <span class="string">&#x27;survey_feedback&#x27;</span>, <span class="string">&#x27;survey_rating&#x27;</span>]</span><br><span class="line">        df = pd.read_excel(io.BytesIO(excel_file), usecols=columns)</span><br><span class="line">        df[<span class="string">&#x27;ce_timestamp&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;ce_timestamp&#x27;</span>], <span class="built_in">format</span>=<span class="string">&#x27;%Y-%m-%d %H:%M:%S:%f&#x27;</span>)</span><br><span class="line">        df[<span class="string">&#x27;survey_feedback&#x27;</span>] = df[<span class="string">&#x27;survey_feedback&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">        valid_df = df[df[<span class="string">&#x27;survey_feedback&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.strip() != <span class="string">&#x27;&#x27;</span>)]</span><br><span class="line">        valid_df = valid_df[valid_df[<span class="string">&#x27;survey_feedback&#x27;</span>] != <span class="string">&#x27;nan&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        feedbacks = valid_df[<span class="string">&#x27;survey_feedback&#x27;</span>].tolist()</span><br><span class="line">        </span><br><span class="line">        feedbacks_en = translate_feedbacks(feedbacks)</span><br><span class="line">        valid_df[<span class="string">&quot;survey_feedback_en&quot;</span>]= feedbacks_en</span><br><span class="line">        valid_df[<span class="string">&#x27;sentiment&#x27;</span>] = comprehend_sentiment(feedbacks_en)</span><br><span class="line">        </span><br><span class="line">        parquet_buffer = io.BytesIO()</span><br><span class="line">        pq.write_table(pa.Table.from_pandas(valid_df), parquet_buffer)</span><br><span class="line">        parquet_buffer.seek(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        s3.put_object(Bucket=target_bucket, Key=target_key, Body=parquet_buffer)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;source_key&#125;</span> File converted to Parquet <span class="subst">&#123;target_key&#125;</span> and stored in S3 bucket <span class="subst">&#123;target_bucket&#125;</span> successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;statusCode&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">            <span class="string">&#x27;body&#x27;</span>: json.dumps(<span class="string">f&#x27;<span class="subst">&#123;source_key&#125;</span> File converted to Parquet <span class="subst">&#123;target_key&#125;</span> and stored in S3 bucket <span class="subst">&#123;target_bucket&#125;</span> successfully&#x27;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Error processing <span class="subst">&#123;source_key&#125;</span>: <span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">        sns_client.publish(</span><br><span class="line">            TopicArn=SNS_TOPIC_ARN,</span><br><span class="line">            Subject=<span class="string">&#x27;Lambda Function Processing QE Survey Feedback Failure Notification&#x27;</span>,</span><br><span class="line">            Message=<span class="string">f&#x27;An error occurred: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&#x27;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>The above code extracts the survey feedback data from the Excel file, translates the text into English using Amazon Translate, performs sentiment analysis using Amazon Comprehend, and stores the data as Parquet format in another Amazon S3 Bucket. also notify users by email when the Lambda process data failed by using Amazon SNS. </p><p>Below is sentiment analysis results visualization using Amazon QuickSight:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-sentiment-analysis-result.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-sentiment-analysis-result.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Sentiment Analysis Results"/></div><span class="image-caption">AWS Sentiment Analysis Results</span></div><p>This is a high-level overview of the solution implementation. The solution can be further customized and enhanced based on the specific requirements of the app product.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;The App Product User Survey Fe</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Sentiment Analysis" scheme="https://stonefishy.github.io/tags/Sentiment-Analysis/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>How to Fix AWS S3 Event Replacing Space With &#39;+&#39; Character Sign in Object Key Name</title>
    <link href="https://stonefishy.github.io/2024/09/10/aws-s3-event-replacing-space-with-character-sign-in-object-key-name/"/>
    <id>https://stonefishy.github.io/2024/09/10/aws-s3-event-replacing-space-with-character-sign-in-object-key-name/</id>
    <published>2024-09-10T09:22:34.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>The issue with AWS S3 Event notifications is that it replaces spaces with ‘+’ character sign in the object key name. This can cause issues when trying to access the object in S3. It will occurs <code>NoSuchKey</code> error if not handling this issue properly.</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Configured a S3 bucket put event notification to a Lambda function. The Lambda function will be triggered when a new object is uploaded to the S3 bucket. I upload a file named ‘2023 2nd quarter QE survey raw data.xlsx’ into S3 bucket, the Lambda function is triggered, but when I try to access the object in S3, I get <code>NoSuchKey</code> error in <code>AWS CloudWatch Logs</code>. Debugging shows that the object key name is ‘2023+2nd+quarter+QE+survey+raw+data.xlsx’ instead of ‘2023 2nd quarter QE survey raw data.xlsx’. It means the S3 event notification is replacing the space with ‘+’ character sign in the object key name.</p><p>The detail error is below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] NoSuchKey: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.</span><br></pre></td></tr></table></figure><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>There are two solutions to fix this issue, one is from AWS S3 upload file side, another is from Lambda function side.</p><h3 id="1-From-AWS-S3-upload-file-side"><a href="#1-From-AWS-S3-upload-file-side" class="headerlink" title="1. From AWS S3 upload file side:"></a>1. From AWS S3 upload file side:</h3><p>If you have control over the upload process, ensure that the keys are properly URL-encoded.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example key with spaces</span></span><br><span class="line">object_key = <span class="string">&quot;2023 2nd quarter QE survey raw data.xlsx&quot;</span></span><br><span class="line">encoded_key = urllib.parse.quote(object_key)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Upload the object</span></span><br><span class="line">s3_client.upload_file(<span class="string">&quot;/tmp/2023 2nd quarter QE survey raw data.xlsx&quot;</span>, <span class="string">&quot;my-bucket-name&quot;</span>, encoded_key)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>This will ensure that the object key name is properly URL-encoded, which will prevent the S3 event notification from replacing spaces with ‘+’ character sign. The <code>urllib.parse.quote</code> function will replace spaces with ‘%20’ and ‘+’ with ‘%2B’.</p><h3 id="2-From-Lambda-function-side"><a href="#2-From-Lambda-function-side" class="headerlink" title="2. From Lambda function side:"></a>2. From Lambda function side:</h3><p>To fix this issue, we need to modify the Lambda function to handle the object key name with ‘+’ character sign. We can use the <code>urllib.parse</code> package to handle it. The package library provide the function <code>unquote_plus</code> to replace ‘+’ with space. Here is the code to handle the object key name with ‘+’ character sign:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> urlparse</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line">s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    bucket_name = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;bucket&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    object_key = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;object&#x27;</span>][<span class="string">&#x27;key&#x27;</span>]</span><br><span class="line">    <span class="comment"># Replace &#x27;+&#x27; with space</span></span><br><span class="line">    object_key = urlparse.unquote_plus(object_key)</span><br><span class="line">    <span class="comment"># Download the object</span></span><br><span class="line">    s3.download_file(bucket_name, object_key, <span class="string">&#x27;/tmp/file.txt&#x27;</span>)</span><br><span class="line">    <span class="comment"># Do something with the downloaded file</span></span><br><span class="line">    <span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>In the above code, we first get the bucket name and object key from the S3 event notification. We then use the <code>urlparse.unquote_plus</code> function to replace ‘+’ with space in the object key name. Finally, we download the object using the <code>s3.download_file</code> function.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>To fix the issue with AWS S3 Event notifications replacing space with ‘+’ character sign in the object key name, we need to handle it properly in the Lambda function. We can use the <code>urllib.parse</code> package to handle it.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The issue with AWS S3 Event notifications is that it replaces spaces with ‘+’ character sign in the object key name. This can cause issue</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="AWS S3" scheme="https://stonefishy.github.io/tags/AWS-S3/"/>
    
    <category term="AWS Lambda" scheme="https://stonefishy.github.io/tags/AWS-Lambda/"/>
    
  </entry>
  
  <entry>
    <title>SQL 中的 IS DISTINCT FROM 语法详解</title>
    <link href="https://stonefishy.github.io/2024/08/16/introduce-is-distinct-from-in-sql/"/>
    <id>https://stonefishy.github.io/2024/08/16/introduce-is-distinct-from-in-sql/</id>
    <published>2024-08-16T09:22:15.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>在SQL查询中，比较操作符 <code>=</code> 通常用于检查两个值是否相等。然而，当涉及到处理缺失值（<code>NULL</code>）时，这种操作符就会面临挑战。为了解决这一问题，<span class='pbg green'>SQL 提供了 `IS DISTINCT FROM` 操作符，它用于精确比较两个值是否不同，即使这些值中有 NULL</span>。本文将详细介绍 IS DISTINCT FROM 的语法、解决的问题以及常见的使用场景。</p><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><p>IS DISTINCT FROM 的基本语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expression1 <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> expression2</span><br></pre></td></tr></table></figure><p>其中 expression1 和 expression2 是要进行比较的两个表达式。 该操作符返回布尔值：TRUE、FALSE。</p><h2 id="主要解决的问题"><a href="#主要解决的问题" class="headerlink" title="主要解决的问题"></a>主要解决的问题</h2><p>在SQL中，<code>NULL</code> 值代表缺失或未知的数据。当两个表达式中至少有一个为 NULL 时，使用传统的比较操作符（如 &#x3D; 或 &lt;&gt;）进行比较会导致不确定的结果。具体来说：</p><ul><li>expression1 &#x3D; expression2 在 expression1 或 expression2 为 NULL 时会返回 UNKNOWN。</li><li>expression1 &lt;&gt; expression2 在 expression1 或 expression2 为 NULL 时也会返回 UNKNOWN。</li></ul><p>比如下面的查询语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A1,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">&lt;&gt;</span> <span class="number">1</span> <span class="keyword">as</span> A2,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">=</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A3,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">&lt;&gt;</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A4,</span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="number">1</span> <span class="keyword">as</span> A5, </span><br><span class="line">    <span class="number">1</span> <span class="operator">&lt;&gt;</span> <span class="number">1</span> <span class="keyword">as</span> A6</span><br></pre></td></tr></table></figure><p>会返回以下结果：</p><table><thead><tr><th>A1</th><th>A2</th><th>A3</th><th>A4</th><th>A5</th><th>A6</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td>TRUE</td><td>FALSE</td></tr></tbody></table><p>可以看到，当 expression1 或 expression2 为 NULL 时，传统的比较操作符会返回 UNKNOWN空值， 如上面的A1, A2, A3, A4的结果值，这就会导致不确定性。</p><p><code>IS DISTINCT FROM</code> 操作符的出现，解决了这些问题。它能正确处理 <code>NULL</code> 值，会返回 <code>TRUE 或 FALSE</code>，确保结果的可靠性。 在以下情况下返回 TRUE：</p><ul><li>expression1 和 expression2 都为 NULL。</li><li>expression1 和 expression2 的值不同（不论是否为 NULL）。</li></ul><p>而在 expression1 和 expression2 相等（包括都是 NULL）的情况下，IS DISTINCT FROM 返回 FALSE。 另外还有一个 <code>IS NOT DISTINCT FROM</code> 操作符，用于判断两个值是否相等。其用法一样，只是语义相反。</p><p>下面的例子查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="keyword">NULL</span> <span class="keyword">as</span> B1,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B2,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">2</span> <span class="keyword">as</span> B3,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="keyword">NULL</span> <span class="keyword">as</span> B4,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B5,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B6</span><br></pre></td></tr></table></figure><p>查询结果如下:</p><table><thead><tr><th>B1</th><th>B2</th><th>B3</th><th>B4</th><th>B5</th><th>B6</th></tr></thead><tbody><tr><td>TRUE</td><td>TRUE</td><td>TRUE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td></tr></tbody></table><p>可以看到，IS DISTINCT FROM 正确处理 NULL 值，返回 TRUE 或 FALSE，确保结果的可靠性。</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><h3 id="数据清洗和验证"><a href="#数据清洗和验证" class="headerlink" title="数据清洗和验证"></a>数据清洗和验证</h3><p>在<code>数据清洗</code>和<code>数据验证</code>过程中，经常需要检查数据库中的值是否不同，包括对 NULL 值的处理。例如，比较用户输入的数据与现有记录，以确定是否有不同的记录。<span class='pbg warning'>使用 IS DISTINCT FROM 可以更准确地处理 NULL 值，避免出现错误或遗漏。</span></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> users</span><br><span class="line"><span class="keyword">WHERE</span> username <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="string">&#x27;andrewsy&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询会返回所有 username 与 ‘andrewsy’ 不同的记录，包括那些 username 为 NULL 的记录。</p><h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><p>在更新数据时，使用 IS DISTINCT FROM 可以确保只有在数据实际变化时才进行更新，从而避免不必要的更新操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> users</span><br><span class="line"><span class="keyword">SET</span> email <span class="operator">=</span> <span class="string">&#x27;new_andrewsy@email.com&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> email <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="string">&#x27;new_andrewsy@email.com&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询会更新所有 email 不同于 ‘<a href="mailto:&#x6e;&#101;&#119;&#x5f;&#97;&#110;&#100;&#x72;&#x65;&#119;&#x73;&#x79;&#x40;&#101;&#109;&#x61;&#x69;&#108;&#46;&#x63;&#111;&#x6d;">&#x6e;&#101;&#119;&#x5f;&#97;&#110;&#100;&#x72;&#x65;&#119;&#x73;&#x79;&#x40;&#101;&#109;&#x61;&#x69;&#108;&#46;&#x63;&#111;&#x6d;</a>‘ 的记录，包括那些 email 为 NULL 的记录。</p><h3 id="数据比较"><a href="#数据比较" class="headerlink" title="数据比较"></a>数据比较</h3><p>在进行复杂的数据比较时，尤其是涉及到 NULL 值时，IS DISTINCT FROM 提供了更直观的比较逻辑。例如，在合并两个数据集时，可以使用此操作符来确保唯一性。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> </span><br><span class="line">    dataset1</span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> </span><br><span class="line">    dataset2</span><br><span class="line"><span class="keyword">ON</span> </span><br><span class="line">    dataset1.id <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> dataset2.id</span><br></pre></td></tr></table></figure><p>这条查询会找出两个数据集中 id 不同的记录，包括 id 为 NULL 的情况。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p><code>IS DISTINCT FROM</code> 是 SQL 标准中的一部分，但并非所有数据库系统都支持。具体的支持情况需要查阅数据库的文档。在使用 IS DISTINCT FROM 时，确保数据库系统的版本和文档中对此操作符的支持及行为一致。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>IS DISTINCT FROM</code> 是一个强大的工具，用于在 SQL 中处理包含 NULL 值的数据比较。它解决了传统比较操作符在处理 NULL 值时的不足，使得数据验证、更新和比较更加准确和可靠。在实际应用中，根据数据库系统的支持情况，合理使用 IS DISTINCT FROM 可以显著提高数据操作的精确性和健壮性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在SQL查询中，比较操作符 &lt;code&gt;=&lt;/code&gt; 通常用于检查两个值是否相等。然而，当涉及到处理缺失值（&lt;code&gt;NULL&lt;/code&gt;）时，这种操作符就会面临挑战。为了解决这一问题，&lt;span class=&#39;pbg green&#39;&gt;SQL 提供了 `IS DIST</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="Big Data" scheme="https://stonefishy.github.io/tags/Big-Data/"/>
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>详解 SQL 中的 LAG 函数</title>
    <link href="https://stonefishy.github.io/2024/08/15/what-is-lag-in-sql/"/>
    <id>https://stonefishy.github.io/2024/08/15/what-is-lag-in-sql/</id>
    <published>2024-08-15T09:24:21.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>最近在做数据分析，需要挖掘数据随时间变化的信息。所有数据物理存储在AWS S3上，通过AWS Glue Catalog和AWS Athena进行数据查询。AWS Athena支持SQL语言，可以对数据进行分析。在处理时间序列数据或分析行间变化时， SQL中的 <code>LAG</code> 函数和 <code>LEAD</code> 函数是非常有用的。下面，我们来看一下 LAG 函数的基本用法。</p><h2 id="什么是-LAG-函数？"><a href="#什么是-LAG-函数？" class="headerlink" title="什么是 LAG 函数？"></a>什么是 LAG 函数？</h2><p>在 SQL 中，<code>LAG</code> 函数是一种<code>窗口函数</code>，<span class='pbg warning'>用于获取当前行之前某一行的值。这在处理时间序列数据或分析行间变化时非常有用。LAG 函数可以让你访问当前行之前的行数据，而不需要使用子查询或自连接。</span> 而<code>LEAD</code> 函数则是获取当前行之后的行数据。他们的语法和用法类似，只是方向不同。</p><h2 id="LAG-函数的语法"><a href="#LAG-函数的语法" class="headerlink" title="LAG 函数的语法"></a>LAG 函数的语法</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">LAG</span>(expression, <span class="keyword">offset</span>, <span class="keyword">default</span>) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> partition_column <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_column)</span><br></pre></td></tr></table></figure><ul><li><code>expression</code>：要返回的列或计算结果。</li><li><code>offset</code>：向前查找的行数，默认为 1（即前一行）。</li><li><code>default</code>：当没有前行时返回的默认值，默认为 NULL。</li><li><code>PARTITION BY</code>：用于将数据分组。如果省略，LAG 会在整个结果集上应用。</li><li><code>ORDER BY</code>：确定行的顺序，LAG 函数会根据这个顺序来访问前面的行。</li></ul><h2 id="如何使用-LAG-函数"><a href="#如何使用-LAG-函数" class="headerlink" title="如何使用 LAG 函数"></a>如何使用 LAG 函数</h2><p><code>LAG</code> 函数在使用时通常与 <code>OVER</code> 子句一起使用。OVER 子句用于定义窗口（即应用 LAG 函数的范围）。在窗口中，<code>ORDER BY</code> 确定了行的顺序，<code>PARTITION BY</code> 则可以用来将数据分组，使每个分组内的计算互相独立。</p><h3 id="基本使用示例："><a href="#基本使用示例：" class="headerlink" title="基本使用示例："></a>基本使用示例：</h3><p>假设我们有一个名为 sales 的表，包含 sale_date 和 amount 列。我们想要比较每笔销售金额与前一笔销售金额的变化。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    sale_date,</span><br><span class="line">    amount,</span><br><span class="line">    <span class="built_in">LAG</span>(amount, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> sale_date) <span class="keyword">AS</span> previous_amount</span><br><span class="line"><span class="keyword">FROM</span> sales;</span><br></pre></td></tr></table></figure><p>在这个查询中：</p><p>amount 是当前销售金额。<br>LAG(amount, 1) 获取当前销售的前一笔销售金额（根据 sale_date 排序）。</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ol><li><p>时间序列分析：<br>LAG 函数非常适合分析时间序列数据，帮助用户了解数据变化趋势。例如，分析每月的销售数据，找出增长或下降的趋势。</p></li><li><p>计算变化量：<br>可以计算当前值与前一值之间的变化量，例如销售额变化、温度变化等。</p></li><li><p>生成滚动报告：<br>LAG 可以用来生成带有前值的滚动报告，例如计算累计销售额，或者生成滞后数据用于报表。</p></li></ol><h2 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h2><p>假设我们有一个销售记录表 monthly_sales，结构如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> monthly_sales (</span><br><span class="line">    <span class="keyword">month</span> <span class="type">DATE</span>,</span><br><span class="line">    sales_amount <span class="type">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> monthly_sales (<span class="keyword">month</span>, sales_amount) <span class="keyword">VALUES</span></span><br><span class="line">(<span class="string">&#x27;2024-01-01&#x27;</span>, <span class="number">1000.00</span>),</span><br><span class="line">(<span class="string">&#x27;2024-02-01&#x27;</span>, <span class="number">1500.00</span>),</span><br><span class="line">(<span class="string">&#x27;2024-03-01&#x27;</span>, <span class="number">1200.00</span>),</span><br><span class="line">(<span class="string">&#x27;2024-04-01&#x27;</span>, <span class="number">1700.00</span>);</span><br></pre></td></tr></table></figure><p>我们可以使用 <code>LAG</code> 函数来比较每个月的销售额与前一个月的销售额：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">month</span>,</span><br><span class="line">    sales_amount,</span><br><span class="line">    <span class="built_in">LAG</span>(sales_amount, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">month</span>) <span class="keyword">AS</span> previous_month_sales,</span><br><span class="line">    sales_amount <span class="operator">-</span> <span class="built_in">LAG</span>(sales_amount, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">month</span>) <span class="keyword">AS</span> sales_difference</span><br><span class="line"><span class="keyword">FROM</span> monthly_sales;</span><br></pre></td></tr></table></figure><p>查询结果：</p><table><thead><tr><th>month</th><th>sales_amount</th><th>previous_month_sales</th><th>sales_difference</th></tr></thead><tbody><tr><td>2024-01-01</td><td>1000.00</td><td>NULL</td><td>NULL</td></tr><tr><td>2024-02-01</td><td>1500.00</td><td>1000.00</td><td>500.00</td></tr><tr><td>2024-03-01</td><td>1200.00</td><td>1500.00</td><td>-300.00</td></tr><tr><td>2024-04-01</td><td>1700.00</td><td>1200.00</td><td>500.00</td></tr></tbody></table><p>在这个查询中：<br>previous_month_sales 显示了前一个月的销售额。<br>sales_difference 显示了当前月与前一个月的销售额差异。<br>通过上述查询，我们可以方便地分析销售数据的变化情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>LAG</code> 函数是一个强大的工具，可以帮助你在数据分析中处理行间的比较和变化。无论是用于时间序列数据、计算变化量，还是生成滚动报告，LAG 函数都能提供有价值的信息。它通常与 <code>OVER</code> 子句一起使用, 在OVER子句中，我们可以指定分组条件、排序条件等。<code>ORDER BY</code> 确定行的顺序，<code>PARTITION BY</code> 则可以用来将数据分组，使每个分组内的计算互相独立。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近在做数据分析，需要挖掘数据随时间变化的信息。所有数据物理存储在AWS S3上，通过AWS Glue Catalog和AWS Athena进行数据查询。AWS Athena支持SQL语言，可以对数据进行分析。在处理时间序列数据或分析行间变化时， SQL中的 &lt;code&gt;L</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="Big Data" scheme="https://stonefishy.github.io/tags/Big-Data/"/>
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>How to query tree-structured relation data in MySQL</title>
    <link href="https://stonefishy.github.io/2024/08/02/how-to-query-tree-structured-relation-data-in-mysql/"/>
    <id>https://stonefishy.github.io/2024/08/02/how-to-query-tree-structured-relation-data-in-mysql/</id>
    <published>2024-08-02T10:08:52.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>To query hierarchical relational data in <code>MySQL</code>, <code>recursive Common Table Expressions (CTEs)</code> are typically used. However, MySQL did not support recursive CTEs before version 8.0, so in earlier versions, <code>self-joins</code> are commonly used to handle such queries. Below is an example using a self-join, assuming we have a table employees that contains information about employees and their manager IDs (manager_id).</p><h2 id="Create-Table-and-Insert-Data"><a href="#Create-Table-and-Insert-Data" class="headerlink" title="Create Table and Insert Data"></a>Create Table and Insert Data</h2><p>Creating a table named <code>employees</code> with the following columns:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employees (</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">100</span>),</span><br><span class="line">    manager_id <span class="type">INT</span>,</span><br><span class="line">    <span class="keyword">FOREIGN</span> KEY (manager_id) <span class="keyword">REFERENCES</span> employees(id)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> employees (id, name, manager_id) <span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>, <span class="string">&#x27;CEO&#x27;</span>, <span class="keyword">NULL</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="string">&#x27;CTO&#x27;</span>, <span class="number">1</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="string">&#x27;CFO&#x27;</span>, <span class="number">1</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="string">&#x27;Developer Lead&#x27;</span>, <span class="number">2</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="string">&#x27;Accountant Lead&#x27;</span>, <span class="number">3</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="string">&#x27;Developer&#x27;</span>, <span class="number">4</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="string">&#x27;Junior Developer&#x27;</span>, <span class="number">4</span>),</span><br><span class="line">(<span class="number">8</span>, <span class="string">&#x27;Senior Accountant&#x27;</span>, <span class="number">5</span>),</span><br><span class="line">(<span class="number">9</span>, <span class="string">&#x27;Junior Accountant&#x27;</span>, <span class="number">5</span>);</span><br></pre></td></tr></table></figure><h2 id="Self-Join"><a href="#Self-Join" class="headerlink" title="Self-Join"></a>Self-Join</h2><p>We can search for all employees and their direct reports (subordinates) using a self-join. The following SQL statement will list all employees and their direct manager’s name.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e1.name <span class="keyword">AS</span> employee_name, e2.name <span class="keyword">AS</span> manager_name</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e2 <span class="keyword">ON</span> e1.manager_id <span class="operator">=</span> e2.id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> e1.manager_id, e1.id;</span><br></pre></td></tr></table></figure><p>We can also use a self-join to count the number of direct reports for each manager. The following SQL statement will list all managers and the number of their direct reports.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e1.name <span class="keyword">AS</span> manager_name, <span class="built_in">COUNT</span>(e2.id) <span class="keyword">AS</span> subordinate_count</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e2 <span class="keyword">ON</span> e1.id <span class="operator">=</span> e2.manager_id</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> e1.id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> subordinate_count <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><h2 id="Recursive-Common-Table-Expressions-CTEs"><a href="#Recursive-Common-Table-Expressions-CTEs" class="headerlink" title="Recursive Common Table Expressions (CTEs)"></a>Recursive Common Table Expressions (CTEs)</h2><p>MySQL 8.0 introduced support for recursive CTEs, which allows us to query hierarchical relational data more efficiently. The following SQL statement will list all employees and their direct reports (subordinates) using a recursive CTE.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">RECURSIVE</span> subordinates <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> id, name, manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1</span> <span class="comment">-- root node CEO, we can replace with any other root node ID, for example 2 which is CTO</span></span><br><span class="line">    <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line">    <span class="keyword">SELECT</span> e.id, e.name, e.manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">INNER</span> <span class="keyword">JOIN</span> subordinates s <span class="keyword">ON</span> e.manager_id <span class="operator">=</span> s.id</span><br><span class="line">)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> subordinates;</span><br></pre></td></tr></table></figure><p>But please note that this method only works for <code>MySQL 8.0</code> and above, as these versions support <code>recursive CTEs</code>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;To query hierarchical relational data in &lt;code&gt;MySQL&lt;/code&gt;, &lt;code&gt;recursive Common Table Expressions (CTEs)&lt;/code&gt; are typically used. H</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 8.x CTEs feature - WITH clause</title>
    <link href="https://stonefishy.github.io/2024/07/26/mysql-8-x-ctes-feature-with-clause/"/>
    <id>https://stonefishy.github.io/2024/07/26/mysql-8-x-ctes-feature-with-clause/</id>
    <published>2024-07-26T09:19:59.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL <code>Common Table Expressions (CTEs)</code> are a powerful feature introduced in <code>MySQL 8.0</code>. CTEs are a type of MySQL 8.0 that provide a way to create <code>temporary result sets</code> that can be referenced within a <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> statement. <span class='pbg danger'>The primary purpose of `CTEs` is to make complex queries more readable and manageable by breaking them down into simpler</span>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mysql/mysql-cte-with-clause.png" class="lazyload placeholder" data-srcset="/assets/images/mysql/mysql-cte-with-clause.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MYSQL CTEs feature - WITH clause" style="width:600px;"/></div><span class="image-caption">MYSQL CTEs feature - WITH clause</span></div><h2 id="Purpose-of-CTEs"><a href="#Purpose-of-CTEs" class="headerlink" title="Purpose of CTEs"></a>Purpose of CTEs</h2><ul><li><strong>Readability</strong>: <code>CTEs</code> can make SQL queries more readable, especially for complex queries involving multiple subqueries or recursive operations.</li><li><strong>Modularity</strong>: They allow you to define a temporary result set that can be reused within the same query, promoting code reuse and reducing redundancy.</li><li><strong>Recursive Queries</strong>: CTEs support recursive queries, which are useful for querying hierarchical data like organizational charts, bill of materials, or tree structures.</li></ul><h2 id="How-to-Use-CTEs"><a href="#How-to-Use-CTEs" class="headerlink" title="How to Use CTEs"></a>How to Use CTEs</h2><p><code>CTEs</code> are defined using the <code>WITH</code> clause and can be referenced within the main query. Here’s the basic syntax:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> cte_name <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> ...</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> cte_name;</span><br></pre></td></tr></table></figure><h3 id="Basic-CTE"><a href="#Basic-CTE" class="headerlink" title="Basic CTE"></a>Basic CTE</h3><p>Suppose you have a table employees and you want to find the average salary of employees in each department.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> DepartmentSalaries <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id, <span class="built_in">AVG</span>(salary) <span class="keyword">AS</span> avg_salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DepartmentSalaries;</span><br></pre></td></tr></table></figure><p>In this example, DepartmentSalaries is a CTE that calculates the average salary for each department. The main query then selects from this CTE.</p><p><code>CTEs</code> feature also supports multiple temporary result sets in the same query, see below example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span></span><br><span class="line">  cte1 <span class="keyword">AS</span> (<span class="keyword">SELECT</span> a, b <span class="keyword">FROM</span> table1),</span><br><span class="line">  cte2 <span class="keyword">AS</span> (<span class="keyword">SELECT</span> c, d <span class="keyword">FROM</span> table2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> b, d <span class="keyword">FROM</span> cte1 <span class="keyword">JOIN</span> cte2 <span class="keyword">WHERE</span> cte1.a <span class="operator">=</span> cte2.c;</span><br></pre></td></tr></table></figure><p>Above sqls defines two CTEs cte1 and cte2 and then joins them using a WHERE clause.</p><h3 id="Recursive-CTE"><a href="#Recursive-CTE" class="headerlink" title="Recursive CTE"></a>Recursive CTE</h3><p>A CTE can refer to itself to define a <code>recursive CTE</code>. Common applications of recursive CTEs include series generation and traversal of hierarchical or tree-structured data.</p><p>Suppose you have a table employees with a self-referencing column manager_id to represent a hierarchy. You want to find all subordinates of a given manager.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">RECURSIVE</span> Subordinates <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> employee_id, manager_id, name</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> manager_id <span class="operator">=</span> <span class="number">1</span>  <span class="comment">-- Starting with the manager ID 1</span></span><br><span class="line">    <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line">    <span class="keyword">SELECT</span> e.employee_id, e.manager_id, e.name</span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">INNER</span> <span class="keyword">JOIN</span> Subordinates s <span class="keyword">ON</span> e.manager_id <span class="operator">=</span> s.employee_id</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Subordinates;</span><br></pre></td></tr></table></figure><p>In this example, Subordinates is a recursive CTE that starts with employees directly reporting to manager ID 1 and then recursively includes all their subordinates.</p><h2 id="Key-Points"><a href="#Key-Points" class="headerlink" title="Key Points"></a>Key Points</h2><ul><li><strong>Non-Recursive CTEs</strong>: These are straightforward and do not involve recursion. They are simply a way to define a temporary result set for use within the query.</li><li><strong>Recursive CTEs</strong>: These involve recursion and are useful for hierarchical or tree-structured data. They must include a <code>UNION ALL</code> clause to combine the initial result set with the recursive result set.</li><li><strong>Scope</strong>: CTEs are scoped to the query they are defined in and cannot be referenced outside of that query.</li></ul><p><code>CTEs</code> are a powerful tool in MySQL that can significantly improve the <code>readability</code> and <code>maintainability</code> of <code>complex SQL queries</code>.</p><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links:"></a>Reference Links:</h2><p>For other scenarios, like use <code>WITH</code> clause in <code>UPDATE</code> or <code>DELETE</code> statements, please refer to the following links:</p><ul><li><strong>WITH (Common Table Expressions)</strong>: <a href="https://dev.mysql.com/doc/refman/8.4/en/with.html">https://dev.mysql.com/doc/refman/8.4/en/with.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;MySQL &lt;code&gt;Common Table Expressions (CTEs)&lt;/code&gt; are a powerful feature introduced in &lt;code&gt;MySQL 8.0&lt;/code&gt;. CTEs are a type of MySQL </summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Using Pulumi to Import the AWS Resources of the Other Region</title>
    <link href="https://stonefishy.github.io/2024/07/04/using-pulumi-to-import-the-aws-resources-of-the-other-region/"/>
    <id>https://stonefishy.github.io/2024/07/04/using-pulumi-to-import-the-aws-resources-of-the-other-region/</id>
    <published>2024-07-04T10:27:55.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>By default, the Pulumi import the resource in the region which is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file. If we import the resources which is located in other regions. It will cause the error by using <code>pulumi import</code> command.</p><p>For example, we have quicksight resources such like DataSource, DataSet located in the <code>eu-west-1</code> region, we already manage these resources in the pulumi by using <code>pulumi import</code> CLI command. All resources are located in <code>eu-west-1</code> region. It is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file like below.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">config:</span></span><br><span class="line">  <span class="attr">aws:region:</span> <span class="string">eu-west-1</span></span><br></pre></td></tr></table></figure><p>Now we also want to import the existing resources such like QuickSight user Groups into the pulumi. But the AWS Quicksight user Groups resources all are located in the <code>us-east-1</code> region. The pulumi will give us the error if we try to import the other region resource direclty.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-other-region-resource-error.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-other-region-resource-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>This is because the Pulumi is using default <code>provider</code> for the AWS resources. The default provider is set to the region which is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file. So, if we want to import the resources from other region, we need to specify the provider for that region.</p><h2 id="Pulumi-Provider"><a href="#Pulumi-Provider" class="headerlink" title="Pulumi Provider"></a>Pulumi Provider</h2><p>A <code>Pulumi provider</code> is a plugin that enables Pulumi to interact with a specific cloud provider or service. These providers are responsible for translating the Pulumi code into the appropriate API calls for the target cloud platform. </p><p>By default, each provider uses its package’s global configuration settings, which are controlled by your stack’s configuration. You can set information such as your cloud provider credentials with environment variables and configuration files. If you store this data in standard locations, Pulumi knows how to retrieve them. For example, you can run below command to set the AWS region to <code>eu-west-1</code> region for the AWS provider configuration.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi config set aws:region eu-west-1</span><br></pre></td></tr></table></figure><p>This command actually will set the <code>aws:region</code> configuration value for the AWS provider in your Pulumi stack yaml file. You can also define the provider in your pulumi code, and create related resources in the specified region.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new provider for the us-east-1 region</span></span><br><span class="line">us_east_1_provider = aws.Provider(<span class="string">&#x27;us-east-1&#x27;</span>, region=<span class="string">&#x27;us-east-1&#x27;</span>)</span><br><span class="line"><span class="comment"># Create the Quicksight Groups resources in the us-east-1 region</span></span><br><span class="line">quicksight_group = aws.quicksight.Group(</span><br><span class="line">    <span class="string">&quot;dev&quot;</span>,</span><br><span class="line">    aws_account_id=<span class="string">&quot;&lt;aws-account-id&gt;&quot;</span>,</span><br><span class="line">    group_name=<span class="string">&quot;dev&quot;</span>,</span><br><span class="line">    opts=pulumi.ResourceOptions(</span><br><span class="line">        provider=us_east_1_provider</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>In above code, we create a new provider for the <code>us-east-1</code> region and then create the Quicksight user Groups resources in the <code>us-east-1</code> region. The <code>provider</code> option is used to specify the provider to use for the resource. Even we have global configuration for the <code>eu-west-1</code> region, we can still create the resources in the <code>us-east-1</code> region by specifying the provider.</p><h2 id="Importing-the-AWS-Resources-of-the-Other-Region"><a href="#Importing-the-AWS-Resources-of-the-Other-Region" class="headerlink" title="Importing the AWS Resources of the Other Region"></a>Importing the AWS Resources of the Other Region</h2><p>Back to previous topic, if we want to import the AWS Quicksight Users and Groups resources from the <code>us-east-1</code> region in current pulumi stack from the command line, we need to specify the provider for the pulumi command line. The Pulumi CLI import command takes an additional <code>--provider</code> option to specify the provider to use for the import.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:quicksight/group:Group dev xxxxxx/default/dev --provider name=urn</span><br></pre></td></tr></table></figure><p>In above command, we are importing the <code>aws:quicksight/group:Group</code> resource with the <code>dev</code> name in the provider. For the <code>--provider</code> option, The <code>name</code> is the name of the provider to use for the import, and <code>urn</code> is the URN of the provider to use for the import. Typically, the resource urns in pulumis is below format.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urn:pulumi:production::acmecorp-website::custom:resources:Resource$aws:s3/bucket:Bucket::my-bucket</span><br><span class="line">           ^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^</span><br><span class="line">           &lt;stack-name&gt; &lt;project-name&gt;   &lt;parent-type&gt;             &lt;resource-type&gt;       &lt;resource-name&gt;</span><br></pre></td></tr></table></figure><p>If there is no <code>parent-type</code> in the resource urn, the urns will be like below format.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urn:pulumi:production::acmecorp-website::aws:s3/bucket:Bucket::my-bucket</span><br><span class="line">           ^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^</span><br><span class="line">           &lt;stack-name&gt; &lt;project-name&gt;   &lt;resource-type&gt;       &lt;resource-name&gt;</span><br></pre></td></tr></table></figure><p>For the details of Pulumi Resources URNs, please refer to the <a href="https://www.pulumi.com/docs/concepts/resources/names/#urns">Pulumi URNs</a>.</p><p>In our scenario, we can import the Quicksight Groups resources from the <code>us-east-1</code> region by using the provider. <span class='pbg warning'>There is one thing is important to note</span> For example, we don’t have any <code>Provider</code> resources for the <code>us-east-1</code> region in our current stack. If we run below command to import the Quicksight Groups resources from the <code>us-east-1</code> region, it will fail. Below is an examle of the full import resource with <code>--provider</code> option</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:quicksight/group:Group dev &lt;aws-account-id&gt;/default/dev --provider us_east_1_provider=urn:pulumi:&lt;pulumi-project-name&gt;::quicksight::pulumi:providers:aws::us_east_1_provider</span><br></pre></td></tr></table></figure><p>The <code>&lt;aws-account-id&gt;</code> and <code>&lt;pulumi-project-name&gt;</code> are placeholder just for example. Without the <code>Provider</code> resource for the <code>us-east-1</code> region, the import command will fail as below error message.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Preview failed: bad provider reference &#x27;us_east_1_provider=urn:pulumi:&lt;pulumi-project-name&gt;::quicksight::pulumi:providers:aws::us_east_1_provider&#x27; is not valid URN&#x27;</span><br></pre></td></tr></table></figure><p>The error full screenshot is below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-without-provider-error.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-without-provider-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>To fix this issue, we need to create the <code>Provider</code> resource for the <code>us-east-1</code> region in our current stack. We can do this by adding the <code>Provider</code> resource in in our Pulumi code and using <code>Pulumi up</code> command to create the resource.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new provider for the us-east-1 region</span></span><br><span class="line">us_east_1_provider = aws.Provider(<span class="string">&#x27;us-east-1&#x27;</span>, region=<span class="string">&#x27;us-east-1&#x27;</span>)</span><br></pre></td></tr></table></figure><p>After that, we can run the import command again to import the Quicksight Groups resources from the <code>us-east-1</code> region. And now you will see the Quicksight Groups resources of the <code>us-east-1</code> region in your pulumi stack.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-provider-success.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-provider-success.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>To import the AWS resources of the other region, we need to specify the provider for the pulumi command line. The Pulumi CLI import command takes an additional <code>--provider</code> option to specify the provider to use for the import. The <code>provider</code> resource should be created in pulumi before importing the resources of the other region resource.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h2&gt;&lt;p&gt;By default, the Pulumi import the resource in the </summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
  <entry>
    <title>Keras3.0 - A Multi-framework Machine Learning Library</title>
    <link href="https://stonefishy.github.io/2024/06/25/keras3-0-a-multi-framework-machine-learning-library/"/>
    <id>https://stonefishy.github.io/2024/06/25/keras3-0-a-multi-framework-machine-learning-library/</id>
    <published>2024-06-25T10:12:36.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p><code>Keras</code>3 is a full rewrite of Keras that enables you to run your Keras workflows on top of either <code>JAX</code>, <code>TensorFlow</code>, or <code>PyTorch</code>, and that unlocks brand new large-scale model training and deployment capabilities. It’s multi-framework machine learning, meaning that you can use Keras to train models on top of different backends, and deploy them to different platforms. You can also use Keras as a low-level cross-framework language to develop custom components such as layers, models, or metrics that can be used in native workflows in JAX, TensorFlow, or PyTorch — with one codebase.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/keras3-multi-framework-machine-learning.jpg" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/keras3-multi-framework-machine-learning.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Keras 3 Multi-framework Machine Learning"/></div><span class="image-caption">Keras 3 Multi-framework Machine Learning</span></div><h2 id="What’s-New-in-Keras-3"><a href="#What’s-New-in-Keras-3" class="headerlink" title="What’s New in Keras 3?"></a>What’s New in Keras 3?</h2><p>Keras 3 introduces several exciting features that enhance its usability, performance, and flexibility:</p><h4 id="Unified-API"><a href="#Unified-API" class="headerlink" title="Unified API"></a>Unified API</h4><p>Keras 3 continues to build on its legacy of a user-friendly and intuitive API. It aims to unify the high-level and low-level APIs more seamlessly, providing a consistent experience across different backends such as TensorFlow, PyTorch, and others.</p><h4 id="Multi-backend-Support"><a href="#Multi-backend-Support" class="headerlink" title="Multi-backend Support"></a>Multi-backend Support</h4><p>While Keras has traditionally been closely associated with TensorFlow, Keras 3 expands its compatibility to other popular deep learning frameworks. This means you can now use Keras with PyTorch and other backends, leveraging Keras’ high-level abstractions and ease of use across different environments.</p><h4 id="Improved-Performance"><a href="#Improved-Performance" class="headerlink" title="Improved Performance"></a>Improved Performance</h4><p>Efforts have been made in Keras 3 to optimize performance across various operations, ensuring faster execution times and better utilization of hardware resources. This improvement is crucial for handling larger datasets and complex models efficiently.</p><h4 id="Enhanced-Model-Deployment"><a href="#Enhanced-Model-Deployment" class="headerlink" title="Enhanced Model Deployment"></a>Enhanced Model Deployment</h4><p>Keras 3 simplifies the process of deploying trained models to production environments. With streamlined APIs for model serialization and deployment tools, it becomes easier to integrate Keras models into real-world applications.</p><h4 id="Expanded-Model-Zoo"><a href="#Expanded-Model-Zoo" class="headerlink" title="Expanded Model Zoo"></a>Expanded Model Zoo</h4><p>Keras 3 comes with an expanded model zoo, offering <code>pre-trained models</code> for a wider range of tasks and domains. This includes vision models (e.g., ResNet, EfficientNet), NLP models (e.g., BERT, GPT), and other specialized architectures, all accessible through a unified interface.</p><h4 id="Advanced-AutoML-Capabilities"><a href="#Advanced-AutoML-Capabilities" class="headerlink" title="Advanced AutoML Capabilities"></a>Advanced AutoML Capabilities</h4><p>The new release includes improved AutoML capabilities, allowing developers to automate model selection, hyperparameter tuning, and architecture search. This feature can significantly accelerate the model development process, especially for beginners and researchers exploring new domains.</p><h2 id="Pre-trained-Models"><a href="#Pre-trained-Models" class="headerlink" title="Pre-trained Models"></a>Pre-trained Models</h2><p>There’s a wide range of pretrained models that you can start using today with Keras 3. About 40 Keras Applications models (the <code>keras.applications</code> namespace) are available in all backends. These models are pre-trained on large datasets and can be used for transfer learning or fine-tuning. It includes:</p><h4 id="Pre-trained-Models-for-Natural-Language-Processing"><a href="#Pre-trained-Models-for-Natural-Language-Processing" class="headerlink" title="Pre-trained Models for Natural Language Processing"></a>Pre-trained Models for Natural Language Processing</h4><ul><li>Albert</li><li>Bart</li><li>Bert</li><li>Bloom</li><li>DebertaV3</li><li>DistilBert</li><li>Gemma</li><li>Electra</li><li>Falcon</li><li>FNet</li><li>GPT2</li><li>Llama</li><li>Llama3</li><li>Mistral</li><li>OPT</li><li>PaliGemma</li><li>Phi3</li><li>Roberta</li><li>XLMRoberta</li></ul><h4 id="Pre-trained-Models-for-Computer-Vision"><a href="#Pre-trained-Models-for-Computer-Vision" class="headerlink" title="Pre-trained Models for Computer Vision"></a>Pre-trained Models for Computer Vision</h4><ul><li>CSPDarkNet</li><li>EfficientNetV2</li><li>MiT</li><li>MobileNetV3</li><li>ResNetV1</li><li>ResNetV2</li><li>VideoSwinB</li><li>VideoSwinS</li><li>VideoSwinT</li><li>VitDet</li><li>YOLOV8</li><li>ImageClassifier</li><li>VideoClassifier</li><li>CLIP</li><li>RetinaNet</li></ul><h2 id="How-to-Get-Started-with-Keras-3"><a href="#How-to-Get-Started-with-Keras-3" class="headerlink" title="How to Get Started with Keras 3?"></a>How to Get Started with Keras 3?</h2><h4 id="1-Install-Keras-3"><a href="#1-Install-Keras-3" class="headerlink" title="1.Install Keras 3"></a>1.Install Keras 3</h4><p>Ensure you have the latest version of Keras installed. You can install Keras via pip if you haven’t already:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade keras</span><br></pre></td></tr></table></figure><h4 id="2-Define-Model"><a href="#2-Define-Model" class="headerlink" title="2.Define Model"></a>2.Define Model</h4><p>Use Keras’ high-level API to define your deep learning model. Here’s a simple example of a convolutional neural network (CNN) for image classification:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)),</span><br><span class="line">    MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">    Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">    Flatten(),</span><br><span class="line">    Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h4 id="3-Compile-and-Train-Model"><a href="#3-Compile-and-Train-Model" class="headerlink" title="3.Compile and Train Model"></a>3.Compile and Train Model</h4><p>Compile the model with a loss function, optimizer, and metrics, then train it on your data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>, validation_data=(val_images, val_labels))</span><br></pre></td></tr></table></figure><h4 id="4-Deploy-models"><a href="#4-Deploy-models" class="headerlink" title="4.Deploy models"></a>4.Deploy models</h4><p>Keras 3 provides a simple and unified interface for deploying trained models to production environments. You can serialize your models and deploy them using tools such as TensorFlow Serving, PyTorch Hub, or JAX Hub. </p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Keras 3 bring a lot of exciting features to the table, including multi-backend support, improved performance, and enhanced model deployment. It also includes a wide range of pre-trained models for natural language processing and computer vision, making it easy to get started with deep learning. With these features, Keras 3 is a powerful and flexible tool for building and deploying deep learning models.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Keras&lt;/code&gt;3 is a full rewrite of Keras that enables you to run your Keras workflows on top of either &lt;code&gt;JAX&lt;/code&gt;, &lt;code&gt;Tens</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Keras" scheme="https://stonefishy.github.io/tags/Keras/"/>
    
    <category term="TensorFlow" scheme="https://stonefishy.github.io/tags/TensorFlow/"/>
    
    <category term="PyTorch" scheme="https://stonefishy.github.io/tags/PyTorch/"/>
    
    <category term="JAX" scheme="https://stonefishy.github.io/tags/JAX/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the X-Frame-Options HTTP Header</title>
    <link href="https://stonefishy.github.io/2024/06/14/understanding-the-x-frame-options-http-header/"/>
    <id>https://stonefishy.github.io/2024/06/14/understanding-the-x-frame-options-http-header/</id>
    <published>2024-06-14T14:36:28.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, we build a frontend website as a nginx docker image, before go live on production. We asking the security team to do the security scan for the website on stage environment. One of security issues indicates the <code>X-Frame-Options</code> HTTP header is not set properly. It will cause the website to be vulnerable to clickjacking attacks.</p><h2 id="Clickjacking-Attack"><a href="#Clickjacking-Attack" class="headerlink" title="Clickjacking Attack"></a>Clickjacking Attack</h2><p><code>Clickjacking</code> is a type of security vulnerability that allows an attacker to trick a user into clicking on a link or button on a malicious website that is designed to look like the legitimate website. This can happen when the attacker embeds the malicious website within a frame on the legitimate website, which can trick the user into clicking on the malicious link or button.</p><p>To prevent clickjacking attacks, we can use the <code>X-Frame-Options</code> HTTP header to specify whether a web page can be displayed within a frame or iframe. This header can have three possible values: <code>DENY</code>, <code>SAMEORIGIN</code>, and <code>ALLOW-FROM</code> uri.</p><h2 id="What-is-X-Frame-Options"><a href="#What-is-X-Frame-Options" class="headerlink" title="What is X-Frame-Options?"></a>What is X-Frame-Options?</h2><p>The X-Frame-Options is an HTTP response header used to control whether a web page can be displayed within a frame or iframe. It helps to mitigate clickjacking attacks by preventing malicious websites from embedding a vulnerable site within a frame and tricking users into taking unintended actions.</p><h2 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h2><p>The X-Frame-Options header can have three possible values: DENY, SAMEORIGIN, and ALLOW-FROM uri.</p><p><code>DENY</code>: This value prevents the page from being displayed in a frame, regardless of the site attempting to do so.</p><p><code>SAMEORIGIN</code>: With this value, the page can be displayed in a frame on the same origin as the page itself. This restricts the frame to the same origin as the parent page.</p><p><code>ALLOW-FROM uri</code>: Here, the page can only be displayed in a frame on the specified origin.</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>To implement the X-Frame-Options header, simply include the header in the server’s HTTP response. It can be implemented on code programming, server configuration, or web server configuration.</p><h3 id="Code-Programming"><a href="#Code-Programming" class="headerlink" title="Code Programming"></a>Code Programming</h3><p>Below is an example of how to set the header using different programming languages:</p><h4 id="Using-Node-js-Express"><a href="#Using-Node-js-Express" class="headerlink" title="Using Node.js (Express)"></a>Using Node.js (Express)</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set X-Frame-Options header to DENY</span></span><br><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">  res.<span class="title function_">setHeader</span>(<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>);</span><br><span class="line">  <span class="title function_">next</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="Using-Django-Python"><a href="#Using-Django-Python" class="headerlink" title="Using Django (Python)"></a>Using Django (Python)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set X-Frame-Options header to SAMEORIGIN</span></span><br><span class="line">response[<span class="string">&#x27;X-Frame-Options&#x27;</span>] = <span class="string">&#x27;SAMEORIGIN&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="Using-ASP-NET-C"><a href="#Using-ASP-NET-C" class="headerlink" title="Using ASP.NET (C#)"></a>Using ASP.NET (C#)</h4><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set X-Frame-Options header to ALLOW-FROM</span></span><br><span class="line">Response.AddHeader(<span class="string">&quot;X-Frame-Options&quot;</span>, <span class="string">&quot;ALLOW-FROM https://example.com&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="Server-Configuration"><a href="#Server-Configuration" class="headerlink" title="Server Configuration"></a>Server Configuration</h3><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h4><p>To configure Nginx to send the X-Frame-Options header, add this either to your http, server or location configuration:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_header X-Frame-Options SAMEORIGIN always;</span><br></pre></td></tr></table></figure><h4 id="Apache"><a href="#Apache" class="headerlink" title="Apache"></a>Apache</h4><p>To configure Apache to send the X-Frame-Options header for all pages, add this to your site’s configuration:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Header always set X-Frame-Options &quot;DENY&quot;</span><br></pre></td></tr></table></figure><h4 id="IIS"><a href="#IIS" class="headerlink" title="IIS"></a>IIS</h4><p>To configure IIS to send the X-Frame-Options header for all pages, add this to your web.config file:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">httpProtocol</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">customHeaders</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">&quot;X-Frame-Options&quot;</span> <span class="attr">value</span>=<span class="string">&quot;DENY&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">customHeaders</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">httpProtocol</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>To demonstrate the effectiveness of the X-Frame-Options header, we can create a parent html page, and a child html page that is embedded within a frame in the parent page.</p><h3 id="Parent-HTML-Page"><a href="#Parent-HTML-Page" class="headerlink" title="Parent HTML Page"></a>Parent HTML Page</h3><p>Parent HTML page includes the iframe of the child page. The child page is hosted on a different domain (<a href="http://localhost:3333/child.html">http://localhost:3333/child.html</a>) to demonstrate the effectiveness of the X-Frame-Options header. </p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Parent Page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Parent Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is parent page. below is the iframe of child page.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">iframe</span> <span class="attr">src</span>=<span class="string">&quot;http://localhost:3333/child.html&quot;</span> <span class="attr">frameborder</span>=<span class="string">&quot;0&quot;</span> <span class="attr">sandbox</span>=<span class="string">&quot;allow-scripts&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 100%; height: 200px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Child-HTML-Page"><a href="#Child-HTML-Page" class="headerlink" title="Child HTML Page"></a>Child HTML Page</h3><p>Child HTML page is a simple page that displays a message. It is hosted on the domain (<a href="http://localhost:3333/child.html">http://localhost:3333/child.html</a>) by using <code>httpster</code> tool.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Child Page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Child Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is a child page.<span class="tag">&lt;/<span class="name">p</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><p>To test the effectiveness of the X-Frame-Options header, we can open the parent page in a browser and observe the behavior.</p><h4 id="Without-X-Frame-Options-Header"><a href="#Without-X-Frame-Options-Header" class="headerlink" title="Without X-Frame-Options Header"></a>Without X-Frame-Options Header</h4><p>By default, the <code>httpster</code> does not add the X-Frame-Options header to the response. Therefore, the child page can be embedded within a frame on the parent page. See below screenshot, these is no X-Frame-Options header in the response.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/without-x-frame-options-response-header.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/without-x-frame-options-response-header.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Without X-Frame-Options Header"/></div><span class="image-caption">Without X-Frame-Options Header</span></div><h4 id="With-X-Frame-Options-Header"><a href="#With-X-Frame-Options-Header" class="headerlink" title="With X-Frame-Options Header"></a>With X-Frame-Options Header</h4><p>With the X-Frame-Options header set to DENY, the child page cannot be embedded within a frame on the parent page.</p><p>To test the X-Frame-Options header, we need to modify the <code>httpster</code> server source code to add the X-Frame-Options header to the response. Actually, the <code>httpster</code> tool is a simple HTTP server base on node express. We can modify the <code>app.use</code> function to set the X-Frame-Options header in the httpster source code. </p><p>Here is the modified <code>app.use</code> function with the X-Frame-Options header set to DENY:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">   res.<span class="title function_">setHeader</span>(<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>);</span><br><span class="line">   <span class="title function_">next</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>We can then open the parent page in a browser and observe the behavior. See below screenshot, these is with X-Frame-Options header value set to DENY in the response. And the child page is blocked from being embedded within a frame on the parent page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/with-x-frame-options-response-header-deny.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/with-x-frame-options-response-header-deny.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="With X-Frame-Options Header Value DENY"/></div><span class="image-caption">With X-Frame-Options Header Value DENY</span></div><p>And also, there is error message in the console of the browser, which indicates that the child page is blocked from being embedded within a frame on the parent page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/with-x-frame-opitons-response-header-deny-console.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/with-x-frame-opitons-response-header-deny-console.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="With X-Frame-Options Header Value DENY Console Error"/></div><span class="image-caption">With X-Frame-Options Header Value DENY Console Error</span></div><p>You can also test the X-Frame-Options header with different values such as SAMEORIGIN and ALLOW-FROM uri to see how it affects the behavior of the website.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By implementing the X-Frame-Options header, web developers can enhance the security of their websites and protect users from potential clickjacking attacks. It is recommended to set this header appropriately based on the specific requirements of the web application.</p><p>Remember to test the effectiveness of the header using browser developer tools and security testing tools to ensure that it is properly configured.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently, we build a frontend website as a nginx docker image, before go live on production. We asking the security team to do the securi</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="Web" scheme="https://stonefishy.github.io/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>The Points of AWS China CloudFront You Need to Notice</title>
    <link href="https://stonefishy.github.io/2024/04/18/the-points-of-aws-china-cloudfront-you-need-to-notice/"/>
    <id>https://stonefishy.github.io/2024/04/18/the-points-of-aws-china-cloudfront-you-need-to-notice/</id>
    <published>2024-04-18T10:16:54.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>There are much difference between AWS Global and AWS China. The background of this blog is that I’m responsible for migrating the aws global application to aws china. The application already go lived on AWS Global. The application is  collecting the user inforamtion and for business logic. The business wants this application to serve China customer. Due to the application regulation,  the application needs to deployed in AWS China and store the user information in AWS China.</p><p>The application is using below AWS services:</p><ul><li>AWS S3: store the static website assets and user information.</li><li>AWS ALB: the load balancer for the application.</li><li>AWS ASG: auto scaling group for the application.</li><li>AWS ECR: store the application container image.</li><li>AWS ECS: run the application container.</li><li>AWS ACM: manage the SSL certificate.</li><li>AWS WAF: web application firewall.</li><li>AWS VPC: virtual private cloud.</li><li>AWS S3 VPC Gateway: access the S3 bucket from the VPC.</li><li>AWS CloudWatch: monitor the application logs, performance and alarms.</li><li>AWS SNS: notificate the stack holder when application performance is abnormal.</li><li>AWS CloudFront: serve the static website and user information.</li></ul><h2 id="AWS-China"><a href="#AWS-China" class="headerlink" title="AWS China"></a>AWS China</h2><p>The AWS China is a separate entity operated by a local partner in compliance with Chinese regulations. Data centers located in Beijing and Ningxia. The operator is different between Beijing and Ningxia. Beijing region operated by Sinnet(光环新网)，Ningxia region operated by NWCD(西云数据). Basically， the service price of Ningxia region is cheaper than Beijing region. You can find the detail pricing in the AWS China link <a href="https://calculator.amazonaws.cn/#/">https://calculator.amazonaws.cn/#/</a>. AWS Fargate priciing is here <a href="https://www.amazonaws.cn/en/fargate/pricing">https://www.amazonaws.cn/en/fargate/pricing</a></p><h2 id="Difference-between-AWS-Global-and-AWS-China"><a href="#Difference-between-AWS-Global-and-AWS-China" class="headerlink" title="Difference between AWS Global and AWS China"></a>Difference between AWS Global and AWS China</h2><p>The AWS China has many limiation and difference with AWS Global. And also some new services are not available in AWS China. When you migrate the application to AWS China, you need to consider the below points:</p><ol><li>AWS China has different pricing policy. The pricing policy is different between Beijing and Ningxia. </li><li>The Infrastructure code is different between AWS Global and AWS China. The code need to be modified to adapt to AWS China.</li><li>The Website should be do the ICP filling and Goverment Filling. (域名备案，网安备案)</li></ol><h3 id="Infrastructure-as-Code"><a href="#Infrastructure-as-Code" class="headerlink" title="Infrastructure as Code"></a>Infrastructure as Code</h3><p>We’re using <code>Pulumi</code> to manage the infrastructure as code. Pulumi is a tool for developing, building, and deploying cloud applications and infrastructure. It supports multiple cloud providers including AWS, Azure, GCP, and Kubernetes.<br>There are AWS Service Resource definition is different with AWS Global on AWS China. In AWS China there is an <code>amazonaws.com.cn</code> string for endpoint, and <code>aws-cn</code> ARN prefix. The code need to be modified to adapt to AWS China.</p><h4 id="AWS-China-1"><a href="#AWS-China-1" class="headerlink" title="AWS China"></a>AWS China</h4><ul><li>AWS EndPoint: xxxxxxx.s3.cn-northwest-1.<strong>amazonaws.com.cn</strong>&#x2F;example.txt</li><li>AWS ARNs: arn:<strong>aws-cn</strong>:s3:::xxxxxxx&#x2F;example.txt</li></ul><h4 id="AWS-Global"><a href="#AWS-Global" class="headerlink" title="AWS Global"></a>AWS Global</h4><ul><li>AWS EndPoint: xxxxxxx.s3.cn-northwest-1.<strong>amazonaws.com</strong>&#x2F;example.txt</li><li>AWS ARNs: arn:<strong>aws</strong>:s3:::xxxxxxx&#x2F;example.txt</li></ul><h3 id="CloudFront"><a href="#CloudFront" class="headerlink" title="CloudFront"></a>CloudFront</h3><p>In our application is much difference between AWS Global and AWS China, especially the CloudFront.</p><ul><li>Requires ICP filing and domain name filing in AWS China.</li><li>The CloudFront provides domain name like “*.cloudfront.cn” which cannot be used in for website serving in AWS China. You can not access the website through the CloudFront domain name. It returns 403 Forbidden error.</li><li>The SSL&#x2F;TLS certificates for CloudFront does not support the Amazon Certificate Manager in AWS China. It requires to use SSL&#x2F;TLS certificate from third party, and then - - import certificate in IAM. It is only support IAM to store the certificates for CloudFront in AWS China.</li><li>The CloudFront does not supports the Amazon WAF in AWS China.</li><li>The Cache polices and Origin request polices does not support in AWS China</li><li>The Lambda@Edge is not available in AWS China.</li><li>CloudFront origin access only supports legacy access identities OAI for S3 bucket, does not support OAC in AWS China</li><li>The CloudFront origin for S3 bucket which is not a website endpoint, the following format: <code>bucket-name.s3.region.amazonaws.com.cn</code>, remember <code>region</code> after <code>s3</code></li><li>The CloudFront origin for S3 bucket which is a website endpoint, use the following format: <code>bucket-name.s3-website.region.amazonaws.com.cn</code>, remember <code>region</code> after <code>s3-website</code></li></ul><p>For more information, please refer to the AWS China CloudFront <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/cloudfront.html#feature-diff">https://docs.amazonaws.cn/en_us/aws/latest/userguide/cloudfront.html#feature-diff</a></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this blog, we have discussed the important points when migrate the aws global application to aws china, especially for the AWS CloudFront. We have listed the difference between AWS Global and AWS China, and also the CloudFront difference between AWS Global and AWS China.</p><p>If you want to know more about AWS China service difference with AWS Global, you can refer to this official link <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html">https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html</a></p><p>Hope this blog can help you to migrate the application to AWS China.</p><h2 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h2><ul><li>AWS China Service Difference: <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html">https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html</a></li><li>AWS China Service Pricing: <a href="https://calculator.amazonaws.cn/#/">https://calculator.amazonaws.cn/#/</a></li><li>AWS China Fargate Pricing: <a href="https://www.amazonaws.cn/en/fargate/pricing">https://www.amazonaws.cn/en/fargate/pricing</a></li><li>AWS China Edge Location: <a href="https://www.amazonaws.cn/en/cloudfront/features/">https://www.amazonaws.cn/en/cloudfront/features/</a></li><li>AWS China CloudFront Error Investigation: <a href="https://zhuanlan.zhihu.com/p/182517851">https://zhuanlan.zhihu.com/p/182517851</a></li><li>ICP&#x2F;IP地址&#x2F;域名信息备案管理系统: <a href="https://beian.miit.gov.cn/#/Integrated/index">https://beian.miit.gov.cn/#/Integrated/index</a></li><li>全国互联网安全管理服务平台: <a href="https://beian.mps.gov.cn/#/query/webSearch">https://beian.mps.gov.cn/#/query/webSearch</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;There are much difference between AWS Global and AWS China. The background of this blog is that I’m responsible for migrating the aws glo</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Migrate a legacy application to AWS Cloud</title>
    <link href="https://stonefishy.github.io/2024/03/13/migrate-a-legacy-application-to-aws-cloud/"/>
    <id>https://stonefishy.github.io/2024/03/13/migrate-a-legacy-application-to-aws-cloud/</id>
    <published>2024-03-13T14:20:44.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Recently, we got a requirement from the company to move the application to AWS Cloud. The company has a strong focus on security and compliance, and stack holders also want the application more reliable and scalable. The migration also need to be done as soon as possible.</p><p>The application running on a local data center. The application is consists of two parts, frontend is a static website built with React and provide the user interface to user, the backend is a Python Flask application that provide the API to interact with the frontend. The backend server also contains a machine learning model algorithm that is used to process the user’s ears photo. </p><p>The application main logic is that the user answer some questions and scan and upload their ears photo to the backend server from the website, the backend server will process the photo and return the suggestion result to user to recommend which headset or earphone is the best fit for them.</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>After analysis application technologies and architecture, base on the requirements, we did some architecture design. Below is the architecture of the application on AWS Cloud. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-migrate-legacy-app-arch.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-migrate-legacy-app-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Application Architecture on AWS Cloud"/></div><span class="image-caption">Application Architecture on AWS Cloud</span></div><p>The application is hosted on AWS Cloud, major is that the frontend is served by CloudFront, the backend is served by ECS, and the user’s ears photo is stored in S3 bucket. The application is using the following AWS services:</p><h4 id="AWS-S3-Bucket"><a href="#AWS-S3-Bucket" class="headerlink" title="AWS S3 Bucket"></a>AWS S3 Bucket</h4><p>Setup two s3 buckets, one is for storing the user’s ears photo, and config the object expires after 90 days. second bucket is for storing the static website files. All s3 buckets are public blocked.</p><h4 id="AWS-VPC"><a href="#AWS-VPC" class="headerlink" title="AWS VPC"></a>AWS VPC</h4><p>Create a dedicate VPC for the application, and configure the subnets, route tables, and security groups. Two public subnets and two private subnets are used.</p><h4 id="AWS-ECR"><a href="#AWS-ECR" class="headerlink" title="AWS ECR"></a>AWS ECR</h4><p>Use ECR to store the Docker image of the backend application. The image will be built and pushed to ECR by CI&#x2F;CD pipeline.</p><h4 id="AWS-ECS"><a href="#AWS-ECS" class="headerlink" title="AWS ECS"></a>AWS ECS</h4><p>Use ECS to run the backend application as a container in private subnets, and configure the auto scaling group and load balancer. Autoscaling minimum size is 2 and maximum size is 20.</p><h4 id="AWS-ALB"><a href="#AWS-ALB" class="headerlink" title="AWS ALB"></a>AWS ALB</h4><p>Create a ALB to serve the backend ECS service, and configure the listener rules to forward the traffic to the ECS service. The ALB attached the SSL certificate from ACM.</p><h4 id="AWS-S3-VPC-Gateway-Endpoint"><a href="#AWS-S3-VPC-Gateway-Endpoint" class="headerlink" title="AWS S3 VPC Gateway Endpoint"></a>AWS S3 VPC Gateway Endpoint</h4><p>Use the S3 VPC Gateway Endpoint to access the s3 bucket from the backend ECS container.</p><h4 id="AWS-Internet-Gateway"><a href="#AWS-Internet-Gateway" class="headerlink" title="AWS Internet Gateway"></a>AWS Internet Gateway</h4><p>The Internet Gateway to connect the VPC to the internet. Put the ALB on the two public subnets across two AZs </p><h4 id="AWS-CloudWatch"><a href="#AWS-CloudWatch" class="headerlink" title="AWS CloudWatch"></a>AWS CloudWatch</h4><p>Use CloudWatch to monitor the application performance, and create alarms to notify the team when the application is not running as expected.</p><h4 id="AWS-SNS"><a href="#AWS-SNS" class="headerlink" title="AWS SNS"></a>AWS SNS</h4><p>Use SNS to notify the team when the application performance is not good, and the team can take action to improve the application performance.</p><h4 id="AWS-ACM"><a href="#AWS-ACM" class="headerlink" title="AWS ACM"></a>AWS ACM</h4><p>Use ACM to manage the SSL certificate for the ALB and CloudFront, the certificate is issued by the IT team. The application is served over HTTPS.</p><h4 id="AWS-CloudFront"><a href="#AWS-CloudFront" class="headerlink" title="AWS CloudFront"></a>AWS CloudFront</h4><p>Use CloudFront to serve the static website files, and cache the files to improve the website loading speed. Config CloudFront to access s3 bucket by OAC. Create a another origin for the ALB.</p><h4 id="AWS-Security-Group"><a href="#AWS-Security-Group" class="headerlink" title="AWS Security Group"></a>AWS Security Group</h4><p>Create a security group for the ECS container, and allow the traffic from the ALB to the ECS container. And one more security group for the ALB to allow the traffic only from AWS CloudFront prefix list.</p><h4 id="AWS-IAM"><a href="#AWS-IAM" class="headerlink" title="AWS IAM"></a>AWS IAM</h4><p>Create an IAM role for the ECS container, and attach the necessary policies to the role to access the s3 bucket, ECR, and CloudWatch.</p><h4 id="AWS-WAF"><a href="#AWS-WAF" class="headerlink" title="AWS WAF"></a>AWS WAF</h4><p>Use WAF to protect the application from common web exploits and attacks. This is mandatory for the company’s security policy. The security team will also review the infrastucture and do the security scan the application. The application won’t be deployed to production if the security scan failed.</p><h2 id="IaC-with-Pulumi"><a href="#IaC-with-Pulumi" class="headerlink" title="IaC with Pulumi"></a>IaC with Pulumi</h2><p>Use Pulumi to manage the AWS resources, and create the infrastructure as code. The code will be checked into the source control, and for the pipeline, we’re using Bamboo pipeline as company already using Bamboo for CI&#x2F;CD. The pipeline will doing below major things.</p><ol><li>Build the Docker image and push to ECR.</li><li>Deploy the frontend static website to CloudFront, and invalidate the cache to make the content updated for end user.</li><li>Update the infrastucture by creating or updating the AWS resources by using pulumi.</li></ol><h2 id="Rationale"><a href="#Rationale" class="headerlink" title="Rationale"></a>Rationale</h2><p>The migration of the legacy application to AWS Cloud is a complex task, and we need to follow the best practices to make the migration successful.</p><ol><li>Using CloudFront and S3 bucket to host the static website and user’s ears photo is scalable and cost-effective. </li><li>Using the ECS and ALB to serve the backend application is also a good choice to improve the application performance and scalability. We’re not using AWS API Gateway and AWS Lambda to serve as backend because we are requested to migrate the application to Cloud as soon as possible. Build the python <code>Flask</code> application to a docker image and push to ECR is a good practice to deploy the application to AWS Cloud in this situation.</li><li>Using the VPC and security group to isolate the application and improve the security is a must. The ECS is located in private subnets, and the ALB is in public subnets, and the traffic is only allowed from AWS CloudFront prefix list to ALB, then forward traffic to ECS container.</li><li>Using the ACM to manage the SSL certificate for the ALB and CloudFront is a good practice to improve the security and compliance.</li><li>Using the CloudWatch to monitor the application performance and create alarms to notify the team when the application is not running as expected is a good practice to improve the application reliability.</li><li>Using the IAM role to access the s3 bucket, ECR, and CloudWatch is a good practice to improve the security and control.</li><li>Using the WAF to protect the application from common web exploits and attacks is a mandatory requirement for the company’s security policy.</li><li>Using Pulumi to manage the AWS resources as code is a good practice to improve the automation and reliability of the migration process.</li></ol><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This is just a sample of how to migrate a legacy application to AWS Cloud, and there are many other factors to consider when migrating a legacy application to AWS Cloud. The key is to follow the best practices and use the right tools to make the migration successful base on the requirements.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h2&gt;&lt;p&gt;Recently, we got a requirement from th</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>Manage the Existing Cloud Resources By Using Pulumi Import</title>
    <link href="https://stonefishy.github.io/2024/02/27/importing-existing-cloud-resources-with-pulumi/"/>
    <id>https://stonefishy.github.io/2024/02/27/importing-existing-cloud-resources-with-pulumi/</id>
    <published>2024-02-27T14:26:24.000Z</published>
    <updated>2024-11-15T06:39:09.206Z</updated>
    
    <content type="html"><![CDATA[<p>In many real-world scenarios, cloud infrastructure is already in place before adopting infrastructure as code (IaC) solutions like Pulumi. Pulumi provides a feature called <code>import</code> to help manage existing cloud resources within its IaC framework. This feature allows users to import the current state of resources into their Pulumi codebase, making it easier to adopt Pulumi for managing existing infrastructure.</p><h2 id="Pulumi-Import"><a href="#Pulumi-Import" class="headerlink" title="Pulumi Import"></a>Pulumi Import</h2><p>Pulumi’s import feature provides a way to bring existing cloud resources under Pulumi’s management. By creating a Pulumi program and using the pulumi import command, users can declare and manage existing infrastructure resources using Pulumi. The pulumi supports both importing existing resources with the CLI and importing existing resources in the code. Here we’re talking about the CLI import to generate the code for the imported resources. </p><h2 id="Usage-and-Syntax"><a href="#Usage-and-Syntax" class="headerlink" title="Usage and Syntax"></a>Usage and Syntax</h2><p>To import an existing cloud resource into Pulumi, you need to follow these steps:</p><ol><li><p>Create a Pulumi Project<br>Create a new Pulumi project or use an existing Pulumi project where you want to manage the imported resources. For creating a pulumi project, you can check the previous blog post on how to create a new Pulumi project.</p></li><li><p>Identify the Resource to Import<br>Identify the existing resource in your cloud provider environment that you want to import into Pulumi. This could be a virtual machine, database, storage bucket, or any other supported resource.</p></li><li><p>Apply the Import<br>Apply the import operation to bring the existing resource under Pulumi’s management. Pulumi will generate the appropriate code for the resource based on its current state in the cloud provider environment.</p></li></ol><p>The syntax for the import command is as follows:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import &lt;type&gt; &lt;name&gt; &lt;id&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;type&gt;</code> is the Pulumi type token to use for the imported resource.</li><li><code>&lt;name&gt;</code> is the resource name to apply to the resource once it’s imported.</li><li><code>&lt;id&gt;</code> is the value to use for the resource lookup in the cloud provider.</li></ul><h2 id="Managing-Imported-Resources"><a href="#Managing-Imported-Resources" class="headerlink" title="Managing Imported Resources"></a>Managing Imported Resources</h2><p>Once the resources are imported, they can be managed just like any other Pulumi-managed resources. The imported resources can be updated, deleted, and included in stacks alongside other Pulumi-declared infrastructure.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>I created a S3 bucket name <code>my-s3-bucket</code> from AWS Console manually. But now I want to manage this S3 bucket by Pulumi. After identifying the bucket to be imported, the import command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:s3/bucket:Bucket my-bucket my-s3-bucket</span><br></pre></td></tr></table></figure><ul><li><code>aws:s3/bucket:Bucket</code> is the Pulumi type token for the S3 bucket resource.</li><li><code>my-bucket</code> is the resource name to apply to the imported resource.</li><li><code>my-s3-bucket</code> is the value to use for the resource lookup in the AWS provider, here it’s bucket name.</li></ul><p>After running the import command, Pulumi will generate the appropriate code for the S3 bucket resource based on its current state in the AWS provider. Below is screenshot of the output of the import command:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Import"/></div><span class="image-caption">Pulumi Import</span></div><p>And generated code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">my_bucket = aws.s3.Bucket(<span class="string">&quot;my-bucket&quot;</span>,</span><br><span class="line">    arn=<span class="string">&quot;arn:aws-cn:s3:::my-s3-bucket&quot;</span>,</span><br><span class="line">    bucket=<span class="string">&quot;my-s3-bucket&quot;</span>,</span><br><span class="line">    hosted_zone_id=<span class="string">&quot;Z282HJ1KT0DH03&quot;</span>,</span><br><span class="line">    request_payer=<span class="string">&quot;BucketOwner&quot;</span>,</span><br><span class="line">    server_side_encryption_configuration=aws.s3.BucketServerSideEncryptionConfigurationArgs(</span><br><span class="line">        rule=aws.s3.BucketServerSideEncryptionConfigurationRuleArgs(</span><br><span class="line">            apply_server_side_encryption_by_default=aws.s3.BucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefaultArgs(</span><br><span class="line">                sse_algorithm=<span class="string">&quot;AES256&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            bucket_key_enabled=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure><p>In above code, you will notice there is a <code>protect=True</code> option set for the imported resource. This is to prevent any accidental deletion of the imported resource.</p><p>So when you try to delete the imported resource, Pulumi will give the errors to you. Let’s try to delete the imported S3 bucket:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi destroy</span><br></pre></td></tr></table></figure><p>You see, it displays the error message that the S3 bucket is protected and cannot be deleted.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-destory-import.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-destory-import.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Destory Import Protected Resource"/></div><span class="image-caption">Pulumi Destory Import Protected Resource</span></div><p>If you want to delete the resource in the cloud provider environment, you can remove the <code>protect=True</code> option from the code or change the <code>protect</code> option to <code>False</code>.</p><p>In above we’re using <code>pulumi import</code> to import the s3 bucket resource and code is generated on console. We can also generate the code into python file directly by using below command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:s3/bucket:Bucket my-bucket my-s3-bucket -o my-s3-bucket.py</span><br></pre></td></tr></table></figure><h2 id="Pulumi-State"><a href="#Pulumi-State" class="headerlink" title="Pulumi State"></a>Pulumi State</h2><p>Pulumi maintains a state file that tracks the current state of all resources in the cloud provider environment. When a resource is imported, Pulumi updates the state file to reflect the imported resource. This allows Pulumi to manage the imported resource as if it were created in the cloud provider environment.</p><p>Sometimes, we want to delete the state which imported in pulumi, but keep the existing cloud resources. In such case, we can use below command to only delete the state and keep the existing cloud resources.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi state delete &lt;urn&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;urn&gt;</code> is the unique resource identifier of the imported resource.</li></ul><p>To check the <code>&lt;urn&gt;</code> of the resource, we can use <code>pulumi stack --show-urns</code> to see the list urns of all resources in the current stack.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack --show-urns</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-stack-show-urns.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-stack-show-urns.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Stack Show Urns"/></div><span class="image-caption">Pulumi Stack Show Urns</span></div><p>In above screenshot, we can see the <code>&lt;urn&gt;</code> of the imported S3 bucket resource.To delete the state of the imported resource, we can use the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi state delete urn:pulumi:dev::pulumi-test::aws:s3/bucket:Bucket::my-bucket --force -y</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-state-delete.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-state-delete.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi State Delete Imported Resource"/></div><span class="image-caption">Pulumi State Delete Imported Resource</span></div><p>After deleting the state, the imported S3 bucket will still exist in the cloud provider environment.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Pulumi’s import feature allows users to seamlessly integrate existing cloud resources into their Pulumi programs. By following the import process and syntax, users can effectively manage their entire infrastructure, including existing resources, through Pulumi’s IaC approach.</p><p>This feature simplifies the transition to Pulumi for managing infrastructure and enables teams to leverage the benefits of IaC without having to recreate their entire cloud environment from scratch.</p><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links"></a>Reference Links</h2><ul><li>Pulumi Import: <a href="https://www.pulumi.com/docs/cli/commands/pulumi_import/">https://www.pulumi.com/docs/cli/commands/pulumi_import/</a></li><li>S3 Bucket Import: <a href="https://www.pulumi.com/registry/packages/aws/api-docs/s3/bucket/#import">https://www.pulumi.com/registry/packages/aws/api-docs/s3/bucket/#import</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In many real-world scenarios, cloud infrastructure is already in place before adopting infrastructure as code (IaC) solutions like Pulumi</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
</feed>
