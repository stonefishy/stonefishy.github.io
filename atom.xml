<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andrewsy&#39;s Space</title>
  
  
  <link href="https://stonefishy.github.io/atom.xml" rel="self"/>
  
  <link href="https://stonefishy.github.io/"/>
  <updated>2025-06-19T09:28:26.172Z</updated>
  <id>https://stonefishy.github.io/</id>
  
  <author>
    <name>Andrewsy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Speech Translator base on Azure Speech Service</title>
    <link href="https://stonefishy.github.io/2025/06/19/speech-translator-base-on-azure-speech-service/"/>
    <id>https://stonefishy.github.io/2025/06/19/speech-translator-base-on-azure-speech-service/</id>
    <published>2025-06-19T15:14:38.000Z</published>
    <updated>2025-06-19T09:28:26.172Z</updated>
    
    <content type="html"><![CDATA[<p>Today we’re going to talk about how to build a speech translator using <code>Azure Speech Service</code> of <code>Azure AI</code> . We’ll be using the <code>JavaScript SDK</code> for the Speech Service to build the translator. We’ll using <code>Next.js</code> to build the web application.</p><h2 id="What-is-speech-translation"><a href="#What-is-speech-translation" class="headerlink" title="What is speech translation?"></a>What is speech translation?</h2><p>Speech translation is the process of translating speech from one language to another. It involves using speech recognition to convert the <code>speech to text</code>, and then using <code>text-to-speech</code> to convert the translated text back to speech. The <code>Azure AI Speech</code> provides a <code>speech to speech</code> translation service that can translate speech from one language to another. The Speech service supports <code>real-time</code>, <code>multi-language</code> speech to speech and speech to text translation of audio streams.</p><h2 id="Create-Azure-Speech-Service-resource"><a href="#Create-Azure-Speech-Service-resource" class="headerlink" title="Create Azure Speech Service resource"></a>Create Azure Speech Service resource</h2><p>In <code>Microsfot Azure</code> Cloud portal, select the <code>Speech Service</code> resource and go to the <code>AI Foundry</code> - <code>Speech service</code> management page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Select Azure Speech Service" style="width:800px;"/></div><span class="image-caption">Select Azure Speech Service</span></div><p>To create a new <code>Speech Service</code> resource is very simple, just click the <code>Create</code> button, and then fill the name, location, and pricing tier of the resource.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service-create.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service-create.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create Azure Speech Service" style="width:800px;"/></div><span class="image-caption">Create Azure Speech Service</span></div><p>Once the speech service created, you can see it in resouce list.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service-list.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Azure Speech Service List" style="width:800px;"/></div><span class="image-caption">Azure Speech Service List</span></div><p>To get the <code>key</code> and <code>endpoint</code> of the speech service, click the <code>Manage Key</code> link, it will show the <code>key</code> and <code>endpoint</code>, <code>location</code> of the speech service. The subscription <code>Key</code> and <code>Location</code> will be used to access the speech service. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service-key.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service-key.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Azure Speech Service Key" style="width:800px;"/></div><span class="image-caption">Azure Speech Service Key</span></div><h2 id="Play-the-Speech-Service-via-Speech-Studio"><a href="#Play-the-Speech-Service-via-Speech-Studio" class="headerlink" title="Play the Speech Service via Speech Studio"></a>Play the Speech Service via Speech Studio</h2><p>To play the speech service, you can use the <code>Speech Studio</code> tool. Just go to the <code>Speech Studio</code> page, and then click the <code>Get Started</code> button. Select the <code>Speech Translation</code> card. Let’s speech Chinese to English voice.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-studio.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-studio.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Azure Speech Studio - Speech Translation" style="width:800px;"/></div><span class="image-caption">Azure Speech Studio - Speech Translation</span></div><p>Now, our speech service is ready to use.</p><h2 id="Create-Web-applicaiton"><a href="#Create-Web-applicaiton" class="headerlink" title="Create Web applicaiton"></a>Create Web applicaiton</h2><p>To create the web application, we’ll be using <code>Next.js</code> framework. The <code>Next.js</code> is a React framework that allows us to build server-side rendered (SSR) or client-side rendered (CSR) web applications. It is a powerful framework that allows us to build fast and efficient web applications.</p><p>To create the web application, we’ll use the <code>create-next-app</code> command. Open the terminal and run the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx create-next-app@latest</span><br></pre></td></tr></table></figure><p>Let’s build a simple web application that user can access the device microphone and translate the Chinese (普通话), Cantonese (粤语) speech voice to English language voice in real-time. The UI of the web application will be simple and easy to use. Screenshots like below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-translator-ui-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-translator-ui-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Speech Translator UI - Microphone" style="width:300px;"/></div><span class="image-caption">Speech Translator UI - Microphone</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-translator-ui-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-translator-ui-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Speech Translator UI - Listening & Translation" style="width:300px;"/></div><span class="image-caption">Speech Translator UI - Listening & Translation</span></div><p>The UI is based on the <code>Tailwind CSS</code> framework. The <code>Tailwind CSS</code> is a utility-first CSS framework that allows us to build custom user interfaces with pre-defined classes. The <code>Tailwind CSS</code> framework provides a set of pre-defined classes that we can use to style our web application. The <code>Tailwind CSS</code> framework is very flexible and allows us to build custom user interfaces with pre-defined classes. Below are the <code>Tailwind CSS</code> classes that we can use to style our web application.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">main</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">geistSans.variable</span>&#125; $&#123;<span class="attr">geistMono.variable</span>&#125; <span class="attr">font-sans</span> <span class="attr">flex</span> <span class="attr">flex-col</span> <span class="attr">h-screen</span>`&#125;&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center pt-10 pb-10 gap-5&quot;</span>&gt;</span></span><br><span class="line">    &#123;OriginalLanguages.map((language) =&gt; &#123;</span><br><span class="line">      return (</span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center&quot;</span> <span class="attr">key</span>=<span class="string">&#123;language.value&#125;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">value</span>=<span class="string">&#123;language.value&#125;</span> <span class="attr">checked</span>=<span class="string">&#123;originalLanguage</span> === <span class="string">language.value&#125;</span> <span class="attr">disabled</span>=<span class="string">&#123;isRecording&#125;</span> <span class="attr">onChange</span>=<span class="string">&#123;()</span> =&gt;</span> setOriginalLanguage(language.value)&#125; name=&quot;default-radio&quot; className=&quot;w-8 h-8 text-blue-600 bg-gray-100 border-gray-30 dark:ring-offset-gray-800 dark:bg-gray-700 dark:border-gray-600&quot; /&gt;</span><br><span class="line">          <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">text-gray-400</span>&quot; <span class="attr">:</span> &quot;<span class="attr">text-gray-900</span>&quot;&#125; <span class="attr">ms-2</span> <span class="attr">text-2xl</span> <span class="attr">font-medium</span> <span class="attr">dark:text-gray-300</span>`&#125;&gt;</span>&#123;language.label&#125;<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      )</span><br><span class="line">    &#125;)&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center flex-auto pb-20&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">hidden</span>&quot; <span class="attr">:</span> &quot;<span class="attr">block</span>&quot;&#125; <span class="attr">flex</span> <span class="attr">items-center</span> <span class="attr">justify-center</span> <span class="attr">rounded-full</span> <span class="attr">size-64</span> <span class="attr">bg-blue-200</span> <span class="attr">mx-auto</span> <span class="attr">cursor-pointer</span> <span class="attr">hover:bg-blue-300</span> <span class="attr">transition-colors</span>`&#125;</span></span><br><span class="line"><span class="tag">    <span class="attr">onClick</span>=<span class="string">&#123;startRecording&#125;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-blue-400 hover:bg-blue-500 transition-colors&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/microphone.svg&quot;</span>  <span class="attr">alt</span>=<span class="string">&quot;Microphone&quot;</span> <span class="attr">className</span>=<span class="string">&quot;size-24&quot;</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">block</span>&quot; <span class="attr">:</span> &quot;<span class="attr">hidden</span>&quot;&#125; <span class="attr">flex-col</span> <span class="attr">items-center</span> <span class="attr">justify-center</span>`&#125;&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-64 bg-red-200 mx-auto cursor-pointer hover:bg-red-300 transition-colors&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">onClick</span>=<span class="string">&#123;stopRecording&#125;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-red-400 hover:bg-red-500 transition-colors&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;w-16 h-16 bg-white animate-pulse&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center mt-2&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;block w-64 items-center justify-start text-xl&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/speech.svg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;voice&quot;</span> <span class="attr">className</span>=<span class="string">&quot;inline-block ml-12 size-12&quot;</span> /&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block text-center font-medium ml-2&quot;</span>&gt;</span>Listening <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block font-medium&quot;</span>&gt;</span>&#123;listenLoading&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">main</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Integrated-with-Azure-Speech-Service"><a href="#Integrated-with-Azure-Speech-Service" class="headerlink" title="Integrated with Azure Speech Service"></a>Integrated with Azure Speech Service</h2><p>The <code>Azure Speech Service</code> provides multiple language SDKs, including <code>JavaScript</code>, <code>Go</code>, <code>C#</code>, <code>Python</code>, <code>Java</code>, <code>Swift</code>, <code>Objective-C</code>, and <code>C++</code>. You can access this speech SDK link <a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-sdk">https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-sdk</a>. We’ll be using the <code>JavaScript</code> SDK to integrate with the speech service.</p><p>To install the <code>JavaScript</code> SDK, we’ll use the <code>npm</code> command. Open the terminal and run the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install microsoft-cognitiveservices-speech-sdk</span><br></pre></td></tr></table></figure><p>Accessing the device microhpone, we can use <code>navigator.mediaDevices.getUserMedia()</code> method. The <code>getUserMedia()</code> method returns a <code>Promise</code> that resolves with a <code>MediaStream</code> object representing the captured media. We can then pass this <code>MediaStream</code> object to the <code>SpeechSDK.AudioConfig</code> object to create a <code>SpeechSDK.AudioConfig</code> object that represents the audio input device.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">requestMicrophoneAccess</span> = (<span class="params">callback</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (navigator.<span class="property">mediaDevices</span> &amp;&amp; navigator.<span class="property">mediaDevices</span>.<span class="property">getUserMedia</span>) &#123;</span><br><span class="line">      navigator.<span class="property">mediaDevices</span>.<span class="title function_">getUserMedia</span>(&#123; <span class="attr">audio</span>: <span class="literal">true</span> &#125;)</span><br><span class="line">        .<span class="title function_">then</span>(<span class="function">(<span class="params">stream</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Microphone access granted.&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> speechConfig = <span class="title class_">SpeechSDK</span>.<span class="property">SpeechTranslationConfig</span>.<span class="title function_">fromSubscription</span>(config.<span class="property">SPEECH_SUBSCRIPTION_KEY</span>, config.<span class="property">SPEECH_SERVICE_REGION</span>);</span><br><span class="line">          speechConfig.<span class="property">outputFormat</span> = <span class="title class_">SpeechSDK</span>.<span class="property">OutputFormat</span>.<span class="property">Detailed</span>;</span><br><span class="line">          speechConfig.<span class="property">speechRecognitionLanguage</span> = originalLanguage;</span><br><span class="line">          speechConfig.<span class="title function_">addTargetLanguage</span>(<span class="title class_">TargetLanguage</span>);</span><br><span class="line">          speechConfig.<span class="title function_">setProperty</span>(<span class="title class_">SpeechSDK</span>.<span class="property">PropertyId</span>.<span class="property">SpeechServiceConnection_TranslationVoice</span>, <span class="string">&quot;en-US-JennyNeural&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> audioConfig = <span class="title class_">SpeechSDK</span>.<span class="property">AudioConfig</span>.<span class="title function_">fromStreamInput</span>(stream);</span><br><span class="line">          <span class="keyword">const</span> recognizer = <span class="keyword">new</span> <span class="title class_">SpeechSDK</span>.<span class="title class_">TranslationRecognizer</span>(speechConfig, audioConfig);</span><br><span class="line">          recognizer.<span class="property">recognizing</span> = speechRecognizing;</span><br><span class="line">          recognizer.<span class="property">recognized</span> = speechRecognized;</span><br><span class="line">          recognizer.<span class="property">synthesizing</span> = speechSynthesizing;</span><br><span class="line">          callback &amp;&amp; <span class="title function_">callback</span>(recognizer);</span><br><span class="line">        &#125;)</span><br><span class="line">        .<span class="title function_">catch</span>(<span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Error accessing microphone:&quot;</span>, error);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;getUserMedia is not supported in this browser.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, we are using the <code>SpeechTranslationConfig</code> object to configure the speech translation service. We are setting the <code>outputFormat</code> to <code>Detailed</code> to get the detailed translation result. We are setting the <code>speechRecognitionLanguage</code> to the original language and the <code>addTargetLanguage</code> to the target language. We are setting the <code>SpeechServiceConnection_TranslationVoice</code> property to <code>en-US-JennyNeural</code> to get the neural voice for the target language. We are creating a <code>SpeechSDK.AudioConfig</code> object from the <code>MediaStream</code> object and passing it to the <code>SpeechSDK.TranslationRecognizer</code> object, and setting the <code>recognizing</code>, <code>recognized</code>, and <code>synthesizing</code> event handlers to get the translation result.</p><p>The <code>config.SPEECH_SUBSCRIPTION_KEY</code> and <code>config.SPEECH_SERVICE_REGION</code> are the subscription key and region for the speech service. We are using these values to configure the speech translation service.</p><p>The <code>recognizing</code> event handler is called when the speech service is processing the audio input, and the <code>recognized</code> event handler is called when the speech service has recognized the speech input. The <code>synthesizing</code> event handler is called when the speech service is synthesizing the translated text to speech.</p><p>Below are these event handlers.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">speechRecognizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognizing: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">speechRecognized</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">RecognizedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">TranslatedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Translate Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">NoMatch</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;No speech could be recognized.&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">Canceled</span>) &#123;</span><br><span class="line">      <span class="keyword">const</span> cancellation = <span class="title class_">SpeechSDK</span>.<span class="property">CancellationDetails</span>.<span class="title function_">fromResult</span>(e.<span class="property">result</span>);</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: Reason=<span class="subst">$&#123;cancellation.reason&#125;</span>`</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (cancellation.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">CancellationReason</span>.<span class="property">Error</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorCode=<span class="subst">$&#123;cancellation.errorCode&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorDetails=<span class="subst">$&#123;cancellation.errorDetails&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;CANCELED: Did you set the speech resource key and region values?&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">speechSynthesizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> audioSize = e.<span class="property">result</span>.<span class="property">audio</span> === <span class="literal">undefined</span> ? <span class="number">0</span> : e.<span class="property">result</span>.<span class="property">audio</span>.<span class="property">byteLength</span>;</span><br><span class="line">    <span class="keyword">var</span> text =<span class="string">&quot;&quot;</span>;</span><br><span class="line">    text += <span class="string">`(synthesizing) Reason: <span class="subst">$&#123;SpeechSDK.ResultReason[e.result.reason]&#125;</span>`</span></span><br><span class="line">        + <span class="string">` <span class="subst">$&#123;audioSize&#125;</span> bytes\r\n`</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">audio</span> &amp;&amp; soundContext) &#123;</span><br><span class="line">        <span class="keyword">var</span> source = soundContext.<span class="title function_">createBufferSource</span>();</span><br><span class="line">        soundContext.<span class="title function_">decodeAudioData</span>(e.<span class="property">result</span>.<span class="property">audio</span>, <span class="keyword">function</span> (<span class="params">newBuffer</span>) &#123;</span><br><span class="line">            source.<span class="property">buffer</span> = newBuffer;</span><br><span class="line">            source.<span class="title function_">connect</span>(soundContext.<span class="property">destination</span>);</span><br><span class="line">            source.<span class="title function_">start</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In <code>synthesizing</code> event handler, we are logging the <code>ResultReason</code> and the audio size. If the <code>audio</code> property is not <code>undefined</code>, we are decoding the <code>audio</code> data and playing it using the <code>Web Audio API</code>.</p><p>The above <code>soundContext</code> is a global variable that we are using to play the audio. We can create the <code>soundContext</code> object using the <code>AudioContext</code> constructor. Below is the code to create the <code>soundContext</code> object.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">getSoundContext</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">var</span> soundContext = <span class="literal">undefined</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> <span class="title class_">AudioContext</span> = <span class="variable language_">window</span>.<span class="property">AudioContext</span> || <span class="variable language_">window</span>.<span class="property">webkitAudioContext</span> || <span class="literal">false</span>;                          </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="title class_">AudioContext</span>) &#123;</span><br><span class="line">        soundContext = <span class="keyword">new</span> <span class="title class_">AudioContext</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Audio context not supported&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;no sound context found, no audio output. &quot;</span> + e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> soundContext;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> soundContext = <span class="title function_">getSoundContext</span>();</span><br></pre></td></tr></table></figure><h2 id="Play-it"><a href="#Play-it" class="headerlink" title="Play it"></a>Play it</h2><p>Now, we can run the web application using the <code>npm run dev</code> command. Open the web browser and go to <code>http://localhost:3000</code>. You should see the web application with the microphone icon. Click the microphone icon to start recording the speech. Speak Chinese Mandarin, Cantonese speech voice and the web application will translate the speech to English language voice in real-time.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-translator-demo.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-translator-demo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Speech Translator Demo" style="width:800px;"/></div><span class="image-caption">Speech Translator Demo</span></div><p>In above screenshot, it is recognize the speech to the text and we print it in console log. Once speech recognized. It is translated to English language voice and played in the web application.</p><p>Below are major code in <code>index.js</code> for <code>Azure Speech Translator</code>. It is simple to using <code>Azure Speech Service</code> to do the continous <code>Speech Translation</code> in real-time.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123; useState, useEffect &#125; <span class="keyword">from</span> <span class="string">&quot;react&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Geist</span>, <span class="title class_">Geist</span>_Mono &#125; <span class="keyword">from</span> <span class="string">&quot;next/font/google&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> <span class="title class_">SpeechSDK</span> <span class="keyword">from</span> <span class="string">&quot;microsoft-cognitiveservices-speech-sdk&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> config <span class="keyword">from</span> <span class="string">&quot;../config&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> geistSans = <span class="title class_">Geist</span>(&#123;</span><br><span class="line">  <span class="attr">variable</span>: <span class="string">&quot;--font-geist-sans&quot;</span>,</span><br><span class="line">  <span class="attr">subsets</span>: [<span class="string">&quot;latin&quot;</span>],</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> geistMono = <span class="title class_">Geist</span>_Mono(&#123;</span><br><span class="line">  <span class="attr">variable</span>: <span class="string">&quot;--font-geist-mono&quot;</span>,</span><br><span class="line">  <span class="attr">subsets</span>: [<span class="string">&quot;latin&quot;</span>],</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">TargetLanguage</span> = <span class="string">&quot;en-US&quot;</span>; <span class="comment">// &quot;en-US&quot;</span></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">OriginalLanguages</span> = [&#123;</span><br><span class="line">  <span class="attr">label</span>: <span class="string">&#x27;Mandarin&#x27;</span>,</span><br><span class="line">  <span class="attr">value</span>: <span class="string">&#x27;zh-CN&#x27;</span>,</span><br><span class="line">&#125;, &#123;</span><br><span class="line">  <span class="attr">label</span>: <span class="string">&quot;Cantonese&quot;</span>,</span><br><span class="line">  <span class="attr">value</span>: <span class="string">&quot;yue-cn&quot;</span>,</span><br><span class="line">&#125;];</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">getSoundContext</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">var</span> soundContext = <span class="literal">undefined</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> <span class="title class_">AudioContext</span> = <span class="variable language_">window</span>.<span class="property">AudioContext</span> || <span class="variable language_">window</span>.<span class="property">webkitAudioContext</span> || <span class="literal">false</span>;                          </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="title class_">AudioContext</span>) &#123;</span><br><span class="line">        soundContext = <span class="keyword">new</span> <span class="title class_">AudioContext</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Audio context not supported&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;no sound context found, no audio output. &quot;</span> + e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> soundContext;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> soundContext = <span class="title function_">getSoundContext</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Home</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [isRecording, setIsRecording] = <span class="title function_">useState</span>(<span class="literal">false</span>);</span><br><span class="line">  <span class="keyword">const</span> [speechRecognizer, setSpeechRecognizer] = <span class="title function_">useState</span>(<span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">const</span> [originalLanguage, setOriginalLanguage] = <span class="title function_">useState</span>(<span class="string">&#x27;zh-CN&#x27;</span>);</span><br><span class="line">  <span class="keyword">const</span> [listenLoading, setlistenLoading] = <span class="title function_">useState</span>(<span class="string">&quot;...&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">startRecording</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="title function_">requestMicrophoneAccess</span>(<span class="function">(<span class="params">recognizer</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="title function_">setSpeechRecognizer</span>(recognizer);</span><br><span class="line">      <span class="title function_">setIsRecording</span>(<span class="literal">true</span>);</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Microphone access granted, starting recognition...&quot;</span>);</span><br><span class="line"></span><br><span class="line">      recognizer.<span class="title function_">startContinuousRecognitionAsync</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Continuous recognition started.&quot;</span>);</span><br><span class="line">      &#125;, <span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">stopRecording</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (speechRecognizer !== <span class="literal">null</span>) &#123;</span><br><span class="line">      speechRecognizer.<span class="title function_">stopContinuousRecognitionAsync</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Continuous recognition stopped.&quot;</span>);</span><br><span class="line">        <span class="title function_">setIsRecording</span>(<span class="literal">false</span>);</span><br><span class="line">      &#125;, <span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">requestMicrophoneAccess</span> = (<span class="params">callback</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (navigator.<span class="property">mediaDevices</span> &amp;&amp; navigator.<span class="property">mediaDevices</span>.<span class="property">getUserMedia</span>) &#123;</span><br><span class="line">      navigator.<span class="property">mediaDevices</span>.<span class="title function_">getUserMedia</span>(&#123; <span class="attr">audio</span>: <span class="literal">true</span> &#125;)</span><br><span class="line">        .<span class="title function_">then</span>(<span class="function">(<span class="params">stream</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Microphone access granted.&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> speechConfig = <span class="title class_">SpeechSDK</span>.<span class="property">SpeechTranslationConfig</span>.<span class="title function_">fromSubscription</span>(config.<span class="property">SPEECH_SUBSCRIPTION_KEY</span>, config.<span class="property">SPEECH_SERVICE_REGION</span>);</span><br><span class="line">          speechConfig.<span class="property">outputFormat</span> = <span class="title class_">SpeechSDK</span>.<span class="property">OutputFormat</span>.<span class="property">Detailed</span>;</span><br><span class="line">          speechConfig.<span class="property">speechRecognitionLanguage</span> = originalLanguage;</span><br><span class="line">          speechConfig.<span class="title function_">addTargetLanguage</span>(<span class="title class_">TargetLanguage</span>);</span><br><span class="line">          speechConfig.<span class="title function_">setProperty</span>(<span class="title class_">SpeechSDK</span>.<span class="property">PropertyId</span>.<span class="property">SpeechServiceConnection_TranslationVoice</span>, <span class="string">&quot;en-US-JennyNeural&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> audioConfig = <span class="title class_">SpeechSDK</span>.<span class="property">AudioConfig</span>.<span class="title function_">fromStreamInput</span>(stream);</span><br><span class="line">          <span class="keyword">const</span> recognizer = <span class="keyword">new</span> <span class="title class_">SpeechSDK</span>.<span class="title class_">TranslationRecognizer</span>(speechConfig, audioConfig);</span><br><span class="line">          recognizer.<span class="property">recognizing</span> = speechRecognizing;</span><br><span class="line">          recognizer.<span class="property">recognized</span> = speechRecognized;</span><br><span class="line">          recognizer.<span class="property">synthesizing</span> = speechSynthesizing;</span><br><span class="line">          callback &amp;&amp; <span class="title function_">callback</span>(recognizer);</span><br><span class="line">        &#125;)</span><br><span class="line">        .<span class="title function_">catch</span>(<span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Error accessing microphone:&quot;</span>, error);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;getUserMedia is not supported in this browser.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">speechRecognizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognizing: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">speechRecognized</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">RecognizedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">TranslatedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Translate Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">NoMatch</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;No speech could be recognized.&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">Canceled</span>) &#123;</span><br><span class="line">      <span class="keyword">const</span> cancellation = <span class="title class_">SpeechSDK</span>.<span class="property">CancellationDetails</span>.<span class="title function_">fromResult</span>(e.<span class="property">result</span>);</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: Reason=<span class="subst">$&#123;cancellation.reason&#125;</span>`</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (cancellation.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">CancellationReason</span>.<span class="property">Error</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorCode=<span class="subst">$&#123;cancellation.errorCode&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorDetails=<span class="subst">$&#123;cancellation.errorDetails&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;CANCELED: Did you set the speech resource key and region values?&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">speechSynthesizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> audioSize = e.<span class="property">result</span>.<span class="property">audio</span> === <span class="literal">undefined</span> ? <span class="number">0</span> : e.<span class="property">result</span>.<span class="property">audio</span>.<span class="property">byteLength</span>;</span><br><span class="line">    <span class="keyword">var</span> text =<span class="string">&quot;&quot;</span>;</span><br><span class="line">    text += <span class="string">`(synthesizing) Reason: <span class="subst">$&#123;SpeechSDK.ResultReason[e.result.reason]&#125;</span>`</span></span><br><span class="line">        + <span class="string">` <span class="subst">$&#123;audioSize&#125;</span> bytes\r\n`</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">audio</span> &amp;&amp; soundContext) &#123;</span><br><span class="line">        <span class="keyword">var</span> source = soundContext.<span class="title function_">createBufferSource</span>();</span><br><span class="line">        soundContext.<span class="title function_">decodeAudioData</span>(e.<span class="property">result</span>.<span class="property">audio</span>, <span class="keyword">function</span> (<span class="params">newBuffer</span>) &#123;</span><br><span class="line">            source.<span class="property">buffer</span> = newBuffer;</span><br><span class="line">            source.<span class="title function_">connect</span>(soundContext.<span class="property">destination</span>);</span><br><span class="line">            source.<span class="title function_">start</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isRecording) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> listening = <span class="built_in">setInterval</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (isRecording) &#123;</span><br><span class="line">        <span class="title function_">setlistenLoading</span>(<span class="function">(<span class="params">prev</span>) =&gt;</span> prev.<span class="property">length</span> &lt; <span class="number">5</span> ? prev + <span class="string">&quot;.&quot;</span> : <span class="string">&quot;&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, <span class="number">700</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="function">() =&gt;</span> <span class="built_in">clearInterval</span>(listening);</span><br><span class="line">  &#125;, [isRecording]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">main</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">geistSans.variable</span>&#125; $&#123;<span class="attr">geistMono.variable</span>&#125; <span class="attr">font-sans</span> <span class="attr">flex</span> <span class="attr">flex-col</span> <span class="attr">h-screen</span>`&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center pt-10 pb-10 gap-5&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        &#123;OriginalLanguages.map((language) =&gt; &#123;</span></span><br><span class="line"><span class="language-xml">          return (</span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center&quot;</span> <span class="attr">key</span>=<span class="string">&#123;language.value&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">value</span>=<span class="string">&#123;language.value&#125;</span> <span class="attr">checked</span>=<span class="string">&#123;originalLanguage</span> === <span class="string">language.value&#125;</span> <span class="attr">disabled</span>=<span class="string">&#123;isRecording&#125;</span> <span class="attr">onChange</span>=<span class="string">&#123;()</span> =&gt;</span> setOriginalLanguage(language.value)&#125; name=&quot;default-radio&quot; className=&quot;w-8 h-8 text-blue-600 bg-gray-100 border-gray-30 dark:ring-offset-gray-800 dark:bg-gray-700 dark:border-gray-600&quot; /&gt;</span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">text-gray-400</span>&quot; <span class="attr">:</span> &quot;<span class="attr">text-gray-900</span>&quot;&#125; <span class="attr">ms-2</span> <span class="attr">text-2xl</span> <span class="attr">font-medium</span> <span class="attr">dark:text-gray-300</span>`&#125;&gt;</span>&#123;language.label&#125;<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          )</span></span><br><span class="line"><span class="language-xml">        &#125;)&#125;</span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center flex-auto pb-20&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">hidden</span>&quot; <span class="attr">:</span> &quot;<span class="attr">block</span>&quot;&#125; <span class="attr">flex</span> <span class="attr">items-center</span> <span class="attr">justify-center</span> <span class="attr">rounded-full</span> <span class="attr">size-64</span> <span class="attr">bg-blue-200</span> <span class="attr">mx-auto</span> <span class="attr">cursor-pointer</span> <span class="attr">hover:bg-blue-300</span> <span class="attr">transition-colors</span>`&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">onClick</span>=<span class="string">&#123;startRecording&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-blue-400 hover:bg-blue-500 transition-colors&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/microphone.svg&quot;</span>  <span class="attr">alt</span>=<span class="string">&quot;Microphone&quot;</span> <span class="attr">className</span>=<span class="string">&quot;size-24&quot;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">block</span>&quot; <span class="attr">:</span> &quot;<span class="attr">hidden</span>&quot;&#125; <span class="attr">flex-col</span> <span class="attr">items-center</span> <span class="attr">justify-center</span>`&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-64 bg-red-200 mx-auto cursor-pointer hover:bg-red-300 transition-colors&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">onClick</span>=<span class="string">&#123;stopRecording&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-red-400 hover:bg-red-500 transition-colors&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;w-16 h-16 bg-white animate-pulse&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center mt-2&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;block w-64 items-center justify-start text-xl&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/speech.svg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;voice&quot;</span> <span class="attr">className</span>=<span class="string">&quot;inline-block ml-12 size-12&quot;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block text-center font-medium ml-2&quot;</span>&gt;</span>Listening <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block font-medium&quot;</span>&gt;</span>&#123;listenLoading&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span>  </span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">main</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The <code>Speech Service</code> of <code>Azure AI</code> is a cloud-based service that provides speech recognition and speech synthesis capabilities. It is a part of <code>Azure AI</code> suite. We can use it to build speech-enabled applications, such as speech-to-text, text-to-speech, and speech translation.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Today we’re going to talk about how to build a speech translator using &lt;code&gt;Azure Speech Service&lt;/code&gt; of &lt;code&gt;Azure AI&lt;/code&gt; . We’ll</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="Next.js" scheme="https://stonefishy.github.io/tags/Next-js/"/>
    
    <category term="Tailwind" scheme="https://stonefishy.github.io/tags/Tailwind/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Generative AI Tools</title>
    <link href="https://stonefishy.github.io/2025/05/11/introduction-to-generative-ai-tools/"/>
    <id>https://stonefishy.github.io/2025/05/11/introduction-to-generative-ai-tools/</id>
    <published>2025-05-11T15:27:34.000Z</published>
    <updated>2025-06-19T09:28:26.172Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction-to-Generative-AI-Tools"><a href="#Introduction-to-Generative-AI-Tools" class="headerlink" title="Introduction to Generative AI Tools"></a>Introduction to Generative AI Tools</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-intro.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-intro.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Generative AI Tools" style="width:500px;"/></div><span class="image-caption">Generative AI Tools</span></div><p>Generative AI tools are revolutionizing the way content is created by leveraging advanced machine learning models. These tools enable users to generate <code>text</code>, <code>images</code>, <code>videos</code>, and more, offering innovative solutions across various industries.</p><h2 id="Popular-Generative-AI-Tools"><a href="#Popular-Generative-AI-Tools" class="headerlink" title="Popular Generative AI Tools"></a>Popular Generative AI Tools</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-popular.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-popular.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Popular Generative AI Tools" style="width:800px;"/></div><span class="image-caption">Popular Generative AI Tools</span></div><p>Several generative AI tools are widely used across industries. Tools like <code>ChatGPT</code> and <code>Jasper</code> are popular for generating human-like text, while platforms like <code>DALL·E</code> and <code>Midjourney</code> excel in creating stunning visuals based on textual descriptions.</p><p>Other tools, such as <code>Runway</code> for video creation and <code>ElevenLabs</code> for AI-generated voices, showcase the versatility of generative AI. These tools simplify complex tasks, making them accessible to professionals and non-experts alike.</p><h3 id="AI-Tools-for-Text-Generation"><a href="#AI-Tools-for-Text-Generation" class="headerlink" title="AI Tools for Text Generation"></a>AI Tools for Text Generation</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-text.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-text.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Text Generation AI Tools" style="width:800px;"/></div><span class="image-caption">Text Generation AI Tools</span></div><p>Generative AI tools for text creation include platforms like <code>Jasper</code> and <code>Anyword</code>, which assist in crafting marketing content and sales copy. These tools leverage advanced machine learning algorithms to produce human-like text tailored to specific audiences and purposes.</p><p><code>Quillbot</code> is another example, offering paraphrasing and summarization features that enhance writing efficiency. Such tools are widely used in industries ranging from education to marketing, streamlining workflows and boosting productivity.</p><h3 id="AI-Tools-for-Image-Creation"><a href="#AI-Tools-for-Image-Creation" class="headerlink" title="AI Tools for Image Creation"></a>AI Tools for Image Creation</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-image.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-image.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Image Generation AI Tools" style="width:800px;"/></div><span class="image-caption">Image Generation AI Tools</span></div><p>Generative AI tools like <code>DALL·E 3</code> and <code>Midjourney</code> are revolutionizing image creation by generating high-quality visuals from textual descriptions. These tools are ideal for creating unique artwork, marketing materials, and design prototypes.</p><p><code>Adobe Photoshop</code> also incorporates AI features for enhancing images, such as automated background removal and content-aware editing. These tools empower users to produce professional-grade visuals with minimal effort.</p><h3 id="Video-And-Audio-Generation-Platforms"><a href="#Video-And-Audio-Generation-Platforms" class="headerlink" title="Video And Audio Generation Platforms"></a>Video And Audio Generation Platforms</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-audio-video.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-audio-video.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Audio and Video Generation AI Tools" style="width:800px;"/></div><span class="image-caption">Audio and Video Generation AI Tools</span></div><p><code>Runway</code> and <code>Wondershare Filmora</code> are popular generative AI tools for video creation, enabling users to produce creative and polished videos effortlessly. These platforms offer features like automated editing, special effects, and AI-driven enhancements.</p><p>For audio, <code>ElevenLabs</code> provides an extensive library of AI-generated voices, while <code>Suno</code> specializes in music generation. These tools are transforming the way multimedia content is created, making it accessible to professionals and hobbyists alike.</p><h2 id="Applications-Across-Industries"><a href="#Applications-Across-Industries" class="headerlink" title="Applications Across Industries"></a>Applications Across Industries</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-industries.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-industries.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Generative AI Tools for Industries" style="width:800px;"/></div><span class="image-caption">Generative AI Tools for Industries</span></div><p>Generative AI tools have diverse applications, from creating personalized marketing content to designing immersive <code>gaming</code> environments. In <code>healthcare</code>, these tools assist in generating synthetic data for research and training purposes.</p><p>In <code>education</code>, generative AI enhances learning experiences by creating tailored materials and automating grading. The technology’s adaptability ensures its relevance across various sectors, driving innovation and efficiency.</p><h3 id="Applications-in-Content-Generation"><a href="#Applications-in-Content-Generation" class="headerlink" title="Applications in Content Generation"></a>Applications in Content Generation</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-applications.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-applications.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="20 Best AI Tools for Content Creation" style="width:800px;"/></div><span class="image-caption">20 Best AI Tools for Content Creation</span></div><p>Generative AI tools are widely used in content creation to streamline processes and enhance creativity. For instance, tools like <code>Jasper</code> and <code>DALL·E 3</code> enable marketers to craft engaging campaigns with minimal manual effort.</p><p>In education, generative AI helps create personalized learning materials and automate grading. These applications demonstrate the versatility of generative AI in addressing diverse content needs across industries.</p><h2 id="Selecting-the-Right-Tool"><a href="#Selecting-the-Right-Tool" class="headerlink" title="Selecting the Right Tool"></a>Selecting the Right Tool</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-choose.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-choose.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Selecting the Right Generative AI Tool" style="width:800px;"/></div><span class="image-caption">Selecting the Right Generative AI Tool</span></div><p>Choosing the right generative AI tool depends on your specific needs and objectives. <span class='pbg sucess'>Consider factors such as the type of content you want to create</span></p><p>For instance, tools like <code>Jasper</code> are ideal for marketing professionals, while <code>DALL·E</code> suits designers seeking AI-generated visuals. Evaluating the tool’s features and limitations ensures optimal results for your projects.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p><code>Generative AI</code> tools are transforming industries by enabling the creation of innovative and personalized content. By understanding their capabilities and applications, users can harness these tools to enhance creativity and streamline workflows.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction-to-Generative-AI-Tools&quot;&gt;&lt;a href=&quot;#Introduction-to-Generative-AI-Tools&quot; class=&quot;headerlink&quot; title=&quot;Introduction to Genera</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="Tools" scheme="https://stonefishy.github.io/tags/Tools/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Generative AI" scheme="https://stonefishy.github.io/tags/Generative-AI/"/>
    
  </entry>
  
  <entry>
    <title>Traditional Programming vs Artificial Intelligence</title>
    <link href="https://stonefishy.github.io/2025/05/03/traditional-programming-vs-artificial-intelligence/"/>
    <id>https://stonefishy.github.io/2025/05/03/traditional-programming-vs-artificial-intelligence/</id>
    <published>2025-05-03T15:56:55.000Z</published>
    <updated>2025-06-19T09:28:26.172Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Traditional Programming</strong> relies on <code>algorithms</code> and <code>code</code> and is restricted to the limitations defined by the programmer. It follows <code>rules</code> and <code>logic</code>, making it ideal for problems with clear guidelines and well-defined logic.</p><p><strong>Artificial Intelligence (AI)</strong> is <code>data-driven</code> and learns from examples by <code>training</code> itself. AI relies on <code>large datasets</code> to identify patterns, make predictions, and make real-time decisions based on its <code>analysis of historical data</code>.</p><h2 id="Key-Differences-Between-AI-and-Traditional-Programming"><a href="#Key-Differences-Between-AI-and-Traditional-Programming" class="headerlink" title="Key Differences Between AI and Traditional Programming"></a>Key Differences Between AI and Traditional Programming</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ai-vs-traditional-programming.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ai-vs-traditional-programming.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Traditional Programming vs Artificial Intelligence" style="width:800px;"/></div><span class="image-caption">Traditional Programming vs Artificial Intelligence</span></div><h3 id="Key-Differences-in-Outputs"><a href="#Key-Differences-in-Outputs" class="headerlink" title="Key Differences in Outputs"></a>Key Differences in Outputs</h3><p>Conventional programming produces reliable and <code>expected results</code>, delivering the <code>identical output</code> for the same input. This characteristic makes them perfect for activities demanding total accuracy, like mathematical computations or established procedures.</p><p>Conversely, AI outputs depend on <code>probabilities</code> and <code>patterns</code> that come from data. They are employed in situations characterized by uncertainty or variability, such as forecasting customer behavior or predicting the weather.</p><h3 id="When-to-Use-Traditional-Programming"><a href="#When-to-Use-Traditional-Programming" class="headerlink" title="When to Use Traditional Programming"></a>When to Use Traditional Programming</h3><p><strong>Traditional programming</strong> models are particularly <code>well-suited for scenarios where precision and consistency are crucial</code>. These models find their primary applications in fields such as <code>financial computations</code>, <code>engineering simulations</code>, and <code>software development</code> tailored for specific tasks.</p><p>Furthermore, these programming approaches are favored in situations where the <code>logic</code> and <code>rules</code> are clearly articulated and well-defined. They provide developers with the ability to meticulously control every step of the development process, which not only enhances the reliability of the final product but also simplifies the debugging process. This level of control is critical in ensuring that the applications function correctly and meet the high standards expected in various industries.</p><h3 id="When-to-Use-AI"><a href="#When-to-Use-AI" class="headerlink" title="When to Use AI"></a>When to Use AI</h3><p><strong>AI models</strong> are particularly adept at managing <code>complex and data-driven scenarios where outcomes are not predetermined</code>. AI solutions have been applied extensively across various fields, including <code>healthcare</code> for <code>predicting disease outbreaks</code>, <code>finance</code> for conducting thorough risk assessments, and <code>marketing</code> for effectively segmenting customers.</p><p>These advanced models utilize historical data to generate informed <code>predictions</code>, continuously learning and adapting to emerging new <code>patterns</code> and <code>trends</code>. This capacity for flexibility and evolution is what makes AI models especially invaluable in dynamic and uncertain environments where conditions frequently change and new challenges arise. Their ability to process and analyze vast amounts of data enables organizations to make informed decisions, mitigate risks, and optimize outcomes in a rapidly changing world.</p><h3 id="Advantages-and-Limitaitons-of-Each"><a href="#Advantages-and-Limitaitons-of-Each" class="headerlink" title="Advantages and Limitaitons of Each"></a>Advantages and Limitaitons of Each</h3><p><strong>Traditional programming</strong> models are praised for their <code>precision</code> and <code>simplicity</code>, which facilitate easy understanding and debugging. However, they struggle with flexibility, making it challenging to adapt to varying inputs and changing requirements.</p><p>In contrast, <strong>AI solutions</strong> excel at handling <code>complex</code>, <code>variable data</code> and can <code>learn</code> from new information, enabling greater adaptability and responsiveness. This inherent flexibility of AI comes at the cost of increased complexity in understanding and debugging compared to traditional programming.</p><p><strong>AI solutions</strong> can analyze vast datasets and uncover hidden patterns, enabling informed decision-making. However, <span class='pbg danger'>the effectiveness of AI is heavily dependent on the `quality and quantity of data` available</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Traditional Programming&lt;/strong&gt; relies on &lt;code&gt;algorithms&lt;/code&gt; and &lt;code&gt;code&lt;/code&gt; and is restricted to the limitations def</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>The difference of set cookie in Tomcat and Jetty</title>
    <link href="https://stonefishy.github.io/2025/04/25/the-difference-of-set-cookie-in-tomcat-and-jetty/"/>
    <id>https://stonefishy.github.io/2025/04/25/the-difference-of-set-cookie-in-tomcat-and-jetty/</id>
    <published>2025-04-25T17:42:11.000Z</published>
    <updated>2025-06-19T09:28:26.172Z</updated>
    
    <content type="html"><![CDATA[<p>In previous blog <a href="https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/">Switching Tomcat with Jetty in Spring Boot Easily</a>, to resolve the spring boot 2 tomcat security issue in short time, we switching <code>Tomcat</code> with <code>Jetty</code> in Spring Boot. We found there is a difference by set cookie handling between <code>Tomcat</code> and <code>Jetty</code> by default. Let’s first talk about the cookie.</p><h2 id="What-is-cookie"><a href="#What-is-cookie" class="headerlink" title="What is cookie?"></a>What is cookie?</h2><p>A cookie is a small piece of data that is stored on the user’s computer by the web server. It is used to store user preferences, login information, and other information that the user wants to be remembered. The cookie is sent to the user’s browser when the user makes a request to the web server. The browser then sends it back to the web server with subsequent requests.</p><h2 id="Cookie-Attributes"><a href="#Cookie-Attributes" class="headerlink" title="Cookie Attributes"></a>Cookie Attributes</h2><p>There are several attributes that can be set for a cookie:</p><ul><li><code>Domain</code>: The domain attribute specifies the domain for which the cookie is valid. If the domain is not specified, the cookie is valid for the entire domain.</li><li><code>Path</code>: The path attribute specifies the path on the server where the cookie is valid. If the path is not specified, the cookie is valid for the entire path.</li><li><code>Max-Age</code>: The max-age attribute specifies the maximum age of the cookie in seconds. If the max-age is not specified, the cookie is valid until the browser is closed.</li><li><code>Expires</code>: The expires attribute specifies the expiration date of the cookie. If the expires attribute is not specified, the cookie is valid until the browser is closed.</li><li><code>Secure</code>: The secure attribute specifies that the cookie should only be sent over HTTPS connections.</li><li><code>HttpOnly</code>: The httpOnly attribute specifies that the cookie should not be accessible to client-side scripts.</li><li><code>SameSite</code>: The sameSite attribute specifies whether the cookie should be sent with cross-site requests. The sameSite attribute can have the following values: <code>Strict</code>, <code>Lax</code>, or <code>None</code>.</li></ul><p>When <code>Max-Age</code> and <code>Expires</code> are not specified, the cookie is valid until the browser is closed. If <code>Max-Age</code> is specified, the cookie is valid for the specified number of seconds. If <code>Expires</code> is specified, the cookie is valid until the specified date. If both <code>Max-Age</code> and <code>Expires</code> are specified, the cookie is valid for the minimum of the two values.</p><h2 id="Set-Cookie-in-Spring-Boot"><a href="#Set-Cookie-in-Spring-Boot" class="headerlink" title="Set-Cookie in Spring Boot"></a>Set-Cookie in Spring Boot</h2><p>In Spring Boot, the <code>Set-Cookie</code> header is used to send cookies to the user’s browser. The <code>Set-Cookie</code> header is sent in the response to the user’s request. The <code>Set-Cookie</code> header contains the name, value, and other attributes of the cookie. Here is an example of the <code>Set-Cookie</code> header in Spring Boot:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Set-Cookie: JSESSIONID=1234567890; Path=/; HttpOnly; Secure</span><br></pre></td></tr></table></figure><p>In this example, the <code>JSESSIONID</code> is the name of the cookie, <code>1234567890</code> is the value of the cookie, <code>Path</code> is the path on the server where the cookie is valid, <code>/</code> is the path, <code>HttpOnly</code> is a flag that indicates that the cookie should not be accessible to client-side scripts, <code>Secure</code> is a flag that indicates that the cookie should only be sent over HTTPS connections, and <code>SameSite</code> is not set.</p><p>In <code>Network</code> tab of <code>Chrome DevTools</code>, we can see the <code>Set-Cookie</code> header in the response headers. That means these cookie are set by web server and sent to the user’s browser and stored in the user’s computer.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/set-cookie-in-response-headers.png" class="lazyload placeholder" data-srcset="/assets/images/java/set-cookie-in-response-headers.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Set-Cookie in response headers"/></div><span class="image-caption">Set-Cookie in response headers</span></div><p>And we can also see the cookies in <code>Application</code> tab of <code>Chrome DevTools</code>. The cookies are stored in the user’s browser and can be accessed by the web server in subsequent requests.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/cookie-in-browser-application-tab.png" class="lazyload placeholder" data-srcset="/assets/images/java/cookie-in-browser-application-tab.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Cookies in Browser Application tab"/></div><span class="image-caption">Cookies in Browser Application tab</span></div><h2 id="Difference-of-Set-Cookie-in-Tomcat-and-Jetty"><a href="#Difference-of-Set-Cookie-in-Tomcat-and-Jetty" class="headerlink" title="Difference of Set-Cookie in Tomcat and Jetty"></a>Difference of Set-Cookie in Tomcat and Jetty</h2><p>Okay, let’s talk about the difference of <code>Set-Cookie</code> header handling between <code>Tomcat</code> and <code>Jetty</code>. Here we will use <code>curl</code> command to send a request to the server and see the <code>Set-Cookie</code> header in the response for default configuration.</p><h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><p>If we want to reduce <code>XSS cross-site scripting attacks</code> and <code>prevent reading and modifying cookie contents</code>, we can set the <code>HttpOnly</code> attribute for the cookie. In <code>Tomcat 6</code>,  we need to config it in the <code>tomcat/conf/context.xml</code> file. Add the <code>useHttpOnly=&quot;true&quot;</code> attribute in <code>&lt;Context&gt;</code> tag.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Context</span> <span class="attr">useHttpOnly</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Context</span>&gt;</span></span><br></pre></td></tr></table></figure><p>But for <code>Tomcat 7</code> and later version. We don’t need to config it in <code>context.xml</code> any more. The <code>useHttpOnly</code> attribute is set to <code>true</code> by default. It is introduced in <code>Tomcat 7</code> official doc (<a href="https://tomcat.apache.org/tomcat-7.0-doc/config/context.html">https://tomcat.apache.org/tomcat-7.0-doc/config/context.html</a>)</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/http-only-in-tomcat7.png" class="lazyload placeholder" data-srcset="/assets/images/java/http-only-in-tomcat7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="HttpOnly in Tomcat 7"/></div><span class="image-caption">HttpOnly in Tomcat 7</span></div><p>Below is the screenshot that using <code>curl</code> command to send a request to our current Spring Boot application with <code>Tomcat</code> server:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/set-cookie-with-http-only.png" class="lazyload placeholder" data-srcset="/assets/images/java/set-cookie-with-http-only.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Set-Cookie with HttpOnly"/></div><span class="image-caption">Set-Cookie with HttpOnly</span></div><p>From the screenshot, you can see the <code>Set-Cookie</code> header in the response. The <code>HttpOnly</code> attribute is appended in the cookie by default.</p><p>BTW, from <code>Spring Boot</code> 2 version, it is starting use <code>Tomcat</code> 8 version which will set <code>HttpOnly</code> attribute by default in the cookie.</p><h3 id="Jetty"><a href="#Jetty" class="headerlink" title="Jetty"></a>Jetty</h3><p>For <code>Jetty</code>, the <code>HttpOnly</code> attribute is <code>not</code> set by default. We need to config it in the <code>web.xml</code> file. Add the <code>&lt;http-only&gt;</code> element in <code>&lt;cookie-config&gt;</code> tag.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">session-config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">cookie-config</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">http-only</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">cookie-config</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">session-config</span>&gt;</span></span><br></pre></td></tr></table></figure><p>We also can set the <code>HttpOnly</code> attribute for the cookie in the code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SessionCookieConfig.setHttpOnly(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure><p>We can find the evidence in the <code>Jetty</code> official doc <a href="https://jetty.org/docs/jetty/12/programming-guide/server/session.html">https://jetty.org/docs/jetty/12/programming-guide/server/session.html</a>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/http-only-in-jetty.png" class="lazyload placeholder" data-srcset="/assets/images/java/http-only-in-jetty.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="HttpOnly in Jetty"/></div><span class="image-caption">HttpOnly in Jetty</span></div><p>By default, the <code>HttpOnly</code> attribute is not set in the <code>Set-Cookie</code> header in jetty. Below is the screenshot that using <code>curl</code> command to send a request to our current Spring Boot application with <code>Jetty</code> server by default configuration:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/set-cookie-without-http-only.png" class="lazyload placeholder" data-srcset="/assets/images/java/set-cookie-without-http-only.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Set-Cookie without HttpOnly"/></div><span class="image-caption">Set-Cookie without HttpOnly</span></div><p>As you can see, the <code>HttpOnly</code> attribute is not set in the <code>Set-Cookie</code> header in <code>Jetty</code> by default when we use the <code>curl</code> command. The code are same, just simply switch <code>Tomcat</code> to <code>Jetty</code> in the <code>pom.xml</code> file in previous blog.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>The <code>Set-Cookie</code> header is used to send cookies to the user’s browser. The <code>HttpOnly</code> attribute is used to prevent client-side scripts from accessing the cookie. The <code>Secure</code> attribute is used to ensure that the cookie is only sent over HTTPS connections. The <code>SameSite</code> attribute is used to prevent cross-site requests. The difference of <code>Set-Cookie</code> header handling between <code>Tomcat</code> and <code>Jetty</code> is that <code>Tomcat</code> set the <code>HttpOnly</code> attribute by default, while <code>Jetty</code> does not set it by default. We need to config it in the <code>web.xml</code> file for <code>Jetty</code> or set it in the code for <code>Tomcat</code>. So when you switche <code>Tomcat</code> to <code>Jetty</code>, you need to check the <code>HttpOnly</code> attribute in the <code>Set-Cookie</code> header for session id for security reason.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In previous blog &lt;a href=&quot;https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/&quot;&gt;Switching Tomcat wi</summary>
      
    
    
    
    <category term="Backend" scheme="https://stonefishy.github.io/categories/Backend/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="Spring Boot" scheme="https://stonefishy.github.io/tags/Spring-Boot/"/>
    
    <category term="Tomcat" scheme="https://stonefishy.github.io/tags/Tomcat/"/>
    
    <category term="Jetty" scheme="https://stonefishy.github.io/tags/Jetty/"/>
    
    <category term="Cookie" scheme="https://stonefishy.github.io/tags/Cookie/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Model Context Protocol (MCP)</title>
    <link href="https://stonefishy.github.io/2025/04/21/understanding-the-model-context-protocol-mcp/"/>
    <id>https://stonefishy.github.io/2025/04/21/understanding-the-model-context-protocol-mcp/</id>
    <published>2025-04-21T10:38:42.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>In the rapidly evolving landscape of artificial intelligence, ensuring the effective and efficient management of model contexts is crucial for the deployment and utilization of AI systems. The model context is refer to the set of information that is necessary for the <code>AI model</code> like <code>DeepSeek</code>, <code>Claude</code>, <code>ChatGPT</code>, <code>Gemini</code> to make a correct and efficient decision. However, managing the model context is not an easy task, as it requires a combination of technical expertise, domain knowledge, and business intelligence.</p><p>One significant protocol that has emerged to address this challenge is the <code>Model Context Protocol (MCP)</code>. Let’s talk about it in this blog.</p><h2 id="What-is-MCP"><a href="#What-is-MCP" class="headerlink" title="What is MCP?"></a>What is <code>MCP</code>?</h2><p>A brief overview of the <code>Model Context Protocol (MCP)</code> which introduced by official:</p><blockquote><p><code>The Model Context Protocol (MCP)</code> is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you’re building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.</p></blockquote><blockquote><p>Think of <code>MCP</code> like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.</p></blockquote><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-like-usb.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-like-usb.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>So it’s a protocol that defines a standardized way to connect <code>LLMs</code> with the context they need. The <code>MCP</code> is designed to address the challenges of managing the model context. It’s introduced by <code>Anthropic</code> company at 2024, the <code>Claude Desktop</code> supports very well. </p><h2 id="Why-MCP-Came-Out"><a href="#Why-MCP-Came-Out" class="headerlink" title="Why MCP Came Out?"></a>Why MCP Came Out?</h2><p>Below  explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-before-after.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-before-after.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Before the <code>MCP</code>, we usually use the <code>Function calling</code>, which allows LLMs to invoke predetermined functions based on user requests, is a well-established feature of modern AI models. Sometimes referred to as “tool use,” function calling is not mutually exclusive with MCP; the new protocol simply standardizes how this API feature works. </p><p>Without MCP, when you use a function call directly with an LLM API, you need to:</p><ol><li>Define model-specific function schemas, which are JSON descriptions of the function, acceptable parameters, and what it returns.</li><li>Implement handlers (the actual code that executes when a function is called) for those functions.</li><li>Create different implementations for each model you support.</li></ol><p>With MCP, the MCP standardizes this process by:</p><ol><li>Defining a consistent way to specify tools (functions) across any AI system.</li><li>Providing a protocol for discovering available tools and executing them.</li><li>Creating a universal, plug-and-play format where any AI app can use any tool without custom integration code.</li></ol><p>You might be familiar with AI apps that use function calling, like Custom GPTs using GPT Actions. A Custom GPT can determine which API call resolves the user’s prompt, create the necessary JSON, then make the API call with it. While this allows some purpose-built tooling, it’s bound to OpenAI’s ecosystem. <code>MCP</code> brings similar capabilities to any AI application that implements the protocol, regardless of the underlying model vendor.</p><h2 id="MCP-Architectures-and-Core-Components"><a href="#MCP-Architectures-and-Core-Components" class="headerlink" title="MCP Architectures and Core Components"></a>MCP Architectures and Core Components</h2><p>Below is general architecture of <code>MCP</code>:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-general-architecture.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-general-architecture.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MCP General Architecture"/></div><span class="image-caption">MCP General Architecture</span></div><p><strong>Host application</strong>: <code>LLMs</code> that interact with users and initiate connections. This includes <code>Claude Desktop</code>, AI-enhanced IDEs like <code>Cursor</code>, and standard web-based LLM chat interfaces.</p><p><strong>MCP client</strong>: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.</p><p><strong>MCP server</strong>: Adds context and capabilities, exposing specific functions to AI apps through MCP. Each standalone server typically focuses on a specific integration point, like GitHub for repository access or a PostgreSQL for database operations.</p><p><strong>Data Source</strong>: The source of information or functionality that the MCP server connects to. This could be a database, API, or any other data source that the server can access.</p><ol><li><strong>Local Data Sources</strong>: Your computer’s files, databases, and services that MCP servers can securely access</li><li><strong>Remote Services</strong>: External systems available over the internet (e.g., through APIs) that MCP servers can connect to</li></ol><p><strong>Transport layer</strong>: The communication mechanism between clients and servers. MCP supports two primary transport methods:</p><ol><li><strong>STDIO (Standard Input&#x2F;Output)</strong>: Mainly local integrations where the server runs in the same environment as the client.</li><li><strong>HTTP+SSE (Server-Sent Events)</strong>: Remote connections, with HTTP for client requests and SS for server responses and streaming.</li></ol><p>All communication in MCP uses <code>JSON-RPC 2.0</code> as the underlying message standard, providing a standardized structure for requests, responses, and notifications.</p><h2 id="How-MCP-Works"><a href="#How-MCP-Works" class="headerlink" title="How MCP Works"></a>How MCP Works</h2><p>When a user interacts with a host application (an AI app) that supports <code>MCP</code>, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a look the example.</p><h3 id="Protocol-handshake"><a href="#Protocol-handshake" class="headerlink" title="Protocol handshake"></a>Protocol handshake</h3><ol><li><strong>Initial connection</strong>: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.</li><li><strong>Capability discovery</strong>: The client asks each server “What capabilities do you offer?” Each server responds with its available tools, resources, and prompts.</li><li><strong>Registration</strong>: The client registers these capabilities, making them available for the AI to use during your conversation.</li></ol><h3 id="An-Example"><a href="#An-Example" class="headerlink" title="An Example"></a>An Example</h3><p>Let’s use an example to talk about it. Below is the example general communication flow of <code>MCP</code>:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-communication-flow.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-communication-flow.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MCP How Works"/></div><span class="image-caption">MCP How Works</span></div><p>Let’s say you ask Claude, “What’s the weather like in San Francisco today?” Here’s what happens:</p><ol><li><strong>Need recognition</strong>: Claude analyzes your question and recognizes it needs external, real-time information that wasn’t in its training data.</li><li><strong>Tool or resource selection</strong>: Claude identifies that it needs to use an MCP capability to fulfill your request.</li><li><strong>Permission request</strong>: The client displays a permission prompt asking if you want to allow access to the external tool or resource. </li><li><strong>Information exchange</strong>: Once approved, the client sends a request to the appropriate MCP server using the standardized protocol format.</li><li><strong>External processing</strong>: The MCP server processes the request, performing whatever action is needed—querying a weather service, reading a file, or accessing a database.</li><li><strong>Result return</strong>: The server returns the requested information to the client in a standardized format.</li><li><strong>Context integration</strong>: Claude receives this information and incorporates it into its understanding of the conversation.</li><li><strong>Response generation</strong>: Claude generates a response that includes the external information, providing you with an answer based on current data.</li></ol><h2 id="MCP-Servers"><a href="#MCP-Servers" class="headerlink" title="MCP Servers"></a>MCP Servers</h2><p>Since the MCP just released at end of the 2024 by Anthropic, but it is growing rapidly. There are many MCP servers available now, and they are categorized into different categories. There are some awsome MCP servers:</p><ul><li><strong>GitHub</strong>: MCP server for GitHub, which allows you to access repositories and files in your GitHub account.</li><li><strong>PostgreSQL</strong>: MCP server for PostgreSQL, which allows you to access and manage your PostgreSQL databases.</li><li><strong>Docker</strong>: MCP server for Docker, which allows you to manage your Docker containers and images.</li><li><strong>Kubernetes</strong>: MCP server for Kubernetes, which allows you to manage your Kubernetes clusters and resources.</li><li><strong>Google Cloud Platform</strong>: MCP server for Google Cloud Platform, which allows you to access and manage your Google Cloud resources.</li><li><strong>Amazon Web Services</strong>: MCP server for Amazon Web Services, which allows you to access and manage your AWS resources.</li></ul><p>There is a MCP servers collections link: <a href="https://github.com/punkpeye/awesome-mcp-servers">https://github.com/punkpeye/awesome-mcp-servers</a>, you can find existing MCP servers and their capabilities. Also, you can create your own MCP server by following the MCP server development guide. We will talk about it in the future.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the rapidly evolving landscape of artificial intelligence, ensuring the effective and efficient management of model contexts is crucia</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="MCP" scheme="https://stonefishy.github.io/tags/MCP/"/>
    
  </entry>
  
  <entry>
    <title>Supercharge Your Python project with UV: The Lightning-Fast Package Manager</title>
    <link href="https://stonefishy.github.io/2025/04/16/supercharge-your-python-project-with-uv-the-lightning-fast-package-manager/"/>
    <id>https://stonefishy.github.io/2025/04/16/supercharge-your-python-project-with-uv-the-lightning-fast-package-manager/</id>
    <published>2025-04-16T14:00:23.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>Python’s ecosystem thrives on its rich library of packages, but managing dependencies can sometimes feel sluggish, especially in large projects. Enter <code>UV</code>, a modern package manager and resolver designed to supercharge your workflow. Developed by <code>Astral</code> (the team behind the popular Ruff linter), <code>UV</code> promises blazing speed and seamless integration with existing Python tools. Let’s explore why UV might become your new go-to for dependency management.</p><h2 id="What-is-UV"><a href="#What-is-UV" class="headerlink" title="What is UV?"></a>What is UV?</h2><p><code>UV</code> is a Rust-powered tool that combines a package installer (<code>pip</code>) and virtual environment manager (<code>venv</code>) into one ultra-fast solution. It aims to replace traditional tools like <code>pip</code>, <code>pipenv</code>, and <code>poetry</code> while staying fully compatible with their workflows. By leveraging Rust’s performance advantages, UV dramatically reduces installation and resolution times—often by <code>10-100x</code> compared to older tools.</p><h2 id="Why-Use-UV"><a href="#Why-Use-UV" class="headerlink" title="Why Use UV?"></a>Why Use UV?</h2><p><strong>Speed</strong>: <code>UV</code> resolves and installs dependencies in seconds, even for complex projects.<br><strong>Simplicity</strong>: It’s a drop-in replacement for <code>pip</code> and <code>venv</code>, requiring no workflow changes.<br><strong>Modern Features</strong>: Supports <code>pyproject.toml</code>, <code>lock</code> files, and advanced dependency resolution.<br><strong>Cross-Platform</strong>: Works on Windows, macOS, and Linux.</p><h2 id="Getting-Started-with-UV"><a href="#Getting-Started-with-UV" class="headerlink" title="Getting Started with UV"></a>Getting Started with UV</h2><h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><p><code>UV</code> is distributed as a static binary, so installation is straightforward:</p><h4 id="Install-via-pip-recommended"><a href="#Install-via-pip-recommended" class="headerlink" title="Install via pip (recommended)"></a>Install via pip (recommended)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install uv</span><br></pre></td></tr></table></figure><h4 id="Or-use-curl-Mac-Linux-only"><a href="#Or-use-curl-Mac-Linux-only" class="headerlink" title="Or use curl (Mac&#x2F;Linux only)"></a>Or use curl (Mac&#x2F;Linux only)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -LsSf https://astral.sh/uv/install.sh | sh</span><br></pre></td></tr></table></figure><p>Once the installation is complete, you can verify the installation by running:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv --version</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-version.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-version.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV version"/></div><span class="image-caption">UV version</span></div><p>Running below command to get the help message:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-help.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-help.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV help"/></div><span class="image-caption">UV help</span></div><h3 id="Creating-a-Project"><a href="#Creating-a-Project" class="headerlink" title="Creating a Project"></a>Creating a Project</h3><p>To create a new project with <code>UV</code>, run:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv init &lt;project-name&gt;</span><br></pre></td></tr></table></figure><p>This will create a new project called <project-name> directory with a <code>pyproject.toml</code> file and a <code>uv.lock</code> file. The <code>pyproject.toml</code> file is where you can specify your project’s dependencies and other metadata. The <code>uv.lock</code> file is where <code>UV</code> stores the resolved dependencies and their versions.</p><p>Let’s create a new project called <code>uv-sample</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv init uv-sample</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-init1.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-init1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV init project"/></div><span class="image-caption">UV init project</span></div><p>It also creates associated with the <code>git</code> for this project, <code>.python-version</code> file for managing Python version, and a sample <code>main.py</code> python file.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-init2.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-init2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Project files generated by UV init"/></div><span class="image-caption">Project files generated by UV init</span></div><p>The <code>pyproject.toml</code> file is where you can specify your project’s dependencies and other metadata. Since this project doesn’t have any dependencies, so the <code>uv.lock</code> file is empty. Below is <code>uv-sample</code> <code>pyproject.toml</code> file:</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[project]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;uv-sample&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">description</span> = <span class="string">&quot;Add your description here&quot;</span></span><br><span class="line"><span class="attr">readme</span> = <span class="string">&quot;README.md&quot;</span></span><br><span class="line"><span class="attr">requires-python</span> = <span class="string">&quot;&gt;=3.12&quot;</span></span><br><span class="line"><span class="attr">dependencies</span> = []</span><br></pre></td></tr></table></figure><h3 id="Manage-Dependencies"><a href="#Manage-Dependencies" class="headerlink" title="Manage Dependencies"></a>Manage Dependencies</h3><p>Using <code>uv</code> to manage dependencies is as simple as adding them to the <code>dependencies</code> section of the <code>pyproject.toml</code> file. For example, to add <code>pandas</code> as a dependency, we can run:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv add pandas</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-add-dependency.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-add-dependency.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV Add dependency"/></div><span class="image-caption">UV Add dependency</span></div><p>From the screenshot, you can see before adding the dependency in python project. The <code>uv</code> also help us to create a virtual environment for our project. The package and dependencies installed in the virtual environment will be isolated from the system-wide packages.</p><p>The <code>uv.lock</code> file will be updated with the installed dependencies and their versions. And the <code>pyproject.toml</code> file will be updated with the new dependency.</p><p><code>pyproject.toml</code> file after adding <code>pandas</code> as a dependency:</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[project]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;uv-sample&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">description</span> = <span class="string">&quot;Add your description here&quot;</span></span><br><span class="line"><span class="attr">readme</span> = <span class="string">&quot;README.md&quot;</span></span><br><span class="line"><span class="attr">requires-python</span> = <span class="string">&quot;&gt;=3.12&quot;</span></span><br><span class="line"><span class="attr">dependencies</span> = [</span><br><span class="line">    <span class="string">&quot;pandas&gt;=2.2.3&quot;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><code>uv.lock</code> file is like a <code>package-lock.json</code> file for <code>npm</code> or <code>yarn</code>. It contains the resolved dependencies and their versions. We can see the installed dependencies and their versions in the <code>uv.lock</code> file. Please don’t edit this file manually.</p><p>To see the dependencies tree, we can run <code>uv tree</code> command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv tree</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-tree.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-tree.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Dependencies via UV tree"/></div><span class="image-caption">Dependencies via UV tree</span></div><p>It lists all the dependencies and their dependencies recursively.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-lock-file.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-lock-file.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV lock file"/></div><span class="image-caption">UV lock file</span></div><p>You can also remove the dependency by running: <code>uv remove &lt;dependency-name&gt;</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv remove pandas</span><br></pre></td></tr></table></figure><p>If your project is cloned. And you want to setup the development environment on your local. You can run <code>uv sync</code> to install the dependencies from the <code>uv.lock</code> file.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv <span class="built_in">sync</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-sync.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-sync.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Install dependencies from UV sync"/></div><span class="image-caption">Install dependencies from UV sync</span></div><p>See, it’s very easy. It created a virtual environment for our project and installed the dependencies from the <code>uv.lock</code> file.</p><p>The <code>uv</code> has more features like using <code>uv</code> to install and select specific python verison, run the python code.</p><h3 id="Manage-Python-Version"><a href="#Manage-Python-Version" class="headerlink" title="Manage Python Version"></a>Manage Python Version</h3><p>Using the <code>uv</code> also can manage the python version for your project. Below is the snapshot to manage the python.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-python.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-python.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV python"/></div><span class="image-caption">UV python</span></div><p>List all the available downloaded python.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv python list</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-python-list.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-python-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="List of python versions"/></div><span class="image-caption">List of python versions</span></div><p>You can download and install the specific python version. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv python install &lt;version&gt;</span><br></pre></td></tr></table></figure><p>Let’s install the python version 3.14. See below screenshot.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv python install 3.14</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-python-install.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-python-install.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Install python version"/></div><span class="image-caption">Install python version</span></div><p>So using <code>uv</code> we can manage multiple python versions at same time. It’s like <code>nvm</code> for node.js. For more using <code>uv</code> to manage the python version, you can type <code>uv python --help</code> to get the help message.</p><h3 id="Run-Python-Code"><a href="#Run-Python-Code" class="headerlink" title="Run Python Code"></a>Run Python Code</h3><p>Before <code>uv</code>, we running the python code usuallly by using <code>python &lt;python-file&gt;</code>. In <code>uv</code>, we can run the python code using <code>uv run</code> command.</p><p><code>main.py</code> example file.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Hello from uv-sample!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>Executing below command to run the python code.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv run main.py</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-run-python.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-run-python.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Run python code"/></div><span class="image-caption">Run python code</span></div><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p><code>UV</code> is a modern package manager and resolver designed to supercharge your workflow. It promises blazing speed and seamless integration with existing Python tools. It’s a drop-in replacement for <code>pip</code> and <code>venv</code>, requiring no workflow changes. It works on Windows, macOS, and Linux.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Python’s ecosystem thrives on its rich library of packages, but managing dependencies can sometimes feel sluggish, especially in large pr</summary>
      
    
    
    
    <category term="Backend" scheme="https://stonefishy.github.io/categories/Backend/"/>
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="UV" scheme="https://stonefishy.github.io/tags/UV/"/>
    
  </entry>
  
  <entry>
    <title>Switching Tomcat with Jetty in Spring Boot Easily</title>
    <link href="https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/"/>
    <id>https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/</id>
    <published>2025-04-11T11:16:30.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Recently, we received the critical security vulnerability which is CVE-2025-24813 (<a href="https://www.cvedetails.com/cve/CVE-2025-24813/">https://www.cvedetails.com/cve/CVE-2025-24813/</a>) information from cloud security team. It request the team to check if there any projects are using tomcat which affected by this vulnerability, and remediate it quickly.</p><p>The CVE-2025-24813 describe below, and publised at 2025-03-10 17:15:35. It’s new found vulnerability.</p><blockquote><p>Path Equivalence: ‘file.Name’ (Internal Dot) leading to Remote Code Execution and&#x2F;or Information disclosure and&#x2F;or malicious content added to uploaded files via write enabled Default Servlet in Apache Tomcat.</p></blockquote><p>Our all microservices are using tomcat as servlet container. And we’re using <code>spring-boot-starter-tomcat</code> version 2.6.4 which is affacted. Actually all spring boot 2 contains this vulnerability. Even in most of embedded tomcat libraries in sprint boot 3.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/spring-boot-starter-tomcat-2.6.4.png" class="lazyload placeholder" data-srcset="/assets/images/java/spring-boot-starter-tomcat-2.6.4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="CVE-2025-24813 in Spring Boot Starter Tomcat 2.6.4"/></div><span class="image-caption">CVE-2025-24813 in Spring Boot Starter Tomcat 2.6.4</span></div><p>This tomcat vulnerability has been fixed since <code>spring-boot-starter-tomcat</code> version <code>3.4.3</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/spring-boot-starter-tomcat-3.4.3.png" class="lazyload placeholder" data-srcset="/assets/images/java/spring-boot-starter-tomcat-3.4.3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="CVE-2025-24813 Resolved in Spring Boot Starter Tomcat 3.4.3"/></div><span class="image-caption">CVE-2025-24813 Resolved in Spring Boot Starter Tomcat 3.4.3</span></div><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>To resolve this vulnerability issue, there are two solutions: </p><ol><li>One is upgrade <code>spring-boot-starter-tomcat</code> to latest version. </li><li>We can switch to other servlet container, such as <code>Jetty</code>.</li></ol><p>For the first solution, we have to upgrade our entire all microservice from Spring Boot 2 to Spring Boot 3 which requires Java 17. Official guide <a href="https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0">https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0</a>. Currently our all microserces are still using Java 8. In short term, It’s hard to upgrade Java 8 to Java 17 and Spring Boot 2 to Spring Boot 3, it will take much time and efforts. There also third party libraries requires to be upgrade when upgrade Java 8 to Java 17.</p><p>More over, we are using <code>spring-cloud-starter-netflix-zuul</code>, in spring cloud github, it mentioned <code>spring-cloud-starter-netflix-zuul</code> not work with <code>spring-boot 3.0</code> and spring 6.0, it has been out of support. It suggests to using <code>Spring Cloud Gateway</code>.  Refer official issue link: <a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/4158">https://github.com/spring-cloud/spring-cloud-netflix/issues/4158</a>. Besides currently the Spring Cloud Gateway does not support the SSO SAML. Hope it supports SAML in future.</p><p>So the solution 2 is best to resolve this vulnuerability in short term.</p><h2 id="Jetty"><a href="#Jetty" class="headerlink" title="Jetty"></a>Jetty</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/jetty-logo.png" class="lazyload placeholder" data-srcset="/assets/images/java/jetty-logo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Jetty"/></div><span class="image-caption">Jetty</span></div><p><code>Jetty</code> is a part of the Eclipse foundation and started in 1995. Jetty is not just a web server and servlet container. But it offers support for WebSocket, HTTP&#x2F;2, OSGi, JNDI, JMX, JAAS, and many other integrations. Additionally  Jetty is popular among developers and also works as an embedded tool for a lot of frameworks, cloud services, application servers, and devices. </p><p>According to stats Jetty maintains a market share of 10% among Java application servers. Some popular companies that use Jetty are <code>Google</code>, <code>Yahoo</code>, <code>Nuxeo</code> and <code>Canva</code>. </p><p>Jetty can:</p><ul><li>Jetty is user friendly and has a better interface than Tomcat.</li><li>Can be used as a part of or full Java application server stack.</li><li>Might be applied as a part of other frameworks due to its flexibility.</li><li>Supports cloud style operations.</li><li>The conceptual weight of the framework is less, very fast, and thin.</li><li>Better for handling simultaneous users compared to Tomcat.</li><li>Small memory trace to work speedily.</li><li>Users can use it easily because the required knowledge and skills are very few.</li></ul><p>Compare with <code>Tomcat</code>, they have the following simlarities:</p><ul><li>Both these tools are open source platforms and written in Java.</li><li>Companies use them in production environments (live releases).</li><li>They can process all components of the Core Java enterprise.</li><li>Both tools have large community support.</li></ul><h2 id="Code-Implementation"><a href="#Code-Implementation" class="headerlink" title="Code Implementation"></a>Code Implementation</h2><p>To switching Tomcat to Jetty in Spring Boot is very easily. You don’t need to update any logic code, the one thing you need to do is that exclude the embedded Tomcat <code>spring-boot-starter-tomcat</code> from <code>spring-boot-stater-web</code> and add dependency <code>spring-boot-starter-jetty</code> in <code>Maven</code> or <code>Gradle</code></p><h3 id="For-Maven-Users"><a href="#For-Maven-Users" class="headerlink" title="For Maven Users:"></a>For Maven Users:</h3><p>Update the <code>pom.xml</code> and making below changes.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Exclude Tomcat starter --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-tomcat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Add Jetty starter --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jetty<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="For-Gradle-Users"><a href="#For-Gradle-Users" class="headerlink" title="For Gradle Users:"></a>For Gradle Users:</h3><p>Update the <code>build.gradle</code> file as below:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    <span class="comment">// Exclude Tomcat starter</span></span><br><span class="line">    implementation(<span class="string">&#x27;org.springframework.boot:spring-boot-starter-web&#x27;</span>) &#123;</span><br><span class="line">        exclude <span class="attr">group:</span> <span class="string">&#x27;org.springframework.boot&#x27;</span>, <span class="attr">module:</span> <span class="string">&#x27;spring-boot-starter-tomcat&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add Jetty starter</span></span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-jetty&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>After you make above changes. Spring Boot stop auto-configuring <code>Tomcat</code> as the embedded server and to set up <code>Jetty</code> instead. <span class='pbg success'>It’s a seamless transition that requires no additional code.</span> Spring Boot’s auto-configuration capabilities recognize the absence of Tomcat and the presence of Jetty and automatically configure your application to use Jetty as its embedded servlet container.</p><h2 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h2><p>It’s always a good idea to fine-tune your server settings to ensure optimal performance. With Jetty, you can easily configure thread pools, port settings, and more through the <code>application.properties</code> or <code>application.yml</code> file in your Spring Boot project.</p><p>For example, to change the server port and configure the max thread pool size in application.properties, you can add below settings in <code>application.properties</code> file.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server.port=8001</span><br><span class="line">server.jetty.threads.max=200</span><br></pre></td></tr></table></figure><p>Once you have complete configuration. You can start your application. The Jetty servlet container started like below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/spring-boot-jetty-started.png" class="lazyload placeholder" data-srcset="/assets/images/java/spring-boot-jetty-started.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Spring Boot Application Started with Jetty"/></div><span class="image-caption">Spring Boot Application Started with Jetty</span></div><h2 id="Summery"><a href="#Summery" class="headerlink" title="Summery"></a>Summery</h2><p>Switching from <code>Tomcat</code> to <code>Jetty</code> in a Spring Boot application isn’t just feasible; it’s straightforward with Spring Boot’s flexible architecture. Whether you’re looking for increased performance, reduced resource consumption, or simply exploring alternatives, transitioning to Jetty offers tangible benefits with minimal hassle.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h2&gt;&lt;p&gt;Recently, we received the critical sec</summary>
      
    
    
    
    <category term="Backend" scheme="https://stonefishy.github.io/categories/Backend/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="Spring Boot" scheme="https://stonefishy.github.io/tags/Spring-Boot/"/>
    
    <category term="Tomcat" scheme="https://stonefishy.github.io/tags/Tomcat/"/>
    
    <category term="Jetty" scheme="https://stonefishy.github.io/tags/Jetty/"/>
    
  </entry>
  
  <entry>
    <title>Create your own OpenAI endpoints in Azure Cloud.</title>
    <link href="https://stonefishy.github.io/2025/03/14/create-your-own-openai-endpoints-in-azure-cloud/"/>
    <id>https://stonefishy.github.io/2025/03/14/create-your-own-openai-endpoints-in-azure-cloud/</id>
    <published>2025-03-14T15:17:59.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>Previously, we have introduced how to use Azure OpenAI to develop a RAG (Retrieval-Augmented Generation) chatbot. In this article, we will learn how to create your own OpenAI endpoints in <code>Azure Cloud</code>.</p><p><code>Azure OpenAI</code> is a service provided by Microsoft Azure that allows businesses and developers to integrate OpenAI’s advanced AI models into their applications and systems. This service gives users access to powerful language models like <code>GPT-3</code>, <code>GPT-4</code>, and other AI models developed by OpenAI, via an API hosted on Microsoft’s Azure cloud platform.</p><p>To use Azure OpenAI, users need an Azure subscription and access to the OpenAI API via Azure. Assume you already have an Azure Cloud account and an Azure subscription. Here are the steps to create your own OpenAI endpoints in Azure Cloud</p><h2 id="Step-1-Create-Azure-OpenAI-Resource"><a href="#Step-1-Create-Azure-OpenAI-Resource" class="headerlink" title="Step 1: Create Azure OpenAI Resource"></a>Step 1: Create Azure OpenAI Resource</h2><p>In Microsoft Azure Cloud, Open the <code>Azure AI Services</code> and create a <code>Azure OpenAI</code> resource. Select your subscription and resource group, create a new resource group if you don’t have one. Fill the endpoint name and select the pricing tier. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>In Network, choose the All networks including internet option. because we want to access the OpenAI API from anywhere.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>For the tags, you can type your own tags for this resource.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After that, you can review your resource and create it.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-4.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Deploying the resource can take a few seconds.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-5.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Once the resource is deployed, you can select your resource and click the <code>Endpoints</code> and <code>Manage keys</code> to see the API endpoint and key.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-6.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>You can copy the API endpoint and key and use it in your application to access the OpenAI API.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-7.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Do you think we have finished to create our own OpenAI endpoints in Azure Cloud? The answer is No, We still need to deploy the OpenAI Model to our Azure OpenAI resource. If we access this API endpoint directly, we will get an error message. like below</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openai.NotFoundError: Error code: 404 - &#123;&#x27;error&#x27;: &#123;&#x27;code&#x27;: &#x27;DeploymentNotFound&#x27;, &#x27;message&#x27;: &#x27;The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="Step-2-Deploy-OpenAI-Model-to-Azure-OpenAI-Resource"><a href="#Step-2-Deploy-OpenAI-Model-to-Azure-OpenAI-Resource" class="headerlink" title="Step 2: Deploy OpenAI Model to Azure OpenAI Resource"></a>Step 2: Deploy OpenAI Model to Azure OpenAI Resource</h2><p>To deploy the OpenAI model to our Azure OpenAI resource, open <code>Azure AI Foundry</code> and select <code>Deployments</code> item in left menu. Click <code>Deploy model</code> button and select <code>Deploy base model</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-8.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Let’s choose the <code>GPT-4o</code> model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-9.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>In deployment model dialog, let’s keep the deployment name and deployment type select as Global Standard.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-10.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-10.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Step-3-Test-the-OpenAI-Endpoint"><a href="#Step-3-Test-the-OpenAI-Endpoint" class="headerlink" title="Step 3: Test the OpenAI Endpoint"></a>Step 3: Test the OpenAI Endpoint</h2><p>Once the model deployment done, we can go to <code>Playground</code> menu to test our model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-11.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-11.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Now, you can use your own OpenAI endpoints in your application without errors. Below is using <code>RESTMan</code> extension to call the Azure OpenAI endpoints via REST API way.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-12.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-12.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>There are many models in Azure AI Foundry, you can choose the model you want to use.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-models.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-models.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Hope this article helps you to create your own OpenAI endpoints in Azure Cloud.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Previously, we have introduced how to use Azure OpenAI to develop a RAG (Retrieval-Augmented Generation) chatbot. In this article, we wil</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Creating and Rendering a PDF from React Easily</title>
    <link href="https://stonefishy.github.io/2025/03/11/creating-and-rendering-pdf-from-react/"/>
    <id>https://stonefishy.github.io/2025/03/11/creating-and-rendering-pdf-from-react/</id>
    <published>2025-03-11T09:53:13.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>Creating or rendering a PDF file in a web page is a common requirement. It allows user to download the pdf file and view it offline in some scenarios. Today, we will learn how to render and generate a PDF file from React using the <code>react-pdf</code> library.</p><p>The <code>react-pdf</code> library is a React component that allows us to design and render PDF documents in React. Let’s get started an example, it’s very simple to create a pdf and render it in React.</p><h2 id="Install-the-react-pdf-Library"><a href="#Install-the-react-pdf-Library" class="headerlink" title="Install the react-pdf Library"></a>Install the <code>react-pdf</code> Library</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install @react-pdf/renderer --save</span><br></pre></td></tr></table></figure><h2 id="Create-a-PDF-Document"><a href="#Create-a-PDF-Document" class="headerlink" title="Create a PDF Document"></a>Create a PDF Document</h2><p>We will create a simple PDF document using the <code>react-pdf</code> library. It supports customize styles and Flex layout to create the PDF.  Below code example using <code>react-pdf</code> library to create a PDF document, including using <code>Document</code>, <code>Page</code>, <code>StyleSheet</code>, <code>Image</code>, <code>View</code>, <code>Text</code>, <code>Link</code> components.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123;<span class="title class_">Document</span>, <span class="title class_">Page</span>, <span class="title class_">StyleSheet</span>, <span class="title class_">Image</span>, <span class="title class_">View</span>, <span class="title class_">Text</span>, <span class="title class_">Link</span>&#125; <span class="keyword">from</span> <span class="string">&#x27;@react-pdf/renderer&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = <span class="title class_">StyleSheet</span>.<span class="title function_">create</span>(&#123;</span><br><span class="line">    <span class="attr">page</span>: &#123;</span><br><span class="line">        <span class="attr">flexDirection</span>: <span class="string">&#x27;column&#x27;</span>,</span><br><span class="line">        <span class="attr">backgroundColor</span>: <span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">        <span class="attr">padding</span>: <span class="string">&quot;20px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">section</span>: &#123;</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;30px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">header</span>: &#123;</span><br><span class="line">        <span class="attr">textAlign</span>: <span class="string">&quot;center&quot;</span>,</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;24px&quot;</span>,</span><br><span class="line">        <span class="attr">fontWeight</span>: <span class="string">&quot;bold&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;30px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">logo</span>: &#123;</span><br><span class="line">        <span class="attr">height</span>: <span class="string">&quot;90px&quot;</span>,</span><br><span class="line">        <span class="attr">width</span>: <span class="string">&quot;100px&quot;</span>,</span><br><span class="line">        <span class="attr">margin</span>: <span class="string">&quot;20px auto&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">title</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="number">18</span>,</span><br><span class="line">        <span class="attr">fontWeight</span>: <span class="string">&quot;bold&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">text</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;14px&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">code</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;14px&quot;</span>,</span><br><span class="line">        <span class="attr">backgroundColor</span>: <span class="string">&quot;#3e3e3e&quot;</span>,</span><br><span class="line">        <span class="attr">color</span>: <span class="string">&quot;#fff&quot;</span>,</span><br><span class="line">        <span class="attr">padding</span>: <span class="string">&quot;20px&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">        <span class="attr">borderRadius</span>: <span class="string">&quot;5px&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">PdfDocument</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">Document</span> <span class="attr">title</span>=<span class="string">&quot;My PDF Document&quot;</span> <span class="attr">author</span>=<span class="string">&quot;Andrewsy&quot;</span> <span class="attr">subject</span>=<span class="string">&quot;This is a sample PDF document&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Page</span> <span class="attr">size</span>=<span class="string">&quot;A4&quot;</span> <span class="attr">style</span>=<span class="string">&#123;styles.page&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.section&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.header&#125;</span>&gt;</span>React PDF Renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>The react-pdf library allows you to render PDF documents using React components.<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Image</span> <span class="attr">style</span>=<span class="string">&#123;styles.logo&#125;</span> <span class="attr">src</span>=<span class="string">&quot;images/logo.png&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.section&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.title&#125;</span>&gt;</span>Install react-pdf library<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>To install the react-pdf library, you can use npm or yarn:<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.code&#125;</span>&gt;</span>npm install @react-pdf/renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span>&gt;</span><span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.code&#125;</span>&gt;</span>yarn add @react-pdf/renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>For component documentation, visit the official website <span class="tag">&lt;<span class="name">Link</span> <span class="attr">src</span>=<span class="string">&quot;https://react-pdf.org/&quot;</span>&gt;</span>@react-pdf/renderer<span class="tag">&lt;/<span class="name">Link</span>&gt;</span>.<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">Page</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">Document</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="title class_">PdfDocument</span>;</span><br></pre></td></tr></table></figure><p>From above, we can see that we have created a PDF document using <code>react-pdf</code> library. We have used <code>Document</code> and <code>Page</code> components to create the PDF document. We have also used <code>StyleSheet</code> to define the styles for the PDF document. And using <code>Image</code>, <code>View</code>, <code>Text</code>, <code>Link</code> components to create the content of the PDF document.</p><h2 id="View-PDF-Document"><a href="#View-PDF-Document" class="headerlink" title="View PDF Document"></a>View PDF Document</h2><p>To view the PDF document, we need to use <code>PDFViewer</code> component to render the PDF document in the browser. There is one thing need notice, if your project is using <code>Next.js</code>, and you want to use <code>PDFViewer</code> or <code>PDFDownloadLink</code> component in client side render directly, you will get below error:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Error: PDFViewer is a web specific API. You&#x27;re either using this component on Node, or your bundler is not loading react-pdf from the appropriate web build.]</span><br></pre></td></tr></table></figure><p>To fixed the issue in <code>Next.js</code> project. Use Next dynamic function to manually set server-side rendering off and import it through that function instead of the regular import</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&quot;@react-pdf/renderer&quot;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">mod</span>) =&gt;</span> mod. <span class="title class_">PDFViewer</span>),&#123;<span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFDownloadLink</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&quot;@react-pdf/renderer&quot;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">mod</span>) =&gt;</span> mod. <span class="title class_">PDFDownloadLink</span>),&#123;<span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br></pre></td></tr></table></figure><p>instead of</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">PDFViewer</span>, <span class="title class_">PDFDownloadLink</span> &#125; <span class="keyword">from</span> <span class="string">&quot;@react-pdf/renderer&quot;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>The view PDF document code is below, for the <code>PDFViewer</code> component, we need to set the width and height of the PDF document. Actually it is rendered as a <code>iframe</code> element in the browser. This width and height is setting to iframe.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">PdfDocument</span> <span class="keyword">from</span> <span class="string">&#x27;@/components/pdf-document&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFViewer</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Pdf</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">section</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">display:</span> &#x27;<span class="attr">flex</span>&#x27;, <span class="attr">justifyContent:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">alignItems:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">height:</span> &#x27;<span class="attr">100vh</span>&#x27; &#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFViewer</span> <span class="attr">width</span>=<span class="string">&quot;800px&quot;</span> <span class="attr">height</span>=<span class="string">&quot;900px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">PdfDocument</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFViewer</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">section</span>&gt;</span></span></span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Let’s see the screenshot. It’s beautifully and easily rendered PDF document in the browser.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Renderer"/></div><span class="image-caption">React PDF Renderer</span></div><h2 id="Download-the-PDF-Document"><a href="#Download-the-PDF-Document" class="headerlink" title="Download the PDF Document"></a>Download the PDF Document</h2><p>To download the PDF document, we can use <code>PDFDownloadLink</code> component. It allows us to download the PDF document as a file. The code is below.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">PdfDocument</span> <span class="keyword">from</span> <span class="string">&#x27;@/components/pdf-document&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFViewer</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFDownloadLink</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFDownloadLink</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Pdf</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">section</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">display:</span> &#x27;<span class="attr">flex</span>&#x27;, <span class="attr">flexDirection:</span>&#x27;<span class="attr">column</span>&#x27;, <span class="attr">alignItems:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">height:</span> &#x27;<span class="attr">100vh</span>&#x27; &#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFViewer</span> <span class="attr">width</span>=<span class="string">&quot;850px&quot;</span> <span class="attr">height</span>=<span class="string">&quot;850px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">PdfDocument</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFViewer</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFDownloadLink</span> <span class="attr">document</span>=<span class="string">&#123;</span>&lt;<span class="attr">PdfDocument</span> /&gt;</span>&#125; fileName=&quot;my-pdf-document.pdf&quot; style=&#123;&#123;marginTop: &#x27;10px&#x27;&#125;&#125;&gt;</span></span><br><span class="line"><span class="language-xml">                &#123;(&#123; blob, url, loading, error &#125;) =&gt; (</span></span><br><span class="line"><span class="language-xml">                    loading ? &#x27;Loading document...&#x27; : <span class="tag">&lt;<span class="name">button</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">backgroundColor:</span> &#x27;#<span class="attr">171717</span>&#x27;, <span class="attr">color:</span> &#x27;<span class="attr">white</span>&#x27;, <span class="attr">padding:</span> &#x27;<span class="attr">10px</span>&#x27;, <span class="attr">borderRadius:</span> &#x27;<span class="attr">5px</span>&#x27;, <span class="attr">cursor:</span> &#x27;<span class="attr">pointer</span>&#x27; &#125;&#125;&gt;</span>Download<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                )&#125;</span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFDownloadLink</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">section</span>&gt;</span></span></span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the above code, we have used <code>PDFDownloadLink</code> component to download the PDF document, passed the <code>PdfDocument</code> component as the <code>document</code> prop of <code>PDFDownloadLink</code> component. We have also set the <code>fileName</code> prop to <code>my-pdf-document.pdf</code> to set the file name of the downloaded file. The <code>style</code> prop is used to set the style of the download button. We also use the <code>loading</code> prop to show the loading message while the PDF document is being downloaded.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf-download.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf-download.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Download"/></div><span class="image-caption">React PDF Download</span></div><p>Below PDF document is downloaded as a file.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf-doc.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf-doc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Document Opened in Adobe Acrobat Reader"/></div><span class="image-caption">React PDF Document Opened in Adobe Acrobat Reader</span></div><p>See it’s easily to create and render a PDF document in React using the <code>react-pdf</code> library.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The <code>react-pdf</code> library is a React component that allows us to design and render PDF documents in React. It supports customize styles and Flex layout to create the PDF. We have learned how to create a PDF document using <code>react-pdf</code> library, how to view and download the PDF document.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Creating or rendering a PDF file in a web page is a common requirement. It allows user to download the pdf file and view it offline in so</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Next.js" scheme="https://stonefishy.github.io/tags/Next-js/"/>
    
    <category term="PDF" scheme="https://stonefishy.github.io/tags/PDF/"/>
    
  </entry>
  
  <entry>
    <title>Conversational RAG Chatbot - Build a Chatbot with LangChain and Chainlit</title>
    <link href="https://stonefishy.github.io/2025/02/27/conversational-rag-chatbot-build-a-chatbot-with-langchain/"/>
    <id>https://stonefishy.github.io/2025/02/27/conversational-rag-chatbot-build-a-chatbot-with-langchain/</id>
    <published>2025-02-27T15:33:13.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>In previous blog, we have converting the PDF documents into the <code>FAISS</code> vector index, and saved in the local. Now, we will build a RAG chatbot using the <code>LangChain</code>, <code>Chainlit</code> and <code>OpenAI</code> base on previous <code>FAISS</code> index.</p><p>Before we get started, let’s talk about what is <code>Chainlit</code> and <code>LangChain</code>.</p><h2 id="Chainlit"><a href="#Chainlit" class="headerlink" title="Chainlit"></a>Chainlit</h2><p>We choose the <code>Chainlit</code> framework to build the chatbot. <code>Chainlit</code> is a framework designed to simplify the process of building and deploying chatbots for large language models (<code>LLMs</code>). It provides a way to create conversational applications that can interact with users through chat interfaces. Chainlit helps developers to chain together different components of a chatbot, such as the model itself, user interfaces, and data sources, making it easier to build complex conversational systems. It is particularly useful for those who want to integrate LLMs into their existing applications or create standalone chatbots. You can find the <code>Chainlit</code> documentation <a href="https://docs.chainlit.io/get-started/overview">here</a>.</p><h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><p><code>LangChain</code> is a framework designed to simplify the process of building language models and applications that leverage these models. It provides a set of tools and libraries that allow developers to integrate language models into their applications more easily, handle data flow, and manage the interactions between different components of their system. LangChain supports various language models and can be used to create a wide range of applications, from chatbots and virtual assistants to document summarization and translation tools. It aims to make it straightforward to build, deploy, and scale language-driven applications.</p><h2 id="Get-started"><a href="#Get-started" class="headerlink" title="Get started"></a>Get started</h2><p>Ok, let’s get started. First, we need to install the <code>LangChain</code> and <code>Chainlit</code> and other libraries, all the required libraries are below. Creating a <code>requirements.txt</code> file and store below libraries in it:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">openai</span><br><span class="line">langchain</span><br><span class="line">chainlit</span><br><span class="line">faiss-cpu</span><br><span class="line">tiktoken</span><br><span class="line">pymupdf</span><br><span class="line">PyPDF2</span><br><span class="line">langchain_openai</span><br><span class="line">langchain_community</span><br></pre></td></tr></table></figure><p>I suggest to create a virtual environment for this project before installing these libraries. We can use the following command to create a virtual environment:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv venv</span><br></pre></td></tr></table></figure><p>After creating the virtual environment, activate it using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> venv/bin/activate</span><br></pre></td></tr></table></figure><p>Then install all the required libraries using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>Now, we can start building the chatbot.</p><h2 id="Building-Chatbot-UI"><a href="#Building-Chatbot-UI" class="headerlink" title="Building Chatbot UI"></a>Building Chatbot UI</h2><p>The <code>Chainlit</code> provides the wonderful API to build the chatbot UI. It saves much time and efforts. In the project, create a <code>app.py</code> and import the <code>chainlit</code> library then write the below code. We will use 3 chainlit annotations. <code>@cl.set_starters</code>, <code>@cl.on_chat_start</code>, and <code>@cl.on_message</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> chainlit <span class="keyword">as</span> cl</span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.set_starters</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">set_starters</span>():</span><br><span class="line">    <span class="comment"># The chatbot starter page which displays the quick list of questions</span></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;The Major Updates in Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;What&#x27;s the major updates in Wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/specifications.svg&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;Migrate Project from Wix4 to Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;How to mirage the wix4 project to wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/jigsaw.png&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;Build Burn Bootstrapper on Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;How to build a burn bootstrapper on wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/bundle.svg&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_chat_start</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>():</span><br><span class="line">    <span class="comment"># starting the chatbot logic</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_message</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">message: cl.Message</span>):</span><br><span class="line">    <span class="comment"># chatbot logic and response here</span></span><br></pre></td></tr></table></figure><ol><li><p>The <code>@cl.set_starters</code> annotation is used to set the chatbot starter page. It takes a list of <code>cl.Starter</code> objects as input. Each <code>cl.Starter</code> object represents a question and its corresponding message. The <code>icon</code> parameter is used to set the icon for the question.</p></li><li><p>The <code>@cl.on_chat_start</code> annotation is used to start the chatbot logic. Such as setting the initial state of the chatbot, loading the chatbot model, FAISS index, create a langchain pipeline, etc.</p></li><li><p>The <code>@cl.on_message</code> annotation is used to handle the chatbot logic and response. It takes a <code>cl.Message</code> object as input. The <code>cl.Message</code> object contains the user’s message and other metadata. We can use the <code>message.content</code> attribute to get the user’s message.</p></li></ol><p>The starter page screenshot like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-starter-page.png %" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-starter-page.png %" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Chainlit Chatbot Starter Page"/></div><span class="image-caption">Chainlit Chatbot Starter Page</span></div><p>You can also customize the theme, or do some changes in UI. </p><h2 id="Loading-the-FAISS-Vector-Index"><a href="#Loading-the-FAISS-Vector-Index" class="headerlink" title="Loading the FAISS Vector Index"></a>Loading the FAISS Vector Index</h2><p>Using <code>FAISS</code> library, we can load the <code>FAISS</code> vector index. We need to pass the <code>embeddings</code> and <code>index_name</code> to the <code>FAISS.load_local</code> method. The <code>embeddings</code> parameter is the embedding model we used before, and the <code>index_name</code> parameter is the name of the index. Here, our embedding model is <code>AzureOpenAIEmbeddings</code> and the index name is <code>wix-upgrade</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">VECTOR_INDEX_NAME = <span class="string">&#x27;wix-upgrade&#x27;</span></span><br><span class="line">AZURE_OPENAI_API_KEY = os.getenv(<span class="string">&quot;AZURE_OPENAI_API_KEY&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ENDPOINT = os.getenv(<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_DEPLOYMENT_VERSION = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_DEPLOYMENT_VERSION&quot;</span>)</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION= os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME&quot;</span>)</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT_NAME&quot;</span>)</span><br><span class="line"></span><br><span class="line">embeddings = AzureOpenAIEmbeddings(</span><br><span class="line">    deployment=AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,</span><br><span class="line">    model=AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME,</span><br><span class="line">    azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">    openai_api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">    openai_api_version=AZURE_OPENAI_ADA_DEPLOYMENT_VERSION</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">docs_vector_store = FAISS.load_local(</span><br><span class="line">    folder_path=<span class="string">&quot;./vector_stores&quot;</span>, </span><br><span class="line">    embeddings=embeddings, </span><br><span class="line">    index_name=VECTOR_INDEX_NAME,</span><br><span class="line">    allow_dangerous_deserialization=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>Using <code>load_dotenv()</code> method, we can load the environment variables from the <code>.env</code> file. We can put the loading vector index code in the <code>@cl.on_chat_start</code> annotation.</p><h2 id="Building-the-Converstaion-Chain"><a href="#Building-the-Converstaion-Chain" class="headerlink" title="Building the Converstaion Chain"></a>Building the Converstaion Chain</h2><p>After we load the vector index, we can build the conversation chain using <code>LangChain</code>. The main logic are below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureOpenAIEmbeddings,AzureChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain.chains.combine_documents <span class="keyword">import</span> create_stuff_documents_chain</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> create_history_aware_retriever, create_retrieval_chain</span><br><span class="line"><span class="keyword">from</span> langchain_core.chat_history <span class="keyword">import</span> BaseChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables.history <span class="keyword">import</span> RunnableWithMessageHistory</span><br><span class="line"></span><br><span class="line">chat_history_store = &#123;&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_session_history</span>(<span class="params">session_id: <span class="built_in">str</span></span>) -&gt; BaseChatMessageHistory:</span><br><span class="line">    <span class="keyword">if</span> session_id <span class="keyword">not</span> <span class="keyword">in</span> chat_history_store:</span><br><span class="line">        chat_history_store[session_id] = ChatMessageHistory()</span><br><span class="line">    <span class="keyword">return</span> chat_history_store[session_id]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_chat_start</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>():</span><br><span class="line">    docs_vector_store = FAISS.load_local(</span><br><span class="line">        folder_path=<span class="string">&quot;./vector_stores&quot;</span>, </span><br><span class="line">        embeddings=embeddings, </span><br><span class="line">        index_name=VECTOR_INDEX_NAME,</span><br><span class="line">        allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    llm=AzureChatOpenAI(</span><br><span class="line">        api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">        azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">        api_version=AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION,</span><br><span class="line">        openai_api_type=<span class="string">&quot;azure&quot;</span>,</span><br><span class="line">        azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,</span><br><span class="line">        streaming=<span class="literal">True</span>,</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    retriever = docs_vector_store.as_retriever()</span><br><span class="line">    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)</span><br><span class="line">    question_answer_chain = create_stuff_documents_chain(llm, QA_PROMPT)</span><br><span class="line">    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)</span><br><span class="line"></span><br><span class="line">    conversational_rag_chain = RunnableWithMessageHistory(</span><br><span class="line">        rag_chain,</span><br><span class="line">        get_session_history,</span><br><span class="line">        input_messages_key=<span class="string">&quot;input&quot;</span>,</span><br><span class="line">        history_messages_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">        output_messages_key=<span class="string">&quot;answer&quot;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    cl.user_session.<span class="built_in">set</span>(<span class="string">&quot;chain&quot;</span>, conversational_rag_chain)</span><br></pre></td></tr></table></figure><p>In above code, we first load the <code>FAISS</code> vector index and create the <code>AzureChatOpenAI</code> language model. We then create the <code>retriever</code> using the <code>docs_vector_store</code> and create the <code>history_aware_retriever</code> using the <code>create_history_aware_retriever</code> method. The <code>contextualize_q_prompt</code> method is used to create the contextualized question prompt. The <code>create_stuff_documents_chain</code> method is used to create the question answer chain. Finally, we create the <code>rag_chain</code> using the <code>create_retrieval_chain</code> method.</p><p>We then create the <code>conversational_rag_chain</code> using the <code>RunnableWithMessageHistory</code> class. The <code>get_session_history</code> method is used to get the chat history for each session. The <code>input_messages_key</code>, <code>history_messages_key</code>, and <code>output_messages_key</code> parameters are used to set the keys for the input, history, and output messages.</p><p>We set the <code>conversational_rag_chain</code> as the chatbot chain using the <code>cl.user_session.set</code> method. We can use it later.</p><p>Here you’re notice there is <code>contextualize_q_prompt</code> and <code>QA_PROMPT</code> variable. They are prompts which will passting to LLM to restrict the LLM answers. The code is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    MessagesPlaceholder</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">contextualize_q_system_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Given a chat history and the latest user question \</span></span><br><span class="line"><span class="string">which might reference context in the chat history, formulate a standalone question \</span></span><br><span class="line"><span class="string">which can be understood without the chat history. Do NOT answer the question, \</span></span><br><span class="line"><span class="string">just reformulate it if needed and otherwise return it as is.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">contextualize_q_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, contextualize_q_system_prompt),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">qa_system_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Act like a WiX (WixToolset) development expert and help me with related WiX development questions. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Some **strict rules** you have to follow NO MATTER WHAT:</span></span><br><span class="line"><span class="string">Only answer related questions about WiX development.</span></span><br><span class="line"><span class="string">If you don&#x27;t know the answer, say:</span></span><br><span class="line"><span class="string">I don&#x27;t have such information, please refer to WiX offical documentation for the information. https://docs.firegiant.com/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Please Use the following pieces of context to answer the user&#x27;s question. </span></span><br><span class="line"><span class="string">----------------</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">QA_PROMPT = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, qa_system_prompt),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The <code>contextualize_q_prompt</code> is used to create the contextualized question prompt base on chat history and the latest user iput. The <code>MessagesPlaceholder(&quot;chat_history&quot;)</code> is used to insert the chat history in the prompt. From the prompt, It will formulate a standard question base on chat history and the latest user input.</p><p>The <code>qa_system_prompt</code> is used to create the question answer prompt. It is limit to only answer the related questions about WiX development. If the user’s question is not related to WiX development, it will say I don’t have such information, please refer to the WiX offical documentation for the information. You can also remove this limitation prompt text to make the AI model reply any question.</p><p>So now, our chain is ready to use. Next step we will uset this chain to answer the user’s question.</p><h2 id="Invoke-Chain"><a href="#Invoke-Chain" class="headerlink" title="Invoke Chain"></a>Invoke Chain</h2><p>In previous step, we have set the <code>conversational_rag_chain</code> as the chatbot chain using the <code>cl.user_session.set</code> method. Now, we can use it to answer the user’s question. Below is <code>@cl.on_message</code> annotation to invoke the chain and send the response.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@cl.on_message</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">message: cl.Message</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        chain = cl.user_session.get(<span class="string">&quot;chain&quot;</span>)</span><br><span class="line">        msg = cl.Message(content=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        res = chain.invoke(</span><br><span class="line">            &#123;<span class="string">&quot;input&quot;</span>: message.content&#125;, </span><br><span class="line">            config=&#123;</span><br><span class="line">                <span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: cl.user_session.get(<span class="string">&quot;id&quot;</span>)&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        response = res[<span class="string">&quot;answer&quot;</span>]</span><br><span class="line"></span><br><span class="line">        stream_size = <span class="number">20</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">len</span>(response) / stream_size)) + <span class="number">1</span>):</span><br><span class="line">            msg.content = response[<span class="number">0</span> : (i + <span class="number">1</span>) * stream_size]</span><br><span class="line">            <span class="keyword">await</span> msg.send()</span><br><span class="line">            time.sleep(<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;An error occurred: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> e.code == <span class="string">&quot;content_filter&quot;</span>:</span><br><span class="line">            <span class="keyword">await</span> cl.ErrorMessage(</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                The response was filtered due to the prompt triggering Azure OpenAI&#x27;s content management policy. Please modify your prompt and retry. </span></span><br><span class="line"><span class="string">                To learn more about our content filtering policies please read our documentation: </span></span><br><span class="line"><span class="string">                https://go.microsoft.com/fwlink/?linkid=2198766</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                ).send()</span><br></pre></td></tr></table></figure><p>In above code, we get the <code>conversational_rag_chain</code> from the <code>cl.user_session</code> and invoke it with the user’s message. We set the <code>session_id</code> in the <code>config</code> parameter to get the chat history for each session. We then send the response to the user in chunks of 20 characters.</p><p>The following code is simulating the stream response in the UI. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream_size = <span class="number">20</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">len</span>(response) / stream_size)) + <span class="number">1</span>):</span><br><span class="line">    msg.content = response[<span class="number">0</span> : (i + <span class="number">1</span>) * stream_size]</span><br><span class="line">    <span class="keyword">await</span> msg.send()</span><br><span class="line">    time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><p>The AzureOpenAI has content limitation, the user input which pass to the OpenAI API will be filtered if it contains any offensive or inappropriate content. So, we need to handle this situation. We can use the <code>ErrorMessage</code> class to send the error message to the user if the response is filtered.</p><h2 id="Chat-Demo-Screenshoots"><a href="#Chat-Demo-Screenshoots" class="headerlink" title="Chat Demo Screenshoots"></a>Chat Demo Screenshoots</h2><p>Below are screenshots of the chatbot conversation UI and response.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this blog, we have built a RAG chatbot using the <code>LangChain</code>, <code>Chainlit</code> and <code>OpenAI</code> base on previous <code>FAISS</code> index. We have used the <code>Chainlit</code> to build the chatbot UI, and the <code>LangChain</code> to build the conversation chain. We have also used the <code>FAISS</code> library to load the <code>FAISS</code> vector index and the <code>AzureChatOpenAI</code> language model. Finally, we have used the <code>RunnableWithMessageHistory</code> class to handle the chat history and the <code>ErrorMessage</code> class to handle the content filter.</p><p>If you want to get the full code, you can find it in the <a href="https://github.com/stonefishy/converstional-rag-chatbot">GitHub repository</a>. In this demo, we just put the 4 PDF documents which upgrade Wix3, Wix4 to Wix5. You can replace it with your own documents.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In previous blog, we have converting the PDF documents into the &lt;code&gt;FAISS&lt;/code&gt; vector index, and saved in the local. Now, we will bui</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
    <category term="Langchain" scheme="https://stonefishy.github.io/tags/Langchain/"/>
    
    <category term="Chainlit Chatbot" scheme="https://stonefishy.github.io/tags/Chainlit-Chatbot/"/>
    
  </entry>
  
  <entry>
    <title>Conversational RAG Chatbot - Converting PDF Document to Vector</title>
    <link href="https://stonefishy.github.io/2025/02/24/conversational-rag-chatbot-converting-pdf-document-to-vector/"/>
    <id>https://stonefishy.github.io/2025/02/24/conversational-rag-chatbot-converting-pdf-document-to-vector/</id>
    <published>2025-02-24T16:27:50.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this series of blogs, we will build a <code>RAG(Retrieval-Augmented Generation)</code> chatbot which using <code>WiX(WiXToolset)</code> documents as knowledge data. It will contains below steps:</p><ol><li>Converting PDF Document to Vector</li><li>Building a Chatbot that can answer questions based on the documents</li></ol><p>The technology stack used in this project are</p><ul><li>Python</li><li>LangChain</li><li>OpenAI</li><li>Chainlit</li><li>FAISS</li></ul><p>In this blog, we will focus on the first step, Converting PDF Document to Vector. </p><h2 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h2><p>The vector is a mathematical representation of a document or a text. It is a numerical representation of the text that can be used for various natural language processing tasks. The vector can be generated using various techniques like Bag-of-Words, TF-IDF, Word2Vec, etc. To store the vector, we can use various databases like FAISS, Pinecone, chroma etc.</p><h2 id="PDF-Document-to-Vector"><a href="#PDF-Document-to-Vector" class="headerlink" title="PDF Document to Vector"></a>PDF Document to Vector</h2><h3 id="FAISS"><a href="#FAISS" class="headerlink" title="FAISS"></a>FAISS</h3><p>In this blog, we will use <code>FAISS(Facebook AI Similarity Search)</code> to save the vector on local. The FAISS is  is a library for efficient similarity search and clustering of dense vectors. It is developed by Faiss Team at Facebook AI Research. FAISS is designed to handle large-scale nearest neighbor searches, which are common in applications like recommendation systems, image retrieval, and natural language processing. The library provides multiple algorithms for searching and clustering, including exact and approximate methods, and is optimized for both speed and accuracy. It supports various types of vector norms and can be used on both CPU and GPU for fast computation.</p><h3 id="Prepare-the-PDF-documents"><a href="#Prepare-the-PDF-documents" class="headerlink" title="Prepare the PDF documents"></a>Prepare the PDF documents</h3><p>For the WiX documents, we can download the documents from the official website <a href="https://docs.firegiant.com/wix/fivefour/">https://docs.firegiant.com/wix/fivefour/</a>. And here we only use the WiX upgrade guide document. Below are documents we are using:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-pdfs.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-pdfs.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="Extracting-Text-from-PDF-Documents"><a href="#Extracting-Text-from-PDF-Documents" class="headerlink" title="Extracting Text from PDF Documents"></a>Extracting Text from PDF Documents</h3><p>We will using the library <code>PyPDF2</code> to extract the text from the PDF documents. Below is code snippet to extract all the text from the PDF documents and store it in a text variable. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pdf_directory = Path(pdf_storage_path)</span><br><span class="line">text = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">    pdf_reader = PdfReader(pdf_path, <span class="literal">True</span>)</span><br><span class="line">    pdf_text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">        page_text = page.extract_text()</span><br><span class="line">        pdf_text += page_text</span><br><span class="line"></span><br><span class="line">    txt_path = pdf_path.with_name(pdf_path.stem + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(pdf_text)</span><br><span class="line">    text += pdf_text + <span class="string">&quot;\n\n&quot;</span> </span><br></pre></td></tr></table></figure><h3 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h3><p>Using the <code>AzureOpenAIEmbeddings</code> class from <code>langchain</code> library to get the vector representation of the text. For the Azuer OpenAI endpoints and api keys you can define it in the <code>.env</code> file.</p><p>.env file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_ENDPOINT=</span><br><span class="line">AZURE_OPENAI_API_KEY=</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION=<span class="number">2023</span>-07-01-preview</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME=text-embedding-ada-002</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002</span><br><span class="line">AZURE_OPENAI_ADA_DEPLOYMENT_VERSION=<span class="number">2023</span>-07-01-preview</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">embeddings = AzureOpenAIEmbeddings(</span><br><span class="line">    deployment=AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,</span><br><span class="line">    model=AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME,</span><br><span class="line">    azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">    openai_api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">    openai_api_version=AZURE_OPENAI_ADA_DEPLOYMENT_VERSION</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="Construct-FAISS"><a href="#Construct-FAISS" class="headerlink" title="Construct FAISS"></a>Construct FAISS</h3><p>After we have extracted the text from the PDF documents, below code snippet will construct the FAISS index. Using the <code>RecursiveCharacterTextSplitter</code> class from <code>langchain</code> library to split the text into chunks. Using <code>AzureOpenAIEmbeddings</code> class from <code>langchain</code> library, we can get the vector representation of the text. And save it into the FAISS index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>, </span><br><span class="line">    chunk_overlap=<span class="number">250</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;splitting text into chunks...&quot;</span>)</span><br><span class="line">chunks = text_splitter.split_text(text)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">vector_store =FAISS.from_texts(chunks, embeddings)</span><br><span class="line">vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>So the entire workflow is that we have downloaded the PDF documents, extracted the text from the PDF documents, and constructed the FAISS index. The FAISS index will be saved in the local directory.</p><p>Below is the function code snippet:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">250</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        pdf_reader = PdfReader(pdf_path, <span class="literal">True</span>)</span><br><span class="line">        pdf_text = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">            page_text = page.extract_text()</span><br><span class="line">            pdf_text += page_text</span><br><span class="line"></span><br><span class="line">        txt_path = pdf_path.with_name(pdf_path.stem + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            file.write(pdf_text)</span><br><span class="line">        text += pdf_text + <span class="string">&quot;\n\n&quot;</span> </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;splitting text into chunks...&quot;</span>)</span><br><span class="line">    chunks = text_splitter.split_text(text)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">    vector_store =FAISS.from_texts(chunks, embeddings)</span><br><span class="line">    vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>There is also another way to construct the FAISS index using the <code>langchain</code> library from pdf documents. Using <code>PyMuPDFLoader</code> to load the pdf documents instead of extracting the text from the pdf documents. Below is the code snippet:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss2</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    docs = []</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">250</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        loader = PyMuPDFLoader(<span class="built_in">str</span>(pdf_path))</span><br><span class="line">        documents = loader.load()</span><br><span class="line">        pdf_docs= text_splitter.split_documents(documents)</span><br><span class="line">        docs += pdf_docs</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">    vector_store =FAISS.from_documents(docs, embeddings)</span><br><span class="line">    vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>Above two code snippets are reading all documents from one directory and saving them into the FAISS index. But somehow, if the text is too long and exceed the maximum length of the Azure OpenAI API, it failed to process the text. Refer to Azure OpenAI API documentation <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits">https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits</a>. </p><p>We can count the token by using <code>tiktoken</code> library. The model is used to tokenize the text. If the model is not found, it defaults to using the ‘cl100k_base’ tokenizer. Here we can passing the AzureOpenAIEmbeddings model to the <code>count_tokens</code> function to count the number of tokens in the text.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Counts the number of tokens in a given text using the specified model&#x27;s tokenizer.</span></span><br><span class="line"><span class="string">If the model is not found, it defaults to using the &#x27;cl100k_base&#x27; tokenizer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    text (str): The input text to be tokenized.</span></span><br><span class="line"><span class="string">    model (str): The name of the model for which the tokenizer is used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    int: The total number of tokens in the text.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_tokens</span>(<span class="params">text, model</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        encoding = tiktoken.encoding_for_model(model)</span><br><span class="line">    <span class="keyword">except</span> KeyError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Warning: model not found. Using cl100k_base encoding.&quot;</span>)</span><br><span class="line">        encoding = tiktoken.get_encoding(<span class="string">&quot;cl100k_base&quot;</span>)</span><br><span class="line">    num_tokens = <span class="built_in">len</span>(encoding.encode(text))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total tokens: <span class="subst">&#123;num_tokens&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> num_tokens</span><br></pre></td></tr></table></figure><h3 id="Mergging-Indexes"><a href="#Mergging-Indexes" class="headerlink" title="Mergging Indexes"></a>Mergging Indexes</h3><p>The FAISS supports to merge multiple indexes into one index. So we can merge the index of all the documents into one index. Below is the code snippet to merge the index of all the documents into one index.</p><p>Let’s write another function to embedding pdfs into individual index. Below function will embedding all the pdfs into individual index and save it in the specified directory.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss_files</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, faiss_dir_path: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">200</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        loader = PyMuPDFLoader(<span class="built_in">str</span>(pdf_path))</span><br><span class="line">        documents = loader.load()</span><br><span class="line">        pdf_docs= text_splitter.split_documents(documents)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;embedding document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        vector_store =FAISS.from_documents(pdf_docs, embeddings)</span><br><span class="line">        vector_store.save_local(faiss_dir_path, pdf_path.stem)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;finished processing pdf <span class="subst">&#123;pdf_path&#125;</span>!&quot;</span>)</span><br></pre></td></tr></table></figure><p>Call this function with below code snippet to embedding all the pdfs into individual index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pdfs_to_faiss_files(PDF_STORAGE_PATH, <span class="string">&quot;./faiss_files&quot;</span>)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-pdfs-indexing.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-pdfs-indexing.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-indexes.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-indexes.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After these indexes are created, we can use FAISS to merge them into one index. Below is the code snippet to merge the index of all the documents into one index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Merges multiple FAISS files into a single index.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    faiss_dir_path (str): The path to the directory containing the FAISS files.</span></span><br><span class="line"><span class="string">    index_name (str): The name of the index to be saved.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_faiss_files</span>(<span class="params">faiss_dir_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    faiss_directory = Path(faiss_dir_path)</span><br><span class="line">    </span><br><span class="line">    is_first_faiss = <span class="literal">True</span></span><br><span class="line">    first_faiss = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> faiss_path <span class="keyword">in</span> faiss_directory.glob(<span class="string">&quot;*.faiss&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading FAISS file <span class="subst">&#123;faiss_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> is_first_faiss:</span><br><span class="line">            is_first_faiss = <span class="literal">False</span></span><br><span class="line">            first_faiss = FAISS.load_local(</span><br><span class="line">                folder_path=faiss_dir_path, </span><br><span class="line">                embeddings=embeddings, </span><br><span class="line">                index_name=faiss_path.stem,</span><br><span class="line">                allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Merging with <span class="subst">&#123;faiss_path&#125;</span>&quot;</span>)</span><br><span class="line">            first_faiss.merge_from(FAISS.load_local(</span><br><span class="line">                folder_path=faiss_dir_path, </span><br><span class="line">                embeddings=embeddings, </span><br><span class="line">                index_name=faiss_path.stem,</span><br><span class="line">                allow_dangerous_deserialization=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    first_faiss.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br></pre></td></tr></table></figure><p>Call this function with below code snippet to merge all the indexes into one index. We merged all <code>FAISS</code> index files which are saved in the <code>faiss_files</code> directory into one index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge_faiss_files(<span class="string">&quot;./faiss_files&quot;</span>, INDEX_NAME)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-merging-indexings.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-merging-indexings.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-merged-index.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-merged-index.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Next step, we will build a WiX chatbot which loading this <code>FAISS</code> index and passing the question and retrieving the relevant documents from the index. For the entire code, you can check the github <a href="https://github.com/stonefishy/converstional-rag-chatbot">GitHub repository</a> to see the entire code.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this series of blogs, we wi</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
    <category term="Langchain" scheme="https://stonefishy.github.io/tags/Langchain/"/>
    
  </entry>
  
  <entry>
    <title>Deploy User Friendly AI Interface Chatbot on Local by Using Ollama + Open-WebUI.</title>
    <link href="https://stonefishy.github.io/2025/02/10/deploy-user-friendly-ai-interface-on-local-by-using-ollama-open-webui/"/>
    <id>https://stonefishy.github.io/2025/02/10/deploy-user-friendly-ai-interface-on-local-by-using-ollama-open-webui/</id>
    <published>2025-02-10T09:55:11.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>In Previous blog, we talk about how to running <code>DeepSeek</code> large language model (LLM) on local machine by using Ollama. For installing Ollama, you can check the previous blog. We play it and chat on terminal. In this blog, we will talk about how to deploy user-friendly AI interface chatbot on local machine by using Ollama and Open-WebUI.</p><h2 id="What-is-Open-WebUI"><a href="#What-is-Open-WebUI" class="headerlink" title="What is Open-WebUI?"></a>What is Open-WebUI?</h2><p><code>Open WebUI</code> is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like <code>Ollama</code> and <code>OpenAI-compatible APIs</code>, with built-in inference engine for RAG, making it a powerful AI deployment solution.</p><h2 id="Install-Ollama"><a href="#Install-Ollama" class="headerlink" title="Install Ollama"></a>Install Ollama</h2><p>To install the Ollama, you can download the <code>Ollama</code> from official website and follow the installation guide. Once installed, you can check the ollama version and commands using below commands in your terminal.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ollama --version</span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-version-commands.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-version-commands.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>For downloading the <code>LLM</code> model, using below command <code>ollama pull &lt;model_name&gt;</code>in your terminal.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>I already downloaded the <code>deepseek</code> and <code>gemma</code> models in my local machine. You can check the downloaded models using <code>ollama ls</code> command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-models-list.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-models-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Set-up-Open-WebUI"><a href="#Set-up-Open-WebUI" class="headerlink" title="Set up Open-WebUI"></a>Set up Open-WebUI</h2><p>After you setup the Ollama, to set up Open-WebUI, there are multiple ways</p><h3 id="Docker-way"><a href="#Docker-way" class="headerlink" title="Docker way"></a>Docker way</h3><p>If you have installed <code>Docker</code> on your local, you can easily launch Open-WebUI using below command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure><p>Once it done, access the Open-WebUI by using <code>http://localhost:3000</code> in your browser.</p><h3 id="Python-pip-way"><a href="#Python-pip-way" class="headerlink" title="Python pip way"></a>Python pip way</h3><p>The second way is to install Open-WebUI by using Python pip and launch it locally. It requires <code>Python 3.11</code> to avoid the compatibility issues.</p><p>Check Python version, ensure the version is 3.11 or above.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><p>Next, install Open-WebUI using pip.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install open-webui</span><br></pre></td></tr></table></figure><p>When you install Open-WebUI by using python pip command, if you local machine  Microsoft Visual C++ compiler version is lower than 14, you may encounter the below error.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Building wheels for collected packages: chroma-hnswlib</span><br><span class="line">  Building wheel for chroma-hnswlib (pyproject.toml) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line"></span><br><span class="line">  × Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [5 lines of output]</span><br><span class="line">      running bdist_wheel</span><br><span class="line">      running build</span><br><span class="line">      running build_ext</span><br><span class="line">      building &#x27;hnswlib&#x27; extension</span><br><span class="line">      error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/</span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">  ERROR: Failed building wheel for chroma-hnswlib</span><br><span class="line">Failed to build chroma-hnswlib</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-pip-install-error.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-pip-install-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>.<p>To fix this issue, you can install the latest version of C++ compiler and re-install the Open-WebUI. Download the Microsoft C++ Build Tools from the official website <a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/">https://visualstudio.microsoft.com/visual-cpp-build-tools/</a>.</p><p>Install the <code>Desktop development with C++</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-pip-error-resolved.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-pip-error-resolved.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After the latest C++ compiler installed, re-install <code>Open-WebUI</code> again, once all completed, launch the Open-WebUI using below command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open-webui serve</span><br></pre></td></tr></table></figure><p>This will start the Open WebUI server, which we can access at <a href="http://localhost:8080/">http://localhost:8080</a></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-serve.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-serve.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Access the Open-WebUI by using <code>http://localhost:8080</code> in your browser. And create an admin account. Then you can start to use the <code>Open-WebUI</code>.<br>I have already installed some LLM models from <code>Ollama</code>, so we can see there are several models listed in the <code>Open-WebUI</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-models.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-models.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Have-Fun-with-Open-WebUI"><a href="#Have-Fun-with-Open-WebUI" class="headerlink" title="Have Fun with Open-WebUI"></a>Have Fun with Open-WebUI</h2><p>Let’s try to use <code>Gemma</code> model and <code>DeepSeek</code> model to chat with Open-WebUI.</p><h3 id="Using-Gemma-model"><a href="#Using-Gemma-model" class="headerlink" title="Using Gemma model"></a>Using Gemma model</h3><p>To use the <code>Gemma</code> model, select the <code>Gemma</code> model from the <code>Models</code> dropdown list and start to chat with the chatbot. Let’s use the <code>gemma:2b</code> model to chat.<br>If the model is not listed, using <code>Ollama</code> to download the model first.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-gemma-model.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-gemma-model.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="Using-DeepSeek-model"><a href="#Using-DeepSeek-model" class="headerlink" title="Using DeepSeek model"></a>Using DeepSeek model</h3><p>To use the <code>DeepSeek</code> model, select the <code>DeepSeek</code> model from the <code>Models</code> dropdown list and start to chat with the chatbot. Let’s use the <code>deepseek-r1:1.5b</code> model to chat.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-deepseek-model.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-deepseek-model.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>We can see the results of the <code>gemma:2b</code> model and the <code>deepseek-r1:1.5b</code> model are different. The <code>gemma:2b</code> model is just decreased in quality, however, the <code>deepseek-r1:1.5b</code> model is more accurate. It takes some time to deep thinking, and answer it carefully.</p><p>In <code>DeepSeek</code> model, we can see the thinking process of the deepseek model. It is a good way to understand how the deepseek thinking.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-deepseek-thinking.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-deepseek-thinking.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this blog, we have talked about how to deploy user-friendly AI interface chatbot on local machine by using Ollama and Open-WebUI. We have also used the <code>Gemma</code> and <code>DeepSeek</code> models to chat with the chatbot. We can see the results of the <code>gemma:2b</code> model and the <code>deepseek-r1:1.5b</code> model are different. The <code>gemma:2b</code> model is just decreased in quality, however, the <code>deepseek-r1:1.5b</code> model is more accurate. It takes some time to deep thinking, and answer it carefully.</p><p>Hope you like it. have fun to use <code>Open-WebUI</code>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In Previous blog, we talk about how to running &lt;code&gt;DeepSeek&lt;/code&gt; large language model (LLM) on local machine by using Ollama. For ins</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="Ollama" scheme="https://stonefishy.github.io/tags/Ollama/"/>
    
    <category term="DeepSeek" scheme="https://stonefishy.github.io/tags/DeepSeek/"/>
    
    <category term="Gemma" scheme="https://stonefishy.github.io/tags/Gemma/"/>
    
    <category term="Open-WebUI" scheme="https://stonefishy.github.io/tags/Open-WebUI/"/>
    
  </entry>
  
  <entry>
    <title>Running DeepSeek-R1 locally for free</title>
    <link href="https://stonefishy.github.io/2025/02/07/running-deepseek-r1-locally-for-free/"/>
    <id>https://stonefishy.github.io/2025/02/07/running-deepseek-r1-locally-for-free/</id>
    <published>2025-02-07T10:16:27.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/deepseek-logo.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/deepseek-logo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><p>The <code>DeepSeek</code> recently is very popular. The application download is on topest of the app store globally. The deepseek has several models, like <code>deepseek-r1</code>, <code>deepseek-coder</code> and <code>deepseek-v3</code> models etc. It’s all open source and free to use.</p><ul><li><code>deepseek-r1</code>: DeepSeek’s first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.</li><li><code>deepseek-coder</code>: It is a capable coding model trained on two trillion code and natural language tokens.</li><li><code>deepseek-v3</code>: A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.</li></ul><p>Here we will run the <code>deepseek-r1</code> model locally. It’s very easy and setup it quickly. Let’s get started.</p><h2 id="Ollama-download-and-installation"><a href="#Ollama-download-and-installation" class="headerlink" title="Ollama download and installation"></a>Ollama download and installation</h2><p>The first step is to download the <code>Ollama</code> and install it on your local machine. It supports Windows, Linux and MacOS. You can download the latest version from the official website. <a href="https://ollama.com/">https://ollama.com/</a></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama" style="width:600px;"/></div><span class="image-caption">Ollama</span></div><p>After download and install it, you can check the version or commands from terminal or command-line.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Check the version of Ollama</span></span><br><span class="line">ollama --version</span><br><span class="line"></span><br><span class="line"><span class="comment">## Check the commands of Ollama</span></span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-version-commands.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-version-commands.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama version and commands"/></div><span class="image-caption">Ollama version and commands</span></div><h2 id="Running-the-deepseek-r1-model"><a href="#Running-the-deepseek-r1-model" class="headerlink" title="Running the deepseek-r1 model"></a>Running the deepseek-r1 model</h2><p>Now, we can run the <code>deepseek-r1</code> model using Ollama. We need to download this model by using ollama. The <code>deepseek-r1</code> model contains serveral models, 1.5b, 7b, 8b, 14b, 32b, 70b and even 671b. For general computer performance, suggestion to use 1.5b model. I tried the 8b model on my local. It can run but the response is slowlly and memory is up to 90%. The 1.5b model running smoothly and response is fast. My local machine has 16GB RAM and i7 processor.</p><p>We can use the following command to download the <code>deepseek-r1</code> model.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>we also can run this model directly, if the model not exist, it will download automatically.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-run-deepseek-r1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-run-deepseek-r1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama run deepseek-r1"/></div><span class="image-caption">Ollama run deepseek-r1</span></div><h2 id="Ask-anything-in-deepseek"><a href="#Ask-anything-in-deepseek" class="headerlink" title="Ask anything in deepseek"></a>Ask anything in deepseek</h2><p>Now, we can ask anything in deepseek. Just type the question and press enter. The model will answer the question. See below screenshot</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-deepseek-answer-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-deepseek-answer-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="DeepSeek-R1 Answer"/></div><span class="image-caption">DeepSeek-R1 Answer</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-deepseek-answer-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-deepseek-answer-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="DeepSeek-R1 Answer"/></div><span class="image-caption">DeepSeek-R1 Answer</span></div><p>See, it’s easy to run the <code>deepseek-r1</code> model locally. You can also run other models like <code>deepseek-coder</code> and <code>deepseek-v3</code> models, or <code>llama</code> model. The <code>Ollama</code> models contains many open source models, you can use it for free.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/deepseek-logo.png&quot; class=&quot;lazyload</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Ollama" scheme="https://stonefishy.github.io/tags/Ollama/"/>
    
    <category term="DeepSeek" scheme="https://stonefishy.github.io/tags/DeepSeek/"/>
    
  </entry>
  
  <entry>
    <title>A RAG Chatbot base on Azure OpenAI</title>
    <link href="https://stonefishy.github.io/2025/01/23/rag-chatbot-base-on-azure-openai/"/>
    <id>https://stonefishy.github.io/2025/01/23/rag-chatbot-base-on-azure-openai/</id>
    <published>2025-01-23T11:31:28.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this article, we will build a <code>RAG (Retrieval-Augmented Generation)</code> chatbot using Azure OpenAI’s GPT-4 language model. We will use <code>Python</code>, <code>LangChain</code> and the <code>Streamlit</code> library to build the chatbot interface. Vector store will use <code>FAISS</code> library to store the text chunks and metadata.</p><h2 id="What-is-RAG"><a href="#What-is-RAG" class="headerlink" title="What is RAG?"></a>What is RAG?</h2><p><code>RAG</code> is a technique that combines retrieval-based methods with generative models to enhance the quality and relevance of the information produced by AI systems. Here’s a breakdown of the two components:</p><ol><li><p><strong>Retrieval</strong>: The model first retrieves relevant documents, text, or data from a knowledge base, database, or external source using information retrieval techniques. This allows the model to access specialized or domain-specific knowledge, which it might not have inherently learned during training.</p></li><li><p><strong>Generation</strong>: After retrieving relevant information, the model then uses a generative language model (like GPT-3 or GPT-4) to create a response that is coherent, contextually appropriate, and informed by the retrieved content. This allows the AI to answer questions, generate text, or assist in decision-making with enhanced accuracy and knowledge.</p></li></ol><h2 id="Technical-Stack"><a href="#Technical-Stack" class="headerlink" title="Technical Stack"></a>Technical Stack</h2><p>To build the chatbot, we will use the following techiniques:</p><ul><li><strong>Azure OpenAI GPT-4</strong>: We will use the GPT-4 language model from Azure OpenAI to generate responses. GPT-4 is a transformer-based language model that is capable of generating coherent and diverse text.</li><li><strong>LangChain</strong>: LangChain is a Python library that allows us to use the GPT-4 model from Azure OpenAI in our chatbot. LangChain provides a simple interface for building chatbots using GPT-4.</li><li><strong>Streamlit</strong>: We will use Streamlit to build the chatbot interface. Streamlit is a framework for building web applications in Python. It allows us to create a user-friendly interface for our chatbot.</li><li><strong>FAISS</strong>: FAISS (Facebook AI Similarity Search) is an open-source library developed by Facebook AI Research. It’s designed for efficient similarity search and clustering of high-dimensional data, such as vectors. The primary use case for FAISS is in applications where you need to search for the most similar items to a given query item in large datasets of vectors</li></ul><h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>Before we start, make sure you have the following prerequisites:</p><ul><li>An Azure account</li><li>Python 3.6 or higher</li><li>An IDE or text editor</li><li>A knowledge base or dataset of relevant information</li></ul><h2 id="Setting-up-the-Environment"><a href="#Setting-up-the-Environment" class="headerlink" title="Setting up the Environment"></a>Setting up the Environment</h2><p>To set up the environment, we will need to install the following important libraries:</p><ul><li>LangChain</li><li>Streamlit</li><li>Azure OpenAI GPT-4</li></ul><p>And also include the <code>FAISS</code> and <code>PyPDF2</code> libraries. The <code>FAISS</code> library is used for efficient similarity search, and the <code>PyPDF2</code> library is used to extract text from PDF files.</p><p>Below is the entire python libraries:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">streamlit==1.40.0</span><br><span class="line">PyPDF2==3.0.1</span><br><span class="line">faiss-cpu==1.9.0</span><br><span class="line">openai==1.59.6</span><br><span class="line">tiktoken==0.8.0</span><br><span class="line">langchain==0.3.14</span><br><span class="line">langchain-community==0.3.14</span><br><span class="line">langchain-core==0.3.29</span><br><span class="line">langchain-openai==0.3.0</span><br><span class="line">langchain-text-splitters==0.3.5</span><br></pre></td></tr></table></figure><h2 id="Process-PDFs"><a href="#Process-PDFs" class="headerlink" title="Process PDFs"></a>Process PDFs</h2><p>Here we will read the PDF files and extract the text from them. We will use the <code>PyPDF2</code> library to extract the text from the PDF files. And then save it into local vector store which can be used for similarity search by FAISS. The entire code is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> PyPDF2 <span class="keyword">import</span> PdfReader</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureOpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">azure_endpoint = os.getenv(<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>)</span><br><span class="line">api_version = os.getenv(<span class="string">&quot;AZURE_OPENAI_API_VERSION&quot;</span>)</span><br><span class="line">api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line">embedding_deployment = os.getenv(<span class="string">&quot;AZURE_OPENAI_EMBEDDING_DEPLOYMENT&quot;</span>)</span><br><span class="line">chat_deployment = os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embeddings</span>():</span><br><span class="line">    <span class="comment"># generating embedding</span></span><br><span class="line">    <span class="keyword">return</span> AzureOpenAIEmbeddings(</span><br><span class="line">        azure_deployment=embedding_deployment,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        azure_endpoint=azure_endpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_files</span>(<span class="params">directory</span>):</span><br><span class="line">    path = Path(os.path.join(os.getcwd(), directory))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> path.exists():</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">f&quot;Directory <span class="subst">&#123;path.absolute()&#125;</span> does not exist&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">str</span>(file) <span class="keyword">for</span> file <span class="keyword">in</span> path.rglob(<span class="string">&quot;*&quot;</span>) <span class="keyword">if</span> file.is_file()]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_pdfs</span>(<span class="params">pdfs_directory, vector_store_folder_path, vector_store_index_name</span>):</span><br><span class="line">    pdf_files = get_all_files(pdfs_directory)</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> pdf_file <span class="keyword">in</span> pdf_files:</span><br><span class="line">        <span class="comment"># Read pdf file</span></span><br><span class="line">        pdf_reader = PdfReader(pdf_file)</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">            text += page.extract_text()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Break it into chunks</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">        chunk_size=<span class="number">1000</span>,</span><br><span class="line">        chunk_overlap=<span class="number">150</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">    )</span><br><span class="line">    chunks = text_splitter.split_text(text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Creating vector store - FAISS</span></span><br><span class="line">    vector_store = FAISS.from_texts(chunks, embeddings())</span><br><span class="line">    vector_store.save_local(vector_store_folder_path, vector_store_index_name)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Processed PDF documents to vector store path `<span class="subst">&#123;vector_store_folder_path&#125;</span>`&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    process_pdfs(config.pdfs_directory, config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In above code, we are reading the PDF files and extracting the text from them. We are using the <code>RecursiveCharacterTextSplitter</code> to break the text into chunks of 1000 characters with 150 characters overlap. And then using the <code>FAISS</code> library to create a vector store of the text chunks. The vector store is saved in the local file system. The vector store files contains two files (<code>*.faiss</code> and <code>*.pkl</code>) which can be used for similarity search.</p><p>The <code>*.faiss</code> file contains the vector representation of the text chunks. The <code>*.pkl</code> file contains the metadata of the text chunks.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/rag-chatbot-vector-store.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/rag-chatbot-vector-store.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="RAG Chatbot Vector Store"/></div><span class="image-caption">RAG Chatbot Vector Store</span></div><p>You may noticing that we are using the <code>dotenv</code> library to load the environment variables. You can create a <code>.env</code> file in the root directory of your project and add the following variables:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_ENDPOINT=&lt;your_endpoint_url&gt;</span><br><span class="line">AZURE_OPENAI_API_VERSION=&lt;your_api_version&gt;</span><br><span class="line">OPENAI_API_KEY=&lt;your_api_key?</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o # we are using gpt-4o model, you can use any other model which you deployed in your endpoint.</span><br><span class="line">AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002 # we are using text-embedding-ada-002 model.</span><br></pre></td></tr></table></figure><h2 id="Building-the-Chatbot"><a href="#Building-the-Chatbot" class="headerlink" title="Building the Chatbot"></a>Building the Chatbot</h2><p>After we have processed the PDF files and created the vector store, we can now build the chatbot using LangChain.</p><p>First, we will create a <code>LangChain</code> instance and load the vector store. Using <code>FAISS.load_local</code> method, we can load the vector store from the local file system with the same embeddings model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">embeddings</span>():</span><br><span class="line">    <span class="comment"># generating embedding</span></span><br><span class="line">    <span class="keyword">return</span> AzureOpenAIEmbeddings(</span><br><span class="line">        azure_deployment=embedding_deployment,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        azure_endpoint=azure_endpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_vector_store</span>(<span class="params">vector_store_folder_path, vectore_store_name</span>):</span><br><span class="line">    vector_store = FAISS.load_local(</span><br><span class="line">        folder_path=vector_store_folder_path, </span><br><span class="line">        embeddings=embeddings(), </span><br><span class="line">        index_name=vectore_store_name,</span><br><span class="line">        allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> vector_store </span><br></pre></td></tr></table></figure><p>Then, we will create a <code>AzureChatOpenAI</code> instance and load the chatbot model. We will use the <code>AzureChatOpenAI</code> class to interact with the GPT-4 model from Azure OpenAI. Using <code>load_qa_chain</code> method which is provided by <code>LangChain</code>, we can load the chatbot model from the Azure OpenAI.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generateChain</span>():</span><br><span class="line">    llm =  AzureChatOpenAI(</span><br><span class="line">        azure_endpoint=azure_endpoint,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        azure_deployment=chat_deployment,</span><br><span class="line">        temperature=<span class="number">0</span>,</span><br><span class="line">        max_tokens=<span class="number">1000</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># chain -&gt; take the question, get relevant document, pass it to the LLM, generate the output</span></span><br><span class="line">    chain = load_qa_chain(llm, chain_type=<span class="string">&quot;stuff&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> chain</span><br></pre></td></tr></table></figure><p>After the chain and the vector store are loaded, we can use FAISS vector store to similarity search the user input and retrieve the most relevant document. Passing the retrieved document to the LangChain chain which loads the AzureChatOpenAI to generate the response. Below is core code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector_store = load_vector_store(config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line">chain = generateChain()</span><br><span class="line">match_documents = vector_store.similarity_search(prompt)</span><br><span class="line">response = chain.run(input_documents = match_documents, question = prompt)</span><br></pre></td></tr></table></figure><p>The <code>chain.run</code> method takes the input documents and the question as input and returns the generated response. The <code>match_documents</code> variable contains the most relevant documents retrieved from the vector store. The <code>response</code> variable contains the generated response from the chatbot.</p><p>Finally, we will create a Streamlit interface to interact with the chatbot. We will use the <code>streamlit</code> library to create a user-friendly interface for our chatbot. For the <code>streamlit</code> library usage, you can refer to the official documentation. <a href="https://docs.streamlit.io/">https://docs.streamlit.io/</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    st.set_page_config(</span><br><span class="line">        page_title=<span class="string">&quot;JBL Products Chatbot&quot;</span>,</span><br><span class="line">        page_icon=<span class="string">&quot;🧊&quot;</span>,</span><br><span class="line">        layout=<span class="string">&quot;centered&quot;</span>,</span><br><span class="line">        initial_sidebar_state=<span class="string">&quot;expanded&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    st.header(<span class="string">&quot;JBL Products Chatbot&quot;</span>)</span><br><span class="line">    vector_store = load_vector_store(config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line">    chain = generateChain()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">        st.markdown(<span class="string">&quot;Ask me anything about JBL devices (JBL Pulse 5, JBL Clip 5, JBL Bar 500)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">        st.session_state.messages = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> st.session_state.messages:</span><br><span class="line">        <span class="keyword">with</span> st.chat_message(message[<span class="string">&quot;role&quot;</span>]):</span><br><span class="line">            st.markdown(message[<span class="string">&quot;content&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> prompt := st.chat_input(<span class="string">&quot;Ask me something&quot;</span>):</span><br><span class="line">        st.chat_message(<span class="string">&quot;user&quot;</span>).markdown(prompt)</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;)</span><br><span class="line"></span><br><span class="line">        response = <span class="string">&quot;I am thinking...&quot;</span></span><br><span class="line">        <span class="keyword">with</span> st.spinner(response):</span><br><span class="line">            match_documents = vector_store.similarity_search(prompt)</span><br><span class="line">            response = chain.run(input_documents = match_documents, question = prompt)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">            st.write_stream(generate_stream(response))</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response&#125;)</span><br></pre></td></tr></table></figure><p>In above code, we are using the <code>st.chat_message</code> method to create a chat message with a specific role, using the <code>st.chat_input</code> method to get the user input. And using the <code>st.spinner</code> method to show a loading spinner while the chatbot is generating the response. Finally using the <code>st.write_stream</code> method to write the response to the chat message.</p><p>For the stream response, actually we mock it by using the <code>generate_stream</code> method. This method is used to generate the stream response. We can use the <code>st.write_stream</code> method to write the stream response to the chat message. This will let the chatbot to print word one by one in the chat message.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_stream</span>(<span class="params">response</span>):</span><br><span class="line">    <span class="comment"># generate the stream of messages</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> response.split(<span class="string">&quot; &quot;</span>):</span><br><span class="line">        <span class="keyword">yield</span> word + <span class="string">&quot; &quot;</span></span><br><span class="line">        time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><p>Below is chatbot conversational interface:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/rag-chatbot-streamlit-interface.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/rag-chatbot-streamlit-interface.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="RAG Chatbot Streamlit Interface"/></div><span class="image-caption">RAG Chatbot Streamlit Interface</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article, we have built a <code>RAG (Retrieval-Augmented Generation)</code> chatbot using Azure OpenAI’s GPT-4 language model. We have used Python, LangChain and the Streamlit library to build the chatbot interface. We have also processed the PDF files and created the vector store using FAISS library. The pdf files is crawled from the website <a href="https://www.manua.ls/">https://www.manua.ls</a></p><p>For the entire code, you can refer to the Github repository: <a href="https://github.com/stonefishy/rag-chatbot">https://github.com/stonefishy/rag-chatbot</a>. Please don’t forget to star the repository if you find it useful. Thank you for reading.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this article, we will build</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="Streamlit" scheme="https://stonefishy.github.io/tags/Streamlit/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
  </entry>
  
  <entry>
    <title>How to use Paho MQTT Client Lib in Python3</title>
    <link href="https://stonefishy.github.io/2025/01/06/how-to-use-paho-mqtt-client-lib-in-python3/"/>
    <id>https://stonefishy.github.io/2025/01/06/how-to-use-paho-mqtt-client-lib-in-python3/</id>
    <published>2025-01-06T14:57:57.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>The <code>Paho MQTT client</code> library for Python is a popular choice for building MQTT applications in Python. Here’s how to use it in Python3. <code>Paho MQTT Client</code> provides a simple and easy-to-use API for publishing and subscribing to MQTT topics. It supports MQTT 5.0, 3.1.1, and 3.1 protocols.</p><h2 id="Install-Paho-MQTT-Client"><a href="#Install-Paho-MQTT-Client" class="headerlink" title="Install Paho MQTT Client"></a>Install Paho MQTT Client</h2><p>To install <code>Paho MQTT Client</code> library, you can use the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install paho-mqtt</span><br></pre></td></tr></table></figure><h2 id="Prepare-the-MQTT-Broker"><a href="#Prepare-the-MQTT-Broker" class="headerlink" title="Prepare the MQTT Broker"></a>Prepare the MQTT Broker</h2><p>Before using the <code>Paho MQTT Client</code> library, we need to prepare the MQTT broker. We can use any MQTT broker that supports the MQTT 5.0, 3.1.1, or 3.1 protocols. Here we use the public free MQTT broker: <code>EMQX</code>, below is broker information.</p><blockquote><p>Server：broker.emqx.io<br>TCP Port：1883<br>WebSocket Port：8083<br>SSL&#x2F;TLS Port：8883<br>Secure WebSocket Port：8084</p></blockquote><h2 id="Import-Paho-MQTT-Client"><a href="#Import-Paho-MQTT-Client" class="headerlink" title="Import Paho MQTT Client"></a>Import Paho MQTT Client</h2><p>To use the <code>Paho MQTT Client</code> library in the Python code, need to import it first.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paho.mqtt <span class="keyword">import</span> client <span class="keyword">as</span> mqtt_client</span><br></pre></td></tr></table></figure><h2 id="Create-a-MQTT-Connection"><a href="#Create-a-MQTT-Connection" class="headerlink" title="Create a MQTT Connection"></a>Create a MQTT Connection</h2><p>Before create a MQTT connection, specify the MQTT client id, MQTT broker address, port and mesage topic. We can use the python <code>random.randint()</code> function to generate a random client id.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">broker = <span class="string">&quot;broker.emqx.io&quot;</span></span><br><span class="line">port = <span class="number">1883</span></span><br><span class="line">topic = <span class="string">&quot;paho/mqtt/test&quot;</span></span><br><span class="line">client_id = <span class="string">f&quot;client_<span class="subst">&#123;random.randint(<span class="number">0</span>, <span class="number">1000</span>)&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure><p>Next, we need to write the <code>on_connect</code> callback function in order to connect to the proxy. This function is called after the client successfully connects, we can use the <code>rc</code> parameter to check the connection status. Typically, we also create a client object that is also connected to “broker.emqx.io”.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">connect_mqtt</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_connect</span>(<span class="params">client, userdata, flags, reason_code, properties</span>):</span><br><span class="line">        <span class="keyword">if</span> reason_code == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Connected to MQTT Broker!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Failed to connect, return code %d\n&quot;</span>, reason_code)</span><br><span class="line">    client = mqtt_client.Client(client_id=client_id, callback_api_version=mqtt_client.CallbackAPIVersion.VERSION2)</span><br><span class="line"></span><br><span class="line">    client.on_connect = on_connect</span><br><span class="line">    client.connect(broker, port)</span><br><span class="line">    <span class="keyword">return</span> client</span><br></pre></td></tr></table></figure><p>When execute the <code>connect_mqtt()</code> function, it will return a <code>Client</code> instance that is connected to the MQTT broker, and printed the connection status.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-connected.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-connected.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Connected to Broker"/></div><span class="image-caption">MQTT Connected to Broker</span></div><h2 id="Publish-Messages-to-MQTT-Topics"><a href="#Publish-Messages-to-MQTT-Topics" class="headerlink" title="Publish Messages to MQTT Topics"></a>Publish Messages to MQTT Topics</h2><p>publish messages to MQTT topics, let’s create a <code>publish()</code> function that will publish a message to the specified topic every second. Using <code>client.publish()</code> method, we can publish a message to the specified topic.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">publish</span>(<span class="params">client</span>):</span><br><span class="line">    msg_count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        msg = <span class="string">f&quot;messages: test <span class="subst">&#123;msg_count&#125;</span>&quot;</span></span><br><span class="line">        result = client.publish(topic, msg)</span><br><span class="line">        status = result[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> status == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Send `<span class="subst">&#123;msg&#125;</span>` to topic `<span class="subst">&#123;topic&#125;</span>`&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Failed to send message to topic <span class="subst">&#123;topic&#125;</span>&quot;</span>)</span><br><span class="line">        msg_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> msg_count &gt; <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-publish.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-publish.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Publish Message"/></div><span class="image-caption">MQTT Publish Message</span></div><h2 id="Subscribe-to-MQTT-Topics"><a href="#Subscribe-to-MQTT-Topics" class="headerlink" title="Subscribe to MQTT Topics"></a>Subscribe to MQTT Topics</h2><p>To subscribe to MQTT topics, we can call the <code>subscribe()</code> method of the <code>Client</code> instance. We can define a callback function that will be called when a message is received on a subscribed topic. The callback function <code>on_message()</code> will be called when a message is received on the subscribed topic.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">subscribe</span>(<span class="params">client: mqtt_client</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_message</span>(<span class="params">client, userdata, msg</span>):</span><br><span class="line">        <span class="built_in">print</span>(msg)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Received `<span class="subst">&#123;msg.payload.decode()&#125;</span>` which sent by `<span class="subst">&#123;client._client_id&#125;</span>` from `<span class="subst">&#123;msg.topic&#125;</span>` topic&quot;</span>)</span><br><span class="line"></span><br><span class="line">    client.subscribe(topic)</span><br><span class="line">    client.on_message = on_message</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-subscribe.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-subscribe.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Subscribe Message"/></div><span class="image-caption">MQTT Subscribe Message</span></div><h2 id="Run-the-MQTT-Client"><a href="#Run-the-MQTT-Client" class="headerlink" title="Run the MQTT Client"></a>Run the MQTT Client</h2><p>To run the MQTT client, we can use <code>loop_start()</code> method to run the client in a separate thread, <code>loop_stop()</code> method to stop the client loop. We also can call the <code>loop_forever()</code> method of the <code>Client</code> instance. This method will block the current thread and run the client indefinitely. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">client.loop_start() <span class="comment"># start the client loop</span></span><br><span class="line">client.loop_stop() <span class="comment"># stop the client loop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">client.loop_forever() <span class="comment"># block the current thread and run the client indefinitely</span></span><br></pre></td></tr></table></figure><h2 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h2><p>Here’s the full code that uses the <code>Paho MQTT Client</code> library to connect to the MQTT broker, publish messages to a topic, and subscribe to a topic.</p><h3 id="client1-py"><a href="#client1-py" class="headerlink" title="client1.py"></a>client1.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> paho.mqtt <span class="keyword">import</span> client <span class="keyword">as</span> mqtt_client</span><br><span class="line"></span><br><span class="line">broker = <span class="string">&quot;broker.emqx.io&quot;</span></span><br><span class="line">port = <span class="number">1883</span></span><br><span class="line">topic = <span class="string">&quot;paho/mqtt/test&quot;</span></span><br><span class="line">client_id = <span class="string">f&quot;client_<span class="subst">&#123;random.randint(<span class="number">0</span>, <span class="number">1000</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">connect_mqtt</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_connect</span>(<span class="params">client, userdata, flags, reason_code, properties</span>):</span><br><span class="line">        <span class="keyword">if</span> reason_code == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Connected to MQTT Broker!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Failed to connect, return code %d\n&quot;</span>, reason_code)</span><br><span class="line">    client = mqtt_client.Client(client_id=client_id, callback_api_version=mqtt_client.CallbackAPIVersion.VERSION2)</span><br><span class="line"></span><br><span class="line">    client.on_connect = on_connect</span><br><span class="line">    client.connect(broker, port)</span><br><span class="line">    <span class="keyword">return</span> client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">publish</span>(<span class="params">client</span>):</span><br><span class="line">    msg_count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        msg = <span class="string">f&quot;messages: test <span class="subst">&#123;msg_count&#125;</span>&quot;</span></span><br><span class="line">        result = client.publish(topic, msg)</span><br><span class="line">        status = result[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> status == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Send `<span class="subst">&#123;msg&#125;</span>` to topic `<span class="subst">&#123;topic&#125;</span>`&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Failed to send message to topic <span class="subst">&#123;topic&#125;</span>&quot;</span>)</span><br><span class="line">        msg_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> msg_count &gt; <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    client = connect_mqtt()</span><br><span class="line">    client.loop_start()</span><br><span class="line">    publish(client)</span><br><span class="line">    client.loop_stop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="client2-py"><a href="#client2-py" class="headerlink" title="client2.py"></a>client2.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> paho.mqtt <span class="keyword">import</span> client <span class="keyword">as</span> mqtt_client</span><br><span class="line"></span><br><span class="line">broker = <span class="string">&quot;broker.emqx.io&quot;</span></span><br><span class="line">port = <span class="number">1883</span></span><br><span class="line">topic = <span class="string">&quot;paho/mqtt/test&quot;</span></span><br><span class="line">client_id = <span class="string">f&quot;client_<span class="subst">&#123;random.randint(<span class="number">0</span>, <span class="number">1000</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">connect_mqtt</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_connect</span>(<span class="params">client, userdata, flags, reason_code, properties</span>):</span><br><span class="line">        <span class="keyword">if</span> reason_code == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Connected to MQTT Broker!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Failed to connect, return code %d\n&quot;</span>, reason_code)</span><br><span class="line">    client = mqtt_client.Client(client_id=client_id, callback_api_version=mqtt_client.CallbackAPIVersion.VERSION2)</span><br><span class="line"></span><br><span class="line">    client.on_connect = on_connect</span><br><span class="line">    client.connect(broker, port)</span><br><span class="line">    <span class="keyword">return</span> client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">subscribe</span>(<span class="params">client: mqtt_client</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_message</span>(<span class="params">client, userdata, msg</span>):</span><br><span class="line">        <span class="built_in">print</span>(msg)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Received `<span class="subst">&#123;msg.payload.decode()&#125;</span>` which sent by `<span class="subst">&#123;client._client_id&#125;</span>` from `<span class="subst">&#123;msg.topic&#125;</span>` topic&quot;</span>)</span><br><span class="line"></span><br><span class="line">    client.subscribe(topic)</span><br><span class="line">    client.on_message = on_message</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    client = connect_mqtt()</span><br><span class="line">    subscribe(client)</span><br><span class="line">    client.loop_forever()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure><p>That’s it! You can now use the <code>Paho MQTT Client</code> library to build MQTT applications in Python3.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The &lt;code&gt;Paho MQTT client&lt;/code&gt; library for Python is a popular choice for building MQTT applications in Python. Here’s how to use it i</summary>
      
    
    
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="MQTT" scheme="https://stonefishy.github.io/tags/MQTT/"/>
    
    <category term="IoT" scheme="https://stonefishy.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>The Ultimate MQTT Client Tool - MQTTX</title>
    <link href="https://stonefishy.github.io/2024/12/31/the-ultimate-mqtt-client-tool-mqttx/"/>
    <id>https://stonefishy.github.io/2024/12/31/the-ultimate-mqtt-client-tool-mqttx/</id>
    <published>2024-12-31T14:42:10.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>In the world of <code>IoT (Internet of Things)</code>, <code>MQTT (Message Queuing Telemetry Transport)</code> is a popular lightweight messaging protocol that ensures efficient communication between devices, servers, and clients. MQTT is favored for its low-bandwidth requirements and its ability to work in low network environments. However, testing and debugging MQTT-based applications can be challenging without the right tools.</p><p>Today we’re talking about one such tool called <code>MQTTX</code>. MQTTX is a cross platform, open-source MQTT client tool that provides a user-friendly interface for testing and debugging MQTT-based applications. It supports multiple MQTT brokers, including EMQX, Mosquitto, HiveMQ, and others, and provides a range of features such as message history, message filtering, and more. It is available for multiple platforms, including <code>Windows</code>, <code>macOS</code>, and <code>Linux</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-tool.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-tool.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTTX tool" style="width:800px;"/></div><span class="image-caption">MQTTX tool</span></div><p>MQTTX supports all versions of the MQTT protocol, from MQTT 3.1.1 to MQTT 5.0, which makes it suitable for a wide range of use cases, from simple applications to advanced IoT systems.</p><h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><p>Let’s using MQTTX to test and debug an MQTT-based application. We’ll use the <code>EMQX</code> MQTT broker for this example. And here we using Web version of MQTTX. The web client is <a href="https://mqttx.app/web-client">https://mqttx.app/web-client</a>.</p><p>The public <code>EMQX</code> server information is as follows:</p><blockquote><p><strong>Server</strong>: broker.emqx.io</p><p><strong>TCP Port</strong>: 1883</p><p><strong>WebSocket Port</strong>: 8083</p><p><strong>SSL&#x2F;TLS Port</strong>: 8883</p><p><strong>Secure WebSocket Port</strong>: 8084</p></blockquote><h3 id="Create-a-New-Connection"><a href="#Create-a-New-Connection" class="headerlink" title="Create a New Connection"></a>Create a New Connection</h3><p>Open web client of MQTTX and click on the <code>+</code> button on the top-left corner to create a new connection.  Naming the connection as ‘cloudserver’, and keep to using <code>EMQX</code> as the broker.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-create-connection.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-create-connection.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create a new connection" style="width:800px;"/></div><span class="image-caption">Create a new connection</span></div><h3 id="Subscribe-to-a-Topic"><a href="#Subscribe-to-a-Topic" class="headerlink" title="Subscribe to a Topic"></a>Subscribe to a Topic</h3><p>Once the connection is established, we can subscribe to a topic by clicking on the <code>New Subscription</code> button. Let’s subscribe to the topic <code>test/temperature</code>. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-subscribe-topic.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-subscribe-topic.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create a subscription to a topic" style="width:800px;"/></div><span class="image-caption">Create a subscription to a topic</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-subscribe-topic2.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-subscribe-topic2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Subscribe to a topic" style="width:800px;"/></div><span class="image-caption">Subscribe to a topic</span></div><h3 id="Create-two-new-clients"><a href="#Create-two-new-clients" class="headerlink" title="Create two new clients"></a>Create two new clients</h3><p>Now, let’s create two new clients connection, naming as <code>sensor1</code> and <code>sensor2</code>. Both clients will subscribe to the same topic <code>test/resp</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-create-clients.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-create-clients.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create new clients" style="width:800px;"/></div><span class="image-caption">Create new clients</span></div><h3 id="Publish-a-Message"><a href="#Publish-a-Message" class="headerlink" title="Publish a Message"></a>Publish a Message</h3><p>Let’s publish a message which using JSON format from <code>sensor1</code> to the topic <code>test/temperature</code>. And we can see the message is received by <code>sensor1</code>.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Topic: </span><br><span class="line">test/temperature</span><br><span class="line"></span><br><span class="line">Message:</span><br><span class="line">&#123;&quot;id&quot;: &quot;sensor1&quot;, &quot;value&quot;: &quot;2&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-publish-message.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-publish-message.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Publish a message" style="width:800px;"/></div><span class="image-caption">Publish a message</span></div><p>We can see the ‘cloudserver’ client which subscribed the topic <code>test/temperature</code> received the message.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-message-received.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-message-received.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Message received" style="width:800px;"/></div><span class="image-caption">Message received</span></div><p>In ‘cloudserver’ client, we also can send the message to the topic <code>test/resp</code>. Then both <code>sensor1</code> and <code>sensor2</code> will receive the message.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Topic:</span><br><span class="line">test/resp</span><br><span class="line"></span><br><span class="line">Message:</span><br><span class="line">&#123;&quot;id&quot;: &quot;cloudserver&quot;, &quot;value&quot;: &quot;100&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-publish-message2.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-publish-message2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Publish a message to a topic" style="width:800px;"/></div><span class="image-caption">Publish a message to a topic</span></div><h3 id="Topic-with-Wildcard"><a href="#Topic-with-Wildcard" class="headerlink" title="Topic with Wildcard"></a>Topic with Wildcard</h3><p>The MQTT protocol forwards messages based on the topic. Topics are hierarchical by <code>/</code>, similar to URL paths, for example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chat/room/1</span><br><span class="line"></span><br><span class="line">sensor/10/temperature</span><br><span class="line"></span><br><span class="line">sensor/+/temperature</span><br></pre></td></tr></table></figure><p>MQTT topics support two wildcards: <code>+</code> and <code>#</code>.</p><p><strong>+</strong>: Represents a single-layer wildcard, such as A&#x2F;+ matching A&#x2F;X or A&#x2F;Y.<br><strong>#</strong>: Represents a multi-layered wildcard, e.g. A&#x2F;# matches A&#x2F;X, A&#x2F;B&#x2F;C&#x2F;D.</p><blockquote><p>Note: Wildcard topics can only be used for subscriptions, not for publishing.</p></blockquote><p>Let’s update the subscription of <code>cloudserver</code> client to subscribe to the topic <code>test/+/temperature</code>. This will match all topics that start with <code>test/</code> and end with <code>temperature</code>. And using <code>sensor1</code> client to publish a message to the topic <code>test/1/temperature</code>, <code>sensor2</code> client to publish a message to the topic <code>test/2/temperature</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-subscribe-topic3.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-subscribe-topic3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Subscribe to a topic with wildcard" style="width:800px;"/></div><span class="image-caption">Subscribe to a topic with wildcard</span></div><p>As you can see the <code>cloudserver</code> client received both messages.</p><p>The MQTTX tool provides QoS, message retained and more features for testing and debugging MQTT-based applications. You can test and debug your MQTT-based applications using MQTTX.</p><h2 id="Client-Version"><a href="#Client-Version" class="headerlink" title="Client Version"></a>Client Version</h2><p>The MQTTX tool client version includes more features such as topic tree visualization.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-topic-tree.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-topic-tree.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Topic tree visualization" style="width:800px;"/></div><span class="image-caption">Topic tree visualization</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>MQTTX is a powerful and user-friendly MQTT client tool that provides a range of features for testing and debugging MQTT-based applications. It supports multiple MQTT brokers, including EMQX, Mosquitto, HiveMQ, and others, and provides a cross-platform client for Windows, macOS, and Linux.   </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the world of &lt;code&gt;IoT (Internet of Things)&lt;/code&gt;, &lt;code&gt;MQTT (Message Queuing Telemetry Transport)&lt;/code&gt; is a popular lightweight m</summary>
      
    
    
    
    <category term="Tools" scheme="https://stonefishy.github.io/categories/Tools/"/>
    
    
    <category term="MQTT" scheme="https://stonefishy.github.io/tags/MQTT/"/>
    
    <category term="IoT" scheme="https://stonefishy.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>浅谈物联网IoT中常见的消息传输协议MQTT</title>
    <link href="https://stonefishy.github.io/2024/12/30/what-is-mqtt-and-how-it-works/"/>
    <id>https://stonefishy.github.io/2024/12/30/what-is-mqtt-and-how-it-works/</id>
    <published>2024-12-30T15:02:06.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是MQTT？"><a href="#什么是MQTT？" class="headerlink" title="什么是MQTT？"></a>什么是MQTT？</h2><p><code>MQTT （Message Queuing Telemetry Transport, 消息队列遥测传输协议）</code>是一种基于<code>发布/订阅（Publish/Subscribe）</code>模式的轻量级消息传输协议，最初由IBM在1999年开发，主要用于<code>低带宽</code>、<code>不稳定网络环境</code>下的设备通信。MQTT协议设计简单，占用资源少，适合在资源受限的嵌入式设备上运行。</p><p>MQTT的核心思想是将消息的发送者（发布者）和接收者（订阅者）解耦，通过一个中间代理（Broker）来传递消息。发布者将消息发送到特定的主题（Topic），订阅者则订阅感兴趣的主题，从而接收相关消息。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-diagram.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-diagram.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT (Message Queuing Telemetry Transport)"/></div><span class="image-caption">MQTT (Message Queuing Telemetry Transport)</span></div><h2 id="MQTT的应用场景"><a href="#MQTT的应用场景" class="headerlink" title="MQTT的应用场景"></a>MQTT的应用场景</h2><p><code>MQTT</code>广泛应用于IoT(Internet of Things, 物联网)领域，主要用于物联网、移动互联网、智能家居、工业自动化等领域。以下是一些典型的应用场景：</p><ol><li><p>物联网（IoT）<br>在物联网中，设备通常分布在不同的地理位置，且网络条件可能不稳定。MQTT的低带宽消耗和可靠性使其成为连接这些设备的理想选择。例如，传感器可以通过MQTT将数据发送到云端，供其他设备或应用程序使用。</p></li><li><p>智能家居<br>在智能家居系统中，各种设备（如灯光、温控器、安防系统等）需要相互通信。MQTT可以帮助这些设备高效地交换信息，实现自动化控制。</p></li><li><p>工业自动化<br>在工业自动化领域，MQTT可以用于监控和控制生产线上的设备。通过MQTT，工厂可以实时获取设备状态，进行远程控制和故障诊断。</p></li><li><p>移动应用<br>在移动应用中，MQTT可以用于推送通知、实时消息传递等场景。由于MQTT协议轻量且高效，非常适合在移动设备上使用。</p></li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-example.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-example.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Example"/></div><span class="image-caption">MQTT Example</span></div><h2 id="MQTT的工作原理"><a href="#MQTT的工作原理" class="headerlink" title="MQTT的工作原理"></a>MQTT的工作原理</h2><p>MQTT协议基于发布&#x2F;订阅模式，其核心组件包括以下三个：</p><p><strong>发布者（Publisher）</strong>：负责将消息发送到特定的主题Topic。<br><strong>订阅者（Subscriber）</strong>：订阅感兴趣的主题，接收相关消息。<br><strong>代理（Broker）</strong>：负责接收发布者的消息，并将其转发给订阅者。</p><h4 id="主题（Topic）"><a href="#主题（Topic）" class="headerlink" title="主题（Topic）"></a>主题（Topic）</h4><p>主题是MQTT中消息的分类标识符，采用<code>分层结构</code>。例如，home&#x2F;livingroom&#x2F;temperature 表示“客厅温度”主题。发布者将消息发送到特定主题，订阅者则通过订阅主题来接收消息。</p><h4 id="服务质量（QoS）"><a href="#服务质量（QoS）" class="headerlink" title="服务质量（QoS）"></a>服务质量（QoS）</h4><p>MQTT支持三种服务质量级别，用于控制消息传递的可靠性：</p><p><strong>QoS 0</strong>：最多一次传递。消息可能会丢失，但不会重复。<br><strong>QoS 1</strong>：至少一次传递。消息不会丢失，但可能会重复。<br><strong>QoS 2</strong>：恰好一次传递。消息既不会丢失，也不会重复。</p><h4 id="持久会话（Persistent-Session）"><a href="#持久会话（Persistent-Session）" class="headerlink" title="持久会话（Persistent Session）"></a>持久会话（Persistent Session）</h4><p>MQTT支持持久会话，允许客户端在断开连接后重新连接时，继续接收未处理的消息。这对于不稳定的网络环境非常有用。</p><h2 id="MQTT的工作流程"><a href="#MQTT的工作流程" class="headerlink" title="MQTT的工作流程"></a>MQTT的工作流程</h2><p>MQTT的工作流程可以分为以下几个步骤：</p><ol><li><p>连接代理<br>客户端(Client)（发布者或订阅者）首先与MQTT代理(Broker)建立连接。连接时，客户端需要提供客户端ID、用户名、密码等信息。</p></li><li><p>订阅主题<br>订阅者向代理发送订阅请求，指定感兴趣的主题。代理会记录订阅者的订阅信息。</p></li><li><p>发布消息<br>发布者将消息发送到特定主题。代理接收到消息后，会根据主题将消息转发给所有订阅该主题的订阅者。</p></li><li><p>接收消息<br>订阅者从代理接收消息，并根据需要进行处理。</p></li><li><p>断开连接<br>客户端可以主动断开与代理的连接，或者由于网络问题导致连接断开。如果启用了持久会话，客户端重新连接后可以继续接收未处理的消息。</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>MQTT</code>作为一种轻量级、高效的通信协议，在物联网、智能家居、工业自动化等领域有着广泛的应用。其基于发布&#x2F;订阅模式的设计，使得设备之间的通信更加灵活和高效。通过理解MQTT的工作原理和工作流程，开发者可以更好地利用这一协议，构建稳定、可靠的物联网系统。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是MQTT？&quot;&gt;&lt;a href=&quot;#什么是MQTT？&quot; class=&quot;headerlink&quot; title=&quot;什么是MQTT？&quot;&gt;&lt;/a&gt;什么是MQTT？&lt;/h2&gt;&lt;p&gt;&lt;code&gt;MQTT （Message Queuing Telemetry Transpor</summary>
      
    
    
    
    <category term="中间件" scheme="https://stonefishy.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="MQTT" scheme="https://stonefishy.github.io/tags/MQTT/"/>
    
    <category term="IoT" scheme="https://stonefishy.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>Sentry: The Developer’s Best Friend for Error Tracking and Performance Monitoring</title>
    <link href="https://stonefishy.github.io/2024/12/19/sentry-the-developer-s-best-friend-for-error-tracking-and-performance-monitoring/"/>
    <id>https://stonefishy.github.io/2024/12/19/sentry-the-developer-s-best-friend-for-error-tracking-and-performance-monitoring/</id>
    <published>2024-12-19T14:31:21.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/sentry.png" class="lazyload placeholder" data-srcset="/assets/images/tools/sentry.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Sentry"/></div><span class="image-caption">Sentry</span></div><p>As developers, we know how frustrating it can be to track down bugs and performance issues, especially when they slip through the cracks and impact end-users. Fortunately, <code>Sentry</code> is here to help you take control of your application’s stability and performance, offering a comprehensive solution for error tracking and performance monitoring.</p><p>In this post, we’ll dive into what Sentry is, how it works, and why it should be a key part of your development workflow.</p><h2 id="What-is-Sentry"><a href="#What-is-Sentry" class="headerlink" title="What is Sentry?"></a>What is Sentry?</h2><p><code>Sentry</code> is an <code>open-source</code> <code>error tracking</code> and <code>performance monitoring</code> tool that helps you find and fix issues in your applications—whether they’re web-based, mobile, or server-side. It captures errors in real-time, giving you deep insights into what went wrong, where it happened, and what might be causing it. Whether you’re building an app with React, Django, or even a mobile app, Sentry works across a wide variety of languages and platforms.</p><h2 id="Why-Should-Developers-Use-Sentry"><a href="#Why-Should-Developers-Use-Sentry" class="headerlink" title="Why Should Developers Use Sentry?"></a>Why Should Developers Use Sentry?</h2><ol><li><p>Track Errors in Real-Time<br>No one likes finding out about an issue after a user complains. Sentry sends real-time error alerts straight to your team—whether it’s through email, Slack, or other channels—so you can address problems as they arise. And with detailed stack traces and contextual information, you’re not left guessing about where or why the issue happened.</p></li><li><p>Monitor Performance Issues<br>Sentry isn’t just for catching errors; it also provides powerful performance monitoring. From slow page loads to database bottlenecks, Sentry helps you track performance metrics and diagnose why your app might be lagging, allowing you to optimize performance proactively.</p></li><li><p>Understand Context Around Errors<br>When an error happens, Sentry doesn’t just provide a stack trace. It enriches the error data with contextual information like user actions, environment (production vs. staging), browser version, and the specific code version that caused the issue. This context allows you to fix issues faster because you get a better sense of what happened right before the error occurred.</p></li><li><p>Release Tracking<br>Have you ever deployed a new release, only to realize later that it introduced a bug? Sentry connects errors to specific releases, so you can quickly figure out which version of your app caused the problem. Plus, you can monitor the health of each release, so you know when it’s time to roll back or fix issues.</p></li></ol><h2 id="Core-Features-You’ll-Love"><a href="#Core-Features-You’ll-Love" class="headerlink" title="Core Features You’ll Love"></a>Core Features You’ll Love</h2><ol><li><p>Error Aggregation<br>Sentry aggregates errors that are similar or identical, helping you prioritize the most critical issues without being overwhelmed by duplicates. This makes it easier to focus on the errors that matter.</p></li><li><p>Customizable Alerts &amp; Notifications<br>You can set custom thresholds for error severity or the frequency of an error before triggering an alert. This ensures you’re not flooded with notifications for every minor issue but are still on top of critical bugs.</p></li><li><p>Issue Resolution Workflow<br>With issue tracking integration (e.g., JIRA, GitHub), you can automatically assign issues to team members and track their resolution status without leaving your existing tools. This helps streamline your workflow and ensures bugs don’t fall through the cracks.</p></li><li><p>Contextual Information<br>The error reports include all the context you need to solve a bug, like the user’s device info, the environment it happened in, stack traces, request URLs, and even relevant logs. This reduces the time it takes to identify and fix problems.</p></li><li><p>Performance Monitoring<br>With Sentry’s performance monitoring, you can trace the performance of specific transactions across your app. This helps pinpoint slow database queries, inefficient API calls, and anything else that might be affecting performance.</p></li><li><p>Wide Integration Support<br>Sentry integrates with many of the tools you already use, such as <code>GitHub</code>, <code>GitLab</code>, <code>Slack</code>, <code>JIRA</code>, <code>Trello</code>, and more. This makes it simple to plug Sentry into your existing workflow and ensure your development process is smooth.</p></li></ol><h2 id="How-Does-Sentry-Work"><a href="#How-Does-Sentry-Work" class="headerlink" title="How Does Sentry Work?"></a>How Does Sentry Work?</h2><p>Integrating Sentry is simple and quick, and once you set it up, it works seamlessly behind the scenes. Here’s a high-level look at how it works:</p><ol><li><p>Error Detection:<br>Sentry works by using SDKs specific to your tech stack. Once integrated, it automatically detects unhandled errors in your application.</p></li><li><p>Context Collection:</p><span class='pbg danger'>When an error is captured</span></li><li><p>Error Aggregation &amp; Notifications:<br>The error is aggregated and displayed on your Sentry dashboard. If you’ve set up notifications, your team will be alerted in real-time via Slack, email, or any other supported channel.</p></li><li><p>Resolution &amp; Feedback:<br>Once a developer resolves an issue, Sentry marks it as resolved. If the issue reoccurs, Sentry notifies you again, keeping you in the loop.</p></li></ol><h2 id="How-to-Get-Started-with-Sentry"><a href="#How-to-Get-Started-with-Sentry" class="headerlink" title="How to Get Started with Sentry"></a>How to Get Started with Sentry</h2><ol><li><p>Create an Account<br>Go to Sentry’s website and sign up for a free account. You’ll be guided through the setup process, and you can create a new project for your app. Accessing <a href="https://sentry.io/">https://sentry.io</a> to create your own account.</p></li><li><p>Install the SDK<br>Depending on the tech stack you’re using, you’ll need to install the appropriate SDK. For example:</p></li></ol><p>In React Application:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install @sentry/react</span><br></pre></td></tr></table></figure><p>Then, initialize Sentry in your app:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&quot;react&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">ReactDOM</span> <span class="keyword">from</span> <span class="string">&quot;react-dom&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> <span class="title class_">Sentry</span> <span class="keyword">from</span> <span class="string">&quot;@sentry/react&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">App</span> <span class="keyword">from</span> <span class="string">&quot;./App&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="title class_">Sentry</span>.<span class="title function_">init</span>(&#123;</span><br><span class="line">  <span class="attr">dsn</span>: <span class="string">&quot;https://&lt;key&gt;@sentry.io/&lt;project&gt;&quot;</span>,</span><br><span class="line">  <span class="comment">// This enables automatic instrumentation (highly recommended)</span></span><br><span class="line">  <span class="comment">// If you only want to use custom instrumentation:</span></span><br><span class="line">  <span class="comment">// * Remove the BrowserTracing integration</span></span><br><span class="line">  <span class="comment">// * add Sentry.addTracingExtensions() above your Sentry.init() call</span></span><br><span class="line">  <span class="attr">integrations</span>: [</span><br><span class="line">    <span class="title class_">Sentry</span>.<span class="title function_">browserTracingIntegration</span>(),</span><br><span class="line">    <span class="comment">// Or, if you are using react router, use the appropriate integration</span></span><br><span class="line">    <span class="comment">// See docs for support for different versions of react router</span></span><br><span class="line">    <span class="comment">// https://docs.sentry.io/platforms/javascript/guides/react/configuration/integrations/react-router/</span></span><br><span class="line">    <span class="title class_">Sentry</span>.<span class="title function_">reactRouterV6BrowserTracingIntegration</span>(&#123;</span><br><span class="line">      <span class="attr">useEffect</span>: <span class="title class_">React</span>.<span class="property">useEffect</span>,</span><br><span class="line">      useLocation,</span><br><span class="line">      useNavigationType,</span><br><span class="line">      createRoutesFromChildren,</span><br><span class="line">      matchRoutes,</span><br><span class="line">    &#125;),</span><br><span class="line">  ],</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For finer control of sent transactions you can adjust this value, or</span></span><br><span class="line">  <span class="comment">// use tracesSampler</span></span><br><span class="line">  <span class="attr">tracesSampleRate</span>: <span class="number">1.0</span>,</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Set tracePropagationTargets to control for which URLs distributed tracing should be enabled</span></span><br><span class="line">  <span class="attr">tracePropagationTargets</span>: [<span class="string">&#x27;localhost&#x27;</span>, <span class="regexp">/^https:/</span><span class="regexp">/yourserver.io/</span>api/],</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="title class_">ReactDOM</span>.<span class="title function_">render</span>(<span class="language-xml"><span class="tag">&lt;<span class="name">App</span> /&gt;</span></span>, <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&quot;root&quot;</span>));</span><br></pre></td></tr></table></figure><p>Sentry SDK supports multiple languages and frameworks, including React, Angular, Vue, .NET, Go, Python, SpringBoot, Next.js and more.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/sentry-sdks.png" class="lazyload placeholder" data-srcset="/assets/images/tools/sentry-sdks.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Sentry SDK Integrations"/></div><span class="image-caption">Sentry SDK Integrations</span></div><ol start="3"><li><p>Integrate Error &amp; Performance Monitoring<br>Sentry works out of the box for most errors, but you can also use it to track performance. You can instrument specific parts of your code to track performance issues, like database queries or API calls.</p></li><li><p>Configure Notifications<br>Set up notification channels (e.g., <code>Slack</code>, <code>email</code>) so your team is alerted whenever a critical error occurs. Customize the rules to avoid spamming you with minor issues.</p></li><li><p>Monitor in the Dashboard<br>Once the integration is complete, you’ll start seeing error logs, performance metrics, and more on your Sentry dashboard. You can drill down into individual issues, see affected users, and get all the data you need to fix the bug fast.</p></li></ol><h2 id="Benefits-of-Using-Sentry-for-Developers"><a href="#Benefits-of-Using-Sentry-for-Developers" class="headerlink" title="Benefits of Using Sentry for Developers"></a>Benefits of Using Sentry for Developers</h2><ol><li><p>Faster Debugging:<br>With all the contextual data Sentry provides, debugging becomes faster. No more chasing elusive bugs—get right to the root cause.</p></li><li><p>Proactive Monitoring:<br>Monitor both errors and performance, which helps you prevent issues before they affect users. Sentry gives you the insights to optimize performance and fix bugs early.</p></li><li><p>Increased Collaboration:<br>Integrated workflows with tools like GitHub, JIRA, and Slack mean you and your team can stay on the same page, and bugs can be tracked, assigned, and resolved efficiently.</p></li><li><p>Free Tier Available:<br>Sentry offers a free plan with generous limits, so you can get started without any upfront costs. As your project grows, you can scale to a paid plan with more features.</p></li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Sentry is an invaluable tool for developers, offering real-time error tracking and powerful performance monitoring. By integrating Sentry into your workflow, you can catch and resolve errors faster, improve your app’s performance, and provide a better experience for your users.</p><p>So if you’re looking to streamline your debugging process, improve performance monitoring, and keep your app healthy, you can try sentry in your application!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/tools/sentry.png&quot; class=&quot;lazyload placeh</summary>
      
    
    
    
    <category term="Tools" scheme="https://stonefishy.github.io/categories/Tools/"/>
    
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Sentry" scheme="https://stonefishy.github.io/tags/Sentry/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to LangChain: Make AI Smarter and Easier to use</title>
    <link href="https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/"/>
    <id>https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/</id>
    <published>2024-11-12T13:49:12.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-image.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-image.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:600px;"/></div></div><p>Have you ever wondered how some apps and websites can have conversations with you, answer your questions? Many of these apps use <code>artificial intelligence (AI)</code>, like the chatbot you might use to ask questions or get advice. But creating these smart systems can be tricky. This is where a tool called <code>LangChain</code> comes in to help!</p><p><code>LangChain</code> is a framework that makes it easier for developers to build applications that use <code>AI models</code>, like chatbots or smart helpers. In this blog, we’re going to explain what LangChain is, how it works, and why it’s useful for making AI apps.</p><h2 id="What-is-LangChain"><a href="#What-is-LangChain" class="headerlink" title="What is LangChain?"></a>What is LangChain?</h2><p>LangChain is a tool for developers that helps them build applications using <code>large language models (LLMs)</code>—the same kind of AI that powers chatbots, writing assistants, and more. LLMs can understand and generate text in a way that sounds like a real person. However, using these models to make powerful apps can be complicated. LangChain makes it easier by offering ready-made building blocks to connect these models to other tools, data, and even databases.</p><p>Think of LangChain like a set of Lego blocks that you can use to build cool things with AI. It saves developers time by giving them ready-made pieces to use, rather than having to create everything from scratch.</p><h2 id="Features-of-LangChain"><a href="#Features-of-LangChain" class="headerlink" title="Features of LangChain"></a>Features of LangChain</h2><p>Let’s break down some of the cool features LangChain offers and how they help developers make smarter apps.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-features.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-features.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="LangChain Features"/></div><span class="image-caption">LangChain Features</span></div><ol><li><p><strong>Chains</strong>: Putting Multiple Steps Together<br>Imagine you have a robot that can help with math homework. The robot might need to do multiple things to solve a problem. First, it could look up the math formula, then solve the problem, and finally explain the answer. In LangChain, these steps are called chains.</p><blockquote><p>A chain is a sequence of actions where each step depends on the previous one. For example, you could create a chain where:</p><p>First, the app asks the AI to pull data from a website.<br>Then, it uses that data to answer a question.<br>Finally, it summarizes the answer for the user.</p></blockquote></li><li><p><strong>Prompt Management</strong>: Talking to AI the Right Way<br>When you talk to an AI, how you ask your question or give your instruction is really important. That’s called a prompt. LangChain helps developers make the best prompts by letting them create templates. These templates let developers easily change certain parts of the prompt without having to rewrite it every time.</p><blockquote><p>For example, if you wanted to ask the AI to summarize a story, you could have a prompt like this:</p><p>“Please summarize the following story: {story}”</p><p>In this template, {story} is a placeholder that can be replaced with any story you want the AI to summarize.</p></blockquote></li><li><p><strong>Agents</strong>: Letting AI Decide What to Do Next<br>Sometimes, a smart system needs to decide what to do next based on the information it gets. For example, if you ask an AI about the weather, it might decide to pull the latest weather data from the internet. This decision-making is done by agents.</p><blockquote><p>An agent is like a helper that looks at the information it gets and chooses the best action. LangChain helps developers build agents that can make these decisions automatically.</p></blockquote></li><li><p><strong>Memory</strong>: Remembering What Happened Before<br>Have you ever talked to a chatbot and then later felt like it forgot what you said earlier? That can make a conversation feel weird. <code>LangChain helps solve this problem by letting the AI remember what was said earlier in the conversation</code>. This feature is called memory.</p><blockquote><p>or example, if you ask a chatbot for homework help and then ask a follow-up question, LangChain can help the AI remember the first question and give a more useful answer based on that memory.</p></blockquote></li><li><p><strong>Integrations</strong>: Connecting to Other Tools and Websites<br>Sometimes, an AI app needs to talk to other systems to get more information. <span class='pbg success'>LangChain makes this easy by letting developers connect their AI app to other tools</span> This is like having a personal assistant that not only talks to you but also has access to tons of information online.</p><blockquote><p>For example, an AI app could pull up the latest sports scores, or check the weather for you, using real-time data from the internet.</p></blockquote></li><li><p><strong>Retrieval-Augmented Generation (RAG)</strong>: Getting Smarter Answers<br>LangChain also lets AI search for information in real-time. This is called retrieval-augmented generation (RAG). It allows the AI to look up the latest data, like news stories or facts, and use that information to create smarter answers.</p><blockquote><p>For example, if you ask about the latest trends in video games, the AI can search the web for the most up-to-date information and then explain it to you.</p></blockquote></li></ol><h2 id="Why-Do-Developers-Use-LangChain"><a href="#Why-Do-Developers-Use-LangChain" class="headerlink" title="Why Do Developers Use LangChain?"></a>Why Do Developers Use LangChain?</h2><p>There are several reasons why developers might want to use LangChain:</p><ol><li><p>Makes It Easier to Build AI Apps<br>Instead of starting from scratch, LangChain gives developers tools that speed up the process of creating AI apps. Developers can use LangChain’s building blocks to create powerful applications without needing to write everything by hand.</p></li><li><p>It’s Flexible<br>LangChain can be used for a wide variety of apps. Whether you want to build a chatbot, a smart search engine, or an app that helps you study, LangChain has tools that make it easier to put everything together.</p></li><li><p>Saves Time<br>Developers don’t have to spend a lot of time figuring out how to make an AI model work with a database or how to chain steps together. LangChain does much of the heavy lifting, so developers can focus on the fun and creative parts of building their apps.</p></li><li><p>It’s <code>Open-Source</code><br>LangChain is free for anyone to use and improve. It’s open-source, which means developers from all over the world can contribute to making it better. If you’re learning to code or want to help improve the tool, you can!</p></li></ol><h2 id="Real-World-Examples-of-LangChain"><a href="#Real-World-Examples-of-LangChain" class="headerlink" title="Real-World Examples of LangChain"></a>Real-World Examples of LangChain</h2><p>LangChain is already being used in many cool ways. Here are a few examples:</p><ol><li><p>Chatbots<br>Developers can use LangChain to build chatbots that remember previous conversations and can talk to you like a real person. For example, you could create a chatbot to help you study for a test, and it would remember what you’ve learned so far.</p></li><li><p>Smart Assistants<br>LangChain can help build systems that pull information from the internet and use AI to explain things in simple terms. For example, if you’re stuck on a science problem, an AI could look up the topic online and explain it to you in a way you understand.</p></li><li><p>Automated Content Creation<br>Some apps use LangChain to automatically write articles or summaries. For example, a news website could use LangChain to summarize long articles or pull out the key points from reports, saving readers time.</p></li><li><p>Personalized Search Engines<br>LangChain can be used to build search engines that don’t just give you a list of links but also summarize the best results for you. This could help you find the exact answer you need faster.</p></li></ol><h2 id="How-to-Get-Started-with-LangChain"><a href="#How-to-Get-Started-with-LangChain" class="headerlink" title="How to Get Started with LangChain"></a>How to Get Started with LangChain</h2><p>If you’re excited to try out LangChain, here’s how you can get started:</p><ol><li>Install Python: LangChain works with Python, a programming language that’s great for beginners.</li><li>Install LangChain: You can install LangChain by running the command <code>pip install langchain</code> in Python.</li><li>Start Building: Once LangChain is installed, you can start building your own AI-powered applications! LangChain has tutorials and guides to help you learn how to use it.</li></ol><p>For more information, check out the LangChain documentation at <a href="https://python.langchain.com/docs/introduction/">https://python.langchain.com/docs/introduction/</a></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>LangChain is a super helpful tool for developers who want to build cool apps powered by AI. It makes it easier to connect different parts of an app, like databases or the web, with a language model that can understand and generate text. Whether it’s helping with homework, answering questions, or building a chatbot, LangChain is a great way to build smarter, more interactive applications.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/langchain-image.png&quot; class=&quot;lazylo</summary>
      
    
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
  </entry>
  
  <entry>
    <title>What is Prompt Engineering? Best Practices and Examples</title>
    <link href="https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/"/>
    <id>https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/</id>
    <published>2024-11-05T14:08:09.000Z</published>
    <updated>2025-06-19T09:28:26.171Z</updated>
    
    <content type="html"><![CDATA[<p>As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophisticated, a new role has emerged in the AI ecosystem: <code>the Prompt Engineer</code>. The term might sound technical or niche, but it’s actually pivotal to leveraging AI models effectively. Whether you’re interacting with AI in your personal or professional life, the quality of the interaction largely depends on how well the prompt is designed. This article will explore what a prompt engineer does, the best practices for writing effective prompts, and provide examples comparing outputs with and without a prompt engineer’s expertise.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineering.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineering.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><h2 id="What-is-a-Prompt-Engineer"><a href="#What-is-a-Prompt-Engineer" class="headerlink" title="What is a Prompt Engineer?"></a>What is a Prompt Engineer?</h2><p><em>A Prompt Engineer is someone who specializes in crafting, refining, and optimizing prompts to ensure that AI models respond with the most relevant,accurate,and actionable information.</em> The role requires a blend of creativity, technical understanding, and knowledge of the AI’s underlying model architecture.</p><p>In essence, the prompt engineer’s job is to “speak” the language of the AI model. Since AI models like <code>GPT-3</code> or <code>GPT-4</code> don’t “think” like humans, their responses depend heavily on how the question or task is framed. A prompt engineer ensures that the right context, constraints, and phrasing are in place to guide the model toward producing the most useful responses.</p><h2 id="Why-is-Prompt-Engineering-Important"><a href="#Why-is-Prompt-Engineering-Important" class="headerlink" title="Why is Prompt Engineering Important?"></a>Why is Prompt Engineering Important?</h2><p>While AI models are capable of generating human-like text and performing complex tasks, their outputs are highly sensitive to the structure of the prompt. The same AI model could provide vastly different answers depending on the way a question is asked. Prompt engineers understand this sensitivity and use it to maximize the effectiveness of the interaction with AI.</p><p>Here are some reasons why prompt engineering is important:</p><p><strong>Maximizing output quality</strong>: Well-designed prompts improve the accuracy, relevance, and clarity of responses.<br><strong>Reducing errors</strong>: By properly framing a prompt, prompt engineers can help reduce misunderstandings or irrelevant responses.<br><strong>Efficiency</strong>: Instead of relying on trial and error to get useful responses, prompt engineers streamline the interaction process, saving time and resources.<br><strong>Contextuality</strong>: A good prompt will provide the necessary context for the model, ensuring that the response is in line with the user’s expectations.</p><h2 id="The-Path-of-a-Prompt-Engineer"><a href="#The-Path-of-a-Prompt-Engineer" class="headerlink" title="The Path of a Prompt Engineer"></a>The Path of a Prompt Engineer</h2><p>The process that a prompt engineer follows to ensure optimal results involves several stages. Each stage builds upon the last, leading to an iterative cycle that refines both the prompt and the AI’s output. Here’s a breakdown of the typical path of a prompt engineer:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineer-path.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineer-path.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="The Path of a Prompt Engineer" style="width:800px;"/></div><span class="image-caption">The Path of a Prompt Engineer</span></div><h3 id="1-Task-Understanding"><a href="#1-Task-Understanding" class="headerlink" title="1.Task Understanding:"></a>1.Task Understanding:</h3><p>Before crafting any prompt, the first step is to fully understand the task at hand. This involves clarifying the user’s goal, determining the desired output format, and understanding the nuances of the request. A deep understanding of the problem ensures that the prompt engineer can craft a question or instruction that addresses all necessary aspects.</p><blockquote><p>Example: If the task is to generate a poem, the prompt engineer will need to understand the tone, style, and subject matter required.</p></blockquote><h3 id="2-Crafting-Prompts"><a href="#2-Crafting-Prompts" class="headerlink" title="2.Crafting Prompts:"></a>2.Crafting Prompts:</h3><p>The next step is to craft the prompt. This involves framing the task clearly, with enough specificity to guide the AI toward the desired output. Crafting an effective prompt is not about asking a single question, but about <em>providing the model with the right context, constraints, and direction</em>.</p><blockquote><p>Example: Instead of asking, “Write a poem,” a more specific prompt might be, “Write a rhyming poem about the beauty of autumn, focusing on imagery and feelings of nostalgia.”</p></blockquote><h3 id="3-Prompt-Alignment"><a href="#3-Prompt-Alignment" class="headerlink" title="3.Prompt Alignment:"></a>3.Prompt Alignment:</h3><p>At this stage, the prompt must be aligned with the intended outcome. This means considering the AI model’s strengths and limitations and ensuring that the prompt leads the AI to produce a response that fits the desired format, tone, and depth. The prompt should ensure the model understands the context of the task, as well as any constraints or preferences that need to be respected.</p><blockquote><p>Example: For a technical article, aligning the prompt would involve ensuring the language model knows to prioritize clarity, accuracy, and technical precision.</p></blockquote><h3 id="4-Optimizing-Prompt"><a href="#4-Optimizing-Prompt" class="headerlink" title="4.Optimizing Prompt:"></a>4.Optimizing Prompt:</h3><p>After alignment, the prompt may need further refinement. This step involves fine-tuning the wording, simplifying complex instructions, or narrowing down the scope to ensure that the prompt is as effective as possible. <em>Optimization often involves making the prompt more specific and reducing ambiguity.</em></p><blockquote><p>Example: “Write a 300-word summary of the research paper on AI ethics, emphasizing the ethical dilemmas and implications for technology companies.” This version is more optimized than a broad, vague instruction.</p></blockquote><h3 id="5-AI-Model-Processing"><a href="#5-AI-Model-Processing" class="headerlink" title="5.AI Model Processing:"></a>5.AI Model Processing:</h3><p>Once the optimized prompt is provided, the AI model processes it and generates a response. This is where the model applies its underlying machine learning architecture, leveraging its training data to formulate a response.</p><blockquote><p>Example: The AI will analyze the prompt, consider patterns in its training data, and produce a response based on its understanding of the language and context.</p></blockquote><h3 id="6-Generating-Output"><a href="#6-Generating-Output" class="headerlink" title="6.Generating Output:"></a>6.Generating Output:</h3><p>The AI model generates the initial output based on the prompt. Depending on the AI model’s capabilities, this output may vary in length, style, accuracy, or even relevance to the task.</p><blockquote><p>Example: If the task was to summarize a paper, the output might include key findings, conclusions, and references to methodology.</p></blockquote><h3 id="7-Output-Refinement"><a href="#7-Output-Refinement" class="headerlink" title="7.Output Refinement:"></a>7.Output Refinement:</h3><p>Once the output is generated, prompt engineers review and refine it. This may involve removing irrelevant information, adjusting tone, adding details, or improving clarity. In some cases, the output might need to be restructured to fit the desired format.</p><blockquote><p>Example: If the AI’s response contains tangential information or lacks clarity, the prompt engineer would reword it or fine-tune the output to better align with the user’s expectations.</p></blockquote><h3 id="8-Iterative-Improvement"><a href="#8-Iterative-Improvement" class="headerlink" title="8.Iterative Improvement:"></a>8.Iterative Improvement:</h3><p>Finally, the process of prompt engineering is iterative. After refining the output, prompt engineers analyze the effectiveness of the response and assess how the prompt can be improved for future tasks. This leads to continuous improvement, ensuring that future prompts are even more optimized, concise, and aligned with user needs.</p><blockquote><p>Example: The engineer might adjust the prompt for the next interaction to ensure more relevant details or a more focused response.</p></blockquote><h2 id="Key-Skills-and-Tools-of-a-Prompt-Engineer"><a href="#Key-Skills-and-Tools-of-a-Prompt-Engineer" class="headerlink" title="Key Skills and Tools of a Prompt Engineer"></a>Key Skills and Tools of a Prompt Engineer</h2><p>Prompt engineering requires a variety of skills:</p><p><strong>Understanding of Language Models</strong>:<br>A prompt engineer should have a deep understanding of how LLMs like GPT process language. Knowing their strengths and weaknesses allows for better prompt design.</p><p><strong>Communication Skills</strong>:<br>Effective communication is critical, as prompt engineers must be able to convey complex instructions in a way that the model can interpret clearly.</p><p><strong>Creativity and Experimentation</strong>:<br>Crafting effective prompts often requires trial and error, testing different phrasings and structures to see what works best.</p><p><strong>Analytical Thinking</strong>:<br>Understanding how different types of inputs influence the model’s outputs and iterating to improve results.</p><p>In addition to these skills, prompt engineers also use tools to test and refine their prompts. For instance, platforms like OpenAI’s Playground allow users to experiment with various prompts in real-time, while more advanced professionals might leverage APIs to automate or scale their prompt engineering work.</p><h2 id="Best-Practices-for-Prompt-Engineering"><a href="#Best-Practices-for-Prompt-Engineering" class="headerlink" title="Best Practices for Prompt Engineering"></a>Best Practices for Prompt Engineering</h2><p>There are several strategies that a prompt engineer can employ to get the most out of a language model. Below are some of the best practices:</p><ol><li><p><strong>Be Specific and Clear</strong>: Ambiguous prompts can confuse AI models, leading to vague or incorrect responses. Make sure the prompt is clear and as specific as possible.</p><blockquote><p>Example: Instead of asking, “Tell me about AI,” a more specific prompt would be, “Can you explain the difference between supervised and unsupervised learning in AI?”</p></blockquote></li><li><p><strong>Use Context Effectively</strong>: Providing context can guide the model to better understand the desired output.</p><blockquote><p>Example: Instead of saying, “Write a poem,” say, “Write a rhyming poem about the beauty of autumn with a melancholic tone.”</p></blockquote></li><li><p><strong>Limit the Scope</strong>: Sometimes, less is more. Limit the scope of the prompt to avoid overwhelming the model with too much information or too many instructions.</p><blockquote><p>Example: Instead of “Write an article about the importance of artificial intelligence in modern business, covering all aspects of AI from machine learning to natural language processing,” you could say, “Write a short article explaining the importance of AI in customer service.”</p></blockquote></li><li><p><strong>Test and Iterate</strong>: A prompt engineer should test various iterations of a prompt to identify the most effective structure.</p></li><li><p><strong>Give Examples</strong>: For tasks requiring specific output formats, include an example to guide the model.</p><blockquote><p>Example: If you want a bulleted list, you could say, “List the steps in a process to build a website. For example: Step 1: Plan the layout.”</p></blockquote></li><li><p><strong>Use Temperature and Max Tokens</strong>: Some models allow you to adjust the <code>temperature (which controls randomness)</code> and the <code>max tokens (which sets a character limit)</code> to control the output. These can be adjusted to fine-tune the model’s output.</p></li></ol><h2 id="Comparing-with-and-without-Prompt-Engineering"><a href="#Comparing-with-and-without-Prompt-Engineering" class="headerlink" title="Comparing with and without Prompt Engineering"></a>Comparing with and without Prompt Engineering</h2><p>Now let’s look at some concrete examples of how a well-crafted prompt versus a poorly constructed one can affect the outcome.</p><h3 id="Example-1-Writing-a-Research-Summary"><a href="#Example-1-Writing-a-Research-Summary" class="headerlink" title="Example 1: Writing a Research Summary"></a>Example 1: Writing a Research Summary</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize this research paper.”</p><p>The AI may generate a generic or overly simplistic summary, without capturing the key aspects of the paper, such as methodology, results, and conclusions.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize the research paper titled ‘Exploring AI Ethics in Autonomous Vehicles.’ Focus on the methodology, key findings, and implications for policy. Keep the summary under 200 words.”</p><p>The AI’s response will be more targeted, concise, and aligned with the user’s expectations, providing a detailed summary that addresses the core aspects of the paper.</p><h3 id="Example-2-Writing-a-Creative-Story"><a href="#Example-2-Writing-a-Creative-Story" class="headerlink" title="Example 2: Writing a Creative Story"></a>Example 2: Writing a Creative Story</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a story.”</p><p>The story might lack direction, coherence, or creativity, leading to a generic or even nonsensical narrative.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a short story set in a post-apocalyptic world where humans are living on Mars. The protagonist is a scientist struggling with the ethical implications of using artificial intelligence to terraform the planet. Make the tone introspective and thought-provoking.”</p><p>The story produced will be richer, more engaging, and aligned with the specific context and themes the user wanted.</p><h3 id="Example-3-Asking-for-Code"><a href="#Example-3-Asking-for-Code" class="headerlink" title="Example 3: Asking for Code"></a>Example 3: Asking for Code</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function.”</p><p>The AI may generate a simple function, but it may not meet the user’s needs or lack important features such as error handling or optimization.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function to validate an email address using regular expressions. The function should return True if the email is valid and False if it is invalid. It should also handle common edge cases such as missing domain names or incorrect characters.”</p><p>The AI’s response will be much more precise, including the correct implementation, error handling, and edge case considerations.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In the world of AI, a <code>Prompt Engineer</code> plays a critical role in ensuring that AI models deliver optimal results. The expertise of prompt engineers can dramatically influence the quality, relevance, and accuracy of responses from language models like <code>GPT-4</code>. By following best practices—such as being specific, providing context, testing different iterations, and using examples—they can significantly improve the interaction between humans and AI.</p><p>As AI continues to evolve, the role of prompt engineering will become even more important, helping users and businesses unlock the full potential of artificial intelligence. Whether it’s writing, problem-solving, or complex technical tasks, the way we interact with AI will increasingly depend on how well we craft our prompts.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophis</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
    <category term="GPT-3" scheme="https://stonefishy.github.io/tags/GPT-3/"/>
    
    <category term="Prompt Engineering" scheme="https://stonefishy.github.io/tags/Prompt-Engineering/"/>
    
  </entry>
  
</feed>
