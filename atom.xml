<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andrewsy&#39;s Space</title>
  
  
  <link href="https://stonefishy.github.io/atom.xml" rel="self"/>
  
  <link href="https://stonefishy.github.io/"/>
  <updated>2025-08-26T03:00:18.036Z</updated>
  <id>https://stonefishy.github.io/</id>
  
  <author>
    <name>Andrewsy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>How to pricing the Azure Speech to Speech service</title>
    <link href="https://stonefishy.github.io/2025/08/26/how-to-pricing-the-azure-speech-to-speech-service/"/>
    <id>https://stonefishy.github.io/2025/08/26/how-to-pricing-the-azure-speech-to-speech-service/</id>
    <published>2025-08-26T10:28:50.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>In previous blog <a href="https://stonefishy.github.io/2025/06/19/speech-translator-base-on-azure-speech-service/">Speech Translator Based on Azure Speech Service</a>, we talked about the architecture and implementation details of a speech translation service using Azure’s Speech API. In this blog, we will focus on the pricing aspects of the Azure Speech to Speech service.</p><p>To calculate the Azure Speech to Speech Translation price, reference the Azure Pricing page: <a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/">Azure AI Speech Pricing | Microsoft Azure</a></p><p>The Azure Speech to Speech service involves two main components: Speech Translation and Text to Speech. Below, we will break down the pricing for each component and provide an example calculation for translating 6 hours of Chinese audio to English audio.</p><h3 id="Pricing-Summary"><a href="#Pricing-Summary" class="headerlink" title="Pricing Summary"></a>Pricing Summary</h3><p>The Azure Speech to Speech service combines two main features: Speech Translation and Text to Speech. Below is a summary of the pricing for each feature.</p><table><thead><tr><th>Feature</th><th>Tier</th><th>Included&#x2F;Rate</th></tr></thead><tbody><tr><td>Speech Translation</td><td>Free (F0)</td><td>5 audio hours&#x2F;month free</td></tr><tr><td></td><td>Pay as You Go</td><td>$2.5 per audio hour</td></tr><tr><td>Text to Speech (Neural)</td><td>Free (F0)</td><td>0.5M characters&#x2F;month free</td></tr><tr><td></td><td>Pay as You Go</td><td>$15 per 1M characters</td></tr><tr><td>Text to Speech (Neural HD)</td><td>Pay as You Go</td><td>$30 per 1M characters</td></tr></tbody></table><hr><h3 id="Example-Calculation"><a href="#Example-Calculation" class="headerlink" title="Example Calculation"></a>Example Calculation</h3><p>Assume we are translating 6 Hours of Chinese Audio to English Audio, the Azure Speech to Speech translation include below two steps</p><h4 id="Step-by-Step-Process-for-Real-Time-Translation"><a href="#Step-by-Step-Process-for-Real-Time-Translation" class="headerlink" title="Step-by-Step Process for Real-Time Translation"></a><strong>Step-by-Step Process for Real-Time Translation</strong></h4><ol><li><p><strong>Speech Translation</strong>:<br>The Chinese audio is processed and converted into English text using Azure’s Speech Translation service. This step is billed based on the duration of the audio.</p></li><li><p><strong>Text to Speech</strong>:<br>The translated English text is synthesized into English audio using Azure’s Text to Speech service. This step is billed based on the number of characters in the translated text.</p></li></ol><hr><h4 id="Step-1-Speech-Translation"><a href="#Step-1-Speech-Translation" class="headerlink" title="Step 1: Speech Translation"></a><strong>Step 1: Speech Translation</strong></h4><ul><li><strong>Free Tier</strong>: 5 audio hours are free per month.</li><li><strong>Pay as You Go Tier</strong>: $2.5 per audio hour for additional hours.</li></ul><p>For 6 hours:</p><ul><li>5 hours are free.</li><li>1 hour is charged at $2.5&#x2F;hour.</li></ul><p><strong>Speech Translation Cost</strong>:<br><code>1 hour × $2.5 = $2.5</code></p><hr><h4 id="Step-2-Text-to-Speech"><a href="#Step-2-Text-to-Speech" class="headerlink" title="Step 2: Text to Speech"></a><strong>Step 2: Text to Speech</strong></h4><p>Assume the translated English audio requires <strong>1M characters</strong> for synthesis:</p><ul><li><strong>Free Tier</strong>: 0.5M characters are free per month.</li><li><strong>Pay as You Go Tier</strong>: $15 per 1M characters (Neural).</li></ul><p>For 1M characters:</p><ul><li>0.5M characters are free.</li><li>0.5M characters are charged at $15 per 1M characters.</li></ul><p><strong>Text to Speech Cost</strong>:<br><code>0.5M characters × $15 = $7.5</code></p><hr><h3 id="Total-Cost"><a href="#Total-Cost" class="headerlink" title="Total Cost"></a><strong>Total Cost</strong></h3><ul><li>Speech Translation: $2.5  </li><li>Text to Speech: $7.5</li></ul><p><strong>Total Example Cost</strong>:<br><code>$2.5 + $7.5 = $10.0</code></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>In this example, translating 6 hours of Chinese audio to English audio using Azure’s Speech to Speech service would cost approximately $10.0. This calculation assumes the use of the Pay as You Go tier for both services after utilizing the free tier allowances. Actual costs may vary based on the specific usage and any additional features or services used. Always refer to the <a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/">Azure Pricing page</a> for the most up-to-date pricing information.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In previous blog &lt;a href=&quot;https://stonefishy.github.io/2025/06/19/speech-translator-base-on-azure-speech-service/&quot;&gt;Speech Translator Base</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Using LangGraph to create AI Agentic system.</title>
    <link href="https://stonefishy.github.io/2025/08/15/using-langgraph-to-create-ai-agentic-system/"/>
    <id>https://stonefishy.github.io/2025/08/15/using-langgraph-to-create-ai-agentic-system/</id>
    <published>2025-08-15T10:41:13.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>In the world of AI, creating systems that can autonomously perform tasks and make decisions is a fascinating challenge. <code>LangGraph,</code> a framework designed for building AI agents, provides a powerful way to create such systems. In this blog post, we will explore how to use <code>LangGraph</code> to create an AI agentic system.</p><h2 id="What-is-LangGraph"><a href="#What-is-LangGraph" class="headerlink" title="What is LangGraph?"></a>What is LangGraph?</h2><p><code>LangGraph</code> is a framework that allows developers to create AI agents by defining their behavior using <code>a graph-based approach</code>. This enables the creation of complex decision-making processes and interactions between different components of the system.</p><p><code>LangGraph</code> is introduced by <code>LangChain</code>. With <code>LangGraph</code> you can create highly controllable agents, include both single agent and multi-agents.</p><p><code>LangGraph</code> models agent workflow as a directed acyclic graph (DAG), where nodes represent tasks or actions, and edges represent the dependencies between them.</p><p><code>LangGraph</code> key components.</p><ul><li><p><strong>State</strong>: A shared data structure that represents the current snapshot of your application. It can be any data type, but is typically defined using a shared state schema</p></li><li><p><strong>Nodes</strong>: Functions that encode the logic of your agents. They receive the current state as input, perform some computation or side-effect, and return an updated state.</p></li><li><p><strong>Edges</strong>: Functions that determine which Node to execute next based on the current state. They can be conditional branches or fixed transitions.</p></li><li><p><strong>Graph</strong>: The overall structure that connects Nodes and Edges, defining the flow of execution.</p></li></ul><h2 id="Let’s-Build-an-AI-Agent"><a href="#Let’s-Build-an-AI-Agent" class="headerlink" title="Let’s Build an AI Agent"></a>Let’s Build an AI Agent</h2><p>Assume our company has a offline shop, and the customers often ask the same question about the shop open-closed time. We want to build an AI agent that can handle these inquiries efficiently.</p><p>OK，let start to build this AI Agent system. Create a directoy called “langgraph-agent-sample”. And create a Python virtual environment in this directory.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> langgraph-agent-sample</span><br><span class="line"><span class="built_in">cd</span> langgraph-agent-sample</span><br><span class="line">python -m venv venv</span><br></pre></td></tr></table></figure><p>and activate the virtual environment, the bat file <code>activate.bat</code> will be created in the <code>venv/Scripts</code> directory. the shell file <code>activate</code> will be created in the <code>venv/bin</code> directory base on your operating system.</p><p>Next, we need to install the required packages. Create a <code>requirements.txt</code> file with the following content.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">langgraph</span><br><span class="line">langchain_openai</span><br></pre></td></tr></table></figure><p>The <code>langgraph</code> package provides the core functionality for building graph-based AI agents, while <code>langchain_openai</code> integrates with Azure OpenAI services.</p><p>Then, install the packages using pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>Next, we need to create a Python script to define our agent’s behavior. Create a file named <code>agent.py</code> in the <code>langgraph-agent-sample</code> directory.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> MessagesState, START, StateGraph</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> tools_condition, ToolNode</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up Azure OpenAI credentials</span></span><br><span class="line">os.environ[<span class="string">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = <span class="string">&quot;&lt;your_openai_api_key&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = <span class="string">&quot;&lt;your_openai_endpoint&gt;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = AzureChatOpenAI(</span><br><span class="line">    azure_deployment=<span class="string">&quot;gpt-4o&quot;</span>,</span><br><span class="line">    api_version=<span class="string">&quot;2024-10-21&quot;</span>, <span class="comment">## api version which you deployed model version</span></span><br><span class="line">    temperature=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">sys_msg = SystemMessage(content=<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    You are a helpful assistant responsible for responses whether the shop is open or closed</span></span><br><span class="line"><span class="string">    based on the current time and the shop&#x27;s opening hours.&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">assistant</span>(<span class="params">state: MessagesState</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke([sys_msg] + state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_opening_hours</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;This tool provides the daily opening hours of the shop.&quot;&quot;&quot;</span></span><br><span class="line">    schedule = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Monday: 9 AM - 5 PM</span></span><br><span class="line"><span class="string">        Tuesday: 9 AM - 5 PM</span></span><br><span class="line"><span class="string">        Wednesday: 9 AM - 5 PM</span></span><br><span class="line"><span class="string">        Thursday: 9 AM - 5 PM</span></span><br><span class="line"><span class="string">        Friday: 9 AM - 5 PM</span></span><br><span class="line"><span class="string">        Saturday: 10 AM - 4 PM</span></span><br><span class="line"><span class="string">        Sunday: Closed</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> schedule</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">current_time</span>() -&gt; datetime:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;This tool provides the current date and time.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> datetime.now()</span><br><span class="line"></span><br><span class="line">tools = [shop_opening_hours, current_time]</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line">stateGraph = StateGraph(MessagesState)</span><br><span class="line">stateGraph.add_node(<span class="string">&quot;assistant&quot;</span>, assistant)</span><br><span class="line">stateGraph.add_node(<span class="string">&quot;tools&quot;</span>, ToolNode(tools))</span><br><span class="line"></span><br><span class="line">stateGraph.add_edge(START, <span class="string">&quot;assistant&quot;</span>)</span><br><span class="line">stateGraph.add_conditional_edges(<span class="string">&quot;assistant&quot;</span>, tools_condition)</span><br><span class="line">stateGraph.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;assistant&quot;</span>)</span><br><span class="line"></span><br><span class="line">react_graph = stateGraph.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Console conversation loop</span></span><br><span class="line">messages = []</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Type &#x27;exit&#x27; or &#x27;quit&#x27; to end the conversation.&quot;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> user_input.strip().lower() <span class="keyword">in</span> [<span class="string">&quot;exit&quot;</span>, <span class="string">&quot;quit&quot;</span>]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Conversation ended.&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    messages.append(HumanMessage(content=user_input))</span><br><span class="line">    result = react_graph.invoke(&#123;<span class="string">&quot;messages&quot;</span>: messages&#125;)</span><br><span class="line">    <span class="comment"># Find the latest assistant message</span></span><br><span class="line">    assistant_msgs = [m <span class="keyword">for</span> m <span class="keyword">in</span> result[<span class="string">&quot;messages&quot;</span>] <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(m, HumanMessage)]</span><br><span class="line">    <span class="keyword">if</span> assistant_msgs:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Assistant: <span class="subst">&#123;assistant_msgs[-<span class="number">1</span>].content&#125;</span>\n&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Assistant: Sorry, I don&#x27;t know.\n&quot;</span>)</span><br></pre></td></tr></table></figure><p>In above code, we use <code>Azure OpenAI</code> model <code>gpt-4o</code> and <code>LangGraph</code> to create an AI agent capable of understanding and responding to user queries about shop hours. Create two tools: <code>shop_opening_hours</code> and <code>current_time</code>, which provide the shop’s opening hours and the current time, respectively. The current_time tool can be used to get the current time and check if the shop is open or closed, and also it is a reference to ask the ai about any other future time.</p><p>You can see the <code>LangGraph</code> framework in action as it manages the flow of information between the user, the assistant, and the various tools at our disposal. </p><p>The <code>StateGraph</code> is responsible for defining the various states and transitions that our agent can take. It allows us to easily add new tools and modify the behavior of the agent without having to rewrite large portions of code.</p><p>We can use below snip code to show the graph:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display graph image in a window</span></span><br><span class="line">png_bytes = react_graph.get_graph(xray=<span class="literal">True</span>).draw_mermaid_png()</span><br><span class="line"><span class="keyword">with</span> tempfile.NamedTemporaryFile(delete=<span class="literal">False</span>, suffix=<span class="string">&quot;.png&quot;</span>) <span class="keyword">as</span> tmp_file:</span><br><span class="line">    tmp_file.write(png_bytes)</span><br><span class="line">    tmp_file_path = tmp_file.name</span><br><span class="line">img = PILImage.<span class="built_in">open</span>(tmp_file_path)</span><br><span class="line">img.show()</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langgraph-graph-example.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langgraph-graph-example.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Workflow Graph" style="width:200px;"/></div><span class="image-caption">Workflow Graph</span></div><p>Lets’ run it. execution below scripts:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python agent.py</span><br></pre></td></tr></table></figure><p>Below is agent running screenshot:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langgraph-agent-example.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langgraph-agent-example.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="LangGraph agent example" style="width:900px;"/></div><span class="image-caption">LangGraph agent example</span></div><p>This is simple AI Agent to use <code>LangGraph</code> to build. In tools, you can also write more complex logic to handle various scenarios and improve the agent’s capabilities. Such like invoke service API, access databases, or integrate with other systems.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>LangGraph provides a powerful framework for building AI agentic systems. By leveraging its graph-based approach, developers can create agents that are capable of complex decision-making and autonomous behavior. As AI continues to evolve, tools like LangGraph will play a crucial role in shaping the future of intelligent systems.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the world of AI, creating systems that can autonomously perform tasks and make decisions is a fascinating challenge. &lt;code&gt;LangGraph,&lt;</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="LangGraph" scheme="https://stonefishy.github.io/tags/LangGraph/"/>
    
    <category term="Azure OpenAI" scheme="https://stonefishy.github.io/tags/Azure-OpenAI/"/>
    
  </entry>
  
  <entry>
    <title>The Data Engineering and the Basics of a Machine Learning Pipeline</title>
    <link href="https://stonefishy.github.io/2025/08/13/the-basics-of-the-machine-learning-pipeline/"/>
    <id>https://stonefishy.github.io/2025/08/13/the-basics-of-the-machine-learning-pipeline/</id>
    <published>2025-08-13T10:40:55.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Foundation-Data-Engineering-for-Machine-Learning-Success"><a href="#The-Foundation-Data-Engineering-for-Machine-Learning-Success" class="headerlink" title="The Foundation: Data Engineering for Machine Learning Success"></a>The Foundation: Data Engineering for Machine Learning Success</h2><p>Data Engineering is the foundation of machine learning. Without proper data engineering practices, even the most sophisticated machine learning algorithms will fail to deliver meaningful results.</p><ul><li>Data Engineering at its heart is the study of how to move data and create actionable insights for customers and business users</li><li>Understanding how to move, clean, select, and automate data will greatly affect the cost and prediction ability of machine learning models</li></ul><h2 id="The-Machine-Learning-Pipeline-5-Critical-Components"><a href="#The-Machine-Learning-Pipeline-5-Critical-Components" class="headerlink" title="The Machine Learning Pipeline: 5 Critical Components"></a>The Machine Learning Pipeline: 5 Critical Components</h2><p>Building a successful machine learning pipeline requires careful consideration of several key components. Each component plays a vital role in ensuring that the data is properly prepared, processed, and utilized for effective model training and deployment.</p><h3 id="1-Data-Collection-and-Ingestion"><a href="#1-Data-Collection-and-Ingestion" class="headerlink" title="1. Data Collection and Ingestion"></a>1. Data Collection and Ingestion</h3><p>Data collection forms the first crucial step in any machine learning pipeline. The quality and comprehensiveness of your data collection strategy will determine the upper bound of your model’s performance.</p><h4 id="Multiple-Sources"><a href="#Multiple-Sources" class="headerlink" title="Multiple Sources"></a>Multiple Sources</h4><p>Modern machine learning projects require data from various sources - databases, APIs, streaming services, files, and external datasets. A robust ingestion system must handle:</p><ul><li><strong>Batch processing for large historical datasets</strong>: Think customer transaction histories, sensor readings over months, or archived log files. These are processed in scheduled intervals (hourly, daily, weekly)</li><li><strong>Real-time streaming for continuous data feeds</strong>: Live user interactions on websites, IoT sensor data, financial market feeds, or social media streams that require immediate processing</li><li><strong>API integrations for third-party data sources</strong>: Weather data from meteorological services, economic indicators from financial institutions, or demographic data from census bureaus</li></ul><h4 id="Data-Format-Considerations"><a href="#Data-Format-Considerations" class="headerlink" title="Data Format Considerations"></a>Data Format Considerations</h4><p>It could include:</p><ul><li>Structured data (SQL databases, CSV files)</li><li>Semi-structured data (JSON, XML, log files)</li><li>Unstructured data (images, text documents, audio files)</li></ul><h4 id="Automation-is-Critical"><a href="#Automation-is-Critical" class="headerlink" title="Automation is Critical"></a>Automation is Critical</h4><p>Manual data collection doesn’t scale. Automated pipelines ensure:</p><ul><li><strong>Consistent data flow</strong>: Eliminates human delays and ensures regular data updates</li><li><strong>Reduced human error</strong>: Automated systems follow exact protocols without fatigue or oversight</li><li><strong>Cost-effective operations</strong>: Reduces manual labor costs and allows teams to focus on higher-value tasks</li><li><strong>Timely model updates</strong>: Ensures models receive fresh data for continuous learning and adaptation</li></ul><h4 id="Common-Tools-and-Technologies"><a href="#Common-Tools-and-Technologies" class="headerlink" title="Common Tools and Technologies:"></a>Common Tools and Technologies:</h4><ul><li>Apache Kafka for real-time data streaming</li><li>Apache Airflow for workflow orchestration</li><li>AWS Kinesis or Azure Event Hubs for cloud-based streaming</li><li>ETL tools like Talend, Informatica, or custom Python scripts</li></ul><h3 id="2-Data-Cleaning-and-Preparation"><a href="#2-Data-Cleaning-and-Preparation" class="headerlink" title="2. Data Cleaning and Preparation"></a>2. Data Cleaning and Preparation</h3><p>This stage often consumes 60-80% of a data scientist’s time, yet it’s the most critical for model success. Poor data preparation leads to unreliable models and incorrect business decisions.</p><h4 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h4><p>Raw data rarely comes in a format ready for machine learning. This stage involves:</p><ul><li><strong>Handling missing values and outliers</strong>:</li></ul><ol><li>Missing data strategies: deletion, mean&#x2F;median imputation, or advanced techniques like KNN imputation</li><li>Outlier detection using statistical methods (IQR, Z-score) or machine learning approaches (Isolation Forest)</li></ol><ul><li><strong>Data type conversions and normalization</strong>:</li></ul><ol><li>Converting categorical variables to numerical (one-hot encoding, label encoding)</li><li>Scaling numerical features (StandardScaler, MinMaxScaler, RobustScaler)</li><li>Handling datetime features (extracting day of week, month, seasonality)</li></ol><ul><li><strong>Creating new features from existing data</strong>:</li></ul><ol><li>Aggregating transaction amounts by customer</li><li>Calculating ratios (debt-to-income, click-through rates)</li><li>Text feature extraction (TF-IDF, word embeddings)</li></ol><ul><li><strong>Selecting relevant features for the model</strong>:</li></ul><ol><li>Statistical methods (correlation analysis, chi-square tests)</li><li>Machine learning-based selection (recursive feature elimination, LASSO)</li><li>Domain knowledge-driven selection</li></ol><h4 id="Data-Quality-Dimensions"><a href="#Data-Quality-Dimensions" class="headerlink" title="Data Quality Dimensions"></a>Data Quality Dimensions</h4><ul><li><strong>Accuracy</strong>: Is the data correct and error-free?</li><li><strong>Completeness</strong>: Are all required data points present?</li><li><strong>Consistency</strong>: Is the data uniform across different sources?</li><li><strong>Timeliness</strong>: Is the data current and relevant?</li><li><strong>Validity</strong>: Does the data conform to defined formats and ranges?</li></ul><h4 id="Quality-Directly-Affects-ML-Output"><a href="#Quality-Directly-Affects-ML-Output" class="headerlink" title="Quality Directly Affects ML Output"></a>Quality Directly Affects ML Output</h4><p>Machine learning models require large amounts of clean data. The quality of your data directly affects the performance of your ML models.</p><h4 id="Remember-Junk-In-Junk-Out"><a href="#Remember-Junk-In-Junk-Out" class="headerlink" title="Remember: Junk In - Junk Out"></a>Remember: Junk In - Junk Out</h4><p>Poor quality data will always produce poor quality predictions, regardless of the sophistication of your algorithm.</p><h4 id="Cost-Effectiveness"><a href="#Cost-Effectiveness" class="headerlink" title="Cost Effectiveness"></a>Cost Effectiveness</h4><p>Investing in proper data cleaning upfront saves significant costs in model retraining and poor business decisions later.</p><h3 id="3-Scalability-and-Performance"><a href="#3-Scalability-and-Performance" class="headerlink" title="3. Scalability and Performance"></a>3. Scalability and Performance</h3><p>As organizations grow and data volumes increase exponentially, the ability to scale data processing becomes critical for maintaining performance and controlling costs.</p><h4 id="Design-Scalable-Data-Architectures"><a href="#Design-Scalable-Data-Architectures" class="headerlink" title="Design Scalable Data Architectures"></a>Design Scalable Data Architectures</h4><p>As data volumes grow, your infrastructure must scale accordingly:</p><ul><li><strong>Cloud-native solutions for elastic scaling</strong>:</li></ul><ol><li>Auto-scaling compute resources based on workload demands</li><li>Serverless computing (AWS Lambda, Azure Functions) for event-driven processing</li><li>Container orchestration for microservices deployment</li></ol><ul><li><strong>Microservices architecture for modular components</strong>:</li></ul><ol><li>Separate services for data ingestion, processing, storage, and serving</li><li>Independent scaling of different pipeline components</li><li>Easier maintenance and debugging of individual services</li></ol><ul><li><strong>Load balancing and distributed processing</strong>:</li></ul><ol><li>Distributing workloads across multiple machines</li><li>Horizontal scaling vs. vertical scaling strategies</li><li>Caching strategies for frequently accessed data</li></ol><h4 id="Performance-Optimization-Strategies"><a href="#Performance-Optimization-Strategies" class="headerlink" title="Performance Optimization Strategies"></a>Performance Optimization Strategies</h4><ul><li><strong>Data partitioning</strong>: Dividing large datasets by time, geography, or other logical divisions</li><li><strong>Indexing</strong>: Creating efficient data access patterns for faster queries</li><li><strong>Compression</strong>: Reducing storage costs and improving I&#x2F;O performance</li><li><strong>Parallel processing</strong>: Utilizing multiple CPU cores and machines simultaneously</li></ul><h4 id="Implement-Distributed-Computing-Environments"><a href="#Implement-Distributed-Computing-Environments" class="headerlink" title="Implement Distributed Computing Environments"></a>Implement Distributed Computing Environments</h4><p>Modern data processing requires distributed systems:</p><ul><li><strong>Apache Spark for large-scale data processing</strong>:</li></ul><ol><li>In-memory processing for faster computations</li><li>Support for batch and streaming data</li><li>Built-in machine learning libraries (MLlib)</li></ol><ul><li><strong>Kubernetes for container orchestration</strong>:</li></ul><ol><li>Automated deployment and scaling of containerized applications</li><li>Service discovery and load balancing</li><li>Rolling updates and rollbacks</li></ol><ul><li><strong>Cloud services like AWS, Azure, or GCP for managed scaling</strong>:</li></ul><ol><li>Managed services reduce operational overhead</li><li>Pay-as-you-use pricing models</li><li>Global availability and disaster recovery</li></ol><h3 id="4-Data-Storage-and-Management"><a href="#4-Data-Storage-and-Management" class="headerlink" title="4. Data Storage and Management"></a>4. Data Storage and Management</h3><p>Effective data storage strategies must balance performance, cost, security, and accessibility requirements while supporting both current needs and future growth.</p><h4 id="Storage-Requirements"><a href="#Storage-Requirements" class="headerlink" title="Storage Requirements"></a>Storage Requirements</h4><p>Data training often requires large amounts of storage with specific characteristics:</p><ul><li><strong>High-performance storage for training datasets</strong>:</li></ul><ol><li>SSD storage for faster I&#x2F;O operations during model training</li><li>High-bandwidth storage networks for distributed training</li><li>Optimized file formats (Parquet, ORC) for analytical workloads</li></ol><ul><li><strong>Long-term archival storage for historical data</strong>:</li></ul><ol><li>Cost-effective cold storage solutions (AWS Glacier, Azure Archive)</li><li>Data lifecycle management policies</li><li>Compliance with data retention requirements</li></ol><ul><li><strong>Backup and disaster recovery systems</strong>:</li></ul><ol><li>Automated backup schedules with point-in-time recovery</li><li>Geographic replication for disaster recovery</li><li>Regular backup validation and recovery testing</li></ol><h4 id="Storage-Architecture-Patterns"><a href="#Storage-Architecture-Patterns" class="headerlink" title="Storage Architecture Patterns"></a>Storage Architecture Patterns</h4><ul><li><strong>Data Lakes</strong>: Store raw data in its native format for flexibility</li><li><strong>Data Warehouses</strong>: Structured storage optimized for analytical queries</li><li><strong>Data Lakehouses</strong>: Combine the flexibility of data lakes with the performance of warehouses</li><li><strong>Feature Stores</strong>: Centralized repositories for ML features with versioning and lineage</li></ul><h4 id="Design-and-Optimization"><a href="#Design-and-Optimization" class="headerlink" title="Design and Optimization"></a>Design and Optimization</h4><p>Effective storage solutions require data engineering expertise:</p><ul><li><strong>Database optimization and indexing</strong>:</li></ul><ol><li>Query performance tuning through proper indexing strategies</li><li>Database schema design for optimal access patterns</li><li>Regular maintenance and statistics updates</li></ol><ul><li><strong>Data partitioning strategies</strong>:</li></ul><ol><li>Horizontal partitioning (sharding) across multiple databases</li><li>Vertical partitioning by separating frequently and rarely accessed columns</li><li>Time-based partitioning for time-series data</li></ol><ul><li><strong>Caching mechanisms for frequently accessed data</strong>:</li></ul><ol><li>In-memory caches (Redis, Memcached) for fast data retrieval</li><li>Application-level caching for computed results</li><li>CDN usage for geographically distributed access</li></ol><h3 id="5-Data-Governance-and-Compliance"><a href="#5-Data-Governance-and-Compliance" class="headerlink" title="5. Data Governance and Compliance"></a>5. Data Governance and Compliance</h3><p>In an era of increasing data regulations and ethical AI concerns, robust data governance frameworks are essential for sustainable machine learning operations.</p><h4 id="Regulatory-Requirements"><a href="#Regulatory-Requirements" class="headerlink" title="Regulatory Requirements"></a>Regulatory Requirements</h4><p>Modern data systems must comply with various regulations:</p><ul><li><strong>GDPR for European data protection</strong>:</li></ul><ol><li>Right to be forgotten and data portability requirements</li><li>Consent management and data processing lawfulness</li><li>Data Protection Impact Assessments (DPIAs) for high-risk processing</li></ol><ul><li><strong>CCPA for California consumer privacy</strong>:</li></ul><ol><li>Consumer rights to know, delete, and opt-out of data sales</li><li>Data minimization and purpose limitation principles</li><li>Regular privacy impact assessments</li></ol><ul><li><strong>Industry-specific regulations (HIPAA, SOX, etc.)</strong>:</li></ul><ol><li>Healthcare data protection under HIPAA</li><li>Financial data security under SOX and PCI DSS</li><li>Industry-specific data handling requirements</li></ol><h4 id="Data-Governance-Framework-Components"><a href="#Data-Governance-Framework-Components" class="headerlink" title="Data Governance Framework Components:"></a>Data Governance Framework Components:</h4><ul><li><strong>Data lineage tracking</strong>: Understanding data flow from source to consumption</li><li><strong>Data quality monitoring</strong>: Automated checks for data accuracy and completeness</li><li><strong>Access control and authorization</strong>: Role-based access to sensitive data</li><li><strong>Audit trails</strong>: Comprehensive logging of data access and modifications</li></ul><h4 id="Ethical-Standards"><a href="#Ethical-Standards" class="headerlink" title="Ethical Standards"></a>Ethical Standards</h4><p>Responsible AI requires ethical data practices:</p><ul><li><strong>Bias detection and mitigation</strong>:</li></ul><ol><li>Regular auditing of training data for demographic biases</li><li>Fairness metrics and bias testing throughout the ML lifecycle</li><li>Diverse data collection strategies to ensure representation</li></ol><ul><li><strong>Data privacy protection</strong>:</li></ul><ol><li>Differential privacy techniques for statistical data release</li><li>Data anonymization and pseudonymization methods</li><li>Privacy-preserving machine learning techniques</li></ol><ul><li><strong>Transparent data usage policies</strong>:</li></ul><ol><li>Clear communication about data collection and usage</li><li>Regular policy updates and user notifications</li><li>Explainable AI techniques for model transparency</li></ol><ul><li><strong>Fair representation in training datasets</strong>:</li></ul><ol><li>Ensuring diverse and representative training data</li><li>Regular assessment of dataset composition</li><li>Corrective measures for underrepresented groups</li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Data Engineering is critical to effective machine learning predictions. Understanding how data engineering works will make you a more effective data scientist and ensure your ML projects deliver real business value.</p><p>The success of any machine learning initiative depends heavily on the quality of the underlying data infrastructure. By investing in proper data engineering practices, organizations can build robust, scalable, and reliable ML systems that drive meaningful business outcomes.</p><p><strong>Key Takeaways:</strong></p><ul><li>Quality data engineering is non-negotiable for ML success</li><li>Automation and scalability should be built into every pipeline</li><li>Compliance and ethics must be considered from day one</li><li>The cost of poor data engineering compounds over time</li></ul><p><em>Remember: Great machine learning starts with great data engineering.</em></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;The-Foundation-Data-Engineering-for-Machine-Learning-Success&quot;&gt;&lt;a href=&quot;#The-Foundation-Data-Engineering-for-Machine-Learning-Success</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="Big Data" scheme="https://stonefishy.github.io/tags/Big-Data/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Using GitHub Copilot AI in the CLI</title>
    <link href="https://stonefishy.github.io/2025/08/07/using-github-copilot-ai-in-the-cli/"/>
    <id>https://stonefishy.github.io/2025/08/07/using-github-copilot-ai-in-the-cli/</id>
    <published>2025-08-07T15:39:52.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>The <code>GitHub Copilot</code> is a tool that can help you write code faster and more efficiently. It can suggest code completions based on your code context and can help you write better code. But it is also can be used in the <code>command line interface (CLI)</code> like <code>bash</code>, <code>zsh</code>, <code>PowerShell</code> as well.</p><p>For example, we may want to use some command to execute the task in the CLI. For example, we may want to copy a file from windows to the linux machine. But we don’t know which command to use and how to use it? Usually, we may take some time to search for the right command and then execute it.</p><p>With <code>GitHub Copilot</code>, we can get the command for the task we want to execute in the CLI. We just need to type the task and <code>GitHub Copilot</code> will suggest the command for us. For example, if we want to copy a file from windows to the linux machine, we can type <code>copy file from windows to linux</code> and <code>GitHub Copilot</code> will suggest the command <code>scp file.txt username@linux-machine:/path/to/destination</code>.</p><h2 id="Install-GitHub-CLI"><a href="#Install-GitHub-CLI" class="headerlink" title="Install GitHub CLI"></a>Install GitHub CLI</h2><p>To use <code>GitHub Copilot</code> in the CLI, firstly, we need to install the <code>GitHub CLI</code>. You can install it from the official website: <a href="https://cli.github.com/">https://cli.github.com/</a>. Once we have installed it, we can start using it in the CLI. My local computer is windows, so I need to install the <code>GitHub CLI</code> for windows. You can find the installation instructions for different operating systems on the official website.</p><p>After you install it, you can type <code>gh</code> command to see the help information.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub CLI Commands Example" style="width:800px;"/></div><span class="image-caption">GitHub CLI Commands Example</span></div><h2 id="Install-GitHub-Copilot-extension-in-CLI"><a href="#Install-GitHub-Copilot-extension-in-CLI" class="headerlink" title="Install GitHub Copilot extension in CLI"></a>Install GitHub Copilot extension in CLI</h2><p>To use <code>GitHub Copilot</code> in the CLI, we need to install the <code>GitHub Copilot</code> extension in the CLI. Before that, you need subscribe to the <code>GitHub Copilot</code> first. Go to the website: <a href="https://github.com/features/copilot/plans">https://github.com/features/copilot/plans</a> to check the plans, you can choose the individual plan or business plan. For the individual plan, you can get the <code>GitHub Copilot</code> for free with some limits.</p><p>Once you have subscribed, you can type below command to login GitHub from the command line:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gh auth login</span><br></pre></td></tr></table></figure><p>Follow the command instructions to login with your GitHub account. You can choose the <code>HTTPS</code> protocol or <code>SSH</code> to login.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub Auth Login" style="width:800px;"/></div><span class="image-caption">GitHub Auth Login</span></div><p>After you login successfully, you can install the <code>GitHub Copilot</code> extension in the CLI by running the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gh extension install github/gh-copilot</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub Copilot AI install success in CLI" style="width:800px;"/></div><span class="image-caption">GitHub Copilot AI install success in CLI</span></div><p>Typing <code>gh copilot</code> in the CLI, you can see the help information for the <code>GitHub Copilot</code> extension.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-4.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub Copilot AI help in CLI" style="width:800px;"/></div><span class="image-caption">GitHub Copilot AI help in CLI</span></div><h2 id="Use-GitHub-Copilot-in-the-CLI"><a href="#Use-GitHub-Copilot-in-the-CLI" class="headerlink" title="Use GitHub Copilot in the CLI"></a>Use GitHub Copilot in the CLI</h2><p>To use <code>GitHub Copilot</code> in the CLI, we can use <code>gh copilot suggest &lt;task&gt;</code> command. The task is the task we want to execute in the CLI. </p><p>For example, if we want to copy a file from windows to the linux machine, we can type <code>gh copilot suggest &quot;copy file from windows to linux&quot;</code>. <code>GitHub Copilot</code> will suggest the command <code>scp path\to\file username@linux-server-ip:/path/to/destination</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-5.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub Copilot AI CLI example 1" style="width:800px;"/></div><span class="image-caption">GitHub Copilot AI CLI example 1</span></div><p>Let’s try another example, If we want to check the docker logs in real time when docker container is running, but we forgot the command, we can type below command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gh copilot suggest &quot;check docker logs in real time when the docker container is running.&quot;</span><br></pre></td></tr></table></figure><p>See below result:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-6.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub Copilot AI CLI example 2" style="width:800px;"/></div><span class="image-caption">GitHub Copilot AI CLI example 2</span></div><p>We can also ask the more complex command suggestion, here is example, Let’s create a directory named ‘gh-copilot-test’, create a new file named ‘test.txt’ under this directory and write the ‘Created by GitHub Copilot in CLI’ text in this file.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gh copilot suggest &quot;create a directory named &#x27;gh-copilot-test&#x27;, create a new file named &#x27;test.txt&#x27; under this directory and write the &#x27;Created by GitHub Copilot in CLI&#x27; text in this file.&quot;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/github-copilot-in-cli-7.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/github-copilot-in-cli-7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="GitHub Copilot AI CLI example 3" style="width:800px;"/></div><span class="image-caption">GitHub Copilot AI CLI example 3</span></div><p>Because I’m using windows and not set the <code>ghcs</code> and <code>ghce</code> alias in my <code>PowerShell</code>, So choose the <code>Execute Command</code> not work, it copies the command to the Clipboard. </p><p>To see the <code>Alias</code> help, you can run below command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gh copilot alias --help</span><br></pre></td></tr></table></figure><p>The <code>gh copilot alias</code> command is used to set the <code>ghcs</code> and <code>ghce</code> alias in the CLI. As you can see below screenshot, it supports <code>Bash</code>, <code>PowerShell</code> and <code>Zsh</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img" src="/assets/images/ai-ml/github-copilot-in-cli-8.png" alt="GitHub Copilot AI CLI Alias help %}<p>Note" style="width:800px;"/></div><span class="image-caption">GitHub Copilot AI CLI Alias help %}<p>Note</span></div>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The &lt;code&gt;GitHub Copilot&lt;/code&gt; is a tool that can help you write code faster and more efficiently. It can suggest code completions based</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="GitHub" scheme="https://stonefishy.github.io/tags/GitHub/"/>
    
    <category term="Copilot" scheme="https://stonefishy.github.io/tags/Copilot/"/>
    
    <category term="CLI" scheme="https://stonefishy.github.io/tags/CLI/"/>
    
  </entry>
  
  <entry>
    <title>Copying AWS S3 Object from One Account to Another Account.</title>
    <link href="https://stonefishy.github.io/2025/07/02/copying-aws-s3-object-from-one-account-to-another-account/"/>
    <id>https://stonefishy.github.io/2025/07/02/copying-aws-s3-object-from-one-account-to-another-account/</id>
    <published>2025-07-02T10:32:54.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>In AWS Cloud, copying objects between buckets within an AWS account is a standard, simple process for S3 users. To copy AWS S3 objects from one bucket to another bucket, you can use the AWS CLI. In its simplest form, the following command copies all objects from bucket1 to bucket2:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 cp s3://bucket1 s3://bucket2</span><br></pre></td></tr></table></figure><p>To copy a single object, use the following command:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 cp s3://bucket1/key1 s3://bucket2/key1</span><br></pre></td></tr></table></figure><p>To copy a directory, use the following command:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 cp s3://bucket1/key1/ s3://bucket2/key1/ --recursive</span><br></pre></td></tr></table></figure><p>All commands about S3 copying objects are available in the AWS CLI documentation. You can reference this doc <a href="https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html">https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html</a>.</p><p>But there are some cases where you need to copy objects between accounts instead of within an account. In this blog, we will talk about how to copy objects between AWS accounts using AWS CLI.</p><h2 id="Pre-Requirements"><a href="#Pre-Requirements" class="headerlink" title="Pre-Requirements"></a>Pre-Requirements</h2><p><strong>Two AWS accounts</strong>: Two AWS account entities with their account IDs, one is source account and another is destination account.</p><p><strong>Source and destination buckets</strong>: One source account, needs a bucket with objects. The another destination account, will need a bucket that will receive the source account’s objects.</p><p><strong>IAM user</strong>: This AWS IAM user in the destination account will be responsible for copying the objects.</p><p><strong>Permissions</strong>: The IAM user needs permissions to access both buckets in order to get objects from the source bucket and put objects in the destination bucket. These permissions are granted with the use of policies.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-copy-s3-object-between-accounts.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-copy-s3-object-between-accounts.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Copy S3 Object Between Two Accounts" style="width:800px;"/></div><span class="image-caption">AWS Copy S3 Object Between Two Accounts</span></div><h2 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h2><p>We already have two AWS accounts, source account and destination account. We also have a source bucket and a destination bucket, and one object file which size around 284GB in source account. We need to copy this object file from the source bucket to the destination bucket.</p><h3 id="Step-1-Create-an-IAM-user-in-the-destination-account"><a href="#Step-1-Create-an-IAM-user-in-the-destination-account" class="headerlink" title="Step 1: Create an IAM user in the destination account"></a>Step 1: Create an IAM user in the destination account</h3><p>Go to AWS Console menu and select IAM service. Then select Users from the left menu. Click on Add user button.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-create-iam-user-in-destination-account.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-create-iam-user-in-destination-account.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Create IAM User In Destination Account" style="width:800px;"/></div><span class="image-caption">AWS Create IAM User In Destination Account</span></div><h3 id="Step-2-Create-a-Policy-in-the-destination-account"><a href="#Step-2-Create-a-Policy-in-the-destination-account" class="headerlink" title="Step 2: Create a Policy in the destination account"></a>Step 2: Create a Policy in the destination account</h3><p>Go to IAM console menu and select Policies from the left menu. Click on Create policy button. Switch to Json edit mode in policy editor. Following below policy json in the policy editor, and using your own source and destination bucket name in the resource section. Let’s named this policy as “allow-cross-copy-data”.</p><p>Below policy allows the IAM user to list and get objects from the source bucket and put objects in the destination bucket.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="string">&quot;s3:ListBucket&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;s3:GetObject&quot;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="string">&quot;arn:aws:s3:::&lt;source-account-bucket&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;arn:aws:s3:::&lt;source-account-bucket&gt;/*&quot;</span></span><br><span class="line"><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="string">&quot;s3:ListBucket&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;s3:PutObject&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;s3:PutObjectAcl&quot;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="string">&quot;arn:aws:s3:::&lt;destination-account-bucket&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;arn:aws:s3:::&lt;destination-account-bucket&gt;/*&quot;</span></span><br><span class="line"><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-create-iam-policy-in-destination-account.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-create-iam-policy-in-destination-account.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Create IAM Policy In Destination Account" style="width:800px;"/></div><span class="image-caption">AWS Create IAM Policy In Destination Account</span></div><h3 id="Step-3-Attach-the-policy-to-the-IAM-user"><a href="#Step-3-Attach-the-policy-to-the-IAM-user" class="headerlink" title="Step 3: Attach the policy to the IAM user"></a>Step 3: Attach the policy to the IAM user</h3><p>Go to IAM console menu and select Users from the left menu. Select the IAM user which we created in the destination account. Click on Attach policies button. Attach the “allow-cross-copy-data” policy to the IAM user.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-attach-iam-policy-to-iam-user.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-attach-iam-policy-to-iam-user.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Attach IAM Policy To IAM User" style="width:800px;"/></div><span class="image-caption">AWS Attach IAM Policy To IAM User</span></div><p>Once you attached the policy to the IAM user, you can see the policy attached to the user. Then you can create an <code>AKSK pair (Access Key ID and Secret Access Key)</code> for the IAM user. The AKSK pair will be used to access the source and destination buckets in AWS CLI.</p><h3 id="Step-4-Install-Configure-AWS-CLI"><a href="#Step-4-Install-Configure-AWS-CLI" class="headerlink" title="Step 4: Install &amp; Configure AWS CLI"></a>Step 4: Install &amp; Configure AWS CLI</h3><p>To Install AWS CLI on your machine, follow this official documentation <a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html">https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html</a>. </p><p>Once you have installed the AWS CLI, configure it with your AWS Access Key ID and Secret Access Key.</p><p>In Windows you can set the keys as follows:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET AWS_ACCESS_KEY_ID=&lt;aws_access_key_id&gt; </span><br><span class="line">SET AWS_SECRET_ACCESS_KEY=&lt;aws_secret_access_key&gt;</span><br></pre></td></tr></table></figure><p>In Linux&#x2F;Unix machines or Mac, you can set the keys as follows:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> AWS_ACCESS_KEY_ID=&lt;aws_access_key_id&gt; </span><br><span class="line"><span class="built_in">export</span> AWS_SECRET_ACCESS_KEY=&lt;aws_secret_access_key&gt;</span><br></pre></td></tr></table></figure><h3 id="Step-5-Create-bucket-policy-for-source-bucket"><a href="#Step-5-Create-bucket-policy-for-source-bucket" class="headerlink" title="Step 5: Create bucket policy for source bucket"></a>Step 5: Create bucket policy for source bucket</h3><p>In the source account, we need to create a bucket policy for the source bucket. The bucket policy will allow the IAM user of destination account to access the source bucket. The following bucket policy allows the IAM user to access the source bucket.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;Sid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AllowCopy&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Principal&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;AWS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;arn:aws:iam::&lt;destination-account-id&gt;:user/&lt;destination-account-iam-user&gt;&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="string">&quot;s3:List*&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;s3:Get*&quot;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="string">&quot;arn:aws:s3:::&lt;source-account-bucket&gt;/*&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="string">&quot;arn:aws:s3:::&lt;source-account-bucket&gt;&quot;</span></span><br><span class="line"><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-create-bucket-policy-for-source-bucket.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-create-bucket-policy-for-source-bucket.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Create Bucket Policy For Source Bucket" style="width:800px;"/></div><span class="image-caption">AWS Create Bucket Policy For Source Bucket</span></div><h3 id="Step-6-Copy-the-object-from-source-to-destination-bucket"><a href="#Step-6-Copy-the-object-from-source-to-destination-bucket" class="headerlink" title="Step 6: Copy the object from source to destination bucket"></a>Step 6: Copy the object from source to destination bucket</h3><p>Now, we can copy the object from source to destination bucket using the AWS CLI. Use the following command to copy the object:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 <span class="built_in">cp</span> s3://&lt;source-account-bucket&gt;/&lt;object-key&gt; s3://&lt;destination-account-bucket&gt;/&lt;object-key&gt;</span><br></pre></td></tr></table></figure><p>Below are screenshots of the AWS CLI commands and output.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-copy-s3-object-between-accounts-command-output.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-copy-s3-object-between-accounts-command-output.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Copy S3 Object Between Two Accounts Command Output" style="width:800px;"/></div><span class="image-caption">AWS Copy S3 Object Between Two Accounts Command Output</span></div><p>In above screenshot, you will see the command used to copy the object from source account bucket to destination account bucket. The output shows the progress of the copy operation. Once the copy operation is complete, you will see the object copied successfully.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-copy-s3-object-between-accounts-object-copied.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-copy-s3-object-between-accounts-object-copied.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Copy S3 Object Between Two Accounts Object Copied" style="width:800px;"/></div><span class="image-caption">AWS Copy S3 Object Between Two Accounts Object Copied</span></div><p>That’s all. You have successfully copied the object from source account to destination account using AWS CLI. Hope this can help you.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In AWS Cloud, copying objects between buckets within an AWS account is a standard, simple process for S3 users. To copy AWS S3 objects fr</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Data Engineering in AWS Machine Learning</title>
    <link href="https://stonefishy.github.io/2025/07/01/data-engineering-in-aws-machine-learning/"/>
    <id>https://stonefishy.github.io/2025/07/01/data-engineering-in-aws-machine-learning/</id>
    <published>2025-07-01T10:11:13.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>The entire machine learning domain revolves around data. With clean data, you can gain important business insights. Data enables you to proactively, rather than reactively, make strategic business decisions and helps you gain a deeper understanding of your customers.</p><p>The <code>Data Engineering</code> in machine learning refers to the ingest of the data, the process of storing, processing, <code>ETL</code>(extract, transform, load) and analyzing data.</p><p>However, storing all this data is challenging. You need a way to store the data in a centralized repository and make it easy to access. This means you need to consider data security, availability, cost, and performance.</p><p>AWS provides many services that can help you address these challenges. A <code>data lake</code> is the key solution to address this challenge. With a data lake, you can store both <code>structured</code> and <code>unstructured</code> data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/data-lake-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/data-lake-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Data Lake in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Data Lake in AWS Machine Learning</span></div><h2 id="Data-Storage"><a href="#Data-Storage" class="headerlink" title="Data Storage"></a>Data Storage</h2><h3 id="Data-Lake"><a href="#Data-Lake" class="headerlink" title="Data Lake"></a>Data Lake</h3><p>The AWS Lake Formation and Amazon S3 buckets are the two main components of a data lake. A data lake is a platform for storing and analyzing data, which can help you extract valuable insights. </p><p>The <code>AWS Lake Formation</code> is the data lake solution provided by AWS, and <code>Amazon S3</code> is the preferred storage option for data science processing on AWS. Below is a general architecture of a data lake and Amazon S3 for Machine learning.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/data-lake-s3-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/data-lake-s3-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Data Lake and S3 in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Data Lake and S3 in AWS Machine Learning</span></div><h3 id="Amazon-S3"><a href="#Amazon-S3" class="headerlink" title="Amazon S3"></a>Amazon S3</h3><p>You can use Amazon S3 as storage to store your data. Amazon S3 is a highly available, durable, and scalable object storage service. Amazon S3 offers industry-leading scalability, data availability, security, and performance. It is designed to store and retrieve any amount of data from anywhere on the web.</p><p>There are several storage types of Amazon S3, including:</p><ul><li><strong>S3 Standard</strong>: This is the default storage class for frequently accessed data. It provides high durability, availability, and performance.</li><li><strong>S3 Intelligent-Tiering</strong>: This storage class automatically moves data between two access tiers (frequent and infrequent access) based on changing access patterns.</li><li><strong>S3 Standard-IA</strong>: This is a lower-cost storage class for data that is accessed less frequently, but requires rapid access.</li><li><strong>S3 OneZone-IA</strong>: This is a lower-cost storage class for data that is accessed less frequently, but requires rapid access. It is designed for applications that require low latency and high throughput.</li><li><strong>S3 Glacier</strong>: This is a low-cost storage class for data archiving. It provides retrieval times of <code>several hours</code>.</li><li><strong>S3 Glacier Deep Archive</strong>: This is the lowest-cost storage class for data archiving. It provides retrieval times of <code>several days</code>.</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/amazon-s3-access-frequency.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/amazon-s3-access-frequency.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Amazon S3 Access Frequency" style="width:600px;"/></div><span class="image-caption">Amazon S3 Access Frequency</span></div><p>When you train machine learning models using <code>Amazon SageMaker</code>, you can use Amazon S3 to store your training data and model training output. Amazon S3 and Amazon SageMaker integration is used to store training data and model training output.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/s3-sagemaker-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/s3-sagemaker-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Amazon S3 and SageMaker in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Amazon S3 and SageMaker in AWS Machine Learning</span></div><h3 id="Amazon-FSx-for-Lustre"><a href="#Amazon-FSx-for-Lustre" class="headerlink" title="Amazon FSx for Lustre"></a>Amazon FSx for Lustre</h3><p>However, Amazon S3 is not the only storage solution you can use for model training. If your training data is already stored in Amazon S3, and you plan to run multiple training jobs with different algorithms and parameters, consider using <code>Amazon FSx for Lustre</code> (a file system service). </p><p>FSx for Lustre provides fast access to Amazon S3 data, which is then provided to Amazon SageMaker. The first time you run a training job, <code>FSx for Lustre</code> automatically copies the data from Amazon S3 and provides it to Amazon SageMaker. You can then use the same Amazon FSx file system for subsequent training job iterations to avoid repeatedly downloading the same Amazon S3 objects.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/amazon-FSx-for-Lustre-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/amazon-FSx-for-Lustre-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Amazon FSx for Lustre in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Amazon FSx for Lustre in AWS Machine Learning</span></div><h3 id="Amazon-EFS"><a href="#Amazon-EFS" class="headerlink" title="Amazon EFS"></a>Amazon EFS</h3><p>Or, if your training data is already stored in <code>Amazon EFS</code>, it may be a good choice as a training data source. The advantage of <code>Amazon EFS</code> is that it can be used to start training jobs directly from the service, without moving the data, resulting in shorter training start times. </p><p>If data scientists have a home directory in <code>Amazon EFS</code>, and use it to introduce new data, share data with colleagues, and experiment with different fields or labels in their data set, this advantage is particularly valuable. For example, data scientists can use a Jupyter notebook to clean the training set initially, start a training job from <code>Amazon SageMaker</code>, and then use the notebook to delete a column and restart the training job to compare the results, to see which model performs better.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/amazon-efs-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/amazon-efs-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Amazon EFS in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Amazon EFS in AWS Machine Learning</span></div><p>The Amazon EBS also can be used as a data source for training, but it is generally slower than Amazon S3 and Amazon EFS. Amazon EBS is a block-level storage service that can be attached to EC2 instances. It is ideal for data that is frequently accessed and requires low latency.</p><h2 id="Data-Ingesting"><a href="#Data-Ingesting" class="headerlink" title="Data Ingesting"></a>Data Ingesting</h2><p>The Data Ingesting include the <code>batch</code> and <code>streaming</code> data sources.</p><h3 id="Batch-Data-Ingesting"><a href="#Batch-Data-Ingesting" class="headerlink" title="Batch Data Ingesting"></a>Batch Data Ingesting</h3><p>Using batch processing, the data ingestion layer periodically collects source data and groups it, then sends it to <code>Amazon S3</code> or other target locations. You can group data based on any logical order, activation by certain conditions, or simple timetables. Batch processing is typically used when real-time or nearly real-time data is not required, as it is generally more efficient and cost-effective than other ingestion options.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/batch-data-ingestion-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/batch-data-ingestion-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Batch Data Ingestion in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Batch Data Ingestion in AWS Machine Learning</span></div><p>To ingest data in batches to AWS, you can use services such as <code>AWS Glue</code> or <code>A</code>mazon EMR<code>. These are </code>ETL (extract, transform, and load)<code>services that can be used to classify, clean, and enrich data, as well as move data between various data stores.</code>AWS DMS<code>is another service that can help with batch ingestion. It can read historical data from any source system (such as relational database management systems, data warehouses, and NoSQL databases) at any desired interval. You can also use</code>AWS Step Functions&#96; to automate complex ETL workflows involving various tasks.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/glue-batch-ingest-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/glue-batch-ingest-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Batch Data Ingestion with AWS Glue in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Batch Data Ingestion with AWS Glue in AWS Machine Learning</span></div><h3 id="Streaming-Data-Ingesting"><a href="#Streaming-Data-Ingesting" class="headerlink" title="Streaming Data Ingesting"></a>Streaming Data Ingesting</h3><p>The streaming (including <code>real-time</code> processing) does not involve grouping. Data is created and identified, and it is immediately collected, processed, and loaded by the data ingestion layer. The cost-effectiveness of this ingestion is lower because the system needs to constantly monitor the source and accept new information. However, you may want to use it for <code>real-time predictions</code> (using Amazon SageMaker endpoints that you want to show on your website) or for some <code>real-time analytics</code> that require frequent data refreshes (such as real-time dashboards).</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/streaming-data-ingestion-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/streaming-data-ingestion-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Streaming Data Ingestion in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Streaming Data Ingestion in AWS Machine Learning</span></div><h4 id="Amazon-Kinesis"><a href="#Amazon-Kinesis" class="headerlink" title="Amazon Kinesis"></a>Amazon Kinesis</h4><p><code>Amazon Kinesis</code> is a platform for streaming data processing on AWS. It is a fully managed service that can capture and process data in real-time. You can build custom streaming data applications using Amazon Kinesis, which can satisfy your specific needs. It also provides various services that make it easy to load and analyze streaming data.</p><p>The <code>Amazon Kineis</code> include several services, including:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/amazon-kinesis-services.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/amazon-kinesis-services.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Amazon Kinesis Services" style="width:600px;"/></div><span class="image-caption">Amazon Kinesis Services</span></div><ul><li><p><strong>Amazon Kinesis Video Stream</strong>: You can use <code>Amazon Kinesis Video Streams</code> to capture and analyze video and audio data. For example, a leading home security company uses Kinesis Video Streams to capture audio and video data from its home security cameras. They then connect to their custom machine learning models running in Amazon SageMaker to detect and analyze objects, creating a more comprehensive user experience.</p></li><li><p><strong>Amazon Kinesis Data Streams</strong>: You can use <code>Amazon Kinesis Data Streams</code> to write data to a stream using <code>Kinesis Producer Library (KPL)</code>, which acts as an intermediary between your application code and the Kinesis Data Streams API. You can then use <code>Kinesis Client Library (KCL)</code> to build your own applications that preprocess the data as it streams in, and emit data for downstream analysis.</p></li><li><p><strong>Amazon Kinesis Data Firehose</strong>: You can use <code>Amazon Kinesis Data Firehose</code> to easily batch and compress data as it streams in, and provide an incremental view. You can also use AWS Lambda to perform custom transformation logic before sending the incremental view to <code>Amazon S3</code>.</p></li><li><p><strong>Amazon Kinesis Data Analytics</strong>: You can use <code>Amazon Kinesis Data Analytics</code> to process and transform data streamed through Kinesis Data Streams or Kinesis Data Firehose using <code>SQL</code>. This allows you to get <code>near-real-time insights</code> from the data before it is stored in Amazon S3.</p></li></ul><h3 id="Data-Transform-and-Processing"><a href="#Data-Transform-and-Processing" class="headerlink" title="Data Transform and Processing"></a>Data Transform and Processing</h3><p>Ingestion of raw data into services such as <code>Amazon S3</code> is not directly usable for machine learning. Data needs to be transformed and cleaned, including deduplication of duplicate data, management of incomplete data, and standardization of attributes. If necessary, data transformation may involve changing the data structure to an OLAP model, which makes it easier to query data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/data-transform-processing-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/data-transform-processing-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Data Transform and Processing in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Data Transform and Processing in AWS Machine Learning</span></div><p>Processing of large datasets typically requires data transformation. Distributed computing frameworks such as <code>MapReduce</code> and <code>Apache Spark</code> can provide protocols for data processing and node task assignment and management. They also use algorithms to split datasets into subsets and distribute them across nodes in the compute cluster. Using <code>Apache Spark on Amazon EMR</code> provides a managed framework that can handle large datasets. <code>Amazon EMR</code> supports several instance types, which have higher CPU and enhanced networking performance, which are ideal for <code>high-performance computing (HPC)</code> applications.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/data-transform-processing-with-emr-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/data-transform-processing-with-emr-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Data Transform and Processing with Spark in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Data Transform and Processing with Spark in AWS Machine Learning</span></div><p>The key step of Machine Learning Data Transformations is to partition the dataset. The Machine Learning application requires dataset from databases, streaming IoT input or centralized data lakes. In many use cases, <code>Amazon S3</code> can be used as the target endpoint for the training dataset. <code>ETL processing services (Athena, AWS Glue, Amazon Redshift Spectrum)</code> complement each other in functionality, and can be used to preprocess data stored in Amazon S3 or directed to Amazon S3 datasets. In addition to using Athena and Amazon Redshift Spectrum, you can also use AWS Glue-based services to provide metadata discovery and management functionality. The choice of <code>ETL</code> processing tools depends on the type of data you have. For example, if you are processing tabular data using Athena, you can use SQL to process data files stored in Amazon S3. If the compatibility of the dataset or compute with SQL is not the best, you can use AWS Glue to seamlessly run Spark jobs (Scala and Python support) on data stored in Amazon S3 buckets.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/data-transform-processing-with-glue-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/data-transform-processing-with-glue-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Data Transform and Processing with Glue in AWS Machine Learning" style="width:600px;"/></div><span class="image-caption">Data Transform and Processing with Glue in AWS Machine Learning</span></div><p>Below is an example architecture for a medical data lake and analytics layer on AWS. This reference architecture demonstrates how AWS services for big data and machine learning can help build a scalable analytics layer for healthcare data. Customers can store a single data source in <code>Amazon S3</code> and use <code>Athena</code> for ad-hoc analysis; integrate with data warehouses on <code>Amazon Redshift</code>; build metrics visual dashboards with <code>Amazon QuickSight</code>; and build machine learning models with <code>Amazon SageMaker </code>to predict readmission rates. Users can connect to the data without moving it and use different services to access the data, thus avoiding the creation of redundant copies of the same data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/data-transform-processing-analytics-in-aws-ml.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/data-transform-processing-analytics-in-aws-ml.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Data Transform" style="width:600px;"/></div><span class="image-caption">Data Transform</span></div>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The entire machine learning domain revolves around data. With clean data, you can gain important business insights. Data enables you to p</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Data Engineering" scheme="https://stonefishy.github.io/tags/Data-Engineering/"/>
    
  </entry>
  
  <entry>
    <title>Speech Translator base on Azure Speech Service</title>
    <link href="https://stonefishy.github.io/2025/06/19/speech-translator-base-on-azure-speech-service/"/>
    <id>https://stonefishy.github.io/2025/06/19/speech-translator-base-on-azure-speech-service/</id>
    <published>2025-06-19T15:14:38.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>Today we’re going to talk about how to build a speech translator using <code>Azure Speech Service</code> of <code>Azure AI</code> . We’ll be using the <code>JavaScript SDK</code> for the Speech Service to build the translator. We’ll using <code>Next.js</code> to build the web application.</p><h2 id="What-is-speech-translation"><a href="#What-is-speech-translation" class="headerlink" title="What is speech translation?"></a>What is speech translation?</h2><p>Speech translation is the process of translating speech from one language to another. It involves using speech recognition to convert the <code>speech to text</code>, and then using <code>text-to-speech</code> to convert the translated text back to speech. The <code>Azure AI Speech</code> provides a <code>speech to speech</code> translation service that can translate speech from one language to another. The Speech service supports <code>real-time</code>, <code>multi-language</code> speech to speech and speech to text translation of audio streams.</p><h2 id="Create-Azure-Speech-Service-resource"><a href="#Create-Azure-Speech-Service-resource" class="headerlink" title="Create Azure Speech Service resource"></a>Create Azure Speech Service resource</h2><p>In <code>Microsfot Azure</code> Cloud portal, select the <code>Speech Service</code> resource and go to the <code>AI Foundry</code> - <code>Speech service</code> management page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Select Azure Speech Service" style="width:800px;"/></div><span class="image-caption">Select Azure Speech Service</span></div><p>To create a new <code>Speech Service</code> resource is very simple, just click the <code>Create</code> button, and then fill the name, location, and pricing tier of the resource.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service-create.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service-create.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create Azure Speech Service" style="width:800px;"/></div><span class="image-caption">Create Azure Speech Service</span></div><p>Once the speech service created, you can see it in resouce list.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service-list.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Azure Speech Service List" style="width:800px;"/></div><span class="image-caption">Azure Speech Service List</span></div><p>To get the <code>key</code> and <code>endpoint</code> of the speech service, click the <code>Manage Key</code> link, it will show the <code>key</code> and <code>endpoint</code>, <code>location</code> of the speech service. The subscription <code>Key</code> and <code>Location</code> will be used to access the speech service. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-service-key.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-service-key.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Azure Speech Service Key" style="width:800px;"/></div><span class="image-caption">Azure Speech Service Key</span></div><h2 id="Play-the-Speech-Service-via-Speech-Studio"><a href="#Play-the-Speech-Service-via-Speech-Studio" class="headerlink" title="Play the Speech Service via Speech Studio"></a>Play the Speech Service via Speech Studio</h2><p>To play the speech service, you can use the <code>Speech Studio</code> tool. Just go to the <code>Speech Studio</code> page, and then click the <code>Get Started</code> button. Select the <code>Speech Translation</code> card. Let’s speech Chinese to English voice.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-studio.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-studio.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Azure Speech Studio - Speech Translation" style="width:800px;"/></div><span class="image-caption">Azure Speech Studio - Speech Translation</span></div><p>Now, our speech service is ready to use.</p><h2 id="Create-Web-applicaiton"><a href="#Create-Web-applicaiton" class="headerlink" title="Create Web applicaiton"></a>Create Web applicaiton</h2><p>To create the web application, we’ll be using <code>Next.js</code> framework. The <code>Next.js</code> is a React framework that allows us to build server-side rendered (SSR) or client-side rendered (CSR) web applications. It is a powerful framework that allows us to build fast and efficient web applications.</p><p>To create the web application, we’ll use the <code>create-next-app</code> command. Open the terminal and run the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx create-next-app@latest</span><br></pre></td></tr></table></figure><p>Let’s build a simple web application that user can access the device microphone and translate the Chinese (普通话), Cantonese (粤语) speech voice to English language voice in real-time. The UI of the web application will be simple and easy to use. Screenshots like below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-translator-ui-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-translator-ui-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Speech Translator UI - Microphone" style="width:300px;"/></div><span class="image-caption">Speech Translator UI - Microphone</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-translator-ui-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-translator-ui-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Speech Translator UI - Listening & Translation" style="width:300px;"/></div><span class="image-caption">Speech Translator UI - Listening & Translation</span></div><p>The UI is based on the <code>Tailwind CSS</code> framework. The <code>Tailwind CSS</code> is a utility-first CSS framework that allows us to build custom user interfaces with pre-defined classes. The <code>Tailwind CSS</code> framework provides a set of pre-defined classes that we can use to style our web application. The <code>Tailwind CSS</code> framework is very flexible and allows us to build custom user interfaces with pre-defined classes. Below are the <code>Tailwind CSS</code> classes that we can use to style our web application.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">main</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">geistSans.variable</span>&#125; $&#123;<span class="attr">geistMono.variable</span>&#125; <span class="attr">font-sans</span> <span class="attr">flex</span> <span class="attr">flex-col</span> <span class="attr">h-screen</span>`&#125;&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center pt-10 pb-10 gap-5&quot;</span>&gt;</span></span><br><span class="line">    &#123;OriginalLanguages.map((language) =&gt; &#123;</span><br><span class="line">      return (</span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center&quot;</span> <span class="attr">key</span>=<span class="string">&#123;language.value&#125;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">value</span>=<span class="string">&#123;language.value&#125;</span> <span class="attr">checked</span>=<span class="string">&#123;originalLanguage</span> === <span class="string">language.value&#125;</span> <span class="attr">disabled</span>=<span class="string">&#123;isRecording&#125;</span> <span class="attr">onChange</span>=<span class="string">&#123;()</span> =&gt;</span> setOriginalLanguage(language.value)&#125; name=&quot;default-radio&quot; className=&quot;w-8 h-8 text-blue-600 bg-gray-100 border-gray-30 dark:ring-offset-gray-800 dark:bg-gray-700 dark:border-gray-600&quot; /&gt;</span><br><span class="line">          <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">text-gray-400</span>&quot; <span class="attr">:</span> &quot;<span class="attr">text-gray-900</span>&quot;&#125; <span class="attr">ms-2</span> <span class="attr">text-2xl</span> <span class="attr">font-medium</span> <span class="attr">dark:text-gray-300</span>`&#125;&gt;</span>&#123;language.label&#125;<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      )</span><br><span class="line">    &#125;)&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center flex-auto pb-20&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">hidden</span>&quot; <span class="attr">:</span> &quot;<span class="attr">block</span>&quot;&#125; <span class="attr">flex</span> <span class="attr">items-center</span> <span class="attr">justify-center</span> <span class="attr">rounded-full</span> <span class="attr">size-64</span> <span class="attr">bg-blue-200</span> <span class="attr">mx-auto</span> <span class="attr">cursor-pointer</span> <span class="attr">hover:bg-blue-300</span> <span class="attr">transition-colors</span>`&#125;</span></span><br><span class="line"><span class="tag">    <span class="attr">onClick</span>=<span class="string">&#123;startRecording&#125;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-blue-400 hover:bg-blue-500 transition-colors&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/microphone.svg&quot;</span>  <span class="attr">alt</span>=<span class="string">&quot;Microphone&quot;</span> <span class="attr">className</span>=<span class="string">&quot;size-24&quot;</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">block</span>&quot; <span class="attr">:</span> &quot;<span class="attr">hidden</span>&quot;&#125; <span class="attr">flex-col</span> <span class="attr">items-center</span> <span class="attr">justify-center</span>`&#125;&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-64 bg-red-200 mx-auto cursor-pointer hover:bg-red-300 transition-colors&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">onClick</span>=<span class="string">&#123;stopRecording&#125;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-red-400 hover:bg-red-500 transition-colors&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;w-16 h-16 bg-white animate-pulse&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center mt-2&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;block w-64 items-center justify-start text-xl&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/speech.svg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;voice&quot;</span> <span class="attr">className</span>=<span class="string">&quot;inline-block ml-12 size-12&quot;</span> /&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block text-center font-medium ml-2&quot;</span>&gt;</span>Listening <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block font-medium&quot;</span>&gt;</span>&#123;listenLoading&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">main</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Integrated-with-Azure-Speech-Service"><a href="#Integrated-with-Azure-Speech-Service" class="headerlink" title="Integrated with Azure Speech Service"></a>Integrated with Azure Speech Service</h2><p>The <code>Azure Speech Service</code> provides multiple language SDKs, including <code>JavaScript</code>, <code>Go</code>, <code>C#</code>, <code>Python</code>, <code>Java</code>, <code>Swift</code>, <code>Objective-C</code>, and <code>C++</code>. You can access this speech SDK link <a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-sdk">https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-sdk</a>. We’ll be using the <code>JavaScript</code> SDK to integrate with the speech service.</p><p>To install the <code>JavaScript</code> SDK, we’ll use the <code>npm</code> command. Open the terminal and run the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install microsoft-cognitiveservices-speech-sdk</span><br></pre></td></tr></table></figure><p>Accessing the device microhpone, we can use <code>navigator.mediaDevices.getUserMedia()</code> method. The <code>getUserMedia()</code> method returns a <code>Promise</code> that resolves with a <code>MediaStream</code> object representing the captured media. We can then pass this <code>MediaStream</code> object to the <code>SpeechSDK.AudioConfig</code> object to create a <code>SpeechSDK.AudioConfig</code> object that represents the audio input device.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">requestMicrophoneAccess</span> = (<span class="params">callback</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (navigator.<span class="property">mediaDevices</span> &amp;&amp; navigator.<span class="property">mediaDevices</span>.<span class="property">getUserMedia</span>) &#123;</span><br><span class="line">      navigator.<span class="property">mediaDevices</span>.<span class="title function_">getUserMedia</span>(&#123; <span class="attr">audio</span>: <span class="literal">true</span> &#125;)</span><br><span class="line">        .<span class="title function_">then</span>(<span class="function">(<span class="params">stream</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Microphone access granted.&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> speechConfig = <span class="title class_">SpeechSDK</span>.<span class="property">SpeechTranslationConfig</span>.<span class="title function_">fromSubscription</span>(config.<span class="property">SPEECH_SUBSCRIPTION_KEY</span>, config.<span class="property">SPEECH_SERVICE_REGION</span>);</span><br><span class="line">          speechConfig.<span class="property">outputFormat</span> = <span class="title class_">SpeechSDK</span>.<span class="property">OutputFormat</span>.<span class="property">Detailed</span>;</span><br><span class="line">          speechConfig.<span class="property">speechRecognitionLanguage</span> = originalLanguage;</span><br><span class="line">          speechConfig.<span class="title function_">addTargetLanguage</span>(<span class="title class_">TargetLanguage</span>);</span><br><span class="line">          speechConfig.<span class="title function_">setProperty</span>(<span class="title class_">SpeechSDK</span>.<span class="property">PropertyId</span>.<span class="property">SpeechServiceConnection_TranslationVoice</span>, <span class="string">&quot;en-US-JennyNeural&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> audioConfig = <span class="title class_">SpeechSDK</span>.<span class="property">AudioConfig</span>.<span class="title function_">fromStreamInput</span>(stream);</span><br><span class="line">          <span class="keyword">const</span> recognizer = <span class="keyword">new</span> <span class="title class_">SpeechSDK</span>.<span class="title class_">TranslationRecognizer</span>(speechConfig, audioConfig);</span><br><span class="line">          recognizer.<span class="property">recognizing</span> = speechRecognizing;</span><br><span class="line">          recognizer.<span class="property">recognized</span> = speechRecognized;</span><br><span class="line">          recognizer.<span class="property">synthesizing</span> = speechSynthesizing;</span><br><span class="line">          callback &amp;&amp; <span class="title function_">callback</span>(recognizer);</span><br><span class="line">        &#125;)</span><br><span class="line">        .<span class="title function_">catch</span>(<span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Error accessing microphone:&quot;</span>, error);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;getUserMedia is not supported in this browser.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, we are using the <code>SpeechTranslationConfig</code> object to configure the speech translation service. We are setting the <code>outputFormat</code> to <code>Detailed</code> to get the detailed translation result. We are setting the <code>speechRecognitionLanguage</code> to the original language and the <code>addTargetLanguage</code> to the target language. We are setting the <code>SpeechServiceConnection_TranslationVoice</code> property to <code>en-US-JennyNeural</code> to get the neural voice for the target language. We are creating a <code>SpeechSDK.AudioConfig</code> object from the <code>MediaStream</code> object and passing it to the <code>SpeechSDK.TranslationRecognizer</code> object, and setting the <code>recognizing</code>, <code>recognized</code>, and <code>synthesizing</code> event handlers to get the translation result.</p><p>The <code>config.SPEECH_SUBSCRIPTION_KEY</code> and <code>config.SPEECH_SERVICE_REGION</code> are the subscription key and region for the speech service. We are using these values to configure the speech translation service.</p><p>The <code>recognizing</code> event handler is called when the speech service is processing the audio input, and the <code>recognized</code> event handler is called when the speech service has recognized the speech input. The <code>synthesizing</code> event handler is called when the speech service is synthesizing the translated text to speech.</p><p>Below are these event handlers.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">speechRecognizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognizing: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">speechRecognized</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">RecognizedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">TranslatedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Translate Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">NoMatch</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;No speech could be recognized.&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">Canceled</span>) &#123;</span><br><span class="line">      <span class="keyword">const</span> cancellation = <span class="title class_">SpeechSDK</span>.<span class="property">CancellationDetails</span>.<span class="title function_">fromResult</span>(e.<span class="property">result</span>);</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: Reason=<span class="subst">$&#123;cancellation.reason&#125;</span>`</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (cancellation.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">CancellationReason</span>.<span class="property">Error</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorCode=<span class="subst">$&#123;cancellation.errorCode&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorDetails=<span class="subst">$&#123;cancellation.errorDetails&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;CANCELED: Did you set the speech resource key and region values?&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">speechSynthesizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> audioSize = e.<span class="property">result</span>.<span class="property">audio</span> === <span class="literal">undefined</span> ? <span class="number">0</span> : e.<span class="property">result</span>.<span class="property">audio</span>.<span class="property">byteLength</span>;</span><br><span class="line">    <span class="keyword">var</span> text =<span class="string">&quot;&quot;</span>;</span><br><span class="line">    text += <span class="string">`(synthesizing) Reason: <span class="subst">$&#123;SpeechSDK.ResultReason[e.result.reason]&#125;</span>`</span></span><br><span class="line">        + <span class="string">` <span class="subst">$&#123;audioSize&#125;</span> bytes\r\n`</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">audio</span> &amp;&amp; soundContext) &#123;</span><br><span class="line">        <span class="keyword">var</span> source = soundContext.<span class="title function_">createBufferSource</span>();</span><br><span class="line">        soundContext.<span class="title function_">decodeAudioData</span>(e.<span class="property">result</span>.<span class="property">audio</span>, <span class="keyword">function</span> (<span class="params">newBuffer</span>) &#123;</span><br><span class="line">            source.<span class="property">buffer</span> = newBuffer;</span><br><span class="line">            source.<span class="title function_">connect</span>(soundContext.<span class="property">destination</span>);</span><br><span class="line">            source.<span class="title function_">start</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In <code>synthesizing</code> event handler, we are logging the <code>ResultReason</code> and the audio size. If the <code>audio</code> property is not <code>undefined</code>, we are decoding the <code>audio</code> data and playing it using the <code>Web Audio API</code>.</p><p>The above <code>soundContext</code> is a global variable that we are using to play the audio. We can create the <code>soundContext</code> object using the <code>AudioContext</code> constructor. Below is the code to create the <code>soundContext</code> object.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">getSoundContext</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">var</span> soundContext = <span class="literal">undefined</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> <span class="title class_">AudioContext</span> = <span class="variable language_">window</span>.<span class="property">AudioContext</span> || <span class="variable language_">window</span>.<span class="property">webkitAudioContext</span> || <span class="literal">false</span>;                          </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="title class_">AudioContext</span>) &#123;</span><br><span class="line">        soundContext = <span class="keyword">new</span> <span class="title class_">AudioContext</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Audio context not supported&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;no sound context found, no audio output. &quot;</span> + e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> soundContext;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> soundContext = <span class="title function_">getSoundContext</span>();</span><br></pre></td></tr></table></figure><h2 id="Play-it"><a href="#Play-it" class="headerlink" title="Play it"></a>Play it</h2><p>Now, we can run the web application using the <code>npm run dev</code> command. Open the web browser and go to <code>http://localhost:3000</code>. You should see the web application with the microphone icon. Click the microphone icon to start recording the speech. Speak Chinese Mandarin, Cantonese speech voice and the web application will translate the speech to English language voice in real-time.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-speech-translator-demo.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-speech-translator-demo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Speech Translator Demo" style="width:800px;"/></div><span class="image-caption">Speech Translator Demo</span></div><p>In above screenshot, it is recognize the speech to the text and we print it in console log. Once speech recognized. It is translated to English language voice and played in the web application.</p><p>Below are major code in <code>index.js</code> for <code>Azure Speech Translator</code>. It is simple to using <code>Azure Speech Service</code> to do the continous <code>Speech Translation</code> in real-time.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123; useState, useEffect &#125; <span class="keyword">from</span> <span class="string">&quot;react&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Geist</span>, <span class="title class_">Geist</span>_Mono &#125; <span class="keyword">from</span> <span class="string">&quot;next/font/google&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> <span class="title class_">SpeechSDK</span> <span class="keyword">from</span> <span class="string">&quot;microsoft-cognitiveservices-speech-sdk&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> config <span class="keyword">from</span> <span class="string">&quot;../config&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> geistSans = <span class="title class_">Geist</span>(&#123;</span><br><span class="line">  <span class="attr">variable</span>: <span class="string">&quot;--font-geist-sans&quot;</span>,</span><br><span class="line">  <span class="attr">subsets</span>: [<span class="string">&quot;latin&quot;</span>],</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> geistMono = <span class="title class_">Geist</span>_Mono(&#123;</span><br><span class="line">  <span class="attr">variable</span>: <span class="string">&quot;--font-geist-mono&quot;</span>,</span><br><span class="line">  <span class="attr">subsets</span>: [<span class="string">&quot;latin&quot;</span>],</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">TargetLanguage</span> = <span class="string">&quot;en-US&quot;</span>; <span class="comment">// &quot;en-US&quot;</span></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">OriginalLanguages</span> = [&#123;</span><br><span class="line">  <span class="attr">label</span>: <span class="string">&#x27;Mandarin&#x27;</span>,</span><br><span class="line">  <span class="attr">value</span>: <span class="string">&#x27;zh-CN&#x27;</span>,</span><br><span class="line">&#125;, &#123;</span><br><span class="line">  <span class="attr">label</span>: <span class="string">&quot;Cantonese&quot;</span>,</span><br><span class="line">  <span class="attr">value</span>: <span class="string">&quot;yue-cn&quot;</span>,</span><br><span class="line">&#125;];</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">getSoundContext</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">var</span> soundContext = <span class="literal">undefined</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> <span class="title class_">AudioContext</span> = <span class="variable language_">window</span>.<span class="property">AudioContext</span> || <span class="variable language_">window</span>.<span class="property">webkitAudioContext</span> || <span class="literal">false</span>;                          </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="title class_">AudioContext</span>) &#123;</span><br><span class="line">        soundContext = <span class="keyword">new</span> <span class="title class_">AudioContext</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Audio context not supported&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;no sound context found, no audio output. &quot;</span> + e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> soundContext;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> soundContext = <span class="title function_">getSoundContext</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Home</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [isRecording, setIsRecording] = <span class="title function_">useState</span>(<span class="literal">false</span>);</span><br><span class="line">  <span class="keyword">const</span> [speechRecognizer, setSpeechRecognizer] = <span class="title function_">useState</span>(<span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">const</span> [originalLanguage, setOriginalLanguage] = <span class="title function_">useState</span>(<span class="string">&#x27;zh-CN&#x27;</span>);</span><br><span class="line">  <span class="keyword">const</span> [listenLoading, setlistenLoading] = <span class="title function_">useState</span>(<span class="string">&quot;...&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">startRecording</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="title function_">requestMicrophoneAccess</span>(<span class="function">(<span class="params">recognizer</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="title function_">setSpeechRecognizer</span>(recognizer);</span><br><span class="line">      <span class="title function_">setIsRecording</span>(<span class="literal">true</span>);</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Microphone access granted, starting recognition...&quot;</span>);</span><br><span class="line"></span><br><span class="line">      recognizer.<span class="title function_">startContinuousRecognitionAsync</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Continuous recognition started.&quot;</span>);</span><br><span class="line">      &#125;, <span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">stopRecording</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (speechRecognizer !== <span class="literal">null</span>) &#123;</span><br><span class="line">      speechRecognizer.<span class="title function_">stopContinuousRecognitionAsync</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Continuous recognition stopped.&quot;</span>);</span><br><span class="line">        <span class="title function_">setIsRecording</span>(<span class="literal">false</span>);</span><br><span class="line">      &#125;, <span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">requestMicrophoneAccess</span> = (<span class="params">callback</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (navigator.<span class="property">mediaDevices</span> &amp;&amp; navigator.<span class="property">mediaDevices</span>.<span class="property">getUserMedia</span>) &#123;</span><br><span class="line">      navigator.<span class="property">mediaDevices</span>.<span class="title function_">getUserMedia</span>(&#123; <span class="attr">audio</span>: <span class="literal">true</span> &#125;)</span><br><span class="line">        .<span class="title function_">then</span>(<span class="function">(<span class="params">stream</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Microphone access granted.&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> speechConfig = <span class="title class_">SpeechSDK</span>.<span class="property">SpeechTranslationConfig</span>.<span class="title function_">fromSubscription</span>(config.<span class="property">SPEECH_SUBSCRIPTION_KEY</span>, config.<span class="property">SPEECH_SERVICE_REGION</span>);</span><br><span class="line">          speechConfig.<span class="property">outputFormat</span> = <span class="title class_">SpeechSDK</span>.<span class="property">OutputFormat</span>.<span class="property">Detailed</span>;</span><br><span class="line">          speechConfig.<span class="property">speechRecognitionLanguage</span> = originalLanguage;</span><br><span class="line">          speechConfig.<span class="title function_">addTargetLanguage</span>(<span class="title class_">TargetLanguage</span>);</span><br><span class="line">          speechConfig.<span class="title function_">setProperty</span>(<span class="title class_">SpeechSDK</span>.<span class="property">PropertyId</span>.<span class="property">SpeechServiceConnection_TranslationVoice</span>, <span class="string">&quot;en-US-JennyNeural&quot;</span>);</span><br><span class="line">          <span class="keyword">const</span> audioConfig = <span class="title class_">SpeechSDK</span>.<span class="property">AudioConfig</span>.<span class="title function_">fromStreamInput</span>(stream);</span><br><span class="line">          <span class="keyword">const</span> recognizer = <span class="keyword">new</span> <span class="title class_">SpeechSDK</span>.<span class="title class_">TranslationRecognizer</span>(speechConfig, audioConfig);</span><br><span class="line">          recognizer.<span class="property">recognizing</span> = speechRecognizing;</span><br><span class="line">          recognizer.<span class="property">recognized</span> = speechRecognized;</span><br><span class="line">          recognizer.<span class="property">synthesizing</span> = speechSynthesizing;</span><br><span class="line">          callback &amp;&amp; <span class="title function_">callback</span>(recognizer);</span><br><span class="line">        &#125;)</span><br><span class="line">        .<span class="title function_">catch</span>(<span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;Error accessing microphone:&quot;</span>, error);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&quot;getUserMedia is not supported in this browser.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">speechRecognizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognizing: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">speechRecognized</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">RecognizedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">TranslatedSpeech</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Translate Recognized: <span class="subst">$&#123;e.result.text&#125;</span>`</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">NoMatch</span>) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;No speech could be recognized.&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">ResultReason</span>.<span class="property">Canceled</span>) &#123;</span><br><span class="line">      <span class="keyword">const</span> cancellation = <span class="title class_">SpeechSDK</span>.<span class="property">CancellationDetails</span>.<span class="title function_">fromResult</span>(e.<span class="property">result</span>);</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: Reason=<span class="subst">$&#123;cancellation.reason&#125;</span>`</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (cancellation.<span class="property">reason</span> === <span class="title class_">SpeechSDK</span>.<span class="property">CancellationReason</span>.<span class="property">Error</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorCode=<span class="subst">$&#123;cancellation.errorCode&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`CANCELED: ErrorDetails=<span class="subst">$&#123;cancellation.errorDetails&#125;</span>`</span>);</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;CANCELED: Did you set the speech resource key and region values?&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="title function_">speechSynthesizing</span> = (<span class="params">s, e</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> audioSize = e.<span class="property">result</span>.<span class="property">audio</span> === <span class="literal">undefined</span> ? <span class="number">0</span> : e.<span class="property">result</span>.<span class="property">audio</span>.<span class="property">byteLength</span>;</span><br><span class="line">    <span class="keyword">var</span> text =<span class="string">&quot;&quot;</span>;</span><br><span class="line">    text += <span class="string">`(synthesizing) Reason: <span class="subst">$&#123;SpeechSDK.ResultReason[e.result.reason]&#125;</span>`</span></span><br><span class="line">        + <span class="string">` <span class="subst">$&#123;audioSize&#125;</span> bytes\r\n`</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">result</span>.<span class="property">audio</span> &amp;&amp; soundContext) &#123;</span><br><span class="line">        <span class="keyword">var</span> source = soundContext.<span class="title function_">createBufferSource</span>();</span><br><span class="line">        soundContext.<span class="title function_">decodeAudioData</span>(e.<span class="property">result</span>.<span class="property">audio</span>, <span class="keyword">function</span> (<span class="params">newBuffer</span>) &#123;</span><br><span class="line">            source.<span class="property">buffer</span> = newBuffer;</span><br><span class="line">            source.<span class="title function_">connect</span>(soundContext.<span class="property">destination</span>);</span><br><span class="line">            source.<span class="title function_">start</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isRecording) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> listening = <span class="built_in">setInterval</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (isRecording) &#123;</span><br><span class="line">        <span class="title function_">setlistenLoading</span>(<span class="function">(<span class="params">prev</span>) =&gt;</span> prev.<span class="property">length</span> &lt; <span class="number">5</span> ? prev + <span class="string">&quot;.&quot;</span> : <span class="string">&quot;&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, <span class="number">700</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="function">() =&gt;</span> <span class="built_in">clearInterval</span>(listening);</span><br><span class="line">  &#125;, [isRecording]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">main</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">geistSans.variable</span>&#125; $&#123;<span class="attr">geistMono.variable</span>&#125; <span class="attr">font-sans</span> <span class="attr">flex</span> <span class="attr">flex-col</span> <span class="attr">h-screen</span>`&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center pt-10 pb-10 gap-5&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        &#123;OriginalLanguages.map((language) =&gt; &#123;</span></span><br><span class="line"><span class="language-xml">          return (</span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center&quot;</span> <span class="attr">key</span>=<span class="string">&#123;language.value&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">value</span>=<span class="string">&#123;language.value&#125;</span> <span class="attr">checked</span>=<span class="string">&#123;originalLanguage</span> === <span class="string">language.value&#125;</span> <span class="attr">disabled</span>=<span class="string">&#123;isRecording&#125;</span> <span class="attr">onChange</span>=<span class="string">&#123;()</span> =&gt;</span> setOriginalLanguage(language.value)&#125; name=&quot;default-radio&quot; className=&quot;w-8 h-8 text-blue-600 bg-gray-100 border-gray-30 dark:ring-offset-gray-800 dark:bg-gray-700 dark:border-gray-600&quot; /&gt;</span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&#123;</span>`<span class="attr">radio-</span>$&#123;<span class="attr">language.value</span>&#125;`&#125; <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">text-gray-400</span>&quot; <span class="attr">:</span> &quot;<span class="attr">text-gray-900</span>&quot;&#125; <span class="attr">ms-2</span> <span class="attr">text-2xl</span> <span class="attr">font-medium</span> <span class="attr">dark:text-gray-300</span>`&#125;&gt;</span>&#123;language.label&#125;<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          )</span></span><br><span class="line"><span class="language-xml">        &#125;)&#125;</span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center flex-auto pb-20&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">hidden</span>&quot; <span class="attr">:</span> &quot;<span class="attr">block</span>&quot;&#125; <span class="attr">flex</span> <span class="attr">items-center</span> <span class="attr">justify-center</span> <span class="attr">rounded-full</span> <span class="attr">size-64</span> <span class="attr">bg-blue-200</span> <span class="attr">mx-auto</span> <span class="attr">cursor-pointer</span> <span class="attr">hover:bg-blue-300</span> <span class="attr">transition-colors</span>`&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">onClick</span>=<span class="string">&#123;startRecording&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-blue-400 hover:bg-blue-500 transition-colors&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/microphone.svg&quot;</span>  <span class="attr">alt</span>=<span class="string">&quot;Microphone&quot;</span> <span class="attr">className</span>=<span class="string">&quot;size-24&quot;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&#123;</span>`$&#123;<span class="attr">isRecording</span>? &quot;<span class="attr">block</span>&quot; <span class="attr">:</span> &quot;<span class="attr">hidden</span>&quot;&#125; <span class="attr">flex-col</span> <span class="attr">items-center</span> <span class="attr">justify-center</span>`&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-64 bg-red-200 mx-auto cursor-pointer hover:bg-red-300 transition-colors&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">onClick</span>=<span class="string">&#123;stopRecording&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center rounded-full size-48 bg-red-400 hover:bg-red-500 transition-colors&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;w-16 h-16 bg-white animate-pulse&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;flex items-center justify-center mt-2&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;block w-64 items-center justify-start text-xl&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/speech.svg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;voice&quot;</span> <span class="attr">className</span>=<span class="string">&quot;inline-block ml-12 size-12&quot;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block text-center font-medium ml-2&quot;</span>&gt;</span>Listening <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">p</span> <span class="attr">className</span>=<span class="string">&quot;inline-block font-medium&quot;</span>&gt;</span>&#123;listenLoading&#125;<span class="tag">&lt;/<span class="name">p</span>&gt;</span>  </span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">main</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The <code>Speech Service</code> of <code>Azure AI</code> is a cloud-based service that provides speech recognition and speech synthesis capabilities. It is a part of <code>Azure AI</code> suite. We can use it to build speech-enabled applications, such as speech-to-text, text-to-speech, and speech translation.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Today we’re going to talk about how to build a speech translator using &lt;code&gt;Azure Speech Service&lt;/code&gt; of &lt;code&gt;Azure AI&lt;/code&gt; . We’ll</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="Next.js" scheme="https://stonefishy.github.io/tags/Next-js/"/>
    
    <category term="Tailwind" scheme="https://stonefishy.github.io/tags/Tailwind/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Generative AI Tools</title>
    <link href="https://stonefishy.github.io/2025/05/11/introduction-to-generative-ai-tools/"/>
    <id>https://stonefishy.github.io/2025/05/11/introduction-to-generative-ai-tools/</id>
    <published>2025-05-11T15:27:34.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction-to-Generative-AI-Tools"><a href="#Introduction-to-Generative-AI-Tools" class="headerlink" title="Introduction to Generative AI Tools"></a>Introduction to Generative AI Tools</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-intro.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-intro.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Generative AI Tools" style="width:500px;"/></div><span class="image-caption">Generative AI Tools</span></div><p>Generative AI tools are revolutionizing the way content is created by leveraging advanced machine learning models. These tools enable users to generate <code>text</code>, <code>images</code>, <code>videos</code>, and more, offering innovative solutions across various industries.</p><h2 id="Popular-Generative-AI-Tools"><a href="#Popular-Generative-AI-Tools" class="headerlink" title="Popular Generative AI Tools"></a>Popular Generative AI Tools</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-popular.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-popular.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Popular Generative AI Tools" style="width:800px;"/></div><span class="image-caption">Popular Generative AI Tools</span></div><p>Several generative AI tools are widely used across industries. Tools like <code>ChatGPT</code> and <code>Jasper</code> are popular for generating human-like text, while platforms like <code>DALL·E</code> and <code>Midjourney</code> excel in creating stunning visuals based on textual descriptions.</p><p>Other tools, such as <code>Runway</code> for video creation and <code>ElevenLabs</code> for AI-generated voices, showcase the versatility of generative AI. These tools simplify complex tasks, making them accessible to professionals and non-experts alike.</p><h3 id="AI-Tools-for-Text-Generation"><a href="#AI-Tools-for-Text-Generation" class="headerlink" title="AI Tools for Text Generation"></a>AI Tools for Text Generation</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-text.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-text.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Text Generation AI Tools" style="width:800px;"/></div><span class="image-caption">Text Generation AI Tools</span></div><p>Generative AI tools for text creation include platforms like <code>Jasper</code> and <code>Anyword</code>, which assist in crafting marketing content and sales copy. These tools leverage advanced machine learning algorithms to produce human-like text tailored to specific audiences and purposes.</p><p><code>Quillbot</code> is another example, offering paraphrasing and summarization features that enhance writing efficiency. Such tools are widely used in industries ranging from education to marketing, streamlining workflows and boosting productivity.</p><h3 id="AI-Tools-for-Image-Creation"><a href="#AI-Tools-for-Image-Creation" class="headerlink" title="AI Tools for Image Creation"></a>AI Tools for Image Creation</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-image.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-image.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Image Generation AI Tools" style="width:800px;"/></div><span class="image-caption">Image Generation AI Tools</span></div><p>Generative AI tools like <code>DALL·E 3</code> and <code>Midjourney</code> are revolutionizing image creation by generating high-quality visuals from textual descriptions. These tools are ideal for creating unique artwork, marketing materials, and design prototypes.</p><p><code>Adobe Photoshop</code> also incorporates AI features for enhancing images, such as automated background removal and content-aware editing. These tools empower users to produce professional-grade visuals with minimal effort.</p><h3 id="Video-And-Audio-Generation-Platforms"><a href="#Video-And-Audio-Generation-Platforms" class="headerlink" title="Video And Audio Generation Platforms"></a>Video And Audio Generation Platforms</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-audio-video.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-audio-video.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Audio and Video Generation AI Tools" style="width:800px;"/></div><span class="image-caption">Audio and Video Generation AI Tools</span></div><p><code>Runway</code> and <code>Wondershare Filmora</code> are popular generative AI tools for video creation, enabling users to produce creative and polished videos effortlessly. These platforms offer features like automated editing, special effects, and AI-driven enhancements.</p><p>For audio, <code>ElevenLabs</code> provides an extensive library of AI-generated voices, while <code>Suno</code> specializes in music generation. These tools are transforming the way multimedia content is created, making it accessible to professionals and hobbyists alike.</p><h2 id="Applications-Across-Industries"><a href="#Applications-Across-Industries" class="headerlink" title="Applications Across Industries"></a>Applications Across Industries</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-industries.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-industries.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Generative AI Tools for Industries" style="width:800px;"/></div><span class="image-caption">Generative AI Tools for Industries</span></div><p>Generative AI tools have diverse applications, from creating personalized marketing content to designing immersive <code>gaming</code> environments. In <code>healthcare</code>, these tools assist in generating synthetic data for research and training purposes.</p><p>In <code>education</code>, generative AI enhances learning experiences by creating tailored materials and automating grading. The technology’s adaptability ensures its relevance across various sectors, driving innovation and efficiency.</p><h3 id="Applications-in-Content-Generation"><a href="#Applications-in-Content-Generation" class="headerlink" title="Applications in Content Generation"></a>Applications in Content Generation</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-applications.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-applications.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="20 Best AI Tools for Content Creation" style="width:800px;"/></div><span class="image-caption">20 Best AI Tools for Content Creation</span></div><p>Generative AI tools are widely used in content creation to streamline processes and enhance creativity. For instance, tools like <code>Jasper</code> and <code>DALL·E 3</code> enable marketers to craft engaging campaigns with minimal manual effort.</p><p>In education, generative AI helps create personalized learning materials and automate grading. These applications demonstrate the versatility of generative AI in addressing diverse content needs across industries.</p><h2 id="Selecting-the-Right-Tool"><a href="#Selecting-the-Right-Tool" class="headerlink" title="Selecting the Right Tool"></a>Selecting the Right Tool</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-ai-tool-choose.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-ai-tool-choose.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Selecting the Right Generative AI Tool" style="width:800px;"/></div><span class="image-caption">Selecting the Right Generative AI Tool</span></div><p>Choosing the right generative AI tool depends on your specific needs and objectives. <span class='pbg sucess'>Consider factors such as the type of content you want to create</span></p><p>For instance, tools like <code>Jasper</code> are ideal for marketing professionals, while <code>DALL·E</code> suits designers seeking AI-generated visuals. Evaluating the tool’s features and limitations ensures optimal results for your projects.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p><code>Generative AI</code> tools are transforming industries by enabling the creation of innovative and personalized content. By understanding their capabilities and applications, users can harness these tools to enhance creativity and streamline workflows.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction-to-Generative-AI-Tools&quot;&gt;&lt;a href=&quot;#Introduction-to-Generative-AI-Tools&quot; class=&quot;headerlink&quot; title=&quot;Introduction to Genera</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="Tools" scheme="https://stonefishy.github.io/tags/Tools/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Generative AI" scheme="https://stonefishy.github.io/tags/Generative-AI/"/>
    
  </entry>
  
  <entry>
    <title>Traditional Programming vs Artificial Intelligence</title>
    <link href="https://stonefishy.github.io/2025/05/03/traditional-programming-vs-artificial-intelligence/"/>
    <id>https://stonefishy.github.io/2025/05/03/traditional-programming-vs-artificial-intelligence/</id>
    <published>2025-05-03T15:56:55.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Traditional Programming</strong> relies on <code>algorithms</code> and <code>code</code> and is restricted to the limitations defined by the programmer. It follows <code>rules</code> and <code>logic</code>, making it ideal for problems with clear guidelines and well-defined logic.</p><p><strong>Artificial Intelligence (AI)</strong> is <code>data-driven</code> and learns from examples by <code>training</code> itself. AI relies on <code>large datasets</code> to identify patterns, make predictions, and make real-time decisions based on its <code>analysis of historical data</code>.</p><h2 id="Key-Differences-Between-AI-and-Traditional-Programming"><a href="#Key-Differences-Between-AI-and-Traditional-Programming" class="headerlink" title="Key Differences Between AI and Traditional Programming"></a>Key Differences Between AI and Traditional Programming</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ai-vs-traditional-programming.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ai-vs-traditional-programming.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Traditional Programming vs Artificial Intelligence" style="width:800px;"/></div><span class="image-caption">Traditional Programming vs Artificial Intelligence</span></div><h3 id="Key-Differences-in-Outputs"><a href="#Key-Differences-in-Outputs" class="headerlink" title="Key Differences in Outputs"></a>Key Differences in Outputs</h3><p>Conventional programming produces reliable and <code>expected results</code>, delivering the <code>identical output</code> for the same input. This characteristic makes them perfect for activities demanding total accuracy, like mathematical computations or established procedures.</p><p>Conversely, AI outputs depend on <code>probabilities</code> and <code>patterns</code> that come from data. They are employed in situations characterized by uncertainty or variability, such as forecasting customer behavior or predicting the weather.</p><h3 id="When-to-Use-Traditional-Programming"><a href="#When-to-Use-Traditional-Programming" class="headerlink" title="When to Use Traditional Programming"></a>When to Use Traditional Programming</h3><p><strong>Traditional programming</strong> models are particularly <code>well-suited for scenarios where precision and consistency are crucial</code>. These models find their primary applications in fields such as <code>financial computations</code>, <code>engineering simulations</code>, and <code>software development</code> tailored for specific tasks.</p><p>Furthermore, these programming approaches are favored in situations where the <code>logic</code> and <code>rules</code> are clearly articulated and well-defined. They provide developers with the ability to meticulously control every step of the development process, which not only enhances the reliability of the final product but also simplifies the debugging process. This level of control is critical in ensuring that the applications function correctly and meet the high standards expected in various industries.</p><h3 id="When-to-Use-AI"><a href="#When-to-Use-AI" class="headerlink" title="When to Use AI"></a>When to Use AI</h3><p><strong>AI models</strong> are particularly adept at managing <code>complex and data-driven scenarios where outcomes are not predetermined</code>. AI solutions have been applied extensively across various fields, including <code>healthcare</code> for <code>predicting disease outbreaks</code>, <code>finance</code> for conducting thorough risk assessments, and <code>marketing</code> for effectively segmenting customers.</p><p>These advanced models utilize historical data to generate informed <code>predictions</code>, continuously learning and adapting to emerging new <code>patterns</code> and <code>trends</code>. This capacity for flexibility and evolution is what makes AI models especially invaluable in dynamic and uncertain environments where conditions frequently change and new challenges arise. Their ability to process and analyze vast amounts of data enables organizations to make informed decisions, mitigate risks, and optimize outcomes in a rapidly changing world.</p><h3 id="Advantages-and-Limitaitons-of-Each"><a href="#Advantages-and-Limitaitons-of-Each" class="headerlink" title="Advantages and Limitaitons of Each"></a>Advantages and Limitaitons of Each</h3><p><strong>Traditional programming</strong> models are praised for their <code>precision</code> and <code>simplicity</code>, which facilitate easy understanding and debugging. However, they struggle with flexibility, making it challenging to adapt to varying inputs and changing requirements.</p><p>In contrast, <strong>AI solutions</strong> excel at handling <code>complex</code>, <code>variable data</code> and can <code>learn</code> from new information, enabling greater adaptability and responsiveness. This inherent flexibility of AI comes at the cost of increased complexity in understanding and debugging compared to traditional programming.</p><p><strong>AI solutions</strong> can analyze vast datasets and uncover hidden patterns, enabling informed decision-making. However, <span class='pbg danger'>the effectiveness of AI is heavily dependent on the `quality and quantity of data` available</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Traditional Programming&lt;/strong&gt; relies on &lt;code&gt;algorithms&lt;/code&gt; and &lt;code&gt;code&lt;/code&gt; and is restricted to the limitations def</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>The difference of set cookie in Tomcat and Jetty</title>
    <link href="https://stonefishy.github.io/2025/04/25/the-difference-of-set-cookie-in-tomcat-and-jetty/"/>
    <id>https://stonefishy.github.io/2025/04/25/the-difference-of-set-cookie-in-tomcat-and-jetty/</id>
    <published>2025-04-25T17:42:11.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>In previous blog <a href="https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/">Switching Tomcat with Jetty in Spring Boot Easily</a>, to resolve the spring boot 2 tomcat security issue in short time, we switching <code>Tomcat</code> with <code>Jetty</code> in Spring Boot. We found there is a difference by set cookie handling between <code>Tomcat</code> and <code>Jetty</code> by default. Let’s first talk about the cookie.</p><h2 id="What-is-cookie"><a href="#What-is-cookie" class="headerlink" title="What is cookie?"></a>What is cookie?</h2><p>A cookie is a small piece of data that is stored on the user’s computer by the web server. It is used to store user preferences, login information, and other information that the user wants to be remembered. The cookie is sent to the user’s browser when the user makes a request to the web server. The browser then sends it back to the web server with subsequent requests.</p><h2 id="Cookie-Attributes"><a href="#Cookie-Attributes" class="headerlink" title="Cookie Attributes"></a>Cookie Attributes</h2><p>There are several attributes that can be set for a cookie:</p><ul><li><code>Domain</code>: The domain attribute specifies the domain for which the cookie is valid. If the domain is not specified, the cookie is valid for the entire domain.</li><li><code>Path</code>: The path attribute specifies the path on the server where the cookie is valid. If the path is not specified, the cookie is valid for the entire path.</li><li><code>Max-Age</code>: The max-age attribute specifies the maximum age of the cookie in seconds. If the max-age is not specified, the cookie is valid until the browser is closed.</li><li><code>Expires</code>: The expires attribute specifies the expiration date of the cookie. If the expires attribute is not specified, the cookie is valid until the browser is closed.</li><li><code>Secure</code>: The secure attribute specifies that the cookie should only be sent over HTTPS connections.</li><li><code>HttpOnly</code>: The httpOnly attribute specifies that the cookie should not be accessible to client-side scripts.</li><li><code>SameSite</code>: The sameSite attribute specifies whether the cookie should be sent with cross-site requests. The sameSite attribute can have the following values: <code>Strict</code>, <code>Lax</code>, or <code>None</code>.</li></ul><p>When <code>Max-Age</code> and <code>Expires</code> are not specified, the cookie is valid until the browser is closed. If <code>Max-Age</code> is specified, the cookie is valid for the specified number of seconds. If <code>Expires</code> is specified, the cookie is valid until the specified date. If both <code>Max-Age</code> and <code>Expires</code> are specified, the cookie is valid for the minimum of the two values.</p><h2 id="Set-Cookie-in-Spring-Boot"><a href="#Set-Cookie-in-Spring-Boot" class="headerlink" title="Set-Cookie in Spring Boot"></a>Set-Cookie in Spring Boot</h2><p>In Spring Boot, the <code>Set-Cookie</code> header is used to send cookies to the user’s browser. The <code>Set-Cookie</code> header is sent in the response to the user’s request. The <code>Set-Cookie</code> header contains the name, value, and other attributes of the cookie. Here is an example of the <code>Set-Cookie</code> header in Spring Boot:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Set-Cookie: JSESSIONID=1234567890; Path=/; HttpOnly; Secure</span><br></pre></td></tr></table></figure><p>In this example, the <code>JSESSIONID</code> is the name of the cookie, <code>1234567890</code> is the value of the cookie, <code>Path</code> is the path on the server where the cookie is valid, <code>/</code> is the path, <code>HttpOnly</code> is a flag that indicates that the cookie should not be accessible to client-side scripts, <code>Secure</code> is a flag that indicates that the cookie should only be sent over HTTPS connections, and <code>SameSite</code> is not set.</p><p>In <code>Network</code> tab of <code>Chrome DevTools</code>, we can see the <code>Set-Cookie</code> header in the response headers. That means these cookie are set by web server and sent to the user’s browser and stored in the user’s computer.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/set-cookie-in-response-headers.png" class="lazyload placeholder" data-srcset="/assets/images/java/set-cookie-in-response-headers.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Set-Cookie in response headers"/></div><span class="image-caption">Set-Cookie in response headers</span></div><p>And we can also see the cookies in <code>Application</code> tab of <code>Chrome DevTools</code>. The cookies are stored in the user’s browser and can be accessed by the web server in subsequent requests.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/cookie-in-browser-application-tab.png" class="lazyload placeholder" data-srcset="/assets/images/java/cookie-in-browser-application-tab.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Cookies in Browser Application tab"/></div><span class="image-caption">Cookies in Browser Application tab</span></div><h2 id="Difference-of-Set-Cookie-in-Tomcat-and-Jetty"><a href="#Difference-of-Set-Cookie-in-Tomcat-and-Jetty" class="headerlink" title="Difference of Set-Cookie in Tomcat and Jetty"></a>Difference of Set-Cookie in Tomcat and Jetty</h2><p>Okay, let’s talk about the difference of <code>Set-Cookie</code> header handling between <code>Tomcat</code> and <code>Jetty</code>. Here we will use <code>curl</code> command to send a request to the server and see the <code>Set-Cookie</code> header in the response for default configuration.</p><h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><p>If we want to reduce <code>XSS cross-site scripting attacks</code> and <code>prevent reading and modifying cookie contents</code>, we can set the <code>HttpOnly</code> attribute for the cookie. In <code>Tomcat 6</code>,  we need to config it in the <code>tomcat/conf/context.xml</code> file. Add the <code>useHttpOnly=&quot;true&quot;</code> attribute in <code>&lt;Context&gt;</code> tag.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Context</span> <span class="attr">useHttpOnly</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Context</span>&gt;</span></span><br></pre></td></tr></table></figure><p>But for <code>Tomcat 7</code> and later version. We don’t need to config it in <code>context.xml</code> any more. The <code>useHttpOnly</code> attribute is set to <code>true</code> by default. It is introduced in <code>Tomcat 7</code> official doc (<a href="https://tomcat.apache.org/tomcat-7.0-doc/config/context.html">https://tomcat.apache.org/tomcat-7.0-doc/config/context.html</a>)</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/http-only-in-tomcat7.png" class="lazyload placeholder" data-srcset="/assets/images/java/http-only-in-tomcat7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="HttpOnly in Tomcat 7"/></div><span class="image-caption">HttpOnly in Tomcat 7</span></div><p>Below is the screenshot that using <code>curl</code> command to send a request to our current Spring Boot application with <code>Tomcat</code> server:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/set-cookie-with-http-only.png" class="lazyload placeholder" data-srcset="/assets/images/java/set-cookie-with-http-only.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Set-Cookie with HttpOnly"/></div><span class="image-caption">Set-Cookie with HttpOnly</span></div><p>From the screenshot, you can see the <code>Set-Cookie</code> header in the response. The <code>HttpOnly</code> attribute is appended in the cookie by default.</p><p>BTW, from <code>Spring Boot</code> 2 version, it is starting use <code>Tomcat</code> 8 version which will set <code>HttpOnly</code> attribute by default in the cookie.</p><h3 id="Jetty"><a href="#Jetty" class="headerlink" title="Jetty"></a>Jetty</h3><p>For <code>Jetty</code>, the <code>HttpOnly</code> attribute is <code>not</code> set by default. We need to config it in the <code>web.xml</code> file. Add the <code>&lt;http-only&gt;</code> element in <code>&lt;cookie-config&gt;</code> tag.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">session-config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">cookie-config</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">http-only</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">cookie-config</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">session-config</span>&gt;</span></span><br></pre></td></tr></table></figure><p>We also can set the <code>HttpOnly</code> attribute for the cookie in the code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SessionCookieConfig.setHttpOnly(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure><p>We can find the evidence in the <code>Jetty</code> official doc <a href="https://jetty.org/docs/jetty/12/programming-guide/server/session.html">https://jetty.org/docs/jetty/12/programming-guide/server/session.html</a>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/http-only-in-jetty.png" class="lazyload placeholder" data-srcset="/assets/images/java/http-only-in-jetty.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="HttpOnly in Jetty"/></div><span class="image-caption">HttpOnly in Jetty</span></div><p>By default, the <code>HttpOnly</code> attribute is not set in the <code>Set-Cookie</code> header in jetty. Below is the screenshot that using <code>curl</code> command to send a request to our current Spring Boot application with <code>Jetty</code> server by default configuration:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/set-cookie-without-http-only.png" class="lazyload placeholder" data-srcset="/assets/images/java/set-cookie-without-http-only.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Set-Cookie without HttpOnly"/></div><span class="image-caption">Set-Cookie without HttpOnly</span></div><p>As you can see, the <code>HttpOnly</code> attribute is not set in the <code>Set-Cookie</code> header in <code>Jetty</code> by default when we use the <code>curl</code> command. The code are same, just simply switch <code>Tomcat</code> to <code>Jetty</code> in the <code>pom.xml</code> file in previous blog.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>The <code>Set-Cookie</code> header is used to send cookies to the user’s browser. The <code>HttpOnly</code> attribute is used to prevent client-side scripts from accessing the cookie. The <code>Secure</code> attribute is used to ensure that the cookie is only sent over HTTPS connections. The <code>SameSite</code> attribute is used to prevent cross-site requests. The difference of <code>Set-Cookie</code> header handling between <code>Tomcat</code> and <code>Jetty</code> is that <code>Tomcat</code> set the <code>HttpOnly</code> attribute by default, while <code>Jetty</code> does not set it by default. We need to config it in the <code>web.xml</code> file for <code>Jetty</code> or set it in the code for <code>Tomcat</code>. So when you switche <code>Tomcat</code> to <code>Jetty</code>, you need to check the <code>HttpOnly</code> attribute in the <code>Set-Cookie</code> header for session id for security reason.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In previous blog &lt;a href=&quot;https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/&quot;&gt;Switching Tomcat wi</summary>
      
    
    
    
    <category term="Backend" scheme="https://stonefishy.github.io/categories/Backend/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="Spring Boot" scheme="https://stonefishy.github.io/tags/Spring-Boot/"/>
    
    <category term="Tomcat" scheme="https://stonefishy.github.io/tags/Tomcat/"/>
    
    <category term="Jetty" scheme="https://stonefishy.github.io/tags/Jetty/"/>
    
    <category term="Cookie" scheme="https://stonefishy.github.io/tags/Cookie/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Model Context Protocol (MCP)</title>
    <link href="https://stonefishy.github.io/2025/04/21/understanding-the-model-context-protocol-mcp/"/>
    <id>https://stonefishy.github.io/2025/04/21/understanding-the-model-context-protocol-mcp/</id>
    <published>2025-04-21T10:38:42.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>In the rapidly evolving landscape of artificial intelligence, ensuring the effective and efficient management of model contexts is crucial for the deployment and utilization of AI systems. The model context is refer to the set of information that is necessary for the <code>AI model</code> like <code>DeepSeek</code>, <code>Claude</code>, <code>ChatGPT</code>, <code>Gemini</code> to make a correct and efficient decision. However, managing the model context is not an easy task, as it requires a combination of technical expertise, domain knowledge, and business intelligence.</p><p>One significant protocol that has emerged to address this challenge is the <code>Model Context Protocol (MCP)</code>. Let’s talk about it in this blog.</p><h2 id="What-is-MCP"><a href="#What-is-MCP" class="headerlink" title="What is MCP?"></a>What is <code>MCP</code>?</h2><p>A brief overview of the <code>Model Context Protocol (MCP)</code> which introduced by official:</p><blockquote><p><code>The Model Context Protocol (MCP)</code> is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you’re building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.</p></blockquote><blockquote><p>Think of <code>MCP</code> like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.</p></blockquote><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-like-usb.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-like-usb.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>So it’s a protocol that defines a standardized way to connect <code>LLMs</code> with the context they need. The <code>MCP</code> is designed to address the challenges of managing the model context. It’s introduced by <code>Anthropic</code> company at 2024, the <code>Claude Desktop</code> supports very well. </p><h2 id="Why-MCP-Came-Out"><a href="#Why-MCP-Came-Out" class="headerlink" title="Why MCP Came Out?"></a>Why MCP Came Out?</h2><p>Below  explains the Model Context Protocol’s architecture and capabilities, how it solves the inherent challenges of AI integration.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-before-after.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-before-after.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Before the <code>MCP</code>, we usually use the <code>Function calling</code>, which allows LLMs to invoke predetermined functions based on user requests, is a well-established feature of modern AI models. Sometimes referred to as “tool use,” function calling is not mutually exclusive with MCP; the new protocol simply standardizes how this API feature works. </p><p>Without MCP, when you use a function call directly with an LLM API, you need to:</p><ol><li>Define model-specific function schemas, which are JSON descriptions of the function, acceptable parameters, and what it returns.</li><li>Implement handlers (the actual code that executes when a function is called) for those functions.</li><li>Create different implementations for each model you support.</li></ol><p>With MCP, the MCP standardizes this process by:</p><ol><li>Defining a consistent way to specify tools (functions) across any AI system.</li><li>Providing a protocol for discovering available tools and executing them.</li><li>Creating a universal, plug-and-play format where any AI app can use any tool without custom integration code.</li></ol><p>You might be familiar with AI apps that use function calling, like Custom GPTs using GPT Actions. A Custom GPT can determine which API call resolves the user’s prompt, create the necessary JSON, then make the API call with it. While this allows some purpose-built tooling, it’s bound to OpenAI’s ecosystem. <code>MCP</code> brings similar capabilities to any AI application that implements the protocol, regardless of the underlying model vendor.</p><h2 id="MCP-Architectures-and-Core-Components"><a href="#MCP-Architectures-and-Core-Components" class="headerlink" title="MCP Architectures and Core Components"></a>MCP Architectures and Core Components</h2><p>Below is general architecture of <code>MCP</code>:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-general-architecture.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-general-architecture.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MCP General Architecture"/></div><span class="image-caption">MCP General Architecture</span></div><p><strong>Host application</strong>: <code>LLMs</code> that interact with users and initiate connections. This includes <code>Claude Desktop</code>, AI-enhanced IDEs like <code>Cursor</code>, and standard web-based LLM chat interfaces.</p><p><strong>MCP client</strong>: Integrated within the host application to handle connections with MCP servers, translating between the host’s requirements and the Model Context Protocol. Clients are built into host applications, like the MCP client inside Claude Desktop.</p><p><strong>MCP server</strong>: Adds context and capabilities, exposing specific functions to AI apps through MCP. Each standalone server typically focuses on a specific integration point, like GitHub for repository access or a PostgreSQL for database operations.</p><p><strong>Data Source</strong>: The source of information or functionality that the MCP server connects to. This could be a database, API, or any other data source that the server can access.</p><ol><li><strong>Local Data Sources</strong>: Your computer’s files, databases, and services that MCP servers can securely access</li><li><strong>Remote Services</strong>: External systems available over the internet (e.g., through APIs) that MCP servers can connect to</li></ol><p><strong>Transport layer</strong>: The communication mechanism between clients and servers. MCP supports two primary transport methods:</p><ol><li><strong>STDIO (Standard Input&#x2F;Output)</strong>: Mainly local integrations where the server runs in the same environment as the client.</li><li><strong>HTTP+SSE (Server-Sent Events)</strong>: Remote connections, with HTTP for client requests and SS for server responses and streaming.</li></ol><p>All communication in MCP uses <code>JSON-RPC 2.0</code> as the underlying message standard, providing a standardized structure for requests, responses, and notifications.</p><h2 id="How-MCP-Works"><a href="#How-MCP-Works" class="headerlink" title="How MCP Works"></a>How MCP Works</h2><p>When a user interacts with a host application (an AI app) that supports <code>MCP</code>, several processes occur behind the scenes to enable quick and seamless communication between the AI and external systems. Let’s take a look the example.</p><h3 id="Protocol-handshake"><a href="#Protocol-handshake" class="headerlink" title="Protocol handshake"></a>Protocol handshake</h3><ol><li><strong>Initial connection</strong>: When an MCP client (like Claude Desktop) starts up, it connects to the configured MCP servers on your device.</li><li><strong>Capability discovery</strong>: The client asks each server “What capabilities do you offer?” Each server responds with its available tools, resources, and prompts.</li><li><strong>Registration</strong>: The client registers these capabilities, making them available for the AI to use during your conversation.</li></ol><h3 id="An-Example"><a href="#An-Example" class="headerlink" title="An Example"></a>An Example</h3><p>Let’s use an example to talk about it. Below is the example general communication flow of <code>MCP</code>:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/mcp-communication-flow.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/mcp-communication-flow.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MCP How Works"/></div><span class="image-caption">MCP How Works</span></div><p>Let’s say you ask Claude, “What’s the weather like in San Francisco today?” Here’s what happens:</p><ol><li><strong>Need recognition</strong>: Claude analyzes your question and recognizes it needs external, real-time information that wasn’t in its training data.</li><li><strong>Tool or resource selection</strong>: Claude identifies that it needs to use an MCP capability to fulfill your request.</li><li><strong>Permission request</strong>: The client displays a permission prompt asking if you want to allow access to the external tool or resource. </li><li><strong>Information exchange</strong>: Once approved, the client sends a request to the appropriate MCP server using the standardized protocol format.</li><li><strong>External processing</strong>: The MCP server processes the request, performing whatever action is needed—querying a weather service, reading a file, or accessing a database.</li><li><strong>Result return</strong>: The server returns the requested information to the client in a standardized format.</li><li><strong>Context integration</strong>: Claude receives this information and incorporates it into its understanding of the conversation.</li><li><strong>Response generation</strong>: Claude generates a response that includes the external information, providing you with an answer based on current data.</li></ol><h2 id="MCP-Servers"><a href="#MCP-Servers" class="headerlink" title="MCP Servers"></a>MCP Servers</h2><p>Since the MCP just released at end of the 2024 by Anthropic, but it is growing rapidly. There are many MCP servers available now, and they are categorized into different categories. There are some awsome MCP servers:</p><ul><li><strong>GitHub</strong>: MCP server for GitHub, which allows you to access repositories and files in your GitHub account.</li><li><strong>PostgreSQL</strong>: MCP server for PostgreSQL, which allows you to access and manage your PostgreSQL databases.</li><li><strong>Docker</strong>: MCP server for Docker, which allows you to manage your Docker containers and images.</li><li><strong>Kubernetes</strong>: MCP server for Kubernetes, which allows you to manage your Kubernetes clusters and resources.</li><li><strong>Google Cloud Platform</strong>: MCP server for Google Cloud Platform, which allows you to access and manage your Google Cloud resources.</li><li><strong>Amazon Web Services</strong>: MCP server for Amazon Web Services, which allows you to access and manage your AWS resources.</li></ul><p>There is a MCP servers collections link: <a href="https://github.com/punkpeye/awesome-mcp-servers">https://github.com/punkpeye/awesome-mcp-servers</a>, you can find existing MCP servers and their capabilities. Also, you can create your own MCP server by following the MCP server development guide. We will talk about it in the future.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the rapidly evolving landscape of artificial intelligence, ensuring the effective and efficient management of model contexts is crucia</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="MCP" scheme="https://stonefishy.github.io/tags/MCP/"/>
    
  </entry>
  
  <entry>
    <title>Supercharge Your Python project with UV: The Lightning-Fast Package Manager</title>
    <link href="https://stonefishy.github.io/2025/04/16/supercharge-your-python-project-with-uv-the-lightning-fast-package-manager/"/>
    <id>https://stonefishy.github.io/2025/04/16/supercharge-your-python-project-with-uv-the-lightning-fast-package-manager/</id>
    <published>2025-04-16T14:00:23.000Z</published>
    <updated>2025-08-26T03:00:18.036Z</updated>
    
    <content type="html"><![CDATA[<p>Python’s ecosystem thrives on its rich library of packages, but managing dependencies can sometimes feel sluggish, especially in large projects. Enter <code>UV</code>, a modern package manager and resolver designed to supercharge your workflow. Developed by <code>Astral</code> (the team behind the popular Ruff linter), <code>UV</code> promises blazing speed and seamless integration with existing Python tools. Let’s explore why UV might become your new go-to for dependency management.</p><h2 id="What-is-UV"><a href="#What-is-UV" class="headerlink" title="What is UV?"></a>What is UV?</h2><p><code>UV</code> is a Rust-powered tool that combines a package installer (<code>pip</code>) and virtual environment manager (<code>venv</code>) into one ultra-fast solution. It aims to replace traditional tools like <code>pip</code>, <code>pipenv</code>, and <code>poetry</code> while staying fully compatible with their workflows. By leveraging Rust’s performance advantages, UV dramatically reduces installation and resolution times—often by <code>10-100x</code> compared to older tools.</p><h2 id="Why-Use-UV"><a href="#Why-Use-UV" class="headerlink" title="Why Use UV?"></a>Why Use UV?</h2><p><strong>Speed</strong>: <code>UV</code> resolves and installs dependencies in seconds, even for complex projects.<br><strong>Simplicity</strong>: It’s a drop-in replacement for <code>pip</code> and <code>venv</code>, requiring no workflow changes.<br><strong>Modern Features</strong>: Supports <code>pyproject.toml</code>, <code>lock</code> files, and advanced dependency resolution.<br><strong>Cross-Platform</strong>: Works on Windows, macOS, and Linux.</p><h2 id="Getting-Started-with-UV"><a href="#Getting-Started-with-UV" class="headerlink" title="Getting Started with UV"></a>Getting Started with UV</h2><h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><p><code>UV</code> is distributed as a static binary, so installation is straightforward:</p><h4 id="Install-via-pip-recommended"><a href="#Install-via-pip-recommended" class="headerlink" title="Install via pip (recommended)"></a>Install via pip (recommended)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install uv</span><br></pre></td></tr></table></figure><h4 id="Or-use-curl-Mac-Linux-only"><a href="#Or-use-curl-Mac-Linux-only" class="headerlink" title="Or use curl (Mac&#x2F;Linux only)"></a>Or use curl (Mac&#x2F;Linux only)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -LsSf https://astral.sh/uv/install.sh | sh</span><br></pre></td></tr></table></figure><p>Once the installation is complete, you can verify the installation by running:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv --version</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-version.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-version.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV version"/></div><span class="image-caption">UV version</span></div><p>Running below command to get the help message:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-help.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-help.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV help"/></div><span class="image-caption">UV help</span></div><h3 id="Creating-a-Project"><a href="#Creating-a-Project" class="headerlink" title="Creating a Project"></a>Creating a Project</h3><p>To create a new project with <code>UV</code>, run:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv init &lt;project-name&gt;</span><br></pre></td></tr></table></figure><p>This will create a new project called <project-name> directory with a <code>pyproject.toml</code> file and a <code>uv.lock</code> file. The <code>pyproject.toml</code> file is where you can specify your project’s dependencies and other metadata. The <code>uv.lock</code> file is where <code>UV</code> stores the resolved dependencies and their versions.</p><p>Let’s create a new project called <code>uv-sample</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv init uv-sample</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-init1.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-init1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV init project"/></div><span class="image-caption">UV init project</span></div><p>It also creates associated with the <code>git</code> for this project, <code>.python-version</code> file for managing Python version, and a sample <code>main.py</code> python file.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-init2.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-init2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Project files generated by UV init"/></div><span class="image-caption">Project files generated by UV init</span></div><p>The <code>pyproject.toml</code> file is where you can specify your project’s dependencies and other metadata. Since this project doesn’t have any dependencies, so the <code>uv.lock</code> file is empty. Below is <code>uv-sample</code> <code>pyproject.toml</code> file:</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[project]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;uv-sample&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">description</span> = <span class="string">&quot;Add your description here&quot;</span></span><br><span class="line"><span class="attr">readme</span> = <span class="string">&quot;README.md&quot;</span></span><br><span class="line"><span class="attr">requires-python</span> = <span class="string">&quot;&gt;=3.12&quot;</span></span><br><span class="line"><span class="attr">dependencies</span> = []</span><br></pre></td></tr></table></figure><h3 id="Manage-Dependencies"><a href="#Manage-Dependencies" class="headerlink" title="Manage Dependencies"></a>Manage Dependencies</h3><p>Using <code>uv</code> to manage dependencies is as simple as adding them to the <code>dependencies</code> section of the <code>pyproject.toml</code> file. For example, to add <code>pandas</code> as a dependency, we can run:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv add pandas</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-add-dependency.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-add-dependency.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV Add dependency"/></div><span class="image-caption">UV Add dependency</span></div><p>From the screenshot, you can see before adding the dependency in python project. The <code>uv</code> also help us to create a virtual environment for our project. The package and dependencies installed in the virtual environment will be isolated from the system-wide packages.</p><p>The <code>uv.lock</code> file will be updated with the installed dependencies and their versions. And the <code>pyproject.toml</code> file will be updated with the new dependency.</p><p><code>pyproject.toml</code> file after adding <code>pandas</code> as a dependency:</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[project]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;uv-sample&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">description</span> = <span class="string">&quot;Add your description here&quot;</span></span><br><span class="line"><span class="attr">readme</span> = <span class="string">&quot;README.md&quot;</span></span><br><span class="line"><span class="attr">requires-python</span> = <span class="string">&quot;&gt;=3.12&quot;</span></span><br><span class="line"><span class="attr">dependencies</span> = [</span><br><span class="line">    <span class="string">&quot;pandas&gt;=2.2.3&quot;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><code>uv.lock</code> file is like a <code>package-lock.json</code> file for <code>npm</code> or <code>yarn</code>. It contains the resolved dependencies and their versions. We can see the installed dependencies and their versions in the <code>uv.lock</code> file. Please don’t edit this file manually.</p><p>To see the dependencies tree, we can run <code>uv tree</code> command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv tree</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-tree.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-tree.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Dependencies via UV tree"/></div><span class="image-caption">Dependencies via UV tree</span></div><p>It lists all the dependencies and their dependencies recursively.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-lock-file.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-lock-file.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV lock file"/></div><span class="image-caption">UV lock file</span></div><p>You can also remove the dependency by running: <code>uv remove &lt;dependency-name&gt;</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv remove pandas</span><br></pre></td></tr></table></figure><p>If your project is cloned. And you want to setup the development environment on your local. You can run <code>uv sync</code> to install the dependencies from the <code>uv.lock</code> file.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv <span class="built_in">sync</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-sync.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-sync.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Install dependencies from UV sync"/></div><span class="image-caption">Install dependencies from UV sync</span></div><p>See, it’s very easy. It created a virtual environment for our project and installed the dependencies from the <code>uv.lock</code> file.</p><p>The <code>uv</code> has more features like using <code>uv</code> to install and select specific python verison, run the python code.</p><h3 id="Manage-Python-Version"><a href="#Manage-Python-Version" class="headerlink" title="Manage Python Version"></a>Manage Python Version</h3><p>Using the <code>uv</code> also can manage the python version for your project. Below is the snapshot to manage the python.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-python.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-python.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="UV python"/></div><span class="image-caption">UV python</span></div><p>List all the available downloaded python.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv python list</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-python-list.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-python-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="List of python versions"/></div><span class="image-caption">List of python versions</span></div><p>You can download and install the specific python version. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv python install &lt;version&gt;</span><br></pre></td></tr></table></figure><p>Let’s install the python version 3.14. See below screenshot.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv python install 3.14</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-python-install.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-python-install.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Install python version"/></div><span class="image-caption">Install python version</span></div><p>So using <code>uv</code> we can manage multiple python versions at same time. It’s like <code>nvm</code> for node.js. For more using <code>uv</code> to manage the python version, you can type <code>uv python --help</code> to get the help message.</p><h3 id="Run-Python-Code"><a href="#Run-Python-Code" class="headerlink" title="Run Python Code"></a>Run Python Code</h3><p>Before <code>uv</code>, we running the python code usuallly by using <code>python &lt;python-file&gt;</code>. In <code>uv</code>, we can run the python code using <code>uv run</code> command.</p><p><code>main.py</code> example file.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Hello from uv-sample!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>Executing below command to run the python code.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv run main.py</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/python/uv-run-python.png" class="lazyload placeholder" data-srcset="/assets/images/python/uv-run-python.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Run python code"/></div><span class="image-caption">Run python code</span></div><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p><code>UV</code> is a modern package manager and resolver designed to supercharge your workflow. It promises blazing speed and seamless integration with existing Python tools. It’s a drop-in replacement for <code>pip</code> and <code>venv</code>, requiring no workflow changes. It works on Windows, macOS, and Linux.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Python’s ecosystem thrives on its rich library of packages, but managing dependencies can sometimes feel sluggish, especially in large pr</summary>
      
    
    
    
    <category term="Backend" scheme="https://stonefishy.github.io/categories/Backend/"/>
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="UV" scheme="https://stonefishy.github.io/tags/UV/"/>
    
  </entry>
  
  <entry>
    <title>Switching Tomcat with Jetty in Spring Boot Easily</title>
    <link href="https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/"/>
    <id>https://stonefishy.github.io/2025/04/11/switching-tomcat-with-jetty-in-spring-boot-easily/</id>
    <published>2025-04-11T11:16:30.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Recently, we received the critical security vulnerability which is CVE-2025-24813 (<a href="https://www.cvedetails.com/cve/CVE-2025-24813/">https://www.cvedetails.com/cve/CVE-2025-24813/</a>) information from cloud security team. It request the team to check if there any projects are using tomcat which affected by this vulnerability, and remediate it quickly.</p><p>The CVE-2025-24813 describe below, and publised at 2025-03-10 17:15:35. It’s new found vulnerability.</p><blockquote><p>Path Equivalence: ‘file.Name’ (Internal Dot) leading to Remote Code Execution and&#x2F;or Information disclosure and&#x2F;or malicious content added to uploaded files via write enabled Default Servlet in Apache Tomcat.</p></blockquote><p>Our all microservices are using tomcat as servlet container. And we’re using <code>spring-boot-starter-tomcat</code> version 2.6.4 which is affacted. Actually all spring boot 2 contains this vulnerability. Even in most of embedded tomcat libraries in sprint boot 3.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/spring-boot-starter-tomcat-2.6.4.png" class="lazyload placeholder" data-srcset="/assets/images/java/spring-boot-starter-tomcat-2.6.4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="CVE-2025-24813 in Spring Boot Starter Tomcat 2.6.4"/></div><span class="image-caption">CVE-2025-24813 in Spring Boot Starter Tomcat 2.6.4</span></div><p>This tomcat vulnerability has been fixed since <code>spring-boot-starter-tomcat</code> version <code>3.4.3</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/spring-boot-starter-tomcat-3.4.3.png" class="lazyload placeholder" data-srcset="/assets/images/java/spring-boot-starter-tomcat-3.4.3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="CVE-2025-24813 Resolved in Spring Boot Starter Tomcat 3.4.3"/></div><span class="image-caption">CVE-2025-24813 Resolved in Spring Boot Starter Tomcat 3.4.3</span></div><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>To resolve this vulnerability issue, there are two solutions: </p><ol><li>One is upgrade <code>spring-boot-starter-tomcat</code> to latest version. </li><li>We can switch to other servlet container, such as <code>Jetty</code>.</li></ol><p>For the first solution, we have to upgrade our entire all microservice from Spring Boot 2 to Spring Boot 3 which requires Java 17. Official guide <a href="https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0">https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0</a>. Currently our all microserces are still using Java 8. In short term, It’s hard to upgrade Java 8 to Java 17 and Spring Boot 2 to Spring Boot 3, it will take much time and efforts. There also third party libraries requires to be upgrade when upgrade Java 8 to Java 17.</p><p>More over, we are using <code>spring-cloud-starter-netflix-zuul</code>, in spring cloud github, it mentioned <code>spring-cloud-starter-netflix-zuul</code> not work with <code>spring-boot 3.0</code> and spring 6.0, it has been out of support. It suggests to using <code>Spring Cloud Gateway</code>.  Refer official issue link: <a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/4158">https://github.com/spring-cloud/spring-cloud-netflix/issues/4158</a>. Besides currently the Spring Cloud Gateway does not support the SSO SAML. Hope it supports SAML in future.</p><p>So the solution 2 is best to resolve this vulnuerability in short term.</p><h2 id="Jetty"><a href="#Jetty" class="headerlink" title="Jetty"></a>Jetty</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/jetty-logo.png" class="lazyload placeholder" data-srcset="/assets/images/java/jetty-logo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Jetty"/></div><span class="image-caption">Jetty</span></div><p><code>Jetty</code> is a part of the Eclipse foundation and started in 1995. Jetty is not just a web server and servlet container. But it offers support for WebSocket, HTTP&#x2F;2, OSGi, JNDI, JMX, JAAS, and many other integrations. Additionally  Jetty is popular among developers and also works as an embedded tool for a lot of frameworks, cloud services, application servers, and devices. </p><p>According to stats Jetty maintains a market share of 10% among Java application servers. Some popular companies that use Jetty are <code>Google</code>, <code>Yahoo</code>, <code>Nuxeo</code> and <code>Canva</code>. </p><p>Jetty can:</p><ul><li>Jetty is user friendly and has a better interface than Tomcat.</li><li>Can be used as a part of or full Java application server stack.</li><li>Might be applied as a part of other frameworks due to its flexibility.</li><li>Supports cloud style operations.</li><li>The conceptual weight of the framework is less, very fast, and thin.</li><li>Better for handling simultaneous users compared to Tomcat.</li><li>Small memory trace to work speedily.</li><li>Users can use it easily because the required knowledge and skills are very few.</li></ul><p>Compare with <code>Tomcat</code>, they have the following simlarities:</p><ul><li>Both these tools are open source platforms and written in Java.</li><li>Companies use them in production environments (live releases).</li><li>They can process all components of the Core Java enterprise.</li><li>Both tools have large community support.</li></ul><h2 id="Code-Implementation"><a href="#Code-Implementation" class="headerlink" title="Code Implementation"></a>Code Implementation</h2><p>To switching Tomcat to Jetty in Spring Boot is very easily. You don’t need to update any logic code, the one thing you need to do is that exclude the embedded Tomcat <code>spring-boot-starter-tomcat</code> from <code>spring-boot-stater-web</code> and add dependency <code>spring-boot-starter-jetty</code> in <code>Maven</code> or <code>Gradle</code></p><h3 id="For-Maven-Users"><a href="#For-Maven-Users" class="headerlink" title="For Maven Users:"></a>For Maven Users:</h3><p>Update the <code>pom.xml</code> and making below changes.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Exclude Tomcat starter --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-tomcat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Add Jetty starter --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jetty<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="For-Gradle-Users"><a href="#For-Gradle-Users" class="headerlink" title="For Gradle Users:"></a>For Gradle Users:</h3><p>Update the <code>build.gradle</code> file as below:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    <span class="comment">// Exclude Tomcat starter</span></span><br><span class="line">    implementation(<span class="string">&#x27;org.springframework.boot:spring-boot-starter-web&#x27;</span>) &#123;</span><br><span class="line">        exclude <span class="attr">group:</span> <span class="string">&#x27;org.springframework.boot&#x27;</span>, <span class="attr">module:</span> <span class="string">&#x27;spring-boot-starter-tomcat&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add Jetty starter</span></span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-jetty&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>After you make above changes. Spring Boot stop auto-configuring <code>Tomcat</code> as the embedded server and to set up <code>Jetty</code> instead. <span class='pbg success'>It’s a seamless transition that requires no additional code.</span> Spring Boot’s auto-configuration capabilities recognize the absence of Tomcat and the presence of Jetty and automatically configure your application to use Jetty as its embedded servlet container.</p><h2 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h2><p>It’s always a good idea to fine-tune your server settings to ensure optimal performance. With Jetty, you can easily configure thread pools, port settings, and more through the <code>application.properties</code> or <code>application.yml</code> file in your Spring Boot project.</p><p>For example, to change the server port and configure the max thread pool size in application.properties, you can add below settings in <code>application.properties</code> file.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server.port=8001</span><br><span class="line">server.jetty.threads.max=200</span><br></pre></td></tr></table></figure><p>Once you have complete configuration. You can start your application. The Jetty servlet container started like below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/java/spring-boot-jetty-started.png" class="lazyload placeholder" data-srcset="/assets/images/java/spring-boot-jetty-started.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Spring Boot Application Started with Jetty"/></div><span class="image-caption">Spring Boot Application Started with Jetty</span></div><h2 id="Summery"><a href="#Summery" class="headerlink" title="Summery"></a>Summery</h2><p>Switching from <code>Tomcat</code> to <code>Jetty</code> in a Spring Boot application isn’t just feasible; it’s straightforward with Spring Boot’s flexible architecture. Whether you’re looking for increased performance, reduced resource consumption, or simply exploring alternatives, transitioning to Jetty offers tangible benefits with minimal hassle.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h2&gt;&lt;p&gt;Recently, we received the critical sec</summary>
      
    
    
    
    <category term="Backend" scheme="https://stonefishy.github.io/categories/Backend/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="Spring Boot" scheme="https://stonefishy.github.io/tags/Spring-Boot/"/>
    
    <category term="Tomcat" scheme="https://stonefishy.github.io/tags/Tomcat/"/>
    
    <category term="Jetty" scheme="https://stonefishy.github.io/tags/Jetty/"/>
    
  </entry>
  
  <entry>
    <title>Create your own OpenAI endpoints in Azure Cloud.</title>
    <link href="https://stonefishy.github.io/2025/03/14/create-your-own-openai-endpoints-in-azure-cloud/"/>
    <id>https://stonefishy.github.io/2025/03/14/create-your-own-openai-endpoints-in-azure-cloud/</id>
    <published>2025-03-14T15:17:59.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<p>Previously, we have introduced how to use Azure OpenAI to develop a RAG (Retrieval-Augmented Generation) chatbot. In this article, we will learn how to create your own OpenAI endpoints in <code>Azure Cloud</code>.</p><p><code>Azure OpenAI</code> is a service provided by Microsoft Azure that allows businesses and developers to integrate OpenAI’s advanced AI models into their applications and systems. This service gives users access to powerful language models like <code>GPT-3</code>, <code>GPT-4</code>, and other AI models developed by OpenAI, via an API hosted on Microsoft’s Azure cloud platform.</p><p>To use Azure OpenAI, users need an Azure subscription and access to the OpenAI API via Azure. Assume you already have an Azure Cloud account and an Azure subscription. Here are the steps to create your own OpenAI endpoints in Azure Cloud</p><h2 id="Step-1-Create-Azure-OpenAI-Resource"><a href="#Step-1-Create-Azure-OpenAI-Resource" class="headerlink" title="Step 1: Create Azure OpenAI Resource"></a>Step 1: Create Azure OpenAI Resource</h2><p>In Microsoft Azure Cloud, Open the <code>Azure AI Services</code> and create a <code>Azure OpenAI</code> resource. Select your subscription and resource group, create a new resource group if you don’t have one. Fill the endpoint name and select the pricing tier. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>In Network, choose the All networks including internet option. because we want to access the OpenAI API from anywhere.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>For the tags, you can type your own tags for this resource.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After that, you can review your resource and create it.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-4.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Deploying the resource can take a few seconds.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-5.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Once the resource is deployed, you can select your resource and click the <code>Endpoints</code> and <code>Manage keys</code> to see the API endpoint and key.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-6.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>You can copy the API endpoint and key and use it in your application to access the OpenAI API.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-7.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Do you think we have finished to create our own OpenAI endpoints in Azure Cloud? The answer is No, We still need to deploy the OpenAI Model to our Azure OpenAI resource. If we access this API endpoint directly, we will get an error message. like below</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openai.NotFoundError: Error code: 404 - &#123;&#x27;error&#x27;: &#123;&#x27;code&#x27;: &#x27;DeploymentNotFound&#x27;, &#x27;message&#x27;: &#x27;The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="Step-2-Deploy-OpenAI-Model-to-Azure-OpenAI-Resource"><a href="#Step-2-Deploy-OpenAI-Model-to-Azure-OpenAI-Resource" class="headerlink" title="Step 2: Deploy OpenAI Model to Azure OpenAI Resource"></a>Step 2: Deploy OpenAI Model to Azure OpenAI Resource</h2><p>To deploy the OpenAI model to our Azure OpenAI resource, open <code>Azure AI Foundry</code> and select <code>Deployments</code> item in left menu. Click <code>Deploy model</code> button and select <code>Deploy base model</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-8.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Let’s choose the <code>GPT-4o</code> model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-9.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>In deployment model dialog, let’s keep the deployment name and deployment type select as Global Standard.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-10.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-10.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Step-3-Test-the-OpenAI-Endpoint"><a href="#Step-3-Test-the-OpenAI-Endpoint" class="headerlink" title="Step 3: Test the OpenAI Endpoint"></a>Step 3: Test the OpenAI Endpoint</h2><p>Once the model deployment done, we can go to <code>Playground</code> menu to test our model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-11.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-11.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Now, you can use your own OpenAI endpoints in your application without errors. Below is using <code>RESTMan</code> extension to call the Azure OpenAI endpoints via REST API way.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-create-12.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-create-12.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>There are many models in Azure AI Foundry, you can choose the model you want to use.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/azure-openai-models.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/azure-openai-models.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Hope this article helps you to create your own OpenAI endpoints in Azure Cloud.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Previously, we have introduced how to use Azure OpenAI to develop a RAG (Retrieval-Augmented Generation) chatbot. In this article, we wil</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Creating and Rendering a PDF from React Easily</title>
    <link href="https://stonefishy.github.io/2025/03/11/creating-and-rendering-pdf-from-react/"/>
    <id>https://stonefishy.github.io/2025/03/11/creating-and-rendering-pdf-from-react/</id>
    <published>2025-03-11T09:53:13.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<p>Creating or rendering a PDF file in a web page is a common requirement. It allows user to download the pdf file and view it offline in some scenarios. Today, we will learn how to render and generate a PDF file from React using the <code>react-pdf</code> library.</p><p>The <code>react-pdf</code> library is a React component that allows us to design and render PDF documents in React. Let’s get started an example, it’s very simple to create a pdf and render it in React.</p><h2 id="Install-the-react-pdf-Library"><a href="#Install-the-react-pdf-Library" class="headerlink" title="Install the react-pdf Library"></a>Install the <code>react-pdf</code> Library</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install @react-pdf/renderer --save</span><br></pre></td></tr></table></figure><h2 id="Create-a-PDF-Document"><a href="#Create-a-PDF-Document" class="headerlink" title="Create a PDF Document"></a>Create a PDF Document</h2><p>We will create a simple PDF document using the <code>react-pdf</code> library. It supports customize styles and Flex layout to create the PDF.  Below code example using <code>react-pdf</code> library to create a PDF document, including using <code>Document</code>, <code>Page</code>, <code>StyleSheet</code>, <code>Image</code>, <code>View</code>, <code>Text</code>, <code>Link</code> components.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123;<span class="title class_">Document</span>, <span class="title class_">Page</span>, <span class="title class_">StyleSheet</span>, <span class="title class_">Image</span>, <span class="title class_">View</span>, <span class="title class_">Text</span>, <span class="title class_">Link</span>&#125; <span class="keyword">from</span> <span class="string">&#x27;@react-pdf/renderer&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = <span class="title class_">StyleSheet</span>.<span class="title function_">create</span>(&#123;</span><br><span class="line">    <span class="attr">page</span>: &#123;</span><br><span class="line">        <span class="attr">flexDirection</span>: <span class="string">&#x27;column&#x27;</span>,</span><br><span class="line">        <span class="attr">backgroundColor</span>: <span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">        <span class="attr">padding</span>: <span class="string">&quot;20px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">section</span>: &#123;</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;30px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">header</span>: &#123;</span><br><span class="line">        <span class="attr">textAlign</span>: <span class="string">&quot;center&quot;</span>,</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;24px&quot;</span>,</span><br><span class="line">        <span class="attr">fontWeight</span>: <span class="string">&quot;bold&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;30px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">logo</span>: &#123;</span><br><span class="line">        <span class="attr">height</span>: <span class="string">&quot;90px&quot;</span>,</span><br><span class="line">        <span class="attr">width</span>: <span class="string">&quot;100px&quot;</span>,</span><br><span class="line">        <span class="attr">margin</span>: <span class="string">&quot;20px auto&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">title</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="number">18</span>,</span><br><span class="line">        <span class="attr">fontWeight</span>: <span class="string">&quot;bold&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">text</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;14px&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">code</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;14px&quot;</span>,</span><br><span class="line">        <span class="attr">backgroundColor</span>: <span class="string">&quot;#3e3e3e&quot;</span>,</span><br><span class="line">        <span class="attr">color</span>: <span class="string">&quot;#fff&quot;</span>,</span><br><span class="line">        <span class="attr">padding</span>: <span class="string">&quot;20px&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">        <span class="attr">borderRadius</span>: <span class="string">&quot;5px&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">PdfDocument</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">Document</span> <span class="attr">title</span>=<span class="string">&quot;My PDF Document&quot;</span> <span class="attr">author</span>=<span class="string">&quot;Andrewsy&quot;</span> <span class="attr">subject</span>=<span class="string">&quot;This is a sample PDF document&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Page</span> <span class="attr">size</span>=<span class="string">&quot;A4&quot;</span> <span class="attr">style</span>=<span class="string">&#123;styles.page&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.section&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.header&#125;</span>&gt;</span>React PDF Renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>The react-pdf library allows you to render PDF documents using React components.<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Image</span> <span class="attr">style</span>=<span class="string">&#123;styles.logo&#125;</span> <span class="attr">src</span>=<span class="string">&quot;images/logo.png&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.section&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.title&#125;</span>&gt;</span>Install react-pdf library<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>To install the react-pdf library, you can use npm or yarn:<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.code&#125;</span>&gt;</span>npm install @react-pdf/renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span>&gt;</span><span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.code&#125;</span>&gt;</span>yarn add @react-pdf/renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>For component documentation, visit the official website <span class="tag">&lt;<span class="name">Link</span> <span class="attr">src</span>=<span class="string">&quot;https://react-pdf.org/&quot;</span>&gt;</span>@react-pdf/renderer<span class="tag">&lt;/<span class="name">Link</span>&gt;</span>.<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">Page</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">Document</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="title class_">PdfDocument</span>;</span><br></pre></td></tr></table></figure><p>From above, we can see that we have created a PDF document using <code>react-pdf</code> library. We have used <code>Document</code> and <code>Page</code> components to create the PDF document. We have also used <code>StyleSheet</code> to define the styles for the PDF document. And using <code>Image</code>, <code>View</code>, <code>Text</code>, <code>Link</code> components to create the content of the PDF document.</p><h2 id="View-PDF-Document"><a href="#View-PDF-Document" class="headerlink" title="View PDF Document"></a>View PDF Document</h2><p>To view the PDF document, we need to use <code>PDFViewer</code> component to render the PDF document in the browser. There is one thing need notice, if your project is using <code>Next.js</code>, and you want to use <code>PDFViewer</code> or <code>PDFDownloadLink</code> component in client side render directly, you will get below error:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Error: PDFViewer is a web specific API. You&#x27;re either using this component on Node, or your bundler is not loading react-pdf from the appropriate web build.]</span><br></pre></td></tr></table></figure><p>To fixed the issue in <code>Next.js</code> project. Use Next dynamic function to manually set server-side rendering off and import it through that function instead of the regular import</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&quot;@react-pdf/renderer&quot;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">mod</span>) =&gt;</span> mod. <span class="title class_">PDFViewer</span>),&#123;<span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFDownloadLink</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&quot;@react-pdf/renderer&quot;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">mod</span>) =&gt;</span> mod. <span class="title class_">PDFDownloadLink</span>),&#123;<span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br></pre></td></tr></table></figure><p>instead of</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">PDFViewer</span>, <span class="title class_">PDFDownloadLink</span> &#125; <span class="keyword">from</span> <span class="string">&quot;@react-pdf/renderer&quot;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>The view PDF document code is below, for the <code>PDFViewer</code> component, we need to set the width and height of the PDF document. Actually it is rendered as a <code>iframe</code> element in the browser. This width and height is setting to iframe.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">PdfDocument</span> <span class="keyword">from</span> <span class="string">&#x27;@/components/pdf-document&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFViewer</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Pdf</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">section</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">display:</span> &#x27;<span class="attr">flex</span>&#x27;, <span class="attr">justifyContent:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">alignItems:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">height:</span> &#x27;<span class="attr">100vh</span>&#x27; &#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFViewer</span> <span class="attr">width</span>=<span class="string">&quot;800px&quot;</span> <span class="attr">height</span>=<span class="string">&quot;900px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">PdfDocument</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFViewer</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">section</span>&gt;</span></span></span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Let’s see the screenshot. It’s beautifully and easily rendered PDF document in the browser.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Renderer"/></div><span class="image-caption">React PDF Renderer</span></div><h2 id="Download-the-PDF-Document"><a href="#Download-the-PDF-Document" class="headerlink" title="Download the PDF Document"></a>Download the PDF Document</h2><p>To download the PDF document, we can use <code>PDFDownloadLink</code> component. It allows us to download the PDF document as a file. The code is below.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">PdfDocument</span> <span class="keyword">from</span> <span class="string">&#x27;@/components/pdf-document&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFViewer</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFDownloadLink</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFDownloadLink</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Pdf</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">section</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">display:</span> &#x27;<span class="attr">flex</span>&#x27;, <span class="attr">flexDirection:</span>&#x27;<span class="attr">column</span>&#x27;, <span class="attr">alignItems:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">height:</span> &#x27;<span class="attr">100vh</span>&#x27; &#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFViewer</span> <span class="attr">width</span>=<span class="string">&quot;850px&quot;</span> <span class="attr">height</span>=<span class="string">&quot;850px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">PdfDocument</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFViewer</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFDownloadLink</span> <span class="attr">document</span>=<span class="string">&#123;</span>&lt;<span class="attr">PdfDocument</span> /&gt;</span>&#125; fileName=&quot;my-pdf-document.pdf&quot; style=&#123;&#123;marginTop: &#x27;10px&#x27;&#125;&#125;&gt;</span></span><br><span class="line"><span class="language-xml">                &#123;(&#123; blob, url, loading, error &#125;) =&gt; (</span></span><br><span class="line"><span class="language-xml">                    loading ? &#x27;Loading document...&#x27; : <span class="tag">&lt;<span class="name">button</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">backgroundColor:</span> &#x27;#<span class="attr">171717</span>&#x27;, <span class="attr">color:</span> &#x27;<span class="attr">white</span>&#x27;, <span class="attr">padding:</span> &#x27;<span class="attr">10px</span>&#x27;, <span class="attr">borderRadius:</span> &#x27;<span class="attr">5px</span>&#x27;, <span class="attr">cursor:</span> &#x27;<span class="attr">pointer</span>&#x27; &#125;&#125;&gt;</span>Download<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                )&#125;</span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFDownloadLink</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">section</span>&gt;</span></span></span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the above code, we have used <code>PDFDownloadLink</code> component to download the PDF document, passed the <code>PdfDocument</code> component as the <code>document</code> prop of <code>PDFDownloadLink</code> component. We have also set the <code>fileName</code> prop to <code>my-pdf-document.pdf</code> to set the file name of the downloaded file. The <code>style</code> prop is used to set the style of the download button. We also use the <code>loading</code> prop to show the loading message while the PDF document is being downloaded.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf-download.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf-download.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Download"/></div><span class="image-caption">React PDF Download</span></div><p>Below PDF document is downloaded as a file.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf-doc.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf-doc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Document Opened in Adobe Acrobat Reader"/></div><span class="image-caption">React PDF Document Opened in Adobe Acrobat Reader</span></div><p>See it’s easily to create and render a PDF document in React using the <code>react-pdf</code> library.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The <code>react-pdf</code> library is a React component that allows us to design and render PDF documents in React. It supports customize styles and Flex layout to create the PDF. We have learned how to create a PDF document using <code>react-pdf</code> library, how to view and download the PDF document.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Creating or rendering a PDF file in a web page is a common requirement. It allows user to download the pdf file and view it offline in so</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Next.js" scheme="https://stonefishy.github.io/tags/Next-js/"/>
    
    <category term="PDF" scheme="https://stonefishy.github.io/tags/PDF/"/>
    
  </entry>
  
  <entry>
    <title>Conversational RAG Chatbot - Build a Chatbot with LangChain and Chainlit</title>
    <link href="https://stonefishy.github.io/2025/02/27/conversational-rag-chatbot-build-a-chatbot-with-langchain/"/>
    <id>https://stonefishy.github.io/2025/02/27/conversational-rag-chatbot-build-a-chatbot-with-langchain/</id>
    <published>2025-02-27T15:33:13.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<p>In previous blog, we have converting the PDF documents into the <code>FAISS</code> vector index, and saved in the local. Now, we will build a RAG chatbot using the <code>LangChain</code>, <code>Chainlit</code> and <code>OpenAI</code> base on previous <code>FAISS</code> index.</p><p>Before we get started, let’s talk about what is <code>Chainlit</code> and <code>LangChain</code>.</p><h2 id="Chainlit"><a href="#Chainlit" class="headerlink" title="Chainlit"></a>Chainlit</h2><p>We choose the <code>Chainlit</code> framework to build the chatbot. <code>Chainlit</code> is a framework designed to simplify the process of building and deploying chatbots for large language models (<code>LLMs</code>). It provides a way to create conversational applications that can interact with users through chat interfaces. Chainlit helps developers to chain together different components of a chatbot, such as the model itself, user interfaces, and data sources, making it easier to build complex conversational systems. It is particularly useful for those who want to integrate LLMs into their existing applications or create standalone chatbots. You can find the <code>Chainlit</code> documentation <a href="https://docs.chainlit.io/get-started/overview">here</a>.</p><h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><p><code>LangChain</code> is a framework designed to simplify the process of building language models and applications that leverage these models. It provides a set of tools and libraries that allow developers to integrate language models into their applications more easily, handle data flow, and manage the interactions between different components of their system. LangChain supports various language models and can be used to create a wide range of applications, from chatbots and virtual assistants to document summarization and translation tools. It aims to make it straightforward to build, deploy, and scale language-driven applications.</p><h2 id="Get-started"><a href="#Get-started" class="headerlink" title="Get started"></a>Get started</h2><p>Ok, let’s get started. First, we need to install the <code>LangChain</code> and <code>Chainlit</code> and other libraries, all the required libraries are below. Creating a <code>requirements.txt</code> file and store below libraries in it:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">openai</span><br><span class="line">langchain</span><br><span class="line">chainlit</span><br><span class="line">faiss-cpu</span><br><span class="line">tiktoken</span><br><span class="line">pymupdf</span><br><span class="line">PyPDF2</span><br><span class="line">langchain_openai</span><br><span class="line">langchain_community</span><br></pre></td></tr></table></figure><p>I suggest to create a virtual environment for this project before installing these libraries. We can use the following command to create a virtual environment:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv venv</span><br></pre></td></tr></table></figure><p>After creating the virtual environment, activate it using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> venv/bin/activate</span><br></pre></td></tr></table></figure><p>Then install all the required libraries using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>Now, we can start building the chatbot.</p><h2 id="Building-Chatbot-UI"><a href="#Building-Chatbot-UI" class="headerlink" title="Building Chatbot UI"></a>Building Chatbot UI</h2><p>The <code>Chainlit</code> provides the wonderful API to build the chatbot UI. It saves much time and efforts. In the project, create a <code>app.py</code> and import the <code>chainlit</code> library then write the below code. We will use 3 chainlit annotations. <code>@cl.set_starters</code>, <code>@cl.on_chat_start</code>, and <code>@cl.on_message</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> chainlit <span class="keyword">as</span> cl</span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.set_starters</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">set_starters</span>():</span><br><span class="line">    <span class="comment"># The chatbot starter page which displays the quick list of questions</span></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;The Major Updates in Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;What&#x27;s the major updates in Wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/specifications.svg&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;Migrate Project from Wix4 to Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;How to mirage the wix4 project to wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/jigsaw.png&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;Build Burn Bootstrapper on Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;How to build a burn bootstrapper on wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/bundle.svg&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_chat_start</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>():</span><br><span class="line">    <span class="comment"># starting the chatbot logic</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_message</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">message: cl.Message</span>):</span><br><span class="line">    <span class="comment"># chatbot logic and response here</span></span><br></pre></td></tr></table></figure><ol><li><p>The <code>@cl.set_starters</code> annotation is used to set the chatbot starter page. It takes a list of <code>cl.Starter</code> objects as input. Each <code>cl.Starter</code> object represents a question and its corresponding message. The <code>icon</code> parameter is used to set the icon for the question.</p></li><li><p>The <code>@cl.on_chat_start</code> annotation is used to start the chatbot logic. Such as setting the initial state of the chatbot, loading the chatbot model, FAISS index, create a langchain pipeline, etc.</p></li><li><p>The <code>@cl.on_message</code> annotation is used to handle the chatbot logic and response. It takes a <code>cl.Message</code> object as input. The <code>cl.Message</code> object contains the user’s message and other metadata. We can use the <code>message.content</code> attribute to get the user’s message.</p></li></ol><p>The starter page screenshot like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-starter-page.png %" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-starter-page.png %" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Chainlit Chatbot Starter Page"/></div><span class="image-caption">Chainlit Chatbot Starter Page</span></div><p>You can also customize the theme, or do some changes in UI. </p><h2 id="Loading-the-FAISS-Vector-Index"><a href="#Loading-the-FAISS-Vector-Index" class="headerlink" title="Loading the FAISS Vector Index"></a>Loading the FAISS Vector Index</h2><p>Using <code>FAISS</code> library, we can load the <code>FAISS</code> vector index. We need to pass the <code>embeddings</code> and <code>index_name</code> to the <code>FAISS.load_local</code> method. The <code>embeddings</code> parameter is the embedding model we used before, and the <code>index_name</code> parameter is the name of the index. Here, our embedding model is <code>AzureOpenAIEmbeddings</code> and the index name is <code>wix-upgrade</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">VECTOR_INDEX_NAME = <span class="string">&#x27;wix-upgrade&#x27;</span></span><br><span class="line">AZURE_OPENAI_API_KEY = os.getenv(<span class="string">&quot;AZURE_OPENAI_API_KEY&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ENDPOINT = os.getenv(<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_DEPLOYMENT_VERSION = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_DEPLOYMENT_VERSION&quot;</span>)</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION= os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME&quot;</span>)</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT_NAME&quot;</span>)</span><br><span class="line"></span><br><span class="line">embeddings = AzureOpenAIEmbeddings(</span><br><span class="line">    deployment=AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,</span><br><span class="line">    model=AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME,</span><br><span class="line">    azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">    openai_api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">    openai_api_version=AZURE_OPENAI_ADA_DEPLOYMENT_VERSION</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">docs_vector_store = FAISS.load_local(</span><br><span class="line">    folder_path=<span class="string">&quot;./vector_stores&quot;</span>, </span><br><span class="line">    embeddings=embeddings, </span><br><span class="line">    index_name=VECTOR_INDEX_NAME,</span><br><span class="line">    allow_dangerous_deserialization=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>Using <code>load_dotenv()</code> method, we can load the environment variables from the <code>.env</code> file. We can put the loading vector index code in the <code>@cl.on_chat_start</code> annotation.</p><h2 id="Building-the-Converstaion-Chain"><a href="#Building-the-Converstaion-Chain" class="headerlink" title="Building the Converstaion Chain"></a>Building the Converstaion Chain</h2><p>After we load the vector index, we can build the conversation chain using <code>LangChain</code>. The main logic are below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureOpenAIEmbeddings,AzureChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain.chains.combine_documents <span class="keyword">import</span> create_stuff_documents_chain</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> create_history_aware_retriever, create_retrieval_chain</span><br><span class="line"><span class="keyword">from</span> langchain_core.chat_history <span class="keyword">import</span> BaseChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables.history <span class="keyword">import</span> RunnableWithMessageHistory</span><br><span class="line"></span><br><span class="line">chat_history_store = &#123;&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_session_history</span>(<span class="params">session_id: <span class="built_in">str</span></span>) -&gt; BaseChatMessageHistory:</span><br><span class="line">    <span class="keyword">if</span> session_id <span class="keyword">not</span> <span class="keyword">in</span> chat_history_store:</span><br><span class="line">        chat_history_store[session_id] = ChatMessageHistory()</span><br><span class="line">    <span class="keyword">return</span> chat_history_store[session_id]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_chat_start</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>():</span><br><span class="line">    docs_vector_store = FAISS.load_local(</span><br><span class="line">        folder_path=<span class="string">&quot;./vector_stores&quot;</span>, </span><br><span class="line">        embeddings=embeddings, </span><br><span class="line">        index_name=VECTOR_INDEX_NAME,</span><br><span class="line">        allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    llm=AzureChatOpenAI(</span><br><span class="line">        api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">        azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">        api_version=AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION,</span><br><span class="line">        openai_api_type=<span class="string">&quot;azure&quot;</span>,</span><br><span class="line">        azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,</span><br><span class="line">        streaming=<span class="literal">True</span>,</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    retriever = docs_vector_store.as_retriever()</span><br><span class="line">    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)</span><br><span class="line">    question_answer_chain = create_stuff_documents_chain(llm, QA_PROMPT)</span><br><span class="line">    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)</span><br><span class="line"></span><br><span class="line">    conversational_rag_chain = RunnableWithMessageHistory(</span><br><span class="line">        rag_chain,</span><br><span class="line">        get_session_history,</span><br><span class="line">        input_messages_key=<span class="string">&quot;input&quot;</span>,</span><br><span class="line">        history_messages_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">        output_messages_key=<span class="string">&quot;answer&quot;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    cl.user_session.<span class="built_in">set</span>(<span class="string">&quot;chain&quot;</span>, conversational_rag_chain)</span><br></pre></td></tr></table></figure><p>In above code, we first load the <code>FAISS</code> vector index and create the <code>AzureChatOpenAI</code> language model. We then create the <code>retriever</code> using the <code>docs_vector_store</code> and create the <code>history_aware_retriever</code> using the <code>create_history_aware_retriever</code> method. The <code>contextualize_q_prompt</code> method is used to create the contextualized question prompt. The <code>create_stuff_documents_chain</code> method is used to create the question answer chain. Finally, we create the <code>rag_chain</code> using the <code>create_retrieval_chain</code> method.</p><p>We then create the <code>conversational_rag_chain</code> using the <code>RunnableWithMessageHistory</code> class. The <code>get_session_history</code> method is used to get the chat history for each session. The <code>input_messages_key</code>, <code>history_messages_key</code>, and <code>output_messages_key</code> parameters are used to set the keys for the input, history, and output messages.</p><p>We set the <code>conversational_rag_chain</code> as the chatbot chain using the <code>cl.user_session.set</code> method. We can use it later.</p><p>Here you’re notice there is <code>contextualize_q_prompt</code> and <code>QA_PROMPT</code> variable. They are prompts which will passting to LLM to restrict the LLM answers. The code is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    MessagesPlaceholder</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">contextualize_q_system_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Given a chat history and the latest user question \</span></span><br><span class="line"><span class="string">which might reference context in the chat history, formulate a standalone question \</span></span><br><span class="line"><span class="string">which can be understood without the chat history. Do NOT answer the question, \</span></span><br><span class="line"><span class="string">just reformulate it if needed and otherwise return it as is.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">contextualize_q_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, contextualize_q_system_prompt),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">qa_system_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Act like a WiX (WixToolset) development expert and help me with related WiX development questions. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Some **strict rules** you have to follow NO MATTER WHAT:</span></span><br><span class="line"><span class="string">Only answer related questions about WiX development.</span></span><br><span class="line"><span class="string">If you don&#x27;t know the answer, say:</span></span><br><span class="line"><span class="string">I don&#x27;t have such information, please refer to WiX offical documentation for the information. https://docs.firegiant.com/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Please Use the following pieces of context to answer the user&#x27;s question. </span></span><br><span class="line"><span class="string">----------------</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">QA_PROMPT = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, qa_system_prompt),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The <code>contextualize_q_prompt</code> is used to create the contextualized question prompt base on chat history and the latest user iput. The <code>MessagesPlaceholder(&quot;chat_history&quot;)</code> is used to insert the chat history in the prompt. From the prompt, It will formulate a standard question base on chat history and the latest user input.</p><p>The <code>qa_system_prompt</code> is used to create the question answer prompt. It is limit to only answer the related questions about WiX development. If the user’s question is not related to WiX development, it will say I don’t have such information, please refer to the WiX offical documentation for the information. You can also remove this limitation prompt text to make the AI model reply any question.</p><p>So now, our chain is ready to use. Next step we will uset this chain to answer the user’s question.</p><h2 id="Invoke-Chain"><a href="#Invoke-Chain" class="headerlink" title="Invoke Chain"></a>Invoke Chain</h2><p>In previous step, we have set the <code>conversational_rag_chain</code> as the chatbot chain using the <code>cl.user_session.set</code> method. Now, we can use it to answer the user’s question. Below is <code>@cl.on_message</code> annotation to invoke the chain and send the response.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@cl.on_message</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">message: cl.Message</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        chain = cl.user_session.get(<span class="string">&quot;chain&quot;</span>)</span><br><span class="line">        msg = cl.Message(content=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        res = chain.invoke(</span><br><span class="line">            &#123;<span class="string">&quot;input&quot;</span>: message.content&#125;, </span><br><span class="line">            config=&#123;</span><br><span class="line">                <span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: cl.user_session.get(<span class="string">&quot;id&quot;</span>)&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        response = res[<span class="string">&quot;answer&quot;</span>]</span><br><span class="line"></span><br><span class="line">        stream_size = <span class="number">20</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">len</span>(response) / stream_size)) + <span class="number">1</span>):</span><br><span class="line">            msg.content = response[<span class="number">0</span> : (i + <span class="number">1</span>) * stream_size]</span><br><span class="line">            <span class="keyword">await</span> msg.send()</span><br><span class="line">            time.sleep(<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;An error occurred: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> e.code == <span class="string">&quot;content_filter&quot;</span>:</span><br><span class="line">            <span class="keyword">await</span> cl.ErrorMessage(</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                The response was filtered due to the prompt triggering Azure OpenAI&#x27;s content management policy. Please modify your prompt and retry. </span></span><br><span class="line"><span class="string">                To learn more about our content filtering policies please read our documentation: </span></span><br><span class="line"><span class="string">                https://go.microsoft.com/fwlink/?linkid=2198766</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                ).send()</span><br></pre></td></tr></table></figure><p>In above code, we get the <code>conversational_rag_chain</code> from the <code>cl.user_session</code> and invoke it with the user’s message. We set the <code>session_id</code> in the <code>config</code> parameter to get the chat history for each session. We then send the response to the user in chunks of 20 characters.</p><p>The following code is simulating the stream response in the UI. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream_size = <span class="number">20</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">len</span>(response) / stream_size)) + <span class="number">1</span>):</span><br><span class="line">    msg.content = response[<span class="number">0</span> : (i + <span class="number">1</span>) * stream_size]</span><br><span class="line">    <span class="keyword">await</span> msg.send()</span><br><span class="line">    time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><p>The AzureOpenAI has content limitation, the user input which pass to the OpenAI API will be filtered if it contains any offensive or inappropriate content. So, we need to handle this situation. We can use the <code>ErrorMessage</code> class to send the error message to the user if the response is filtered.</p><h2 id="Chat-Demo-Screenshoots"><a href="#Chat-Demo-Screenshoots" class="headerlink" title="Chat Demo Screenshoots"></a>Chat Demo Screenshoots</h2><p>Below are screenshots of the chatbot conversation UI and response.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this blog, we have built a RAG chatbot using the <code>LangChain</code>, <code>Chainlit</code> and <code>OpenAI</code> base on previous <code>FAISS</code> index. We have used the <code>Chainlit</code> to build the chatbot UI, and the <code>LangChain</code> to build the conversation chain. We have also used the <code>FAISS</code> library to load the <code>FAISS</code> vector index and the <code>AzureChatOpenAI</code> language model. Finally, we have used the <code>RunnableWithMessageHistory</code> class to handle the chat history and the <code>ErrorMessage</code> class to handle the content filter.</p><p>If you want to get the full code, you can find it in the <a href="https://github.com/stonefishy/converstional-rag-chatbot">GitHub repository</a>. In this demo, we just put the 4 PDF documents which upgrade Wix3, Wix4 to Wix5. You can replace it with your own documents.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In previous blog, we have converting the PDF documents into the &lt;code&gt;FAISS&lt;/code&gt; vector index, and saved in the local. Now, we will bui</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
    <category term="Langchain" scheme="https://stonefishy.github.io/tags/Langchain/"/>
    
    <category term="Chainlit Chatbot" scheme="https://stonefishy.github.io/tags/Chainlit-Chatbot/"/>
    
  </entry>
  
  <entry>
    <title>Conversational RAG Chatbot - Converting PDF Document to Vector</title>
    <link href="https://stonefishy.github.io/2025/02/24/conversational-rag-chatbot-converting-pdf-document-to-vector/"/>
    <id>https://stonefishy.github.io/2025/02/24/conversational-rag-chatbot-converting-pdf-document-to-vector/</id>
    <published>2025-02-24T16:27:50.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this series of blogs, we will build a <code>RAG(Retrieval-Augmented Generation)</code> chatbot which using <code>WiX(WiXToolset)</code> documents as knowledge data. It will contains below steps:</p><ol><li>Converting PDF Document to Vector</li><li>Building a Chatbot that can answer questions based on the documents</li></ol><p>The technology stack used in this project are</p><ul><li>Python</li><li>LangChain</li><li>OpenAI</li><li>Chainlit</li><li>FAISS</li></ul><p>In this blog, we will focus on the first step, Converting PDF Document to Vector. </p><h2 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h2><p>The vector is a mathematical representation of a document or a text. It is a numerical representation of the text that can be used for various natural language processing tasks. The vector can be generated using various techniques like Bag-of-Words, TF-IDF, Word2Vec, etc. To store the vector, we can use various databases like FAISS, Pinecone, chroma etc.</p><h2 id="PDF-Document-to-Vector"><a href="#PDF-Document-to-Vector" class="headerlink" title="PDF Document to Vector"></a>PDF Document to Vector</h2><h3 id="FAISS"><a href="#FAISS" class="headerlink" title="FAISS"></a>FAISS</h3><p>In this blog, we will use <code>FAISS(Facebook AI Similarity Search)</code> to save the vector on local. The FAISS is  is a library for efficient similarity search and clustering of dense vectors. It is developed by Faiss Team at Facebook AI Research. FAISS is designed to handle large-scale nearest neighbor searches, which are common in applications like recommendation systems, image retrieval, and natural language processing. The library provides multiple algorithms for searching and clustering, including exact and approximate methods, and is optimized for both speed and accuracy. It supports various types of vector norms and can be used on both CPU and GPU for fast computation.</p><h3 id="Prepare-the-PDF-documents"><a href="#Prepare-the-PDF-documents" class="headerlink" title="Prepare the PDF documents"></a>Prepare the PDF documents</h3><p>For the WiX documents, we can download the documents from the official website <a href="https://docs.firegiant.com/wix/fivefour/">https://docs.firegiant.com/wix/fivefour/</a>. And here we only use the WiX upgrade guide document. Below are documents we are using:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-pdfs.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-pdfs.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="Extracting-Text-from-PDF-Documents"><a href="#Extracting-Text-from-PDF-Documents" class="headerlink" title="Extracting Text from PDF Documents"></a>Extracting Text from PDF Documents</h3><p>We will using the library <code>PyPDF2</code> to extract the text from the PDF documents. Below is code snippet to extract all the text from the PDF documents and store it in a text variable. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pdf_directory = Path(pdf_storage_path)</span><br><span class="line">text = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">    pdf_reader = PdfReader(pdf_path, <span class="literal">True</span>)</span><br><span class="line">    pdf_text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">        page_text = page.extract_text()</span><br><span class="line">        pdf_text += page_text</span><br><span class="line"></span><br><span class="line">    txt_path = pdf_path.with_name(pdf_path.stem + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(pdf_text)</span><br><span class="line">    text += pdf_text + <span class="string">&quot;\n\n&quot;</span> </span><br></pre></td></tr></table></figure><h3 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h3><p>Using the <code>AzureOpenAIEmbeddings</code> class from <code>langchain</code> library to get the vector representation of the text. For the Azuer OpenAI endpoints and api keys you can define it in the <code>.env</code> file.</p><p>.env file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_ENDPOINT=</span><br><span class="line">AZURE_OPENAI_API_KEY=</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION=<span class="number">2023</span>-07-01-preview</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME=text-embedding-ada-002</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002</span><br><span class="line">AZURE_OPENAI_ADA_DEPLOYMENT_VERSION=<span class="number">2023</span>-07-01-preview</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">embeddings = AzureOpenAIEmbeddings(</span><br><span class="line">    deployment=AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,</span><br><span class="line">    model=AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME,</span><br><span class="line">    azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">    openai_api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">    openai_api_version=AZURE_OPENAI_ADA_DEPLOYMENT_VERSION</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="Construct-FAISS"><a href="#Construct-FAISS" class="headerlink" title="Construct FAISS"></a>Construct FAISS</h3><p>After we have extracted the text from the PDF documents, below code snippet will construct the FAISS index. Using the <code>RecursiveCharacterTextSplitter</code> class from <code>langchain</code> library to split the text into chunks. Using <code>AzureOpenAIEmbeddings</code> class from <code>langchain</code> library, we can get the vector representation of the text. And save it into the FAISS index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>, </span><br><span class="line">    chunk_overlap=<span class="number">250</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;splitting text into chunks...&quot;</span>)</span><br><span class="line">chunks = text_splitter.split_text(text)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">vector_store =FAISS.from_texts(chunks, embeddings)</span><br><span class="line">vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>So the entire workflow is that we have downloaded the PDF documents, extracted the text from the PDF documents, and constructed the FAISS index. The FAISS index will be saved in the local directory.</p><p>Below is the function code snippet:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">250</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        pdf_reader = PdfReader(pdf_path, <span class="literal">True</span>)</span><br><span class="line">        pdf_text = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">            page_text = page.extract_text()</span><br><span class="line">            pdf_text += page_text</span><br><span class="line"></span><br><span class="line">        txt_path = pdf_path.with_name(pdf_path.stem + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            file.write(pdf_text)</span><br><span class="line">        text += pdf_text + <span class="string">&quot;\n\n&quot;</span> </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;splitting text into chunks...&quot;</span>)</span><br><span class="line">    chunks = text_splitter.split_text(text)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">    vector_store =FAISS.from_texts(chunks, embeddings)</span><br><span class="line">    vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>There is also another way to construct the FAISS index using the <code>langchain</code> library from pdf documents. Using <code>PyMuPDFLoader</code> to load the pdf documents instead of extracting the text from the pdf documents. Below is the code snippet:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss2</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    docs = []</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">250</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        loader = PyMuPDFLoader(<span class="built_in">str</span>(pdf_path))</span><br><span class="line">        documents = loader.load()</span><br><span class="line">        pdf_docs= text_splitter.split_documents(documents)</span><br><span class="line">        docs += pdf_docs</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">    vector_store =FAISS.from_documents(docs, embeddings)</span><br><span class="line">    vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>Above two code snippets are reading all documents from one directory and saving them into the FAISS index. But somehow, if the text is too long and exceed the maximum length of the Azure OpenAI API, it failed to process the text. Refer to Azure OpenAI API documentation <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits">https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits</a>. </p><p>We can count the token by using <code>tiktoken</code> library. The model is used to tokenize the text. If the model is not found, it defaults to using the ‘cl100k_base’ tokenizer. Here we can passing the AzureOpenAIEmbeddings model to the <code>count_tokens</code> function to count the number of tokens in the text.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Counts the number of tokens in a given text using the specified model&#x27;s tokenizer.</span></span><br><span class="line"><span class="string">If the model is not found, it defaults to using the &#x27;cl100k_base&#x27; tokenizer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    text (str): The input text to be tokenized.</span></span><br><span class="line"><span class="string">    model (str): The name of the model for which the tokenizer is used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    int: The total number of tokens in the text.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_tokens</span>(<span class="params">text, model</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        encoding = tiktoken.encoding_for_model(model)</span><br><span class="line">    <span class="keyword">except</span> KeyError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Warning: model not found. Using cl100k_base encoding.&quot;</span>)</span><br><span class="line">        encoding = tiktoken.get_encoding(<span class="string">&quot;cl100k_base&quot;</span>)</span><br><span class="line">    num_tokens = <span class="built_in">len</span>(encoding.encode(text))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total tokens: <span class="subst">&#123;num_tokens&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> num_tokens</span><br></pre></td></tr></table></figure><h3 id="Mergging-Indexes"><a href="#Mergging-Indexes" class="headerlink" title="Mergging Indexes"></a>Mergging Indexes</h3><p>The FAISS supports to merge multiple indexes into one index. So we can merge the index of all the documents into one index. Below is the code snippet to merge the index of all the documents into one index.</p><p>Let’s write another function to embedding pdfs into individual index. Below function will embedding all the pdfs into individual index and save it in the specified directory.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss_files</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, faiss_dir_path: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">200</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        loader = PyMuPDFLoader(<span class="built_in">str</span>(pdf_path))</span><br><span class="line">        documents = loader.load()</span><br><span class="line">        pdf_docs= text_splitter.split_documents(documents)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;embedding document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        vector_store =FAISS.from_documents(pdf_docs, embeddings)</span><br><span class="line">        vector_store.save_local(faiss_dir_path, pdf_path.stem)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;finished processing pdf <span class="subst">&#123;pdf_path&#125;</span>!&quot;</span>)</span><br></pre></td></tr></table></figure><p>Call this function with below code snippet to embedding all the pdfs into individual index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pdfs_to_faiss_files(PDF_STORAGE_PATH, <span class="string">&quot;./faiss_files&quot;</span>)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-pdfs-indexing.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-pdfs-indexing.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-indexes.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-indexes.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After these indexes are created, we can use FAISS to merge them into one index. Below is the code snippet to merge the index of all the documents into one index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Merges multiple FAISS files into a single index.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    faiss_dir_path (str): The path to the directory containing the FAISS files.</span></span><br><span class="line"><span class="string">    index_name (str): The name of the index to be saved.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_faiss_files</span>(<span class="params">faiss_dir_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    faiss_directory = Path(faiss_dir_path)</span><br><span class="line">    </span><br><span class="line">    is_first_faiss = <span class="literal">True</span></span><br><span class="line">    first_faiss = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> faiss_path <span class="keyword">in</span> faiss_directory.glob(<span class="string">&quot;*.faiss&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading FAISS file <span class="subst">&#123;faiss_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> is_first_faiss:</span><br><span class="line">            is_first_faiss = <span class="literal">False</span></span><br><span class="line">            first_faiss = FAISS.load_local(</span><br><span class="line">                folder_path=faiss_dir_path, </span><br><span class="line">                embeddings=embeddings, </span><br><span class="line">                index_name=faiss_path.stem,</span><br><span class="line">                allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Merging with <span class="subst">&#123;faiss_path&#125;</span>&quot;</span>)</span><br><span class="line">            first_faiss.merge_from(FAISS.load_local(</span><br><span class="line">                folder_path=faiss_dir_path, </span><br><span class="line">                embeddings=embeddings, </span><br><span class="line">                index_name=faiss_path.stem,</span><br><span class="line">                allow_dangerous_deserialization=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    first_faiss.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br></pre></td></tr></table></figure><p>Call this function with below code snippet to merge all the indexes into one index. We merged all <code>FAISS</code> index files which are saved in the <code>faiss_files</code> directory into one index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge_faiss_files(<span class="string">&quot;./faiss_files&quot;</span>, INDEX_NAME)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-merging-indexings.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-merging-indexings.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-merged-index.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-merged-index.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Next step, we will build a WiX chatbot which loading this <code>FAISS</code> index and passing the question and retrieving the relevant documents from the index. For the entire code, you can check the github <a href="https://github.com/stonefishy/converstional-rag-chatbot">GitHub repository</a> to see the entire code.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this series of blogs, we wi</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
    <category term="Langchain" scheme="https://stonefishy.github.io/tags/Langchain/"/>
    
  </entry>
  
  <entry>
    <title>Deploy User Friendly AI Interface Chatbot on Local by Using Ollama + Open-WebUI.</title>
    <link href="https://stonefishy.github.io/2025/02/10/deploy-user-friendly-ai-interface-on-local-by-using-ollama-open-webui/"/>
    <id>https://stonefishy.github.io/2025/02/10/deploy-user-friendly-ai-interface-on-local-by-using-ollama-open-webui/</id>
    <published>2025-02-10T09:55:11.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<p>In Previous blog, we talk about how to running <code>DeepSeek</code> large language model (LLM) on local machine by using Ollama. For installing Ollama, you can check the previous blog. We play it and chat on terminal. In this blog, we will talk about how to deploy user-friendly AI interface chatbot on local machine by using Ollama and Open-WebUI.</p><h2 id="What-is-Open-WebUI"><a href="#What-is-Open-WebUI" class="headerlink" title="What is Open-WebUI?"></a>What is Open-WebUI?</h2><p><code>Open WebUI</code> is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like <code>Ollama</code> and <code>OpenAI-compatible APIs</code>, with built-in inference engine for RAG, making it a powerful AI deployment solution.</p><h2 id="Install-Ollama"><a href="#Install-Ollama" class="headerlink" title="Install Ollama"></a>Install Ollama</h2><p>To install the Ollama, you can download the <code>Ollama</code> from official website and follow the installation guide. Once installed, you can check the ollama version and commands using below commands in your terminal.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ollama --version</span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-version-commands.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-version-commands.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>For downloading the <code>LLM</code> model, using below command <code>ollama pull &lt;model_name&gt;</code>in your terminal.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>I already downloaded the <code>deepseek</code> and <code>gemma</code> models in my local machine. You can check the downloaded models using <code>ollama ls</code> command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-models-list.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-models-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Set-up-Open-WebUI"><a href="#Set-up-Open-WebUI" class="headerlink" title="Set up Open-WebUI"></a>Set up Open-WebUI</h2><p>After you setup the Ollama, to set up Open-WebUI, there are multiple ways</p><h3 id="Docker-way"><a href="#Docker-way" class="headerlink" title="Docker way"></a>Docker way</h3><p>If you have installed <code>Docker</code> on your local, you can easily launch Open-WebUI using below command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure><p>Once it done, access the Open-WebUI by using <code>http://localhost:3000</code> in your browser.</p><h3 id="Python-pip-way"><a href="#Python-pip-way" class="headerlink" title="Python pip way"></a>Python pip way</h3><p>The second way is to install Open-WebUI by using Python pip and launch it locally. It requires <code>Python 3.11</code> to avoid the compatibility issues.</p><p>Check Python version, ensure the version is 3.11 or above.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><p>Next, install Open-WebUI using pip.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install open-webui</span><br></pre></td></tr></table></figure><p>When you install Open-WebUI by using python pip command, if you local machine  Microsoft Visual C++ compiler version is lower than 14, you may encounter the below error.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Building wheels for collected packages: chroma-hnswlib</span><br><span class="line">  Building wheel for chroma-hnswlib (pyproject.toml) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line"></span><br><span class="line">  × Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [5 lines of output]</span><br><span class="line">      running bdist_wheel</span><br><span class="line">      running build</span><br><span class="line">      running build_ext</span><br><span class="line">      building &#x27;hnswlib&#x27; extension</span><br><span class="line">      error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/</span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">  ERROR: Failed building wheel for chroma-hnswlib</span><br><span class="line">Failed to build chroma-hnswlib</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-pip-install-error.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-pip-install-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>.<p>To fix this issue, you can install the latest version of C++ compiler and re-install the Open-WebUI. Download the Microsoft C++ Build Tools from the official website <a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/">https://visualstudio.microsoft.com/visual-cpp-build-tools/</a>.</p><p>Install the <code>Desktop development with C++</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-pip-error-resolved.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-pip-error-resolved.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After the latest C++ compiler installed, re-install <code>Open-WebUI</code> again, once all completed, launch the Open-WebUI using below command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open-webui serve</span><br></pre></td></tr></table></figure><p>This will start the Open WebUI server, which we can access at <a href="http://localhost:8080/">http://localhost:8080</a></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-serve.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-serve.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Access the Open-WebUI by using <code>http://localhost:8080</code> in your browser. And create an admin account. Then you can start to use the <code>Open-WebUI</code>.<br>I have already installed some LLM models from <code>Ollama</code>, so we can see there are several models listed in the <code>Open-WebUI</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-models.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-models.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Have-Fun-with-Open-WebUI"><a href="#Have-Fun-with-Open-WebUI" class="headerlink" title="Have Fun with Open-WebUI"></a>Have Fun with Open-WebUI</h2><p>Let’s try to use <code>Gemma</code> model and <code>DeepSeek</code> model to chat with Open-WebUI.</p><h3 id="Using-Gemma-model"><a href="#Using-Gemma-model" class="headerlink" title="Using Gemma model"></a>Using Gemma model</h3><p>To use the <code>Gemma</code> model, select the <code>Gemma</code> model from the <code>Models</code> dropdown list and start to chat with the chatbot. Let’s use the <code>gemma:2b</code> model to chat.<br>If the model is not listed, using <code>Ollama</code> to download the model first.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-gemma-model.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-gemma-model.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="Using-DeepSeek-model"><a href="#Using-DeepSeek-model" class="headerlink" title="Using DeepSeek model"></a>Using DeepSeek model</h3><p>To use the <code>DeepSeek</code> model, select the <code>DeepSeek</code> model from the <code>Models</code> dropdown list and start to chat with the chatbot. Let’s use the <code>deepseek-r1:1.5b</code> model to chat.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-deepseek-model.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-deepseek-model.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>We can see the results of the <code>gemma:2b</code> model and the <code>deepseek-r1:1.5b</code> model are different. The <code>gemma:2b</code> model is just decreased in quality, however, the <code>deepseek-r1:1.5b</code> model is more accurate. It takes some time to deep thinking, and answer it carefully.</p><p>In <code>DeepSeek</code> model, we can see the thinking process of the deepseek model. It is a good way to understand how the deepseek thinking.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-deepseek-thinking.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-deepseek-thinking.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this blog, we have talked about how to deploy user-friendly AI interface chatbot on local machine by using Ollama and Open-WebUI. We have also used the <code>Gemma</code> and <code>DeepSeek</code> models to chat with the chatbot. We can see the results of the <code>gemma:2b</code> model and the <code>deepseek-r1:1.5b</code> model are different. The <code>gemma:2b</code> model is just decreased in quality, however, the <code>deepseek-r1:1.5b</code> model is more accurate. It takes some time to deep thinking, and answer it carefully.</p><p>Hope you like it. have fun to use <code>Open-WebUI</code>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In Previous blog, we talk about how to running &lt;code&gt;DeepSeek&lt;/code&gt; large language model (LLM) on local machine by using Ollama. For ins</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="Ollama" scheme="https://stonefishy.github.io/tags/Ollama/"/>
    
    <category term="DeepSeek" scheme="https://stonefishy.github.io/tags/DeepSeek/"/>
    
    <category term="Gemma" scheme="https://stonefishy.github.io/tags/Gemma/"/>
    
    <category term="Open-WebUI" scheme="https://stonefishy.github.io/tags/Open-WebUI/"/>
    
  </entry>
  
  <entry>
    <title>Running DeepSeek-R1 locally for free</title>
    <link href="https://stonefishy.github.io/2025/02/07/running-deepseek-r1-locally-for-free/"/>
    <id>https://stonefishy.github.io/2025/02/07/running-deepseek-r1-locally-for-free/</id>
    <published>2025-02-07T10:16:27.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/deepseek-logo.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/deepseek-logo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><p>The <code>DeepSeek</code> recently is very popular. The application download is on topest of the app store globally. The deepseek has several models, like <code>deepseek-r1</code>, <code>deepseek-coder</code> and <code>deepseek-v3</code> models etc. It’s all open source and free to use.</p><ul><li><code>deepseek-r1</code>: DeepSeek’s first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.</li><li><code>deepseek-coder</code>: It is a capable coding model trained on two trillion code and natural language tokens.</li><li><code>deepseek-v3</code>: A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.</li></ul><p>Here we will run the <code>deepseek-r1</code> model locally. It’s very easy and setup it quickly. Let’s get started.</p><h2 id="Ollama-download-and-installation"><a href="#Ollama-download-and-installation" class="headerlink" title="Ollama download and installation"></a>Ollama download and installation</h2><p>The first step is to download the <code>Ollama</code> and install it on your local machine. It supports Windows, Linux and MacOS. You can download the latest version from the official website. <a href="https://ollama.com/">https://ollama.com/</a></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama" style="width:600px;"/></div><span class="image-caption">Ollama</span></div><p>After download and install it, you can check the version or commands from terminal or command-line.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Check the version of Ollama</span></span><br><span class="line">ollama --version</span><br><span class="line"></span><br><span class="line"><span class="comment">## Check the commands of Ollama</span></span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-version-commands.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-version-commands.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama version and commands"/></div><span class="image-caption">Ollama version and commands</span></div><h2 id="Running-the-deepseek-r1-model"><a href="#Running-the-deepseek-r1-model" class="headerlink" title="Running the deepseek-r1 model"></a>Running the deepseek-r1 model</h2><p>Now, we can run the <code>deepseek-r1</code> model using Ollama. We need to download this model by using ollama. The <code>deepseek-r1</code> model contains serveral models, 1.5b, 7b, 8b, 14b, 32b, 70b and even 671b. For general computer performance, suggestion to use 1.5b model. I tried the 8b model on my local. It can run but the response is slowlly and memory is up to 90%. The 1.5b model running smoothly and response is fast. My local machine has 16GB RAM and i7 processor.</p><p>We can use the following command to download the <code>deepseek-r1</code> model.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>we also can run this model directly, if the model not exist, it will download automatically.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-run-deepseek-r1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-run-deepseek-r1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama run deepseek-r1"/></div><span class="image-caption">Ollama run deepseek-r1</span></div><h2 id="Ask-anything-in-deepseek"><a href="#Ask-anything-in-deepseek" class="headerlink" title="Ask anything in deepseek"></a>Ask anything in deepseek</h2><p>Now, we can ask anything in deepseek. Just type the question and press enter. The model will answer the question. See below screenshot</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-deepseek-answer-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-deepseek-answer-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="DeepSeek-R1 Answer"/></div><span class="image-caption">DeepSeek-R1 Answer</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-deepseek-answer-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-deepseek-answer-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="DeepSeek-R1 Answer"/></div><span class="image-caption">DeepSeek-R1 Answer</span></div><p>See, it’s easy to run the <code>deepseek-r1</code> model locally. You can also run other models like <code>deepseek-coder</code> and <code>deepseek-v3</code> models, or <code>llama</code> model. The <code>Ollama</code> models contains many open source models, you can use it for free.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/deepseek-logo.png&quot; class=&quot;lazyload</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Ollama" scheme="https://stonefishy.github.io/tags/Ollama/"/>
    
    <category term="DeepSeek" scheme="https://stonefishy.github.io/tags/DeepSeek/"/>
    
  </entry>
  
  <entry>
    <title>A RAG Chatbot base on Azure OpenAI</title>
    <link href="https://stonefishy.github.io/2025/01/23/rag-chatbot-base-on-azure-openai/"/>
    <id>https://stonefishy.github.io/2025/01/23/rag-chatbot-base-on-azure-openai/</id>
    <published>2025-01-23T11:31:28.000Z</published>
    <updated>2025-08-26T03:00:18.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this article, we will build a <code>RAG (Retrieval-Augmented Generation)</code> chatbot using Azure OpenAI’s GPT-4 language model. We will use <code>Python</code>, <code>LangChain</code> and the <code>Streamlit</code> library to build the chatbot interface. Vector store will use <code>FAISS</code> library to store the text chunks and metadata.</p><h2 id="What-is-RAG"><a href="#What-is-RAG" class="headerlink" title="What is RAG?"></a>What is RAG?</h2><p><code>RAG</code> is a technique that combines retrieval-based methods with generative models to enhance the quality and relevance of the information produced by AI systems. Here’s a breakdown of the two components:</p><ol><li><p><strong>Retrieval</strong>: The model first retrieves relevant documents, text, or data from a knowledge base, database, or external source using information retrieval techniques. This allows the model to access specialized or domain-specific knowledge, which it might not have inherently learned during training.</p></li><li><p><strong>Generation</strong>: After retrieving relevant information, the model then uses a generative language model (like GPT-3 or GPT-4) to create a response that is coherent, contextually appropriate, and informed by the retrieved content. This allows the AI to answer questions, generate text, or assist in decision-making with enhanced accuracy and knowledge.</p></li></ol><h2 id="Technical-Stack"><a href="#Technical-Stack" class="headerlink" title="Technical Stack"></a>Technical Stack</h2><p>To build the chatbot, we will use the following techiniques:</p><ul><li><strong>Azure OpenAI GPT-4</strong>: We will use the GPT-4 language model from Azure OpenAI to generate responses. GPT-4 is a transformer-based language model that is capable of generating coherent and diverse text.</li><li><strong>LangChain</strong>: LangChain is a Python library that allows us to use the GPT-4 model from Azure OpenAI in our chatbot. LangChain provides a simple interface for building chatbots using GPT-4.</li><li><strong>Streamlit</strong>: We will use Streamlit to build the chatbot interface. Streamlit is a framework for building web applications in Python. It allows us to create a user-friendly interface for our chatbot.</li><li><strong>FAISS</strong>: FAISS (Facebook AI Similarity Search) is an open-source library developed by Facebook AI Research. It’s designed for efficient similarity search and clustering of high-dimensional data, such as vectors. The primary use case for FAISS is in applications where you need to search for the most similar items to a given query item in large datasets of vectors</li></ul><h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>Before we start, make sure you have the following prerequisites:</p><ul><li>An Azure account</li><li>Python 3.6 or higher</li><li>An IDE or text editor</li><li>A knowledge base or dataset of relevant information</li></ul><h2 id="Setting-up-the-Environment"><a href="#Setting-up-the-Environment" class="headerlink" title="Setting up the Environment"></a>Setting up the Environment</h2><p>To set up the environment, we will need to install the following important libraries:</p><ul><li>LangChain</li><li>Streamlit</li><li>Azure OpenAI GPT-4</li></ul><p>And also include the <code>FAISS</code> and <code>PyPDF2</code> libraries. The <code>FAISS</code> library is used for efficient similarity search, and the <code>PyPDF2</code> library is used to extract text from PDF files.</p><p>Below is the entire python libraries:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">streamlit==1.40.0</span><br><span class="line">PyPDF2==3.0.1</span><br><span class="line">faiss-cpu==1.9.0</span><br><span class="line">openai==1.59.6</span><br><span class="line">tiktoken==0.8.0</span><br><span class="line">langchain==0.3.14</span><br><span class="line">langchain-community==0.3.14</span><br><span class="line">langchain-core==0.3.29</span><br><span class="line">langchain-openai==0.3.0</span><br><span class="line">langchain-text-splitters==0.3.5</span><br></pre></td></tr></table></figure><h2 id="Process-PDFs"><a href="#Process-PDFs" class="headerlink" title="Process PDFs"></a>Process PDFs</h2><p>Here we will read the PDF files and extract the text from them. We will use the <code>PyPDF2</code> library to extract the text from the PDF files. And then save it into local vector store which can be used for similarity search by FAISS. The entire code is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> PyPDF2 <span class="keyword">import</span> PdfReader</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureOpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">azure_endpoint = os.getenv(<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>)</span><br><span class="line">api_version = os.getenv(<span class="string">&quot;AZURE_OPENAI_API_VERSION&quot;</span>)</span><br><span class="line">api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line">embedding_deployment = os.getenv(<span class="string">&quot;AZURE_OPENAI_EMBEDDING_DEPLOYMENT&quot;</span>)</span><br><span class="line">chat_deployment = os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embeddings</span>():</span><br><span class="line">    <span class="comment"># generating embedding</span></span><br><span class="line">    <span class="keyword">return</span> AzureOpenAIEmbeddings(</span><br><span class="line">        azure_deployment=embedding_deployment,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        azure_endpoint=azure_endpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_files</span>(<span class="params">directory</span>):</span><br><span class="line">    path = Path(os.path.join(os.getcwd(), directory))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> path.exists():</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">f&quot;Directory <span class="subst">&#123;path.absolute()&#125;</span> does not exist&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">str</span>(file) <span class="keyword">for</span> file <span class="keyword">in</span> path.rglob(<span class="string">&quot;*&quot;</span>) <span class="keyword">if</span> file.is_file()]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_pdfs</span>(<span class="params">pdfs_directory, vector_store_folder_path, vector_store_index_name</span>):</span><br><span class="line">    pdf_files = get_all_files(pdfs_directory)</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> pdf_file <span class="keyword">in</span> pdf_files:</span><br><span class="line">        <span class="comment"># Read pdf file</span></span><br><span class="line">        pdf_reader = PdfReader(pdf_file)</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">            text += page.extract_text()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Break it into chunks</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">        chunk_size=<span class="number">1000</span>,</span><br><span class="line">        chunk_overlap=<span class="number">150</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">    )</span><br><span class="line">    chunks = text_splitter.split_text(text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Creating vector store - FAISS</span></span><br><span class="line">    vector_store = FAISS.from_texts(chunks, embeddings())</span><br><span class="line">    vector_store.save_local(vector_store_folder_path, vector_store_index_name)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Processed PDF documents to vector store path `<span class="subst">&#123;vector_store_folder_path&#125;</span>`&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    process_pdfs(config.pdfs_directory, config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In above code, we are reading the PDF files and extracting the text from them. We are using the <code>RecursiveCharacterTextSplitter</code> to break the text into chunks of 1000 characters with 150 characters overlap. And then using the <code>FAISS</code> library to create a vector store of the text chunks. The vector store is saved in the local file system. The vector store files contains two files (<code>*.faiss</code> and <code>*.pkl</code>) which can be used for similarity search.</p><p>The <code>*.faiss</code> file contains the vector representation of the text chunks. The <code>*.pkl</code> file contains the metadata of the text chunks.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/rag-chatbot-vector-store.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/rag-chatbot-vector-store.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="RAG Chatbot Vector Store"/></div><span class="image-caption">RAG Chatbot Vector Store</span></div><p>You may noticing that we are using the <code>dotenv</code> library to load the environment variables. You can create a <code>.env</code> file in the root directory of your project and add the following variables:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_ENDPOINT=&lt;your_endpoint_url&gt;</span><br><span class="line">AZURE_OPENAI_API_VERSION=&lt;your_api_version&gt;</span><br><span class="line">OPENAI_API_KEY=&lt;your_api_key?</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o # we are using gpt-4o model, you can use any other model which you deployed in your endpoint.</span><br><span class="line">AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002 # we are using text-embedding-ada-002 model.</span><br></pre></td></tr></table></figure><h2 id="Building-the-Chatbot"><a href="#Building-the-Chatbot" class="headerlink" title="Building the Chatbot"></a>Building the Chatbot</h2><p>After we have processed the PDF files and created the vector store, we can now build the chatbot using LangChain.</p><p>First, we will create a <code>LangChain</code> instance and load the vector store. Using <code>FAISS.load_local</code> method, we can load the vector store from the local file system with the same embeddings model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">embeddings</span>():</span><br><span class="line">    <span class="comment"># generating embedding</span></span><br><span class="line">    <span class="keyword">return</span> AzureOpenAIEmbeddings(</span><br><span class="line">        azure_deployment=embedding_deployment,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        azure_endpoint=azure_endpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_vector_store</span>(<span class="params">vector_store_folder_path, vectore_store_name</span>):</span><br><span class="line">    vector_store = FAISS.load_local(</span><br><span class="line">        folder_path=vector_store_folder_path, </span><br><span class="line">        embeddings=embeddings(), </span><br><span class="line">        index_name=vectore_store_name,</span><br><span class="line">        allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> vector_store </span><br></pre></td></tr></table></figure><p>Then, we will create a <code>AzureChatOpenAI</code> instance and load the chatbot model. We will use the <code>AzureChatOpenAI</code> class to interact with the GPT-4 model from Azure OpenAI. Using <code>load_qa_chain</code> method which is provided by <code>LangChain</code>, we can load the chatbot model from the Azure OpenAI.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generateChain</span>():</span><br><span class="line">    llm =  AzureChatOpenAI(</span><br><span class="line">        azure_endpoint=azure_endpoint,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        azure_deployment=chat_deployment,</span><br><span class="line">        temperature=<span class="number">0</span>,</span><br><span class="line">        max_tokens=<span class="number">1000</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># chain -&gt; take the question, get relevant document, pass it to the LLM, generate the output</span></span><br><span class="line">    chain = load_qa_chain(llm, chain_type=<span class="string">&quot;stuff&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> chain</span><br></pre></td></tr></table></figure><p>After the chain and the vector store are loaded, we can use FAISS vector store to similarity search the user input and retrieve the most relevant document. Passing the retrieved document to the LangChain chain which loads the AzureChatOpenAI to generate the response. Below is core code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector_store = load_vector_store(config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line">chain = generateChain()</span><br><span class="line">match_documents = vector_store.similarity_search(prompt)</span><br><span class="line">response = chain.run(input_documents = match_documents, question = prompt)</span><br></pre></td></tr></table></figure><p>The <code>chain.run</code> method takes the input documents and the question as input and returns the generated response. The <code>match_documents</code> variable contains the most relevant documents retrieved from the vector store. The <code>response</code> variable contains the generated response from the chatbot.</p><p>Finally, we will create a Streamlit interface to interact with the chatbot. We will use the <code>streamlit</code> library to create a user-friendly interface for our chatbot. For the <code>streamlit</code> library usage, you can refer to the official documentation. <a href="https://docs.streamlit.io/">https://docs.streamlit.io/</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    st.set_page_config(</span><br><span class="line">        page_title=<span class="string">&quot;JBL Products Chatbot&quot;</span>,</span><br><span class="line">        page_icon=<span class="string">&quot;🧊&quot;</span>,</span><br><span class="line">        layout=<span class="string">&quot;centered&quot;</span>,</span><br><span class="line">        initial_sidebar_state=<span class="string">&quot;expanded&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    st.header(<span class="string">&quot;JBL Products Chatbot&quot;</span>)</span><br><span class="line">    vector_store = load_vector_store(config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line">    chain = generateChain()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">        st.markdown(<span class="string">&quot;Ask me anything about JBL devices (JBL Pulse 5, JBL Clip 5, JBL Bar 500)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">        st.session_state.messages = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> st.session_state.messages:</span><br><span class="line">        <span class="keyword">with</span> st.chat_message(message[<span class="string">&quot;role&quot;</span>]):</span><br><span class="line">            st.markdown(message[<span class="string">&quot;content&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> prompt := st.chat_input(<span class="string">&quot;Ask me something&quot;</span>):</span><br><span class="line">        st.chat_message(<span class="string">&quot;user&quot;</span>).markdown(prompt)</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;)</span><br><span class="line"></span><br><span class="line">        response = <span class="string">&quot;I am thinking...&quot;</span></span><br><span class="line">        <span class="keyword">with</span> st.spinner(response):</span><br><span class="line">            match_documents = vector_store.similarity_search(prompt)</span><br><span class="line">            response = chain.run(input_documents = match_documents, question = prompt)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">            st.write_stream(generate_stream(response))</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response&#125;)</span><br></pre></td></tr></table></figure><p>In above code, we are using the <code>st.chat_message</code> method to create a chat message with a specific role, using the <code>st.chat_input</code> method to get the user input. And using the <code>st.spinner</code> method to show a loading spinner while the chatbot is generating the response. Finally using the <code>st.write_stream</code> method to write the response to the chat message.</p><p>For the stream response, actually we mock it by using the <code>generate_stream</code> method. This method is used to generate the stream response. We can use the <code>st.write_stream</code> method to write the stream response to the chat message. This will let the chatbot to print word one by one in the chat message.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_stream</span>(<span class="params">response</span>):</span><br><span class="line">    <span class="comment"># generate the stream of messages</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> response.split(<span class="string">&quot; &quot;</span>):</span><br><span class="line">        <span class="keyword">yield</span> word + <span class="string">&quot; &quot;</span></span><br><span class="line">        time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><p>Below is chatbot conversational interface:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/rag-chatbot-streamlit-interface.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/rag-chatbot-streamlit-interface.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="RAG Chatbot Streamlit Interface"/></div><span class="image-caption">RAG Chatbot Streamlit Interface</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article, we have built a <code>RAG (Retrieval-Augmented Generation)</code> chatbot using Azure OpenAI’s GPT-4 language model. We have used Python, LangChain and the Streamlit library to build the chatbot interface. We have also processed the PDF files and created the vector store using FAISS library. The pdf files is crawled from the website <a href="https://www.manua.ls/">https://www.manua.ls</a></p><p>For the entire code, you can refer to the Github repository: <a href="https://github.com/stonefishy/rag-chatbot">https://github.com/stonefishy/rag-chatbot</a>. Please don’t forget to star the repository if you find it useful. Thank you for reading.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this article, we will build</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="Streamlit" scheme="https://stonefishy.github.io/tags/Streamlit/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
  </entry>
  
</feed>
