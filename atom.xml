<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andrewsy&#39;s Space</title>
  
  
  <link href="https://stonefishy.github.io/atom.xml" rel="self"/>
  
  <link href="https://stonefishy.github.io/"/>
  <updated>2024-11-12T06:44:01.445Z</updated>
  <id>https://stonefishy.github.io/</id>
  
  <author>
    <name>Andrewsy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Introduction to LangChain: Make AI Smarter and Easier to use</title>
    <link href="https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/"/>
    <id>https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/</id>
    <published>2024-11-12T13:49:12.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-image.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-image.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:600px;"/></div></div><p>Have you ever wondered how some apps and websites can have conversations with you, answer your questions? Many of these apps use <code>artificial intelligence (AI)</code>, like the chatbot you might use to ask questions or get advice. But creating these smart systems can be tricky. This is where a tool called <code>LangChain</code> comes in to help!</p><p><code>LangChain</code> is a framework that makes it easier for developers to build applications that use <code>AI models</code>, like chatbots or smart helpers. In this blog, we’re going to explain what LangChain is, how it works, and why it’s useful for making AI apps.</p><h2 id="What-is-LangChain"><a href="#What-is-LangChain" class="headerlink" title="What is LangChain?"></a>What is LangChain?</h2><p>LangChain is a tool for developers that helps them build applications using <code>large language models (LLMs)</code>—the same kind of AI that powers chatbots, writing assistants, and more. LLMs can understand and generate text in a way that sounds like a real person. However, using these models to make powerful apps can be complicated. LangChain makes it easier by offering ready-made building blocks to connect these models to other tools, data, and even databases.</p><p>Think of LangChain like a set of Lego blocks that you can use to build cool things with AI. It saves developers time by giving them ready-made pieces to use, rather than having to create everything from scratch.</p><h2 id="Features-of-LangChain"><a href="#Features-of-LangChain" class="headerlink" title="Features of LangChain"></a>Features of LangChain</h2><p>Let’s break down some of the cool features LangChain offers and how they help developers make smarter apps.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-features.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-features.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="LangChain Features"/></div><span class="image-caption">LangChain Features</span></div><ol><li><p><strong>Chains</strong>: Putting Multiple Steps Together<br>Imagine you have a robot that can help with math homework. The robot might need to do multiple things to solve a problem. First, it could look up the math formula, then solve the problem, and finally explain the answer. In LangChain, these steps are called chains.</p><blockquote><p>A chain is a sequence of actions where each step depends on the previous one. For example, you could create a chain where:</p><p>First, the app asks the AI to pull data from a website.<br>Then, it uses that data to answer a question.<br>Finally, it summarizes the answer for the user.</p></blockquote></li><li><p><strong>Prompt Management</strong>: Talking to AI the Right Way<br>When you talk to an AI, how you ask your question or give your instruction is really important. That’s called a prompt. LangChain helps developers make the best prompts by letting them create templates. These templates let developers easily change certain parts of the prompt without having to rewrite it every time.</p><blockquote><p>For example, if you wanted to ask the AI to summarize a story, you could have a prompt like this:</p><p>“Please summarize the following story: {story}”</p><p>In this template, {story} is a placeholder that can be replaced with any story you want the AI to summarize.</p></blockquote></li><li><p><strong>Agents</strong>: Letting AI Decide What to Do Next<br>Sometimes, a smart system needs to decide what to do next based on the information it gets. For example, if you ask an AI about the weather, it might decide to pull the latest weather data from the internet. This decision-making is done by agents.</p><blockquote><p>An agent is like a helper that looks at the information it gets and chooses the best action. LangChain helps developers build agents that can make these decisions automatically.</p></blockquote></li><li><p><strong>Memory</strong>: Remembering What Happened Before<br>Have you ever talked to a chatbot and then later felt like it forgot what you said earlier? That can make a conversation feel weird. <code>LangChain helps solve this problem by letting the AI remember what was said earlier in the conversation</code>. This feature is called memory.</p><blockquote><p>or example, if you ask a chatbot for homework help and then ask a follow-up question, LangChain can help the AI remember the first question and give a more useful answer based on that memory.</p></blockquote></li><li><p><strong>Integrations</strong>: Connecting to Other Tools and Websites<br>Sometimes, an AI app needs to talk to other systems to get more information. <span class='pbg success'>LangChain makes this easy by letting developers connect their AI app to other tools</span> This is like having a personal assistant that not only talks to you but also has access to tons of information online.</p><blockquote><p>For example, an AI app could pull up the latest sports scores, or check the weather for you, using real-time data from the internet.</p></blockquote></li><li><p><strong>Retrieval-Augmented Generation (RAG)</strong>: Getting Smarter Answers<br>LangChain also lets AI search for information in real-time. This is called retrieval-augmented generation (RAG). It allows the AI to look up the latest data, like news stories or facts, and use that information to create smarter answers.</p><blockquote><p>For example, if you ask about the latest trends in video games, the AI can search the web for the most up-to-date information and then explain it to you.</p></blockquote></li></ol><h2 id="Why-Do-Developers-Use-LangChain"><a href="#Why-Do-Developers-Use-LangChain" class="headerlink" title="Why Do Developers Use LangChain?"></a>Why Do Developers Use LangChain?</h2><p>There are several reasons why developers might want to use LangChain:</p><ol><li><p>Makes It Easier to Build AI Apps<br>Instead of starting from scratch, LangChain gives developers tools that speed up the process of creating AI apps. Developers can use LangChain’s building blocks to create powerful applications without needing to write everything by hand.</p></li><li><p>It’s Flexible<br>LangChain can be used for a wide variety of apps. Whether you want to build a chatbot, a smart search engine, or an app that helps you study, LangChain has tools that make it easier to put everything together.</p></li><li><p>Saves Time<br>Developers don’t have to spend a lot of time figuring out how to make an AI model work with a database or how to chain steps together. LangChain does much of the heavy lifting, so developers can focus on the fun and creative parts of building their apps.</p></li><li><p>It’s <code>Open-Source</code><br>LangChain is free for anyone to use and improve. It’s open-source, which means developers from all over the world can contribute to making it better. If you’re learning to code or want to help improve the tool, you can!</p></li></ol><h2 id="Real-World-Examples-of-LangChain"><a href="#Real-World-Examples-of-LangChain" class="headerlink" title="Real-World Examples of LangChain"></a>Real-World Examples of LangChain</h2><p>LangChain is already being used in many cool ways. Here are a few examples:</p><ol><li><p>Chatbots<br>Developers can use LangChain to build chatbots that remember previous conversations and can talk to you like a real person. For example, you could create a chatbot to help you study for a test, and it would remember what you’ve learned so far.</p></li><li><p>Smart Assistants<br>LangChain can help build systems that pull information from the internet and use AI to explain things in simple terms. For example, if you’re stuck on a science problem, an AI could look up the topic online and explain it to you in a way you understand.</p></li><li><p>Automated Content Creation<br>Some apps use LangChain to automatically write articles or summaries. For example, a news website could use LangChain to summarize long articles or pull out the key points from reports, saving readers time.</p></li><li><p>Personalized Search Engines<br>LangChain can be used to build search engines that don’t just give you a list of links but also summarize the best results for you. This could help you find the exact answer you need faster.</p></li></ol><h2 id="How-to-Get-Started-with-LangChain"><a href="#How-to-Get-Started-with-LangChain" class="headerlink" title="How to Get Started with LangChain"></a>How to Get Started with LangChain</h2><p>If you’re excited to try out LangChain, here’s how you can get started:</p><ol><li>Install Python: LangChain works with Python, a programming language that’s great for beginners.</li><li>Install LangChain: You can install LangChain by running the command <code>pip install langchain</code> in Python.</li><li>Start Building: Once LangChain is installed, you can start building your own AI-powered applications! LangChain has tutorials and guides to help you learn how to use it.</li></ol><p>For more information, check out the LangChain documentation at <a href="https://python.langchain.com/docs/introduction/">https://python.langchain.com/docs/introduction/</a></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>LangChain is a super helpful tool for developers who want to build cool apps powered by AI. It makes it easier to connect different parts of an app, like databases or the web, with a language model that can understand and generate text. Whether it’s helping with homework, answering questions, or building a chatbot, LangChain is a great way to build smarter, more interactive applications.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/langchain-image.png&quot; class=&quot;lazylo</summary>
      
    
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
  </entry>
  
  <entry>
    <title>What is Prompt Engineering? Best Practices and Examples</title>
    <link href="https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/"/>
    <id>https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/</id>
    <published>2024-11-05T14:08:09.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophisticated, a new role has emerged in the AI ecosystem: <code>the Prompt Engineer</code>. The term might sound technical or niche, but it’s actually pivotal to leveraging AI models effectively. Whether you’re interacting with AI in your personal or professional life, the quality of the interaction largely depends on how well the prompt is designed. This article will explore what a prompt engineer does, the best practices for writing effective prompts, and provide examples comparing outputs with and without a prompt engineer’s expertise.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineering.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineering.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><h2 id="What-is-a-Prompt-Engineer"><a href="#What-is-a-Prompt-Engineer" class="headerlink" title="What is a Prompt Engineer?"></a>What is a Prompt Engineer?</h2><p><em>A Prompt Engineer is someone who specializes in crafting, refining, and optimizing prompts to ensure that AI models respond with the most relevant,accurate,and actionable information.</em> The role requires a blend of creativity, technical understanding, and knowledge of the AI’s underlying model architecture.</p><p>In essence, the prompt engineer’s job is to “speak” the language of the AI model. Since AI models like <code>GPT-3</code> or <code>GPT-4</code> don’t “think” like humans, their responses depend heavily on how the question or task is framed. A prompt engineer ensures that the right context, constraints, and phrasing are in place to guide the model toward producing the most useful responses.</p><h2 id="Why-is-Prompt-Engineering-Important"><a href="#Why-is-Prompt-Engineering-Important" class="headerlink" title="Why is Prompt Engineering Important?"></a>Why is Prompt Engineering Important?</h2><p>While AI models are capable of generating human-like text and performing complex tasks, their outputs are highly sensitive to the structure of the prompt. The same AI model could provide vastly different answers depending on the way a question is asked. Prompt engineers understand this sensitivity and use it to maximize the effectiveness of the interaction with AI.</p><p>Here are some reasons why prompt engineering is important:</p><p><strong>Maximizing output quality</strong>: Well-designed prompts improve the accuracy, relevance, and clarity of responses.<br><strong>Reducing errors</strong>: By properly framing a prompt, prompt engineers can help reduce misunderstandings or irrelevant responses.<br><strong>Efficiency</strong>: Instead of relying on trial and error to get useful responses, prompt engineers streamline the interaction process, saving time and resources.<br><strong>Contextuality</strong>: A good prompt will provide the necessary context for the model, ensuring that the response is in line with the user’s expectations.</p><h2 id="The-Path-of-a-Prompt-Engineer"><a href="#The-Path-of-a-Prompt-Engineer" class="headerlink" title="The Path of a Prompt Engineer"></a>The Path of a Prompt Engineer</h2><p>The process that a prompt engineer follows to ensure optimal results involves several stages. Each stage builds upon the last, leading to an iterative cycle that refines both the prompt and the AI’s output. Here’s a breakdown of the typical path of a prompt engineer:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineer-path.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineer-path.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="The Path of a Prompt Engineer" style="width:800px;"/></div><span class="image-caption">The Path of a Prompt Engineer</span></div><h3 id="1-Task-Understanding"><a href="#1-Task-Understanding" class="headerlink" title="1.Task Understanding:"></a>1.Task Understanding:</h3><p>Before crafting any prompt, the first step is to fully understand the task at hand. This involves clarifying the user’s goal, determining the desired output format, and understanding the nuances of the request. A deep understanding of the problem ensures that the prompt engineer can craft a question or instruction that addresses all necessary aspects.</p><blockquote><p>Example: If the task is to generate a poem, the prompt engineer will need to understand the tone, style, and subject matter required.</p></blockquote><h3 id="2-Crafting-Prompts"><a href="#2-Crafting-Prompts" class="headerlink" title="2.Crafting Prompts:"></a>2.Crafting Prompts:</h3><p>The next step is to craft the prompt. This involves framing the task clearly, with enough specificity to guide the AI toward the desired output. Crafting an effective prompt is not about asking a single question, but about <em>providing the model with the right context, constraints, and direction</em>.</p><blockquote><p>Example: Instead of asking, “Write a poem,” a more specific prompt might be, “Write a rhyming poem about the beauty of autumn, focusing on imagery and feelings of nostalgia.”</p></blockquote><h3 id="3-Prompt-Alignment"><a href="#3-Prompt-Alignment" class="headerlink" title="3.Prompt Alignment:"></a>3.Prompt Alignment:</h3><p>At this stage, the prompt must be aligned with the intended outcome. This means considering the AI model’s strengths and limitations and ensuring that the prompt leads the AI to produce a response that fits the desired format, tone, and depth. The prompt should ensure the model understands the context of the task, as well as any constraints or preferences that need to be respected.</p><blockquote><p>Example: For a technical article, aligning the prompt would involve ensuring the language model knows to prioritize clarity, accuracy, and technical precision.</p></blockquote><h3 id="4-Optimizing-Prompt"><a href="#4-Optimizing-Prompt" class="headerlink" title="4.Optimizing Prompt:"></a>4.Optimizing Prompt:</h3><p>After alignment, the prompt may need further refinement. This step involves fine-tuning the wording, simplifying complex instructions, or narrowing down the scope to ensure that the prompt is as effective as possible. <em>Optimization often involves making the prompt more specific and reducing ambiguity.</em></p><blockquote><p>Example: “Write a 300-word summary of the research paper on AI ethics, emphasizing the ethical dilemmas and implications for technology companies.” This version is more optimized than a broad, vague instruction.</p></blockquote><h3 id="5-AI-Model-Processing"><a href="#5-AI-Model-Processing" class="headerlink" title="5.AI Model Processing:"></a>5.AI Model Processing:</h3><p>Once the optimized prompt is provided, the AI model processes it and generates a response. This is where the model applies its underlying machine learning architecture, leveraging its training data to formulate a response.</p><blockquote><p>Example: The AI will analyze the prompt, consider patterns in its training data, and produce a response based on its understanding of the language and context.</p></blockquote><h3 id="6-Generating-Output"><a href="#6-Generating-Output" class="headerlink" title="6.Generating Output:"></a>6.Generating Output:</h3><p>The AI model generates the initial output based on the prompt. Depending on the AI model’s capabilities, this output may vary in length, style, accuracy, or even relevance to the task.</p><blockquote><p>Example: If the task was to summarize a paper, the output might include key findings, conclusions, and references to methodology.</p></blockquote><h3 id="7-Output-Refinement"><a href="#7-Output-Refinement" class="headerlink" title="7.Output Refinement:"></a>7.Output Refinement:</h3><p>Once the output is generated, prompt engineers review and refine it. This may involve removing irrelevant information, adjusting tone, adding details, or improving clarity. In some cases, the output might need to be restructured to fit the desired format.</p><blockquote><p>Example: If the AI’s response contains tangential information or lacks clarity, the prompt engineer would reword it or fine-tune the output to better align with the user’s expectations.</p></blockquote><h3 id="8-Iterative-Improvement"><a href="#8-Iterative-Improvement" class="headerlink" title="8.Iterative Improvement:"></a>8.Iterative Improvement:</h3><p>Finally, the process of prompt engineering is iterative. After refining the output, prompt engineers analyze the effectiveness of the response and assess how the prompt can be improved for future tasks. This leads to continuous improvement, ensuring that future prompts are even more optimized, concise, and aligned with user needs.</p><blockquote><p>Example: The engineer might adjust the prompt for the next interaction to ensure more relevant details or a more focused response.</p></blockquote><h2 id="Key-Skills-and-Tools-of-a-Prompt-Engineer"><a href="#Key-Skills-and-Tools-of-a-Prompt-Engineer" class="headerlink" title="Key Skills and Tools of a Prompt Engineer"></a>Key Skills and Tools of a Prompt Engineer</h2><p>Prompt engineering requires a variety of skills:</p><p><strong>Understanding of Language Models</strong>:<br>A prompt engineer should have a deep understanding of how LLMs like GPT process language. Knowing their strengths and weaknesses allows for better prompt design.</p><p><strong>Communication Skills</strong>:<br>Effective communication is critical, as prompt engineers must be able to convey complex instructions in a way that the model can interpret clearly.</p><p><strong>Creativity and Experimentation</strong>:<br>Crafting effective prompts often requires trial and error, testing different phrasings and structures to see what works best.</p><p><strong>Analytical Thinking</strong>:<br>Understanding how different types of inputs influence the model’s outputs and iterating to improve results.</p><p>In addition to these skills, prompt engineers also use tools to test and refine their prompts. For instance, platforms like OpenAI’s Playground allow users to experiment with various prompts in real-time, while more advanced professionals might leverage APIs to automate or scale their prompt engineering work.</p><h2 id="Best-Practices-for-Prompt-Engineering"><a href="#Best-Practices-for-Prompt-Engineering" class="headerlink" title="Best Practices for Prompt Engineering"></a>Best Practices for Prompt Engineering</h2><p>There are several strategies that a prompt engineer can employ to get the most out of a language model. Below are some of the best practices:</p><ol><li><p><strong>Be Specific and Clear</strong>: Ambiguous prompts can confuse AI models, leading to vague or incorrect responses. Make sure the prompt is clear and as specific as possible.</p><blockquote><p>Example: Instead of asking, “Tell me about AI,” a more specific prompt would be, “Can you explain the difference between supervised and unsupervised learning in AI?”</p></blockquote></li><li><p><strong>Use Context Effectively</strong>: Providing context can guide the model to better understand the desired output.</p><blockquote><p>Example: Instead of saying, “Write a poem,” say, “Write a rhyming poem about the beauty of autumn with a melancholic tone.”</p></blockquote></li><li><p><strong>Limit the Scope</strong>: Sometimes, less is more. Limit the scope of the prompt to avoid overwhelming the model with too much information or too many instructions.</p><blockquote><p>Example: Instead of “Write an article about the importance of artificial intelligence in modern business, covering all aspects of AI from machine learning to natural language processing,” you could say, “Write a short article explaining the importance of AI in customer service.”</p></blockquote></li><li><p><strong>Test and Iterate</strong>: A prompt engineer should test various iterations of a prompt to identify the most effective structure.</p></li><li><p><strong>Give Examples</strong>: For tasks requiring specific output formats, include an example to guide the model.</p><blockquote><p>Example: If you want a bulleted list, you could say, “List the steps in a process to build a website. For example: Step 1: Plan the layout.”</p></blockquote></li><li><p><strong>Use Temperature and Max Tokens</strong>: Some models allow you to adjust the <code>temperature (which controls randomness)</code> and the <code>max tokens (which sets a character limit)</code> to control the output. These can be adjusted to fine-tune the model’s output.</p></li></ol><h2 id="Comparing-with-and-without-Prompt-Engineering"><a href="#Comparing-with-and-without-Prompt-Engineering" class="headerlink" title="Comparing with and without Prompt Engineering"></a>Comparing with and without Prompt Engineering</h2><p>Now let’s look at some concrete examples of how a well-crafted prompt versus a poorly constructed one can affect the outcome.</p><h3 id="Example-1-Writing-a-Research-Summary"><a href="#Example-1-Writing-a-Research-Summary" class="headerlink" title="Example 1: Writing a Research Summary"></a>Example 1: Writing a Research Summary</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize this research paper.”</p><p>The AI may generate a generic or overly simplistic summary, without capturing the key aspects of the paper, such as methodology, results, and conclusions.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize the research paper titled ‘Exploring AI Ethics in Autonomous Vehicles.’ Focus on the methodology, key findings, and implications for policy. Keep the summary under 200 words.”</p><p>The AI’s response will be more targeted, concise, and aligned with the user’s expectations, providing a detailed summary that addresses the core aspects of the paper.</p><h3 id="Example-2-Writing-a-Creative-Story"><a href="#Example-2-Writing-a-Creative-Story" class="headerlink" title="Example 2: Writing a Creative Story"></a>Example 2: Writing a Creative Story</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a story.”</p><p>The story might lack direction, coherence, or creativity, leading to a generic or even nonsensical narrative.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a short story set in a post-apocalyptic world where humans are living on Mars. The protagonist is a scientist struggling with the ethical implications of using artificial intelligence to terraform the planet. Make the tone introspective and thought-provoking.”</p><p>The story produced will be richer, more engaging, and aligned with the specific context and themes the user wanted.</p><h3 id="Example-3-Asking-for-Code"><a href="#Example-3-Asking-for-Code" class="headerlink" title="Example 3: Asking for Code"></a>Example 3: Asking for Code</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function.”</p><p>The AI may generate a simple function, but it may not meet the user’s needs or lack important features such as error handling or optimization.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function to validate an email address using regular expressions. The function should return True if the email is valid and False if it is invalid. It should also handle common edge cases such as missing domain names or incorrect characters.”</p><p>The AI’s response will be much more precise, including the correct implementation, error handling, and edge case considerations.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In the world of AI, a <code>Prompt Engineer</code> plays a critical role in ensuring that AI models deliver optimal results. The expertise of prompt engineers can dramatically influence the quality, relevance, and accuracy of responses from language models like <code>GPT-4</code>. By following best practices—such as being specific, providing context, testing different iterations, and using examples—they can significantly improve the interaction between humans and AI.</p><p>As AI continues to evolve, the role of prompt engineering will become even more important, helping users and businesses unlock the full potential of artificial intelligence. Whether it’s writing, problem-solving, or complex technical tasks, the way we interact with AI will increasingly depend on how well we craft our prompts.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophis</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
    <category term="GPT-3" scheme="https://stonefishy.github.io/tags/GPT-3/"/>
    
    <category term="Prompt Engineering" scheme="https://stonefishy.github.io/tags/Prompt-Engineering/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Azure OpenAI GPT-4 API Chat Role Usage</title>
    <link href="https://stonefishy.github.io/2024/11/01/understanding-the-azure-openai-gpt-4-api-role/"/>
    <id>https://stonefishy.github.io/2024/11/01/understanding-the-azure-openai-gpt-4-api-role/</id>
    <published>2024-11-01T10:34:01.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p><code>Azure OpenAI</code> is a service provided by Microsoft that integrates OpenAI’s advanced language models into the Azure cloud platform. It allows developers to access and use OpenAI’s capabilities, such as natural language processing, code generation, and more, through Azure’s infrastructure.</p><p>Recently, we have deployed our first version of the OpenAI <code>GPT-4</code> model into the Azure cloud platform. This model is a powerful natural language model that can generate text based on a given prompt.</p><h2 id="What-is-GPT-4"><a href="#What-is-GPT-4" class="headerlink" title="What is GPT-4?"></a>What is GPT-4?</h2><p><code>GPT-4</code> is a transformer-based language model that was developed by OpenAI. It is a powerful language model that can generate text based on a given prompt. It has been trained on a large dataset of text and can generate coherent and engaging text that is often considered to be the next big thing in language models.</p><h2 id="How-can-I-use-the-GPT-4-API"><a href="#How-can-I-use-the-GPT-4-API" class="headerlink" title="How can I use the GPT-4 API?"></a>How can I use the GPT-4 API?</h2><p>To use the GPT-4 API, you need to follow these steps:</p><ol><li>Create an Azure account.</li><li>Create a resource group.</li><li>Create a new OpenAI resource.</li><li>Generate an API key.</li><li>Use the API key to make API requests.</li></ol><h3 id="1-Create-an-Azure-account"><a href="#1-Create-an-Azure-account" class="headerlink" title="1. Create an Azure account"></a>1. Create an Azure account</h3><p>To use the GPT-4 API, you need to have an Azure account. If you don’t have one, you can create one for free by following the steps in the <a href="https://azure.microsoft.com/en-us/free/">Azure sign-up page</a>.</p><h3 id="2-Create-a-resource-group"><a href="#2-Create-a-resource-group" class="headerlink" title="2. Create a resource group"></a>2. Create a resource group</h3><p>Create a resource group to organize your Azure resources. To create a new resource group, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>Resource groups</code> option in the left-hand menu.</li><li>Click on the <code>+ Create</code> button.</li><li>Enter a name for your resource group and select your subscription.</li><li>Click on the <code>Review + create</code> button.</li></ol><h3 id="3-Create-a-new-OpenAI-resource"><a href="#3-Create-a-new-OpenAI-resource" class="headerlink" title="3. Create a new OpenAI resource"></a>3. Create a new OpenAI resource</h3><p>To create a new OpenAI resource, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>Create a resource</code> button.</li><li>Search for <code>OpenAI</code> in the search bar.</li><li>Click on the <code>OpenAI</code> resource.</li><li>Click on the <code>Create</code> button.</li><li>Enter a name for your OpenAI resource and select your subscription.</li><li>Select the resource group you created earlier.</li><li>Select the pricing tier.</li><li>Click on the <code>Create</code> button.</li></ol><h3 id="4-Generate-an-API-key"><a href="#4-Generate-an-API-key" class="headerlink" title="4. Generate an API key"></a>4. Generate an API key</h3><p>To generate an API key, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>All resources</code> option in the left-hand menu.</li><li>Search for your OpenAI resource.</li><li>Click on the resource.</li><li>Click on the <code>Show access keys</code> button.</li><li>Copy the <code>Key 1</code> value.</li></ol><h3 id="5-Use-the-API-key-to-make-API-requests"><a href="#5-Use-the-API-key-to-make-API-requests" class="headerlink" title="5. Use the API key to make API requests"></a>5. Use the API key to make API requests</h3><p>To make API requests, we need to include the API key in the request headers. Here’s an example of how to make a request to the GPT-4 API with REST styles. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="variable">$AZURE_OPENAI_ENDPOINT</span>/openai/deployments/gpt-4o/chat/completions?api-version=2023-07-01-preview \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;api-key: <span class="variable">$AZURE_OPENAI_API_KEY</span>&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;&quot;messages&quot;:[&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;There are 5 classifications: Suggestion, Meanless, Compliment, Complaint, Please provide a classification for user input.&quot;&#125;,&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Does Azure OpenAI support customer managed keys?&quot;&#125;,&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;A classification word&quot;&#125;,&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;its great and easy to use&quot;&#125;]&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>Place your API key and endpoint in the appropriate variables, and update which deployments model (gpt-4, gpt-4o or other models) and model version of your endpoint is using.</p><p>The Azure OpenAI also supports multiple programming languages, including <code>Python</code>, <code>JavaScript</code>, and <code>C#</code>. You can use the API to generate text in your preferred programming language.</p><h2 id="GPT-4-Chat-Roles"><a href="#GPT-4-Chat-Roles" class="headerlink" title="GPT-4 Chat Roles"></a>GPT-4 Chat Roles</h2><p>In above message parameter, you may notice thata there are three roles: <code>system</code>, <code>user</code>, and <code>assistant</code>. The GPT-4 API supports three chat roles. Let digger deeper into each role:</p><p><strong>System</strong>: This role sets the context or guidelines for the conversation. It’s where you can specify instructions or constraints for how the assistant should behave throughout the interaction.</p><p><strong>User</strong>: This role represents the input from the person interacting with the model. Any questions or prompts posed by the user fall under this role.</p><p><strong>Assistant</strong>: This role is for the model’s responses. It contains the output generated by the assistant based on the user input and the context provided by the system.</p><p>In another word. The <code>system</code> role sets the context, the <code>user</code> role represents the input, and the <code>assistant</code> role contains the output.</p><blockquote><p>Use system to define the conversation’s tone, behavior, or rules.<br>Use user for all queries or statements made by the person.<br>Use assistant for the model’s replies.</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Let’s say we want to classify the product feedback classification as <code>Suggestion</code>, <code>Meanless</code>, <code>Compliment</code>, <code>Complaint</code>, or <code>Others</code>. We can use the GPT-4 API to generate text based on the given prompt and classify the feedback.</p><p>First, we define the context or guidelines to let the assistant know what result we want to achieve. Given below content to the <code>system</code> role.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;There are 5 classifications: Suggestion, Meanless, Compliment, Complaint, Please provide a classification for user input.&quot;&#125;,</span><br></pre></td></tr></table></figure><p>And, we only the <code>OpenAI</code> to reply me the classification word when user input is provided. So we define the <code>assistant</code> role as <code>classification word</code>.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;A classification word&quot;&#125;</span><br></pre></td></tr></table></figure><p>Now, we can ask the user to provide the feedback and provide the <code>user</code> role.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;its great and easy to use&quot;&#125;</span><br></pre></td></tr></table></figure><p>After the conversation, the <code>assistant</code> role will provide the classification word as <code>Compliment</code>. You will notice that there is a piece of json indicates the <code>assistant</code> role content value in the response. The OpenAI gpt-4o model knows “its great and easy to use” is a “Compliment” and provides the classification word as “Compliment”.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Compliment&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/openai-chat-role-api-usage-example-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/openai-chat-role-api-usage-example-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Classification - its great and easy to use" style="width:800px;"/></div><span class="image-caption">Classification - its great and easy to use</span></div><p>Let’s try another user input.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I&#x27;m in your walls&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/openai-chat-role-api-usage-example-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/openai-chat-role-api-usage-example-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Classification - I'm in your walls" style="width:800px;"/></div><span class="image-caption">Classification - I'm in your walls</span></div><p>The <code>assistant</code> role will provide the classification word as <code>Meanless</code>. Because this input is not meanful for any product feedback.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article, we have explored the role of the Azure OpenAI GPT-4 API and how it can be used to generate text. We have also learned about the chat roles and how to use them to classify the product feedback.</p>]]></content>
    
    
    <summary type="html">In this article, we will explore the role of the Azure OpenAI GPT-4 API and how it can be used to generate text.</summary>
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
  </entry>
  
  <entry>
    <title>Data Analysis Chart by Generative AI</title>
    <link href="https://stonefishy.github.io/2024/10/29/data-analysis-chart-by-generative-ai/"/>
    <id>https://stonefishy.github.io/2024/10/29/data-analysis-chart-by-generative-ai/</id>
    <published>2024-10-29T14:18:48.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>In data analysis, we often need to create charts to visualize the data by using BI tools, such as <code>Tableau</code>, <code>Power BI</code>, <code>AWS Quicksight</code>, or <code>Qlik Sense</code>. These tools allow us to create interactive and visually appealing charts, which can help us to identify patterns and trends in the data.</p><h2 id="General-Solution-Architecture-for-Data-Analysis-BI-Chart"><a href="#General-Solution-Architecture-for-Data-Analysis-BI-Chart" class="headerlink" title="General Solution Architecture for Data Analysis BI Chart"></a>General Solution Architecture for Data Analysis BI Chart</h2><p>The general data analysis BI chart solution architecture like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-general-arch.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-general-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="General Solution Architecture for Data Analysis BI Chart" style="width:800px;"/></div><span class="image-caption">General Solution Architecture for Data Analysis BI Chart</span></div>.<p>Usually, the engieering create business chart by using BI tools after data is ETL proceseed. If the business want to see the data distribution chart, they need to ask the data engineer to create the chart. The data engineer will create the chart using BI tools and share it with the business. This may take some time and effort.</p><h2 id="Solution-Architecture-for-Data-Analysis-BI-Chart-by-Generative-AI"><a href="#Solution-Architecture-for-Data-Analysis-BI-Chart-by-Generative-AI" class="headerlink" title="Solution Architecture for Data Analysis BI Chart by Generative AI"></a>Solution Architecture for Data Analysis BI Chart by Generative AI</h2><p>Think about the scenario where the business want to see the data distribution chart without the data engineer’s help. How can we create the chart without the data engineer’s help?</p><p>One way to create the data distribution chart without the data engineer’s help is to use a generative AI model. The business just need to describe what the data they want to see and want to display as which chart type. The generative AI application will create the chart for them.</p><p>The core important thing we need to let the GenAI to understand user’s natural language and generate the information which application can be use. The solution architecture like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-AI-arch.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-AI-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AI Solution Architecture for Data Analysis BI Chart" style="width:800px;"/></div><span class="image-caption">AI Solution Architecture for Data Analysis BI Chart</span></div>.<p>The AI application will take the user’s natural language as input and generate the chart for them. The AI application will use the following steps to generate the chart:</p><ol><li>Understand the user’s natural language and generate the chart title, chart type and chart related sql.</li><li>Connect to the database or dataset and execute the chart related sql to get the data.</li><li>Use the data to create the chart using the chart type.</li></ol><p>The AI model could be <code>ChatGPT</code>, <code>OpenAI</code> or <code>Claude</code> model. The AI model will generate the chart related sql, chart type and chart title based on the user’s natural language. The AI model will use the chart type to create the chart.</p><p>For example, if the user’s natural language is “Show the distribution of the sales by product category”, the AI application will generate the chart title as “Sales Distribution by Product Category” and chart type as “Bar Chart”. The AI application will execute the following sql to get the data:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> product_category, <span class="built_in">SUM</span>(sales) <span class="keyword">as</span> total_sales</span><br><span class="line"><span class="keyword">FROM</span> sales_data</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> product_category</span><br></pre></td></tr></table></figure><p>Below is a demo to generate the chart for the user’s natural language base on testing sample data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>User input natural language: </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;I want to see the distribution of all product categories with duplicate devices removed, and exclude the empty category, please display it in a pie chart.&quot;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-1a.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-1a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>The AI model response below base on the user’s natural language and prompts.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    &#x27;sql&#x27;<span class="punctuation">:</span> <span class="string">&quot;SELECT category, COUNT(DISTINCT macaddress) as device_count FROM device_demo_data WHERE category != &#x27;&#x27; GROUP BY category ORDER BY device_count DESC&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    &#x27;chart&#x27;<span class="punctuation">:</span> &#x27;pie&#x27;<span class="punctuation">,</span> </span><br><span class="line">    &#x27;title&#x27;<span class="punctuation">:</span> &#x27;Distribution of Unique Devices by Product Category&#x27;</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>There is a question, how the AI model know to generate this data format for us? Actually it is because we provide the prompts to the AI model. The prompts will guide the AI model to generate the chart related sql, chart type and chart title. Below is sample prompts:</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">You are a data analyst. Below is the table structure information about devices reported data. I will ask you questions, and then please generate the json data format &#123;&#x27;sql&#x27;:&#x27;&#x27;,&#x27;chart&#x27;:&#x27;table&#x27;,&#x27;title&#x27;:&#x27;&#x27;&#125; based on the questions I asked. </span><br><span class="line">Emphasize: I only need this json data format. The &#x27;sql&#x27; value is used by AWS Athena to query and generate the chart data. </span><br><span class="line">The &#x27;chart&#x27; value is the chart type, &#x27;numeric&#x27; represents a just a number, &#x27;table&#x27; represents a table chart, &#x27;pie&#x27; represents a pie chart, &#x27;bar&#x27; represents a bar chart, &#x27;line&#x27; represents a line chart. </span><br><span class="line">The &#x27;title&#x27; value is the chart title. Please remember, I only need the json string format data, don&#x27;t need other sentence.</span><br><span class="line">CREATE EXTERNAL TABLE `device_demo_data`(</span><br><span class="line">  `macaddress` string COMMENT &#x27;设备mac地址 / The device macaddress&#x27;, </span><br><span class="line">  `productname` string COMMENT &#x27;设备产品名称 / The device product name&#x27;, </span><br><span class="line">  `category` string COMMENT &#x27;设备产品的分类 / The device product category&#x27;, </span><br><span class="line">  `country` string COMMENT &#x27;设备所在的国家 / The country where the device is located&#x27;, </span><br><span class="line">  `region` string COMMENT &#x27;设备上传数据所在的区域 / The region where the device data is reported&#x27;, </span><br><span class="line">  `default_region` string COMMENT &#x27;设备出厂设置的默认区域 / The default region set by the device&#x27;, </span><br><span class="line">  `oneosversion` string COMMENT &#x27;设备OneOS的版本号 / The OneOS version of the device&#x27;, </span><br><span class="line">  `firmwareversion` string COMMENT &#x27;设备的固件版本号 / The firmware version of the device&#x27;, </span><br><span class="line">  `officialversion` string COMMENT &#x27;设备是否是官方的发布版本，1为官方版本， 0为非官方版本 / Whether the device is an official release, 1 for official version, 0 for non-official version&#x27;, </span><br><span class="line">  `createtime` string COMMENT &#x27;设备上报数据的日期, 数据类型是字符串，日期格式是2024-09-01，表示2024年9月1日 / The date when the device reported data, the data type is string, the date format is 2024-09-01, which means September 1, 2024&#x27;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>We tell AI model the data schema and each field means, and indicate only need the json format response with specific field. Once the AI model generate the response, we can use it to create the chart for the user’s natural language.</p><p>We can also generate the line chart base on time line.</p><p>User input natural language: </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">How many distinct devices reported every week, exclude the empty date, display the data in line graph</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>For the front-end UI to display the chart, we can use some chart library like <code>Echarts</code>, <code>Hightcharts</code>, <code>D3.js</code> or <code>Chart.js</code>. The front-end UI display the chart base on chart type and the data which queried by SQL.</p><p>All these generated charts can be added into dashboard.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-dashboard.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-dashboard.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<h2 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h2><p>As you can see, the AI solution architecture is a new way to create BI chart. However, it still has some limitations. It can not generate the complex chart which like some BI tools advanced chart fucntionality. But it is still a good start to create the chart for business users.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In data analysis, we often need to create charts to visualize the data by using BI tools, such as &lt;code&gt;Tableau&lt;/code&gt;, &lt;code&gt;Power BI&lt;/c</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>The Intelligent SQL Generator base on Spring AI with AWS Bedrock</title>
    <link href="https://stonefishy.github.io/2024/10/23/intelligent-sql-generator-base-on-spring-ai-with-aws-bedrock/"/>
    <id>https://stonefishy.github.io/2024/10/23/intelligent-sql-generator-base-on-spring-ai-with-aws-bedrock/</id>
    <published>2024-10-23T15:01:12.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>The generative AI is a type of artificial intelligence (AI) that can learn from data and generate new data. In this article, we will discuss how to build an intelligent SQL generator using <code>Spring AI</code> and <code>AWS Bedrock</code>. For example, the application able to provide the data sql to us after we input the natural language questions, and we can query the data by using the sql, even display the chart base on data queried.</p><h2 id="Spring-AI"><a href="#Spring-AI" class="headerlink" title="Spring AI"></a>Spring AI</h2><p>The <code>Spring AI</code> is a project of <code>Spring</code>. It support for all major AI Model providers such as <code>Anthropic</code>, <code>OpenAI</code>, <code>Microsoft</code>, <code>Amazon</code>, <code>Google</code>, and <code>Ollama</code>. Model type supports such as <code>Chart Completion</code>, <code>Text to Image</code>, <code>Text to Speech</code>, <code>Translation</code>, <code>Audio Transcription</code> and so on. It make it easy to integrate AI models into the application.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/spring-ai.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/spring-ai.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Spring AI" style="width:500px;"/></div><span class="image-caption">Spring AI</span></div><h2 id="AWS-Bedrock"><a href="#AWS-Bedrock" class="headerlink" title="AWS Bedrock"></a>AWS Bedrock</h2><p>Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case. It contains <code>Anthropic</code> (<code>Claude</code>), <code>Meta</code> (<code>Llama</code>) and <code>Stability AI</code> models. In this blog, we will use <code>Claude</code> AI model of <code>Anthropic</code> to build our intelligent SQL generator.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-ai.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-ai.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock" style="width:600px;"/></div><span class="image-caption">AWS Bedrock</span></div><h2 id="Building-Intelligent-SQL-Generator"><a href="#Building-Intelligent-SQL-Generator" class="headerlink" title="Building Intelligent SQL Generator"></a>Building Intelligent SQL Generator</h2><p>Assuming we’re data analyzer, we have product_sales, products and customers three tables data in mysql. And we want to query the data by input natural language instead of write specific SQL manually. We can use AI to understand user natural langauge to generate the SQL base on table schemas. Let’s get start. </p><h3 id="Create-a-new-Spring-Boot-project"><a href="#Create-a-new-Spring-Boot-project" class="headerlink" title="Create a new Spring Boot project"></a>Create a new Spring Boot project</h3><p>Create a <code>Spring Boot</code> project with restful api, add the following dependencies in maven <code>pom.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.ai<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-ai-bedrock-ai-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The <code>spring-ai-bedrock-ai-spring-boot-starter</code> is library that provides integration with <code>AWS Bedrock</code> models in <code>Spring AI</code>.</p><h3 id="Configure-AWS-Bedrock-configuraitons"><a href="#Configure-AWS-Bedrock-configuraitons" class="headerlink" title="Configure AWS Bedrock configuraitons"></a>Configure AWS Bedrock configuraitons</h3><p>In application.properties, configur below configurations.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=spring-ai-datasql</span><br><span class="line">spring.ai.bedrock.aws.region=us-east-1</span><br><span class="line">spring.ai.bedrock.aws.timeout=5m</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.enabled=true</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.options.max-tokens=4000</span><br><span class="line"></span><br><span class="line"># config below AWS credential key, configure it in Java environments or System environments</span><br><span class="line">spring.ai.bedrock.aws.access-key=$&#123;AWS_ACCESS_KEY_ID&#125;</span><br><span class="line">spring.ai.bedrock.aws.secret-key=$&#123;AWS_SECRET_ACCESS_KEY&#125;</span><br></pre></td></tr></table></figure><h3 id="Prepare-prompts-for-AI"><a href="#Prepare-prompts-for-AI" class="headerlink" title="Prepare prompts for AI"></a>Prepare prompts for AI</h3><p>Since we only need AI to generate the SQL base on mysql table schema. So we need prepare prompts to <code>AI</code> to fully understand our requirements. Below is <code>prompts.txt</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">There are 3 mysql tables schema product_sales, products, customers.</span><br><span class="line">CREATE TABLE product_sales (</span><br><span class="line">    sale_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    product_id INT NOT NULL,</span><br><span class="line">    sale_date DATETIME DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">    price DECIMAL(10, 2) NOT NULL,</span><br><span class="line">    customer_id INT,</span><br><span class="line">    region VARCHAR(100),</span><br><span class="line">    FOREIGN KEY (product_id) REFERENCES products(product_id),</span><br><span class="line">    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE products (</span><br><span class="line">    product_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    product_name VARCHAR(100),</span><br><span class="line">    product_category VARCHAR(100)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE customers (</span><br><span class="line">    customer_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    customer_name VARCHAR(100)</span><br><span class="line">);</span><br><span class="line">I will ask you question, please base on table schema to generate the SQL text in single line, please note I only need full correct sql text, do not</span><br><span class="line">need other text or any other characters.</span><br></pre></td></tr></table></figure><p>In above prompts, you can see it tells AI we only need SQL text base on the 3 mysql table schemas.</p><h3 id="Core-Code"><a href="#Core-Code" class="headerlink" title="Core Code"></a>Core Code</h3><p>Create a restful controller and pass the prompts and user input message to AI model.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spring.ai.datasql.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.ai.bedrock.anthropic3.BedrockAnthropic3ChatModel;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.*;</span><br><span class="line"><span class="keyword">import</span> spring.ai.datasql.service.PromptService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SQLGenController</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BedrockAnthropic3ChatModel chatModel;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> PromptService prompts;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SQLGenController</span><span class="params">(BedrockAnthropic3ChatModel chatModel)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.chatModel = chatModel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/ai/sql&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Map <span class="title function_">generate</span><span class="params">(<span class="meta">@RequestBody</span> String message)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">newMsg</span> <span class="operator">=</span> prompts.getContent() + message;</span><br><span class="line">        <span class="keyword">return</span> Map.of(<span class="string">&quot;sql&quot;</span>, chatModel.call(newMsg));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, we inject <code>BedrockAnthropic3ChatModel</code> which is <code>Anthropic</code> model of <code>AWS Bedrock</code> provided by <code>Spring AI</code>. We also inject <code>PromptService</code> which is a service to read prompts.<br>In <code>generate</code> method, we read prompts from <code>PromptService</code> and append user input message to it. Then we call <code>chatModel.call</code> method to generate the SQL text.</p><p>Code of <code>PromptService</code> to read prompts from file.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spring.ai.datasql.service;</span><br><span class="line"><span class="keyword">import</span> jakarta.annotation.PostConstruct;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Files;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Paths;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PromptService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;classpath:prompts.txt&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> org.springframework.core.io.Resource resource;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String fileContent;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        fileContent = <span class="keyword">new</span> <span class="title class_">String</span>(Files.readAllBytes(Paths.get(resource.getURI())));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getContent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fileContent;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Run-the-application"><a href="#Run-the-application" class="headerlink" title="Run the application"></a>Run the application</h3><p>Run the application and test the API by sending a request with user input message. We may encounter below errors.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-model-can-not-access.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-model-can-not-access.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock Model can not access"/></div><span class="image-caption">AWS Bedrock Model can not access</span></div><p>This is because the <code>spring.ai.bedrock.anthropic3.chat.model</code> in  current Spring AI version default value is <code>anthropic.claude-3-sonnet-20240229-v1:0</code>. Let’s check the anthropic available Claude models in AWS Bedrock. Here we use <code>Claude 3.5</code> AI model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-claude-model-id.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-claude-model-id.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock Anthropic Claude Model Id"/></div><span class="image-caption">AWS Bedrock Anthropic Claude Model Id</span></div><p>Copy this model id and update the <code>spring.ai.bedrock.anthropic3.chat.model</code> in <code>application.properties</code> file. The fully updated <code>application.properties</code> file should be like below.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=spring-ai-datasql</span><br><span class="line">spring.ai.bedrock.aws.region=us-east-1</span><br><span class="line">spring.ai.bedrock.aws.timeout=5m</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.enabled=true</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.options.max-tokens=4000</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.model=anthropic.claude-3-5-sonnet-20240620-v1:0</span><br><span class="line"></span><br><span class="line"># config below AWS credential key, it also can be configure in Java environments or System environments</span><br><span class="line">spring.ai.bedrock.aws.access-key=$&#123;AWS_ACCESS_KEY_ID&#125;</span><br><span class="line">spring.ai.bedrock.aws.secret-key=$&#123;AWS_SECRET_ACCESS_KEY&#125;</span><br></pre></td></tr></table></figure><p>Now, we can run the application and test the API.</p><h4 id="Test-Example-1"><a href="#Test-Example-1" class="headerlink" title="Test Example 1"></a>Test Example 1</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">What&#x27;s the total prices of product sales ?</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><p>The response will be like below.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(price) <span class="keyword">FROM</span> product_sales;</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>The <code>AI</code> model can generate the SQL text base on user input message.</p><h4 id="Test-Example-2"><a href="#Test-Example-2" class="headerlink" title="Test Example 2"></a>Test Example 2</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">How many customers by our products? I only need unique customers.</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id) <span class="keyword">FROM</span> product_sales</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-3"><a href="#Test-Example-3" class="headerlink" title="Test Example 3"></a>Test Example 3</h4><p><strong>Input:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I want to see the total sales prices for each product categories.</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> product_category, <span class="built_in">SUM</span>(price) <span class="keyword">AS</span> total_sales <span class="keyword">FROM</span> product_sales <span class="keyword">JOIN</span> products <span class="keyword">ON</span> product_sales.product_id <span class="operator">=</span> products.product_id <span class="keyword">GROUP</span> <span class="keyword">BY</span> product_category;</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-4"><a href="#Test-Example-4" class="headerlink" title="Test Example 4"></a>Test Example 4</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please show me all sales data which contains price, sales date, customer name and product name and product categories</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ps.price, ps.sale_date, c.customer_name, p.product_name, p.product_category <span class="keyword">FROM</span> product_sales ps <span class="keyword">JOIN</span> products p <span class="keyword">ON</span> ps.product_id <span class="operator">=</span> p.product_id <span class="keyword">JOIN</span> customers c <span class="keyword">ON</span> ps.customer_id <span class="operator">=</span> c.customer_id</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-4.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-5"><a href="#Test-Example-5" class="headerlink" title="Test Example 5"></a>Test Example 5</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please show total sales prices of each product category on 2nd quarter this year</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> p.product_category, <span class="built_in">SUM</span>(ps.price) <span class="keyword">AS</span> total_sales <span class="keyword">FROM</span> product_sales ps <span class="keyword">JOIN</span> products p <span class="keyword">ON</span> ps.product_id <span class="operator">=</span> p.product_id <span class="keyword">WHERE</span> <span class="keyword">YEAR</span>(ps.sale_date) <span class="operator">=</span> <span class="keyword">YEAR</span>(CURDATE()) <span class="keyword">AND</span> QUARTER(ps.sale_date) <span class="operator">=</span> <span class="number">2</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> p.product_category</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-5.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>As you can see the <code>AI</code> model can generate the SQL text base on user input message. Base on this function, we can download the data from mysql or display the chart base on data queried. It’s good for business analyst to query the data by natural language.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The generative AI is a type of artificial intelligence (AI) that can learn from data and generate new data. In this article, we will disc</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
    <category term="Spring AI" scheme="https://stonefishy.github.io/tags/Spring-AI/"/>
    
  </entry>
  
  <entry>
    <title>The useEffect of React Runs Twice in Development Mode.</title>
    <link href="https://stonefishy.github.io/2024/10/16/the-useeffect-of-react-runs-twice-in-development-mode/"/>
    <id>https://stonefishy.github.io/2024/10/16/the-useeffect-of-react-runs-twice-in-development-mode/</id>
    <published>2024-10-16T16:23:44.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>Have you noticed that your <code>useEffect</code> hook of <code>React</code> runs twice when the page first loads in development mode? This occurs because since <code>React 18</code>, it can be confusing, especially for new developers. Let’s explore why this happens and what it means.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-hook-useEffect.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-hook-useEffect.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React Hook useEffect" style="width:800px;"/></div><span class="image-caption">React Hook useEffect</span></div><h2 id="What-is-useEffect"><a href="#What-is-useEffect" class="headerlink" title="What is useEffect?"></a>What is <code>useEffect</code>?</h2><p><code>useEffect</code> is a hook that allows you to perform side effects in your components. Side effects can be things like <strong>fetching data</strong>, <strong>subscribing to events</strong>, or <strong>changing the DOM</strong>. This hook takes two arguments:</p><ol><li>A function to run your side effect.</li><li>An optional array of dependencies that tells React when to run the effect again.</li></ol><p>Here’s a simple example of useEffect in action:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; useEffect, useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">ExampleComponent</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Effect has been executed&#x27;</span>);</span><br><span class="line">    <span class="comment">// Side effect logic here</span></span><br><span class="line">  &#125;, [count]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">p</span>&gt;</span>You clicked &#123;count&#125; times<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;()</span> =&gt;</span> setCount(count + 1)&#125;&gt;Click me<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, the log ‘Effect has been executed’ will be printed to the console twice when the component is first render on development mode.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-useEffect-runs-twice.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-useEffect-runs-twice.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React useEffect runs twice in development mode"/></div><span class="image-caption">React useEffect runs twice in development mode</span></div><h2 id="Why-Does-useEffect-Run-Twice-in-Development-Mode"><a href="#Why-Does-useEffect-Run-Twice-in-Development-Mode" class="headerlink" title="Why Does useEffect Run Twice in Development Mode?"></a>Why Does useEffect Run Twice in Development Mode?</h2><p>When you run your React app in development mode, you might see that the useEffect runs twice when the component loads for the first time. This can be confusing, especially for new developers.</p><h3 id="Reasons-for-the-Double-Execution"><a href="#Reasons-for-the-Double-Execution" class="headerlink" title="Reasons for the Double Execution"></a>Reasons for the Double Execution</h3><p><strong>Strict Mode:</strong> This behavior is part of React’s <code>Strict Mode</code>. It purposely runs certain lifecycle methods and hooks like useEffect twice during development. This helps check if your code can handle side effects correctly.</p><p><strong>Testing Effects:</strong> By running the effect two times, React tests if your side effects can handle being called multiple times without causing bugs. This helps catch problems early.</p><h3 id="What-Happens-in-Production"><a href="#What-Happens-in-Production" class="headerlink" title="What Happens in Production?"></a>What Happens in Production?</h3><span class='pbg danger'>The double call only happens in development mode. When you make your app for production</span><h2 id="How-to-Handle-the-Double-Execution"><a href="#How-to-Handle-the-Double-Execution" class="headerlink" title="How to Handle the Double Execution"></a>How to Handle the Double Execution</h2><p>Here are some tips for dealing with the double execution of useEffect:</p><p><strong>Be Careful with State Updates</strong>: If your effect updates state, make sure it’s safe to run the effect multiple times without causing issues.</p><p><strong>Use Cleanup Functions</strong>: Always return a cleanup function from your useEffect to free up resources and avoid memory issues.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// Your side effect code here</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// Cleanup code here</span></span><br><span class="line">  &#125;;</span><br><span class="line">&#125;, [dependencies]);</span><br></pre></td></tr></table></figure><p><strong>Test Your Effects</strong>: Use the extra invocation to ensure that your effects work correctly.</p><h2 id="Disable-Strict-Mode"><a href="#Disable-Strict-Mode" class="headerlink" title="Disable Strict Mode"></a>Disable Strict Mode</h2><p>It is not recommend this way, but if you want to disable Strict Mode, in <code>React 18</code> you can disable Strict Mode by removing the <code>&lt;React.StrictMode&gt;</code> tag from the return statement in your root component.</p><p>In <code>Next.js</code>, you can disable Strict Mode by setting the following parameter in <code>next.config.js</code>:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">  <span class="attr">reactStrictMode</span>: <span class="literal">false</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><span class='pbg green'>Seeing useEffect run twice in development mode can be surprising</span> Understanding this behavior and preparing your code for it will allow you to use React hooks effectively and build better applications.<p>Even though this might seem confusing at first, it’s an important part of the React development experience. Happy coding!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Have you noticed that your &lt;code&gt;useEffect&lt;/code&gt; hook of &lt;code&gt;React&lt;/code&gt; runs twice when the page first loads in development mode? Th</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>AWS Glue Iceberg tables schema can&#39;t be updated with Pulumi</title>
    <link href="https://stonefishy.github.io/2024/10/09/aws-glue-iceberg-tables-schema-can-t-be-updated-with-pulumi/"/>
    <id>https://stonefishy.github.io/2024/10/09/aws-glue-iceberg-tables-schema-can-t-be-updated-with-pulumi/</id>
    <published>2024-10-09T09:46:22.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>Recently, we’re planing to use <code>Pulumi</code> to manage all current existing <code>AWS Glue Datacatalog</code> tables which are <code>Iceberg</code> format. For the <code>Iceberg</code> tables, I have post a blog before to talk about what is iceberg and what’s feature of it. Here is post link: <a href="https://stonefishy.github.io/2020/05/23/what-is-apache-iceberg/">https://stonefishy.github.io/2020/05/23/what-is-apache-iceberg/</a></p><p>To manage the AWS Glue Iceberg tables with <code>Pulumi</code>, due to our catalog table schemas are continue changes base on requirements. We need to do some technical POC whethere the pulumi can also support to update the iceberg metadata schema as well.</p><h2 id="Create-Glue-Iceberg-Table"><a href="#Create-Glue-Iceberg-Table" class="headerlink" title="Create Glue Iceberg Table"></a>Create Glue Iceberg Table</h2><p>We’re using <code>Pulumi</code> to manage the AWS Cloud Infrastructure. Before create glue table, a glue database is indeed.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_database_test = aws.glue.CatalogDatabase(<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    create_table_default_permissions=[aws.glue.CatalogDatabaseCreateTableDefaultPermissionArgs(</span><br><span class="line">        permissions=[<span class="string">&quot;ALL&quot;</span>],</span><br><span class="line">        principal=aws.glue.CatalogDatabaseCreateTableDefaultPermissionPrincipalArgs(</span><br><span class="line">            data_lake_principal_identifier=<span class="string">&quot;IAM_ALLOWED_PRINCIPALS&quot;</span>,</span><br><span class="line">        ),</span><br><span class="line">    )],</span><br><span class="line">    name=<span class="string">&quot;pulumi_database_test&quot;</span>)</span><br></pre></td></tr></table></figure><p>Above code is to create a glue database named pulumi_database_test. Next Step is to create a glue table with <code>Iceberg</code> format.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_external_table_test = aws.glue.CatalogTable(<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    database_name=<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    storage_descriptor=aws.glue.CatalogTableStorageDescriptorArgs(</span><br><span class="line">        additional_locations=[<span class="string">&quot;s3://xxx/pulumi_external_table_test/data&quot;</span>],</span><br><span class="line">        columns=[</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test1&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test2&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test3&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;boolean&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test4&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ],</span><br><span class="line">        location=<span class="string">&quot;s3://xxx/pulumi_external_table_test&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    table_type=<span class="string">&quot;EXTERNAL_TABLE&quot;</span>,</span><br><span class="line">        open_table_format_input=aws.glue.CatalogTableOpenTableFormatInputArgs(</span><br><span class="line">        iceberg_input=aws.glue.CatalogTableOpenTableFormatInputIcebergInputArgs(</span><br><span class="line">            metadata_operation=<span class="string">&quot;CREATE&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>There is important thing to notice here is that we need to set <code>open_table_format_input</code> with <code>iceberg_input</code> and set <code>metadata_operation</code> as <code>CREATE</code>. This is because we want to create a new Iceberg table with new schema. </p><p>Below is glue iceberg table created screenshot. You can see the 4 fields is added in schema and table format is <code>Apache Iceberg</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-table.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-table.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue Table Schema Created by Pulumi"/></div><span class="image-caption">AWS Glue Table Schema Created by Pulumi</span></div><p>Next, let’s check the important file that is <code>Apache Iceberg</code> metadata file which is located in <code>s3://xxx/pulumi_external_table_test/metadata/</code>.  Download this json file <code>00006-fd122b03-a7aa-42cf-8fec-001535a9fcf5.metadata.json</code> from <code>S3</code>. The 4 fields are defined in metadata json file. That is good. The metadata json is created as well when creating glue table.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-metadata.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-metadata.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue Table Iceberg metadata"/></div><span class="image-caption">AWS Glue Table Iceberg metadata</span></div><h2 id="Insert-new-data-in-Glue-iceberg-table"><a href="#Insert-new-data-in-Glue-iceberg-table" class="headerlink" title="Insert new data in Glue iceberg table"></a>Insert new data in Glue iceberg table</h2><p>Let’s using <code>AWS Athena</code> to insert a test data in the table.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pulumi_database_test.pulumi_external_table_test(test1,test2,test3,test4) <span class="keyword">VALUES</span>(<span class="string">&#x27;1a&#x27;</span>, <span class="string">&#x27;2a&#x27;</span>, <span class="literal">true</span>, <span class="string">&#x27;4a&#x27;</span>)</span><br></pre></td></tr></table></figure><p>The data is insert success and we can use <code>SELECT</code> sql to query the data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-table-query.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-table-query.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Query inserted data in AWS Glue Iceberg table"/></div><span class="image-caption">Query inserted data in AWS Glue Iceberg table</span></div><p>In Iceberg table, we can <code>insert</code>, <code>update</code>, <code>delete</code> data as well.</p><h2 id="Update-Glue-Iceberg-table-schema"><a href="#Update-Glue-Iceberg-table-schema" class="headerlink" title="Update Glue Iceberg table schema"></a>Update Glue Iceberg table schema</h2><p>Let’s add a new field <code>test5</code> in the glue iceberg table base on previous code.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_external_table_test = aws.glue.CatalogTable(<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    database_name=<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    storage_descriptor=aws.glue.CatalogTableStorageDescriptorArgs(</span><br><span class="line">        additional_locations=[<span class="string">&quot;s3://xxx/pulumi_external_table_test/data&quot;</span>],</span><br><span class="line">        columns=[</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test1&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test2&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test3&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;boolean&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test4&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test5&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ],</span><br><span class="line">        location=<span class="string">&quot;s3://xxx/pulumi_external_table_test&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    table_type=<span class="string">&quot;EXTERNAL_TABLE&quot;</span>,</span><br><span class="line">        open_table_format_input=aws.glue.CatalogTableOpenTableFormatInputArgs(</span><br><span class="line">        iceberg_input=aws.glue.CatalogTableOpenTableFormatInputIcebergInputArgs(</span><br><span class="line">            metadata_operation=<span class="string">&quot;CREATE&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Execute <code>pulumi up</code> command to update the glue table schema.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-update-by-pulumi.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-update-by-pulumi.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi update AWS Glue Iceberg table schema"/></div><span class="image-caption">Pulumi update AWS Glue Iceberg table schema</span></div><p>After that, we can check the glue table schema is updated to add a new field <code>test5</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-table-new-field.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-table-new-field.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue iceberg table new field"/></div><span class="image-caption">AWS Glue iceberg table new field</span></div><p>Let’s insert new data in the table with new field <code>test5</code> and run it in <code>AWS Athena</code>.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pulumi_database_test.pulumi_external_table_test(test1,test2,test3,test4,test5) <span class="keyword">VALUES</span>(<span class="string">&#x27;1b&#x27;</span>, <span class="string">&#x27;2b&#x27;</span>, <span class="literal">true</span>, <span class="string">&#x27;4b&#x27;</span>, <span class="string">&#x27;5b&#x27;</span>)</span><br></pre></td></tr></table></figure><p>The Athena execute show below errors:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">COLUMN_NOT_FOUND: Insert column name does not exist in target table: test5. If a data manifest file was generated at &#x27;s3://xxxxxx/4c346103-60d2-45ea-9813-d7060bd5efe9/Unsaved/2024/10/09/37f67a67-4604-43cb-b113-af351c363a51-manifest.csv&#x27;, you may need to manually clean the data from locations specified in the manifest. Athena will not delete data in your account.</span><br><span class="line">This query ran against the &quot;pulumi_database_test&quot; database, unless qualified by the query. Please post the error message on our forum  or contact customer support  with Query Id: 37f67a67-4604-43cb-b113-af351c363a51</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-athena-insert-failed.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-athena-insert-failed.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Athena insert glue iceberg table failed"/></div><span class="image-caption">AWS Athena insert glue iceberg table failed</span></div><p>But when we check the <code>Apache Iceberg</code> metadata file again. The new field <code>test5</code> is not added in the new metadata file. That’s why the insert new data with new field failed.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-metadata-not-updated.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-metadata-not-updated.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue iceberg table metadata not updated"/></div><span class="image-caption">AWS Glue iceberg table metadata not updated</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In Pulumi documentation. The <code>metadata_operation</code> of <code>iceberg_input</code> in <code>open_table_format_input</code> is only support <code>CREATE</code> value. It seems it only can create the iceberg metadata file when glue table created.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-pulumi-doc.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-pulumi-doc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi API Doc"/></div><span class="image-caption">Pulumi API Doc</span></div><p>It seems this is <code>pulumi</code> issue. It is not updating the iceberg metadata file when the glue table schema is updated. I’ve raised a issue to pulumi,  here is issue link: <a href="https://github.com/pulumi/pulumi/issues/17516">https://github.com/pulumi/pulumi/issues/17516</a>. Hope this issue can be fixed soon.</p><p>Mean while, I found there is same issue in <code>Terraform</code> which also can not update the iceberg metadata file when the glue table schema is updated. Terraform issue link here <a href="https://github.com/hashicorp/terraform-provider-aws/issues/36641">https://github.com/hashicorp/terraform-provider-aws/issues/36641</a>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h2&gt;&lt;p&gt;Recently, we’re planing to use &lt;code&gt;Pulumi&lt;/code&gt;</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
  <entry>
    <title>User Survey Feedback Sentiment Analysis Base on AWS Cloud Solution</title>
    <link href="https://stonefishy.github.io/2024/09/19/user-survey-feedback-sentiment-analysis-base-on-aws-cloud-solution/"/>
    <id>https://stonefishy.github.io/2024/09/19/user-survey-feedback-sentiment-analysis-base-on-aws-cloud-solution/</id>
    <published>2024-09-19T14:00:33.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The App Product User Survey Feedback Sentiment Analysis Solution is a cloud-based solution that uses AWS services to analyze user feedback and sentiment of the app product. The solution uses Amazon Comprehend to perform sentiment analysis on the feedback and Amazon S3 to store the data. The solution is designed to be scalable and cost-effective, and can be easily integrated into any app product.</p><p>Basically, our survey feedback file is Excel file that contains the user feedback of app and related application info such as OS verion and app version. The feedback text is different language from global users, so we need to translate the text into English using Amazon Translate.  Besides, the feedback file is generated monthly. So, the solution will extract the feedback data from the Excel file, translate the text into English using Amazon Translate, perform sentiment analysis using Amazon Comprehend, and store the data in Amazon S3. The solution will also provide a dashboard to visualize the sentiment analysis results.</p><p>The <code>Amazon Comprehend</code> is a natural language processing (NLP) service that can analyze text and extract insights such as sentiment, syntax, entities, and key phrases. </p><h2 id="Solution-Architecture"><a href="#Solution-Architecture" class="headerlink" title="Solution Architecture"></a>Solution Architecture</h2><p>Below is the high-level architecture of the solution:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-sentiment-analysis-solution.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-sentiment-analysis-solution.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Sentiment Analysis Solution"/></div><span class="image-caption">AWS Sentiment Analysis Solution</span></div><h3 id="AWS-Services-Used"><a href="#AWS-Services-Used" class="headerlink" title="AWS Services Used"></a>AWS Services Used</h3><p>The solution uses the following AWS services:<br><code>AWS S3</code>: Amazon Simple Storage Service (S3) is a scalable object storage service that can store large amounts of data.<br><code>AWS Lambda</code>: AWS Lambda is a serverless compute service that can run code without provisioning or managing servers.<br><code>AWS Comprehend</code>: Amazon Comprehend is a natural language processing (NLP) service that can analyze text and extract insights such as sentiment, syntax, entities, and key phrases.<br><code>AWS SNS</code>: Amazon Simple Notification Service (SNS) is a messaging service that can be used to send notifications to users.<br><code>AWS Translate</code>: Amazon Translate is a machine translation service that can translate text from one language to another.<br><code>AWS SQS</code>: Amazon Simple Queue Service (SQS) is a messaging service that can be used to store and process large amounts of messages.<br><code>AWS CloudWatch</code>: Amazon CloudWatch is a monitoring service that can be used to monitor the solution and generate metrics.<br><code>AWS Glue</code>: Amazon Glue is a serverless ETL (extract, transform, and load) service that can be used to extract data from the survey feedback file and store it in Amazon S3.<br><code>AWS Athena</code>: Amazon Athena is a serverless data analytics service that can be used to query and analyze data stored in Amazon S3.<br><code>AWS QuickSight</code>: Amazon QuickSight is a business intelligence (BI) service that can be used to create visualizations and dashboards based on the sentiment analysis results.</p><h3 id="Solution-Implementation"><a href="#Solution-Implementation" class="headerlink" title="Solution Implementation"></a>Solution Implementation</h3><p>The solution implementation is divided into the following steps:</p><ol><li>Create an Amazon S3 bucket as raw data bucket to store the survey feedback Excel file.</li><li>Uploaded a survey feedback Excel file to the S3 bucket to trigger the AWS Lambda function.</li><li>AWS Lambda to extract the survey feedback data from the Excel file, translate the text into English using Amazon Translate, sentiment analysis using Amazon Comprehend, and store the data as Parquet format in another Amazon S3 Bucket.</li><li>Create an Amazon SNS topic to notify users by email when the Lambda process data failed.</li><li>Create an Amazon CloudWatch to log the lamdba exeuction logs, generate metrics.</li><li>AWS Glue Crawler to extract the parquet data from the processed amazon S3 bucket and generate a table schema.</li><li>Using Amazon Athena to query the data from the processed Amazon S3 bucket.</li><li>Create an Amazon QuickSight dashboard to visualize the sentiment analysis results.</li></ol><p>The AWS Lambda core function code is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pyarrow <span class="keyword">as</span> pa</span><br><span class="line"><span class="keyword">import</span> pyarrow.parquet <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> urlparse</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">S3_TARGET_BUCKET = os.environ[<span class="string">&#x27;QE_SURVEY_PROCESSED_TARGET_BUCKET&#x27;</span>]</span><br><span class="line">SNS_TOPIC_ARN = os.environ[<span class="string">&#x27;SNS_TOPIC_ARN&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">translate_feedbacks</span>(<span class="params">feedbacks</span>):</span><br><span class="line">    translate = boto3.client(<span class="string">&#x27;translate&#x27;</span>)</span><br><span class="line">    feedbacks_en = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Translate to auto detect language and translate feedback, total <span class="subst">&#123;feedbacks.__len__()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feedback <span class="keyword">in</span> feedbacks:</span><br><span class="line">        response = translate.translate_text(</span><br><span class="line">            Text=feedback,</span><br><span class="line">            SourceLanguageCode=<span class="string">&#x27;auto&#x27;</span>,  <span class="comment"># Detect source language automatically</span></span><br><span class="line">            TargetLanguageCode=<span class="string">&#x27;en&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        feedbacks_en.append(response[<span class="string">&#x27;TranslatedText&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Finished transalate sourceText: <span class="subst">&#123;feedback&#125;</span> to targetText: <span class="subst">&#123;response[<span class="string">&#x27;TranslatedText&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feedbacks_en</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comprehend_sentiment</span>(<span class="params">feedbacks</span>):</span><br><span class="line">    comprehend = boto3.client(<span class="string">&#x27;comprehend&#x27;</span>)</span><br><span class="line">    batch_size = <span class="number">25</span></span><br><span class="line">    all_sentiments = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Comprehend AI to analysis feedback, total <span class="subst">&#123;feedbacks.__len__()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feedbacks), batch_size):</span><br><span class="line">        batch_feedbacks = feedbacks[i:i+batch_size]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Comprehend AI to analysis feedback, batch <span class="subst">&#123;i&#125;</span> - <span class="subst">&#123;i+batch_size&#125;</span>&quot;</span>)</span><br><span class="line">        comprehend_response = comprehend.batch_detect_sentiment(TextList=batch_feedbacks, LanguageCode=<span class="string">&#x27;en&#x27;</span>)</span><br><span class="line">        sentiments = [response[<span class="string">&#x27;Sentiment&#x27;</span>] <span class="keyword">for</span> response <span class="keyword">in</span> comprehend_response[<span class="string">&#x27;ResultList&#x27;</span>]]</span><br><span class="line">        all_sentiments.extend(sentiments)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> all_sentiments</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">    sns_client = boto3.client(<span class="string">&#x27;sns&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    source_bucket = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;bucket&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    source_key = urlparse.unquote_plus(event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;object&#x27;</span>][<span class="string">&#x27;key&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    target_bucket = S3_TARGET_BUCKET</span><br><span class="line">    target_key = <span class="string">f&quot;qe-survey/<span class="subst">&#123;source_key.replace(<span class="string">&#x27;.xlsx&#x27;</span>, <span class="string">&#x27;.parquet&#x27;</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = s3.get_object(Bucket=source_bucket, Key=source_key)</span><br><span class="line">        excel_file = response[<span class="string">&#x27;Body&#x27;</span>].read()</span><br><span class="line">        </span><br><span class="line">        columns = [<span class="string">&#x27;ce_timestamp&#x27;</span>, <span class="string">&#x27;ce_host_id&#x27;</span>, <span class="string">&#x27;ce_host_os&#x27;</span>, <span class="string">&#x27;ce_hw&#x27;</span>, <span class="string">&#x27;ce_fw&#x27;</span>, <span class="string">&#x27;ce_sw&#x27;</span>, <span class="string">&#x27;survey_feedback&#x27;</span>, <span class="string">&#x27;survey_rating&#x27;</span>]</span><br><span class="line">        df = pd.read_excel(io.BytesIO(excel_file), usecols=columns)</span><br><span class="line">        df[<span class="string">&#x27;ce_timestamp&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;ce_timestamp&#x27;</span>], <span class="built_in">format</span>=<span class="string">&#x27;%Y-%m-%d %H:%M:%S:%f&#x27;</span>)</span><br><span class="line">        df[<span class="string">&#x27;survey_feedback&#x27;</span>] = df[<span class="string">&#x27;survey_feedback&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">        valid_df = df[df[<span class="string">&#x27;survey_feedback&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.strip() != <span class="string">&#x27;&#x27;</span>)]</span><br><span class="line">        valid_df = valid_df[valid_df[<span class="string">&#x27;survey_feedback&#x27;</span>] != <span class="string">&#x27;nan&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        feedbacks = valid_df[<span class="string">&#x27;survey_feedback&#x27;</span>].tolist()</span><br><span class="line">        </span><br><span class="line">        feedbacks_en = translate_feedbacks(feedbacks)</span><br><span class="line">        valid_df[<span class="string">&quot;survey_feedback_en&quot;</span>]= feedbacks_en</span><br><span class="line">        valid_df[<span class="string">&#x27;sentiment&#x27;</span>] = comprehend_sentiment(feedbacks_en)</span><br><span class="line">        </span><br><span class="line">        parquet_buffer = io.BytesIO()</span><br><span class="line">        pq.write_table(pa.Table.from_pandas(valid_df), parquet_buffer)</span><br><span class="line">        parquet_buffer.seek(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        s3.put_object(Bucket=target_bucket, Key=target_key, Body=parquet_buffer)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;source_key&#125;</span> File converted to Parquet <span class="subst">&#123;target_key&#125;</span> and stored in S3 bucket <span class="subst">&#123;target_bucket&#125;</span> successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;statusCode&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">            <span class="string">&#x27;body&#x27;</span>: json.dumps(<span class="string">f&#x27;<span class="subst">&#123;source_key&#125;</span> File converted to Parquet <span class="subst">&#123;target_key&#125;</span> and stored in S3 bucket <span class="subst">&#123;target_bucket&#125;</span> successfully&#x27;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Error processing <span class="subst">&#123;source_key&#125;</span>: <span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">        sns_client.publish(</span><br><span class="line">            TopicArn=SNS_TOPIC_ARN,</span><br><span class="line">            Subject=<span class="string">&#x27;Lambda Function Processing QE Survey Feedback Failure Notification&#x27;</span>,</span><br><span class="line">            Message=<span class="string">f&#x27;An error occurred: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&#x27;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>The above code extracts the survey feedback data from the Excel file, translates the text into English using Amazon Translate, performs sentiment analysis using Amazon Comprehend, and stores the data as Parquet format in another Amazon S3 Bucket. also notify users by email when the Lambda process data failed by using Amazon SNS. </p><p>Below is sentiment analysis results visualization using Amazon QuickSight:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-sentiment-analysis-result.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-sentiment-analysis-result.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Sentiment Analysis Results"/></div><span class="image-caption">AWS Sentiment Analysis Results</span></div><p>This is a high-level overview of the solution implementation. The solution can be further customized and enhanced based on the specific requirements of the app product.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;The App Product User Survey Fe</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Sentiment Analysis" scheme="https://stonefishy.github.io/tags/Sentiment-Analysis/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>How to Fix AWS S3 Event Replacing Space With &#39;+&#39; Character Sign in Object Key Name</title>
    <link href="https://stonefishy.github.io/2024/09/10/aws-s3-event-replacing-space-with-character-sign-in-object-key-name/"/>
    <id>https://stonefishy.github.io/2024/09/10/aws-s3-event-replacing-space-with-character-sign-in-object-key-name/</id>
    <published>2024-09-10T09:22:34.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>The issue with AWS S3 Event notifications is that it replaces spaces with ‘+’ character sign in the object key name. This can cause issues when trying to access the object in S3. It will occurs <code>NoSuchKey</code> error if not handling this issue properly.</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Configured a S3 bucket put event notification to a Lambda function. The Lambda function will be triggered when a new object is uploaded to the S3 bucket. I upload a file named ‘2023 2nd quarter QE survey raw data.xlsx’ into S3 bucket, the Lambda function is triggered, but when I try to access the object in S3, I get <code>NoSuchKey</code> error in <code>AWS CloudWatch Logs</code>. Debugging shows that the object key name is ‘2023+2nd+quarter+QE+survey+raw+data.xlsx’ instead of ‘2023 2nd quarter QE survey raw data.xlsx’. It means the S3 event notification is replacing the space with ‘+’ character sign in the object key name.</p><p>The detail error is below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] NoSuchKey: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.</span><br></pre></td></tr></table></figure><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>There are two solutions to fix this issue, one is from AWS S3 upload file side, another is from Lambda function side.</p><h3 id="1-From-AWS-S3-upload-file-side"><a href="#1-From-AWS-S3-upload-file-side" class="headerlink" title="1. From AWS S3 upload file side:"></a>1. From AWS S3 upload file side:</h3><p>If you have control over the upload process, ensure that the keys are properly URL-encoded.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example key with spaces</span></span><br><span class="line">object_key = <span class="string">&quot;2023 2nd quarter QE survey raw data.xlsx&quot;</span></span><br><span class="line">encoded_key = urllib.parse.quote(object_key)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Upload the object</span></span><br><span class="line">s3_client.upload_file(<span class="string">&quot;/tmp/2023 2nd quarter QE survey raw data.xlsx&quot;</span>, <span class="string">&quot;my-bucket-name&quot;</span>, encoded_key)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>This will ensure that the object key name is properly URL-encoded, which will prevent the S3 event notification from replacing spaces with ‘+’ character sign. The <code>urllib.parse.quote</code> function will replace spaces with ‘%20’ and ‘+’ with ‘%2B’.</p><h3 id="2-From-Lambda-function-side"><a href="#2-From-Lambda-function-side" class="headerlink" title="2. From Lambda function side:"></a>2. From Lambda function side:</h3><p>To fix this issue, we need to modify the Lambda function to handle the object key name with ‘+’ character sign. We can use the <code>urllib.parse</code> package to handle it. The package library provide the function <code>unquote_plus</code> to replace ‘+’ with space. Here is the code to handle the object key name with ‘+’ character sign:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> urlparse</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line">s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    bucket_name = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;bucket&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    object_key = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;object&#x27;</span>][<span class="string">&#x27;key&#x27;</span>]</span><br><span class="line">    <span class="comment"># Replace &#x27;+&#x27; with space</span></span><br><span class="line">    object_key = urlparse.unquote_plus(object_key)</span><br><span class="line">    <span class="comment"># Download the object</span></span><br><span class="line">    s3.download_file(bucket_name, object_key, <span class="string">&#x27;/tmp/file.txt&#x27;</span>)</span><br><span class="line">    <span class="comment"># Do something with the downloaded file</span></span><br><span class="line">    <span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>In the above code, we first get the bucket name and object key from the S3 event notification. We then use the <code>urlparse.unquote_plus</code> function to replace ‘+’ with space in the object key name. Finally, we download the object using the <code>s3.download_file</code> function.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>To fix the issue with AWS S3 Event notifications replacing space with ‘+’ character sign in the object key name, we need to handle it properly in the Lambda function. We can use the <code>urllib.parse</code> package to handle it.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The issue with AWS S3 Event notifications is that it replaces spaces with ‘+’ character sign in the object key name. This can cause issue</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="AWS S3" scheme="https://stonefishy.github.io/tags/AWS-S3/"/>
    
    <category term="AWS Lambda" scheme="https://stonefishy.github.io/tags/AWS-Lambda/"/>
    
  </entry>
  
  <entry>
    <title>SQL 中的 IS DISTINCT FROM 语法详解</title>
    <link href="https://stonefishy.github.io/2024/08/16/introduce-is-distinct-from-in-sql/"/>
    <id>https://stonefishy.github.io/2024/08/16/introduce-is-distinct-from-in-sql/</id>
    <published>2024-08-16T09:22:15.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>在SQL查询中，比较操作符 <code>=</code> 通常用于检查两个值是否相等。然而，当涉及到处理缺失值（<code>NULL</code>）时，这种操作符就会面临挑战。为了解决这一问题，<span class='pbg green'>SQL 提供了 `IS DISTINCT FROM` 操作符，它用于精确比较两个值是否不同，即使这些值中有 NULL</span>。本文将详细介绍 IS DISTINCT FROM 的语法、解决的问题以及常见的使用场景。</p><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><p>IS DISTINCT FROM 的基本语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expression1 <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> expression2</span><br></pre></td></tr></table></figure><p>其中 expression1 和 expression2 是要进行比较的两个表达式。 该操作符返回布尔值：TRUE、FALSE。</p><h2 id="主要解决的问题"><a href="#主要解决的问题" class="headerlink" title="主要解决的问题"></a>主要解决的问题</h2><p>在SQL中，<code>NULL</code> 值代表缺失或未知的数据。当两个表达式中至少有一个为 NULL 时，使用传统的比较操作符（如 &#x3D; 或 &lt;&gt;）进行比较会导致不确定的结果。具体来说：</p><ul><li>expression1 &#x3D; expression2 在 expression1 或 expression2 为 NULL 时会返回 UNKNOWN。</li><li>expression1 &lt;&gt; expression2 在 expression1 或 expression2 为 NULL 时也会返回 UNKNOWN。</li></ul><p>比如下面的查询语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A1,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">&lt;&gt;</span> <span class="number">1</span> <span class="keyword">as</span> A2,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">=</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A3,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">&lt;&gt;</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A4,</span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="number">1</span> <span class="keyword">as</span> A5, </span><br><span class="line">    <span class="number">1</span> <span class="operator">&lt;&gt;</span> <span class="number">1</span> <span class="keyword">as</span> A6</span><br></pre></td></tr></table></figure><p>会返回以下结果：</p><table><thead><tr><th>A1</th><th>A2</th><th>A3</th><th>A4</th><th>A5</th><th>A6</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td>TRUE</td><td>FALSE</td></tr></tbody></table><p>可以看到，当 expression1 或 expression2 为 NULL 时，传统的比较操作符会返回 UNKNOWN空值， 如上面的A1, A2, A3, A4的结果值，这就会导致不确定性。</p><p><code>IS DISTINCT FROM</code> 操作符的出现，解决了这些问题。它能正确处理 <code>NULL</code> 值，会返回 <code>TRUE 或 FALSE</code>，确保结果的可靠性。 在以下情况下返回 TRUE：</p><ul><li>expression1 和 expression2 都为 NULL。</li><li>expression1 和 expression2 的值不同（不论是否为 NULL）。</li></ul><p>而在 expression1 和 expression2 相等（包括都是 NULL）的情况下，IS DISTINCT FROM 返回 FALSE。 另外还有一个 <code>IS NOT DISTINCT FROM</code> 操作符，用于判断两个值是否相等。其用法一样，只是语义相反。</p><p>下面的例子查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="keyword">NULL</span> <span class="keyword">as</span> B1,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B2,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">2</span> <span class="keyword">as</span> B3,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="keyword">NULL</span> <span class="keyword">as</span> B4,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B5,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B6</span><br></pre></td></tr></table></figure><p>查询结果如下:</p><table><thead><tr><th>B1</th><th>B2</th><th>B3</th><th>B4</th><th>B5</th><th>B6</th></tr></thead><tbody><tr><td>TRUE</td><td>TRUE</td><td>TRUE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td></tr></tbody></table><p>可以看到，IS DISTINCT FROM 正确处理 NULL 值，返回 TRUE 或 FALSE，确保结果的可靠性。</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><h3 id="数据清洗和验证"><a href="#数据清洗和验证" class="headerlink" title="数据清洗和验证"></a>数据清洗和验证</h3><p>在<code>数据清洗</code>和<code>数据验证</code>过程中，经常需要检查数据库中的值是否不同，包括对 NULL 值的处理。例如，比较用户输入的数据与现有记录，以确定是否有不同的记录。<span class='pbg warning'>使用 IS DISTINCT FROM 可以更准确地处理 NULL 值，避免出现错误或遗漏。</span></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> users</span><br><span class="line"><span class="keyword">WHERE</span> username <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="string">&#x27;andrewsy&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询会返回所有 username 与 ‘andrewsy’ 不同的记录，包括那些 username 为 NULL 的记录。</p><h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><p>在更新数据时，使用 IS DISTINCT FROM 可以确保只有在数据实际变化时才进行更新，从而避免不必要的更新操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> users</span><br><span class="line"><span class="keyword">SET</span> email <span class="operator">=</span> <span class="string">&#x27;new_andrewsy@email.com&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> email <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="string">&#x27;new_andrewsy@email.com&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询会更新所有 email 不同于 ‘<a href="mailto:&#110;&#x65;&#x77;&#x5f;&#97;&#110;&#x64;&#x72;&#x65;&#x77;&#115;&#121;&#64;&#x65;&#x6d;&#x61;&#x69;&#108;&#46;&#99;&#x6f;&#109;">&#110;&#x65;&#x77;&#x5f;&#97;&#110;&#x64;&#x72;&#x65;&#x77;&#115;&#121;&#64;&#x65;&#x6d;&#x61;&#x69;&#108;&#46;&#99;&#x6f;&#109;</a>‘ 的记录，包括那些 email 为 NULL 的记录。</p><h3 id="数据比较"><a href="#数据比较" class="headerlink" title="数据比较"></a>数据比较</h3><p>在进行复杂的数据比较时，尤其是涉及到 NULL 值时，IS DISTINCT FROM 提供了更直观的比较逻辑。例如，在合并两个数据集时，可以使用此操作符来确保唯一性。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> </span><br><span class="line">    dataset1</span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> </span><br><span class="line">    dataset2</span><br><span class="line"><span class="keyword">ON</span> </span><br><span class="line">    dataset1.id <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> dataset2.id</span><br></pre></td></tr></table></figure><p>这条查询会找出两个数据集中 id 不同的记录，包括 id 为 NULL 的情况。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p><code>IS DISTINCT FROM</code> 是 SQL 标准中的一部分，但并非所有数据库系统都支持。具体的支持情况需要查阅数据库的文档。在使用 IS DISTINCT FROM 时，确保数据库系统的版本和文档中对此操作符的支持及行为一致。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>IS DISTINCT FROM</code> 是一个强大的工具，用于在 SQL 中处理包含 NULL 值的数据比较。它解决了传统比较操作符在处理 NULL 值时的不足，使得数据验证、更新和比较更加准确和可靠。在实际应用中，根据数据库系统的支持情况，合理使用 IS DISTINCT FROM 可以显著提高数据操作的精确性和健壮性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在SQL查询中，比较操作符 &lt;code&gt;=&lt;/code&gt; 通常用于检查两个值是否相等。然而，当涉及到处理缺失值（&lt;code&gt;NULL&lt;/code&gt;）时，这种操作符就会面临挑战。为了解决这一问题，&lt;span class=&#39;pbg green&#39;&gt;SQL 提供了 `IS DIST</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="Big Data" scheme="https://stonefishy.github.io/tags/Big-Data/"/>
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>详解 SQL 中的 LAG 函数</title>
    <link href="https://stonefishy.github.io/2024/08/15/what-is-lag-in-sql/"/>
    <id>https://stonefishy.github.io/2024/08/15/what-is-lag-in-sql/</id>
    <published>2024-08-15T09:24:21.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>最近在做数据分析，需要挖掘数据随时间变化的信息。所有数据物理存储在AWS S3上，通过AWS Glue Catalog和AWS Athena进行数据查询。AWS Athena支持SQL语言，可以对数据进行分析。在处理时间序列数据或分析行间变化时， SQL中的 <code>LAG</code> 函数和 <code>LEAD</code> 函数是非常有用的。下面，我们来看一下 LAG 函数的基本用法。</p><h2 id="什么是-LAG-函数？"><a href="#什么是-LAG-函数？" class="headerlink" title="什么是 LAG 函数？"></a>什么是 LAG 函数？</h2><p>在 SQL 中，<code>LAG</code> 函数是一种<code>窗口函数</code>，<span class='pbg warning'>用于获取当前行之前某一行的值。这在处理时间序列数据或分析行间变化时非常有用。LAG 函数可以让你访问当前行之前的行数据，而不需要使用子查询或自连接。</span> 而<code>LEAD</code> 函数则是获取当前行之后的行数据。他们的语法和用法类似，只是方向不同。</p><h2 id="LAG-函数的语法"><a href="#LAG-函数的语法" class="headerlink" title="LAG 函数的语法"></a>LAG 函数的语法</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">LAG</span>(expression, <span class="keyword">offset</span>, <span class="keyword">default</span>) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> partition_column <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_column)</span><br></pre></td></tr></table></figure><ul><li><code>expression</code>：要返回的列或计算结果。</li><li><code>offset</code>：向前查找的行数，默认为 1（即前一行）。</li><li><code>default</code>：当没有前行时返回的默认值，默认为 NULL。</li><li><code>PARTITION BY</code>：用于将数据分组。如果省略，LAG 会在整个结果集上应用。</li><li><code>ORDER BY</code>：确定行的顺序，LAG 函数会根据这个顺序来访问前面的行。</li></ul><h2 id="如何使用-LAG-函数"><a href="#如何使用-LAG-函数" class="headerlink" title="如何使用 LAG 函数"></a>如何使用 LAG 函数</h2><p><code>LAG</code> 函数在使用时通常与 <code>OVER</code> 子句一起使用。OVER 子句用于定义窗口（即应用 LAG 函数的范围）。在窗口中，<code>ORDER BY</code> 确定了行的顺序，<code>PARTITION BY</code> 则可以用来将数据分组，使每个分组内的计算互相独立。</p><h3 id="基本使用示例："><a href="#基本使用示例：" class="headerlink" title="基本使用示例："></a>基本使用示例：</h3><p>假设我们有一个名为 sales 的表，包含 sale_date 和 amount 列。我们想要比较每笔销售金额与前一笔销售金额的变化。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    sale_date,</span><br><span class="line">    amount,</span><br><span class="line">    <span class="built_in">LAG</span>(amount, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> sale_date) <span class="keyword">AS</span> previous_amount</span><br><span class="line"><span class="keyword">FROM</span> sales;</span><br></pre></td></tr></table></figure><p>在这个查询中：</p><p>amount 是当前销售金额。<br>LAG(amount, 1) 获取当前销售的前一笔销售金额（根据 sale_date 排序）。</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ol><li><p>时间序列分析：<br>LAG 函数非常适合分析时间序列数据，帮助用户了解数据变化趋势。例如，分析每月的销售数据，找出增长或下降的趋势。</p></li><li><p>计算变化量：<br>可以计算当前值与前一值之间的变化量，例如销售额变化、温度变化等。</p></li><li><p>生成滚动报告：<br>LAG 可以用来生成带有前值的滚动报告，例如计算累计销售额，或者生成滞后数据用于报表。</p></li></ol><h2 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h2><p>假设我们有一个销售记录表 monthly_sales，结构如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> monthly_sales (</span><br><span class="line">    <span class="keyword">month</span> <span class="type">DATE</span>,</span><br><span class="line">    sales_amount <span class="type">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> monthly_sales (<span class="keyword">month</span>, sales_amount) <span class="keyword">VALUES</span></span><br><span class="line">(<span class="string">&#x27;2024-01-01&#x27;</span>, <span class="number">1000.00</span>),</span><br><span class="line">(<span class="string">&#x27;2024-02-01&#x27;</span>, <span class="number">1500.00</span>),</span><br><span class="line">(<span class="string">&#x27;2024-03-01&#x27;</span>, <span class="number">1200.00</span>),</span><br><span class="line">(<span class="string">&#x27;2024-04-01&#x27;</span>, <span class="number">1700.00</span>);</span><br></pre></td></tr></table></figure><p>我们可以使用 <code>LAG</code> 函数来比较每个月的销售额与前一个月的销售额：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">month</span>,</span><br><span class="line">    sales_amount,</span><br><span class="line">    <span class="built_in">LAG</span>(sales_amount, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">month</span>) <span class="keyword">AS</span> previous_month_sales,</span><br><span class="line">    sales_amount <span class="operator">-</span> <span class="built_in">LAG</span>(sales_amount, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">month</span>) <span class="keyword">AS</span> sales_difference</span><br><span class="line"><span class="keyword">FROM</span> monthly_sales;</span><br></pre></td></tr></table></figure><p>查询结果：</p><table><thead><tr><th>month</th><th>sales_amount</th><th>previous_month_sales</th><th>sales_difference</th></tr></thead><tbody><tr><td>2024-01-01</td><td>1000.00</td><td>NULL</td><td>NULL</td></tr><tr><td>2024-02-01</td><td>1500.00</td><td>1000.00</td><td>500.00</td></tr><tr><td>2024-03-01</td><td>1200.00</td><td>1500.00</td><td>-300.00</td></tr><tr><td>2024-04-01</td><td>1700.00</td><td>1200.00</td><td>500.00</td></tr></tbody></table><p>在这个查询中：<br>previous_month_sales 显示了前一个月的销售额。<br>sales_difference 显示了当前月与前一个月的销售额差异。<br>通过上述查询，我们可以方便地分析销售数据的变化情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>LAG</code> 函数是一个强大的工具，可以帮助你在数据分析中处理行间的比较和变化。无论是用于时间序列数据、计算变化量，还是生成滚动报告，LAG 函数都能提供有价值的信息。它通常与 <code>OVER</code> 子句一起使用, 在OVER子句中，我们可以指定分组条件、排序条件等。<code>ORDER BY</code> 确定行的顺序，<code>PARTITION BY</code> 则可以用来将数据分组，使每个分组内的计算互相独立。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近在做数据分析，需要挖掘数据随时间变化的信息。所有数据物理存储在AWS S3上，通过AWS Glue Catalog和AWS Athena进行数据查询。AWS Athena支持SQL语言，可以对数据进行分析。在处理时间序列数据或分析行间变化时， SQL中的 &lt;code&gt;L</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="Big Data" scheme="https://stonefishy.github.io/tags/Big-Data/"/>
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>How to query tree-structured relation data in MySQL</title>
    <link href="https://stonefishy.github.io/2024/08/02/how-to-query-tree-structured-relation-data-in-mysql/"/>
    <id>https://stonefishy.github.io/2024/08/02/how-to-query-tree-structured-relation-data-in-mysql/</id>
    <published>2024-08-02T10:08:52.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>To query hierarchical relational data in <code>MySQL</code>, <code>recursive Common Table Expressions (CTEs)</code> are typically used. However, MySQL did not support recursive CTEs before version 8.0, so in earlier versions, <code>self-joins</code> are commonly used to handle such queries. Below is an example using a self-join, assuming we have a table employees that contains information about employees and their manager IDs (manager_id).</p><h2 id="Create-Table-and-Insert-Data"><a href="#Create-Table-and-Insert-Data" class="headerlink" title="Create Table and Insert Data"></a>Create Table and Insert Data</h2><p>Creating a table named <code>employees</code> with the following columns:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employees (</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">100</span>),</span><br><span class="line">    manager_id <span class="type">INT</span>,</span><br><span class="line">    <span class="keyword">FOREIGN</span> KEY (manager_id) <span class="keyword">REFERENCES</span> employees(id)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> employees (id, name, manager_id) <span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>, <span class="string">&#x27;CEO&#x27;</span>, <span class="keyword">NULL</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="string">&#x27;CTO&#x27;</span>, <span class="number">1</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="string">&#x27;CFO&#x27;</span>, <span class="number">1</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="string">&#x27;Developer Lead&#x27;</span>, <span class="number">2</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="string">&#x27;Accountant Lead&#x27;</span>, <span class="number">3</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="string">&#x27;Developer&#x27;</span>, <span class="number">4</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="string">&#x27;Junior Developer&#x27;</span>, <span class="number">4</span>),</span><br><span class="line">(<span class="number">8</span>, <span class="string">&#x27;Senior Accountant&#x27;</span>, <span class="number">5</span>),</span><br><span class="line">(<span class="number">9</span>, <span class="string">&#x27;Junior Accountant&#x27;</span>, <span class="number">5</span>);</span><br></pre></td></tr></table></figure><h2 id="Self-Join"><a href="#Self-Join" class="headerlink" title="Self-Join"></a>Self-Join</h2><p>We can search for all employees and their direct reports (subordinates) using a self-join. The following SQL statement will list all employees and their direct manager’s name.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e1.name <span class="keyword">AS</span> employee_name, e2.name <span class="keyword">AS</span> manager_name</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e2 <span class="keyword">ON</span> e1.manager_id <span class="operator">=</span> e2.id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> e1.manager_id, e1.id;</span><br></pre></td></tr></table></figure><p>We can also use a self-join to count the number of direct reports for each manager. The following SQL statement will list all managers and the number of their direct reports.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e1.name <span class="keyword">AS</span> manager_name, <span class="built_in">COUNT</span>(e2.id) <span class="keyword">AS</span> subordinate_count</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e2 <span class="keyword">ON</span> e1.id <span class="operator">=</span> e2.manager_id</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> e1.id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> subordinate_count <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><h2 id="Recursive-Common-Table-Expressions-CTEs"><a href="#Recursive-Common-Table-Expressions-CTEs" class="headerlink" title="Recursive Common Table Expressions (CTEs)"></a>Recursive Common Table Expressions (CTEs)</h2><p>MySQL 8.0 introduced support for recursive CTEs, which allows us to query hierarchical relational data more efficiently. The following SQL statement will list all employees and their direct reports (subordinates) using a recursive CTE.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">RECURSIVE</span> subordinates <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> id, name, manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1</span> <span class="comment">-- root node CEO, we can replace with any other root node ID, for example 2 which is CTO</span></span><br><span class="line">    <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line">    <span class="keyword">SELECT</span> e.id, e.name, e.manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">INNER</span> <span class="keyword">JOIN</span> subordinates s <span class="keyword">ON</span> e.manager_id <span class="operator">=</span> s.id</span><br><span class="line">)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> subordinates;</span><br></pre></td></tr></table></figure><p>But please note that this method only works for <code>MySQL 8.0</code> and above, as these versions support <code>recursive CTEs</code>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;To query hierarchical relational data in &lt;code&gt;MySQL&lt;/code&gt;, &lt;code&gt;recursive Common Table Expressions (CTEs)&lt;/code&gt; are typically used. H</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 8.x CTEs feature - WITH clause</title>
    <link href="https://stonefishy.github.io/2024/07/26/mysql-8-x-ctes-feature-with-clause/"/>
    <id>https://stonefishy.github.io/2024/07/26/mysql-8-x-ctes-feature-with-clause/</id>
    <published>2024-07-26T09:19:59.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL <code>Common Table Expressions (CTEs)</code> are a powerful feature introduced in <code>MySQL 8.0</code>. CTEs are a type of MySQL 8.0 that provide a way to create <code>temporary result sets</code> that can be referenced within a <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> statement. <span class='pbg danger'>The primary purpose of `CTEs` is to make complex queries more readable and manageable by breaking them down into simpler</span>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mysql/mysql-cte-with-clause.png" class="lazyload placeholder" data-srcset="/assets/images/mysql/mysql-cte-with-clause.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MYSQL CTEs feature - WITH clause" style="width:600px;"/></div><span class="image-caption">MYSQL CTEs feature - WITH clause</span></div><h2 id="Purpose-of-CTEs"><a href="#Purpose-of-CTEs" class="headerlink" title="Purpose of CTEs"></a>Purpose of CTEs</h2><ul><li><strong>Readability</strong>: <code>CTEs</code> can make SQL queries more readable, especially for complex queries involving multiple subqueries or recursive operations.</li><li><strong>Modularity</strong>: They allow you to define a temporary result set that can be reused within the same query, promoting code reuse and reducing redundancy.</li><li><strong>Recursive Queries</strong>: CTEs support recursive queries, which are useful for querying hierarchical data like organizational charts, bill of materials, or tree structures.</li></ul><h2 id="How-to-Use-CTEs"><a href="#How-to-Use-CTEs" class="headerlink" title="How to Use CTEs"></a>How to Use CTEs</h2><p><code>CTEs</code> are defined using the <code>WITH</code> clause and can be referenced within the main query. Here’s the basic syntax:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> cte_name <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> ...</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> cte_name;</span><br></pre></td></tr></table></figure><h3 id="Basic-CTE"><a href="#Basic-CTE" class="headerlink" title="Basic CTE"></a>Basic CTE</h3><p>Suppose you have a table employees and you want to find the average salary of employees in each department.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> DepartmentSalaries <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id, <span class="built_in">AVG</span>(salary) <span class="keyword">AS</span> avg_salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DepartmentSalaries;</span><br></pre></td></tr></table></figure><p>In this example, DepartmentSalaries is a CTE that calculates the average salary for each department. The main query then selects from this CTE.</p><p><code>CTEs</code> feature also supports multiple temporary result sets in the same query, see below example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span></span><br><span class="line">  cte1 <span class="keyword">AS</span> (<span class="keyword">SELECT</span> a, b <span class="keyword">FROM</span> table1),</span><br><span class="line">  cte2 <span class="keyword">AS</span> (<span class="keyword">SELECT</span> c, d <span class="keyword">FROM</span> table2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> b, d <span class="keyword">FROM</span> cte1 <span class="keyword">JOIN</span> cte2 <span class="keyword">WHERE</span> cte1.a <span class="operator">=</span> cte2.c;</span><br></pre></td></tr></table></figure><p>Above sqls defines two CTEs cte1 and cte2 and then joins them using a WHERE clause.</p><h3 id="Recursive-CTE"><a href="#Recursive-CTE" class="headerlink" title="Recursive CTE"></a>Recursive CTE</h3><p>A CTE can refer to itself to define a <code>recursive CTE</code>. Common applications of recursive CTEs include series generation and traversal of hierarchical or tree-structured data.</p><p>Suppose you have a table employees with a self-referencing column manager_id to represent a hierarchy. You want to find all subordinates of a given manager.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">RECURSIVE</span> Subordinates <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> employee_id, manager_id, name</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> manager_id <span class="operator">=</span> <span class="number">1</span>  <span class="comment">-- Starting with the manager ID 1</span></span><br><span class="line">    <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line">    <span class="keyword">SELECT</span> e.employee_id, e.manager_id, e.name</span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">INNER</span> <span class="keyword">JOIN</span> Subordinates s <span class="keyword">ON</span> e.manager_id <span class="operator">=</span> s.employee_id</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Subordinates;</span><br></pre></td></tr></table></figure><p>In this example, Subordinates is a recursive CTE that starts with employees directly reporting to manager ID 1 and then recursively includes all their subordinates.</p><h2 id="Key-Points"><a href="#Key-Points" class="headerlink" title="Key Points"></a>Key Points</h2><ul><li><strong>Non-Recursive CTEs</strong>: These are straightforward and do not involve recursion. They are simply a way to define a temporary result set for use within the query.</li><li><strong>Recursive CTEs</strong>: These involve recursion and are useful for hierarchical or tree-structured data. They must include a <code>UNION ALL</code> clause to combine the initial result set with the recursive result set.</li><li><strong>Scope</strong>: CTEs are scoped to the query they are defined in and cannot be referenced outside of that query.</li></ul><p><code>CTEs</code> are a powerful tool in MySQL that can significantly improve the <code>readability</code> and <code>maintainability</code> of <code>complex SQL queries</code>.</p><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links:"></a>Reference Links:</h2><p>For other scenarios, like use <code>WITH</code> clause in <code>UPDATE</code> or <code>DELETE</code> statements, please refer to the following links:</p><ul><li><strong>WITH (Common Table Expressions)</strong>: <a href="https://dev.mysql.com/doc/refman/8.4/en/with.html">https://dev.mysql.com/doc/refman/8.4/en/with.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;MySQL &lt;code&gt;Common Table Expressions (CTEs)&lt;/code&gt; are a powerful feature introduced in &lt;code&gt;MySQL 8.0&lt;/code&gt;. CTEs are a type of MySQL </summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Using Pulumi to Import the AWS Resources of the Other Region</title>
    <link href="https://stonefishy.github.io/2024/07/04/using-pulumi-to-import-the-aws-resources-of-the-other-region/"/>
    <id>https://stonefishy.github.io/2024/07/04/using-pulumi-to-import-the-aws-resources-of-the-other-region/</id>
    <published>2024-07-04T10:27:55.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>By default, the Pulumi import the resource in the region which is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file. If we import the resources which is located in other regions. It will cause the error by using <code>pulumi import</code> command.</p><p>For example, we have quicksight resources such like DataSource, DataSet located in the <code>eu-west-1</code> region, we already manage these resources in the pulumi by using <code>pulumi import</code> CLI command. All resources are located in <code>eu-west-1</code> region. It is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file like below.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">config:</span></span><br><span class="line">  <span class="attr">aws:region:</span> <span class="string">eu-west-1</span></span><br></pre></td></tr></table></figure><p>Now we also want to import the existing resources such like QuickSight user Groups into the pulumi. But the AWS Quicksight user Groups resources all are located in the <code>us-east-1</code> region. The pulumi will give us the error if we try to import the other region resource direclty.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-other-region-resource-error.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-other-region-resource-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>This is because the Pulumi is using default <code>provider</code> for the AWS resources. The default provider is set to the region which is specified in the <code>Pulumi.yaml</code> or <code>Pulumi.&lt;stack-name&gt;.yaml</code> file. So, if we want to import the resources from other region, we need to specify the provider for that region.</p><h2 id="Pulumi-Provider"><a href="#Pulumi-Provider" class="headerlink" title="Pulumi Provider"></a>Pulumi Provider</h2><p>A <code>Pulumi provider</code> is a plugin that enables Pulumi to interact with a specific cloud provider or service. These providers are responsible for translating the Pulumi code into the appropriate API calls for the target cloud platform. </p><p>By default, each provider uses its package’s global configuration settings, which are controlled by your stack’s configuration. You can set information such as your cloud provider credentials with environment variables and configuration files. If you store this data in standard locations, Pulumi knows how to retrieve them. For example, you can run below command to set the AWS region to <code>eu-west-1</code> region for the AWS provider configuration.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi config set aws:region eu-west-1</span><br></pre></td></tr></table></figure><p>This command actually will set the <code>aws:region</code> configuration value for the AWS provider in your Pulumi stack yaml file. You can also define the provider in your pulumi code, and create related resources in the specified region.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new provider for the us-east-1 region</span></span><br><span class="line">us_east_1_provider = aws.Provider(<span class="string">&#x27;us-east-1&#x27;</span>, region=<span class="string">&#x27;us-east-1&#x27;</span>)</span><br><span class="line"><span class="comment"># Create the Quicksight Groups resources in the us-east-1 region</span></span><br><span class="line">quicksight_group = aws.quicksight.Group(</span><br><span class="line">    <span class="string">&quot;dev&quot;</span>,</span><br><span class="line">    aws_account_id=<span class="string">&quot;&lt;aws-account-id&gt;&quot;</span>,</span><br><span class="line">    group_name=<span class="string">&quot;dev&quot;</span>,</span><br><span class="line">    opts=pulumi.ResourceOptions(</span><br><span class="line">        provider=us_east_1_provider</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>In above code, we create a new provider for the <code>us-east-1</code> region and then create the Quicksight user Groups resources in the <code>us-east-1</code> region. The <code>provider</code> option is used to specify the provider to use for the resource. Even we have global configuration for the <code>eu-west-1</code> region, we can still create the resources in the <code>us-east-1</code> region by specifying the provider.</p><h2 id="Importing-the-AWS-Resources-of-the-Other-Region"><a href="#Importing-the-AWS-Resources-of-the-Other-Region" class="headerlink" title="Importing the AWS Resources of the Other Region"></a>Importing the AWS Resources of the Other Region</h2><p>Back to previous topic, if we want to import the AWS Quicksight Users and Groups resources from the <code>us-east-1</code> region in current pulumi stack from the command line, we need to specify the provider for the pulumi command line. The Pulumi CLI import command takes an additional <code>--provider</code> option to specify the provider to use for the import.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:quicksight/group:Group dev xxxxxx/default/dev --provider name=urn</span><br></pre></td></tr></table></figure><p>In above command, we are importing the <code>aws:quicksight/group:Group</code> resource with the <code>dev</code> name in the provider. For the <code>--provider</code> option, The <code>name</code> is the name of the provider to use for the import, and <code>urn</code> is the URN of the provider to use for the import. Typically, the resource urns in pulumis is below format.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urn:pulumi:production::acmecorp-website::custom:resources:Resource$aws:s3/bucket:Bucket::my-bucket</span><br><span class="line">           ^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^</span><br><span class="line">           &lt;stack-name&gt; &lt;project-name&gt;   &lt;parent-type&gt;             &lt;resource-type&gt;       &lt;resource-name&gt;</span><br></pre></td></tr></table></figure><p>If there is no <code>parent-type</code> in the resource urn, the urns will be like below format.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urn:pulumi:production::acmecorp-website::aws:s3/bucket:Bucket::my-bucket</span><br><span class="line">           ^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^</span><br><span class="line">           &lt;stack-name&gt; &lt;project-name&gt;   &lt;resource-type&gt;       &lt;resource-name&gt;</span><br></pre></td></tr></table></figure><p>For the details of Pulumi Resources URNs, please refer to the <a href="https://www.pulumi.com/docs/concepts/resources/names/#urns">Pulumi URNs</a>.</p><p>In our scenario, we can import the Quicksight Groups resources from the <code>us-east-1</code> region by using the provider. <span class='pbg warning'>There is one thing is important to note</span> For example, we don’t have any <code>Provider</code> resources for the <code>us-east-1</code> region in our current stack. If we run below command to import the Quicksight Groups resources from the <code>us-east-1</code> region, it will fail. Below is an examle of the full import resource with <code>--provider</code> option</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:quicksight/group:Group dev &lt;aws-account-id&gt;/default/dev --provider us_east_1_provider=urn:pulumi:&lt;pulumi-project-name&gt;::quicksight::pulumi:providers:aws::us_east_1_provider</span><br></pre></td></tr></table></figure><p>The <code>&lt;aws-account-id&gt;</code> and <code>&lt;pulumi-project-name&gt;</code> are placeholder just for example. Without the <code>Provider</code> resource for the <code>us-east-1</code> region, the import command will fail as below error message.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Preview failed: bad provider reference &#x27;us_east_1_provider=urn:pulumi:&lt;pulumi-project-name&gt;::quicksight::pulumi:providers:aws::us_east_1_provider&#x27; is not valid URN&#x27;</span><br></pre></td></tr></table></figure><p>The error full screenshot is below.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-without-provider-error.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-without-provider-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>To fix this issue, we need to create the <code>Provider</code> resource for the <code>us-east-1</code> region in our current stack. We can do this by adding the <code>Provider</code> resource in in our Pulumi code and using <code>Pulumi up</code> command to create the resource.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new provider for the us-east-1 region</span></span><br><span class="line">us_east_1_provider = aws.Provider(<span class="string">&#x27;us-east-1&#x27;</span>, region=<span class="string">&#x27;us-east-1&#x27;</span>)</span><br></pre></td></tr></table></figure><p>After that, we can run the import command again to import the Quicksight Groups resources from the <code>us-east-1</code> region. And now you will see the Quicksight Groups resources of the <code>us-east-1</code> region in your pulumi stack.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import-provider-success.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import-provider-success.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>To import the AWS resources of the other region, we need to specify the provider for the pulumi command line. The Pulumi CLI import command takes an additional <code>--provider</code> option to specify the provider to use for the import. The <code>provider</code> resource should be created in pulumi before importing the resources of the other region resource.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h2&gt;&lt;p&gt;By default, the Pulumi import the resource in the </summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
  <entry>
    <title>Keras3.0 - A Multi-framework Machine Learning Library</title>
    <link href="https://stonefishy.github.io/2024/06/25/keras3-0-a-multi-framework-machine-learning-library/"/>
    <id>https://stonefishy.github.io/2024/06/25/keras3-0-a-multi-framework-machine-learning-library/</id>
    <published>2024-06-25T10:12:36.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p><code>Keras</code>3 is a full rewrite of Keras that enables you to run your Keras workflows on top of either <code>JAX</code>, <code>TensorFlow</code>, or <code>PyTorch</code>, and that unlocks brand new large-scale model training and deployment capabilities. It’s multi-framework machine learning, meaning that you can use Keras to train models on top of different backends, and deploy them to different platforms. You can also use Keras as a low-level cross-framework language to develop custom components such as layers, models, or metrics that can be used in native workflows in JAX, TensorFlow, or PyTorch — with one codebase.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/keras3-multi-framework-machine-learning.jpg" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/keras3-multi-framework-machine-learning.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Keras 3 Multi-framework Machine Learning"/></div><span class="image-caption">Keras 3 Multi-framework Machine Learning</span></div><h2 id="What’s-New-in-Keras-3"><a href="#What’s-New-in-Keras-3" class="headerlink" title="What’s New in Keras 3?"></a>What’s New in Keras 3?</h2><p>Keras 3 introduces several exciting features that enhance its usability, performance, and flexibility:</p><h4 id="Unified-API"><a href="#Unified-API" class="headerlink" title="Unified API"></a>Unified API</h4><p>Keras 3 continues to build on its legacy of a user-friendly and intuitive API. It aims to unify the high-level and low-level APIs more seamlessly, providing a consistent experience across different backends such as TensorFlow, PyTorch, and others.</p><h4 id="Multi-backend-Support"><a href="#Multi-backend-Support" class="headerlink" title="Multi-backend Support"></a>Multi-backend Support</h4><p>While Keras has traditionally been closely associated with TensorFlow, Keras 3 expands its compatibility to other popular deep learning frameworks. This means you can now use Keras with PyTorch and other backends, leveraging Keras’ high-level abstractions and ease of use across different environments.</p><h4 id="Improved-Performance"><a href="#Improved-Performance" class="headerlink" title="Improved Performance"></a>Improved Performance</h4><p>Efforts have been made in Keras 3 to optimize performance across various operations, ensuring faster execution times and better utilization of hardware resources. This improvement is crucial for handling larger datasets and complex models efficiently.</p><h4 id="Enhanced-Model-Deployment"><a href="#Enhanced-Model-Deployment" class="headerlink" title="Enhanced Model Deployment"></a>Enhanced Model Deployment</h4><p>Keras 3 simplifies the process of deploying trained models to production environments. With streamlined APIs for model serialization and deployment tools, it becomes easier to integrate Keras models into real-world applications.</p><h4 id="Expanded-Model-Zoo"><a href="#Expanded-Model-Zoo" class="headerlink" title="Expanded Model Zoo"></a>Expanded Model Zoo</h4><p>Keras 3 comes with an expanded model zoo, offering <code>pre-trained models</code> for a wider range of tasks and domains. This includes vision models (e.g., ResNet, EfficientNet), NLP models (e.g., BERT, GPT), and other specialized architectures, all accessible through a unified interface.</p><h4 id="Advanced-AutoML-Capabilities"><a href="#Advanced-AutoML-Capabilities" class="headerlink" title="Advanced AutoML Capabilities"></a>Advanced AutoML Capabilities</h4><p>The new release includes improved AutoML capabilities, allowing developers to automate model selection, hyperparameter tuning, and architecture search. This feature can significantly accelerate the model development process, especially for beginners and researchers exploring new domains.</p><h2 id="Pre-trained-Models"><a href="#Pre-trained-Models" class="headerlink" title="Pre-trained Models"></a>Pre-trained Models</h2><p>There’s a wide range of pretrained models that you can start using today with Keras 3. About 40 Keras Applications models (the <code>keras.applications</code> namespace) are available in all backends. These models are pre-trained on large datasets and can be used for transfer learning or fine-tuning. It includes:</p><h4 id="Pre-trained-Models-for-Natural-Language-Processing"><a href="#Pre-trained-Models-for-Natural-Language-Processing" class="headerlink" title="Pre-trained Models for Natural Language Processing"></a>Pre-trained Models for Natural Language Processing</h4><ul><li>Albert</li><li>Bart</li><li>Bert</li><li>Bloom</li><li>DebertaV3</li><li>DistilBert</li><li>Gemma</li><li>Electra</li><li>Falcon</li><li>FNet</li><li>GPT2</li><li>Llama</li><li>Llama3</li><li>Mistral</li><li>OPT</li><li>PaliGemma</li><li>Phi3</li><li>Roberta</li><li>XLMRoberta</li></ul><h4 id="Pre-trained-Models-for-Computer-Vision"><a href="#Pre-trained-Models-for-Computer-Vision" class="headerlink" title="Pre-trained Models for Computer Vision"></a>Pre-trained Models for Computer Vision</h4><ul><li>CSPDarkNet</li><li>EfficientNetV2</li><li>MiT</li><li>MobileNetV3</li><li>ResNetV1</li><li>ResNetV2</li><li>VideoSwinB</li><li>VideoSwinS</li><li>VideoSwinT</li><li>VitDet</li><li>YOLOV8</li><li>ImageClassifier</li><li>VideoClassifier</li><li>CLIP</li><li>RetinaNet</li></ul><h2 id="How-to-Get-Started-with-Keras-3"><a href="#How-to-Get-Started-with-Keras-3" class="headerlink" title="How to Get Started with Keras 3?"></a>How to Get Started with Keras 3?</h2><h4 id="1-Install-Keras-3"><a href="#1-Install-Keras-3" class="headerlink" title="1.Install Keras 3"></a>1.Install Keras 3</h4><p>Ensure you have the latest version of Keras installed. You can install Keras via pip if you haven’t already:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade keras</span><br></pre></td></tr></table></figure><h4 id="2-Define-Model"><a href="#2-Define-Model" class="headerlink" title="2.Define Model"></a>2.Define Model</h4><p>Use Keras’ high-level API to define your deep learning model. Here’s a simple example of a convolutional neural network (CNN) for image classification:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)),</span><br><span class="line">    MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">    Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">    Flatten(),</span><br><span class="line">    Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h4 id="3-Compile-and-Train-Model"><a href="#3-Compile-and-Train-Model" class="headerlink" title="3.Compile and Train Model"></a>3.Compile and Train Model</h4><p>Compile the model with a loss function, optimizer, and metrics, then train it on your data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>, validation_data=(val_images, val_labels))</span><br></pre></td></tr></table></figure><h4 id="4-Deploy-models"><a href="#4-Deploy-models" class="headerlink" title="4.Deploy models"></a>4.Deploy models</h4><p>Keras 3 provides a simple and unified interface for deploying trained models to production environments. You can serialize your models and deploy them using tools such as TensorFlow Serving, PyTorch Hub, or JAX Hub. </p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Keras 3 bring a lot of exciting features to the table, including multi-backend support, improved performance, and enhanced model deployment. It also includes a wide range of pre-trained models for natural language processing and computer vision, making it easy to get started with deep learning. With these features, Keras 3 is a powerful and flexible tool for building and deploying deep learning models.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Keras&lt;/code&gt;3 is a full rewrite of Keras that enables you to run your Keras workflows on top of either &lt;code&gt;JAX&lt;/code&gt;, &lt;code&gt;Tens</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Keras" scheme="https://stonefishy.github.io/tags/Keras/"/>
    
    <category term="TensorFlow" scheme="https://stonefishy.github.io/tags/TensorFlow/"/>
    
    <category term="PyTorch" scheme="https://stonefishy.github.io/tags/PyTorch/"/>
    
    <category term="JAX" scheme="https://stonefishy.github.io/tags/JAX/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the X-Frame-Options HTTP Header</title>
    <link href="https://stonefishy.github.io/2024/06/14/understanding-the-x-frame-options-http-header/"/>
    <id>https://stonefishy.github.io/2024/06/14/understanding-the-x-frame-options-http-header/</id>
    <published>2024-06-14T14:36:28.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, we build a frontend website as a nginx docker image, before go live on production. We asking the security team to do the security scan for the website on stage environment. One of security issues indicates the <code>X-Frame-Options</code> HTTP header is not set properly. It will cause the website to be vulnerable to clickjacking attacks.</p><h2 id="Clickjacking-Attack"><a href="#Clickjacking-Attack" class="headerlink" title="Clickjacking Attack"></a>Clickjacking Attack</h2><p><code>Clickjacking</code> is a type of security vulnerability that allows an attacker to trick a user into clicking on a link or button on a malicious website that is designed to look like the legitimate website. This can happen when the attacker embeds the malicious website within a frame on the legitimate website, which can trick the user into clicking on the malicious link or button.</p><p>To prevent clickjacking attacks, we can use the <code>X-Frame-Options</code> HTTP header to specify whether a web page can be displayed within a frame or iframe. This header can have three possible values: <code>DENY</code>, <code>SAMEORIGIN</code>, and <code>ALLOW-FROM</code> uri.</p><h2 id="What-is-X-Frame-Options"><a href="#What-is-X-Frame-Options" class="headerlink" title="What is X-Frame-Options?"></a>What is X-Frame-Options?</h2><p>The X-Frame-Options is an HTTP response header used to control whether a web page can be displayed within a frame or iframe. It helps to mitigate clickjacking attacks by preventing malicious websites from embedding a vulnerable site within a frame and tricking users into taking unintended actions.</p><h2 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h2><p>The X-Frame-Options header can have three possible values: DENY, SAMEORIGIN, and ALLOW-FROM uri.</p><p><code>DENY</code>: This value prevents the page from being displayed in a frame, regardless of the site attempting to do so.</p><p><code>SAMEORIGIN</code>: With this value, the page can be displayed in a frame on the same origin as the page itself. This restricts the frame to the same origin as the parent page.</p><p><code>ALLOW-FROM uri</code>: Here, the page can only be displayed in a frame on the specified origin.</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>To implement the X-Frame-Options header, simply include the header in the server’s HTTP response. It can be implemented on code programming, server configuration, or web server configuration.</p><h3 id="Code-Programming"><a href="#Code-Programming" class="headerlink" title="Code Programming"></a>Code Programming</h3><p>Below is an example of how to set the header using different programming languages:</p><h4 id="Using-Node-js-Express"><a href="#Using-Node-js-Express" class="headerlink" title="Using Node.js (Express)"></a>Using Node.js (Express)</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set X-Frame-Options header to DENY</span></span><br><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">  res.<span class="title function_">setHeader</span>(<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>);</span><br><span class="line">  <span class="title function_">next</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="Using-Django-Python"><a href="#Using-Django-Python" class="headerlink" title="Using Django (Python)"></a>Using Django (Python)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set X-Frame-Options header to SAMEORIGIN</span></span><br><span class="line">response[<span class="string">&#x27;X-Frame-Options&#x27;</span>] = <span class="string">&#x27;SAMEORIGIN&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="Using-ASP-NET-C"><a href="#Using-ASP-NET-C" class="headerlink" title="Using ASP.NET (C#)"></a>Using ASP.NET (C#)</h4><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set X-Frame-Options header to ALLOW-FROM</span></span><br><span class="line">Response.AddHeader(<span class="string">&quot;X-Frame-Options&quot;</span>, <span class="string">&quot;ALLOW-FROM https://example.com&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="Server-Configuration"><a href="#Server-Configuration" class="headerlink" title="Server Configuration"></a>Server Configuration</h3><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h4><p>To configure Nginx to send the X-Frame-Options header, add this either to your http, server or location configuration:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_header X-Frame-Options SAMEORIGIN always;</span><br></pre></td></tr></table></figure><h4 id="Apache"><a href="#Apache" class="headerlink" title="Apache"></a>Apache</h4><p>To configure Apache to send the X-Frame-Options header for all pages, add this to your site’s configuration:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Header always set X-Frame-Options &quot;DENY&quot;</span><br></pre></td></tr></table></figure><h4 id="IIS"><a href="#IIS" class="headerlink" title="IIS"></a>IIS</h4><p>To configure IIS to send the X-Frame-Options header for all pages, add this to your web.config file:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">httpProtocol</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">customHeaders</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">&quot;X-Frame-Options&quot;</span> <span class="attr">value</span>=<span class="string">&quot;DENY&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">customHeaders</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">httpProtocol</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>To demonstrate the effectiveness of the X-Frame-Options header, we can create a parent html page, and a child html page that is embedded within a frame in the parent page.</p><h3 id="Parent-HTML-Page"><a href="#Parent-HTML-Page" class="headerlink" title="Parent HTML Page"></a>Parent HTML Page</h3><p>Parent HTML page includes the iframe of the child page. The child page is hosted on a different domain (<a href="http://localhost:3333/child.html">http://localhost:3333/child.html</a>) to demonstrate the effectiveness of the X-Frame-Options header. </p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Parent Page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Parent Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is parent page. below is the iframe of child page.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">iframe</span> <span class="attr">src</span>=<span class="string">&quot;http://localhost:3333/child.html&quot;</span> <span class="attr">frameborder</span>=<span class="string">&quot;0&quot;</span> <span class="attr">sandbox</span>=<span class="string">&quot;allow-scripts&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 100%; height: 200px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Child-HTML-Page"><a href="#Child-HTML-Page" class="headerlink" title="Child HTML Page"></a>Child HTML Page</h3><p>Child HTML page is a simple page that displays a message. It is hosted on the domain (<a href="http://localhost:3333/child.html">http://localhost:3333/child.html</a>) by using <code>httpster</code> tool.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Child Page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Child Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is a child page.<span class="tag">&lt;/<span class="name">p</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><p>To test the effectiveness of the X-Frame-Options header, we can open the parent page in a browser and observe the behavior.</p><h4 id="Without-X-Frame-Options-Header"><a href="#Without-X-Frame-Options-Header" class="headerlink" title="Without X-Frame-Options Header"></a>Without X-Frame-Options Header</h4><p>By default, the <code>httpster</code> does not add the X-Frame-Options header to the response. Therefore, the child page can be embedded within a frame on the parent page. See below screenshot, these is no X-Frame-Options header in the response.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/without-x-frame-options-response-header.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/without-x-frame-options-response-header.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Without X-Frame-Options Header"/></div><span class="image-caption">Without X-Frame-Options Header</span></div><h4 id="With-X-Frame-Options-Header"><a href="#With-X-Frame-Options-Header" class="headerlink" title="With X-Frame-Options Header"></a>With X-Frame-Options Header</h4><p>With the X-Frame-Options header set to DENY, the child page cannot be embedded within a frame on the parent page.</p><p>To test the X-Frame-Options header, we need to modify the <code>httpster</code> server source code to add the X-Frame-Options header to the response. Actually, the <code>httpster</code> tool is a simple HTTP server base on node express. We can modify the <code>app.use</code> function to set the X-Frame-Options header in the httpster source code. </p><p>Here is the modified <code>app.use</code> function with the X-Frame-Options header set to DENY:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">   res.<span class="title function_">setHeader</span>(<span class="string">&#x27;X-Frame-Options&#x27;</span>, <span class="string">&#x27;DENY&#x27;</span>);</span><br><span class="line">   <span class="title function_">next</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>We can then open the parent page in a browser and observe the behavior. See below screenshot, these is with X-Frame-Options header value set to DENY in the response. And the child page is blocked from being embedded within a frame on the parent page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/with-x-frame-options-response-header-deny.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/with-x-frame-options-response-header-deny.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="With X-Frame-Options Header Value DENY"/></div><span class="image-caption">With X-Frame-Options Header Value DENY</span></div><p>And also, there is error message in the console of the browser, which indicates that the child page is blocked from being embedded within a frame on the parent page.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/frontend/with-x-frame-opitons-response-header-deny-console.png" class="lazyload placeholder" data-srcset="/assets/images/frontend/with-x-frame-opitons-response-header-deny-console.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="With X-Frame-Options Header Value DENY Console Error"/></div><span class="image-caption">With X-Frame-Options Header Value DENY Console Error</span></div><p>You can also test the X-Frame-Options header with different values such as SAMEORIGIN and ALLOW-FROM uri to see how it affects the behavior of the website.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By implementing the X-Frame-Options header, web developers can enhance the security of their websites and protect users from potential clickjacking attacks. It is recommended to set this header appropriately based on the specific requirements of the web application.</p><p>Remember to test the effectiveness of the header using browser developer tools and security testing tools to ensure that it is properly configured.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently, we build a frontend website as a nginx docker image, before go live on production. We asking the security team to do the securi</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="Web" scheme="https://stonefishy.github.io/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>The Points of AWS China CloudFront You Need to Notice</title>
    <link href="https://stonefishy.github.io/2024/04/18/the-points-of-aws-china-cloudfront-you-need-to-notice/"/>
    <id>https://stonefishy.github.io/2024/04/18/the-points-of-aws-china-cloudfront-you-need-to-notice/</id>
    <published>2024-04-18T10:16:54.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>There are much difference between AWS Global and AWS China. The background of this blog is that I’m responsible for migrating the aws global application to aws china. The application already go lived on AWS Global. The application is  collecting the user inforamtion and for business logic. The business wants this application to serve China customer. Due to the application regulation,  the application needs to deployed in AWS China and store the user information in AWS China.</p><p>The application is using below AWS services:</p><ul><li>AWS S3: store the static website assets and user information.</li><li>AWS ALB: the load balancer for the application.</li><li>AWS ASG: auto scaling group for the application.</li><li>AWS ECR: store the application container image.</li><li>AWS ECS: run the application container.</li><li>AWS ACM: manage the SSL certificate.</li><li>AWS WAF: web application firewall.</li><li>AWS VPC: virtual private cloud.</li><li>AWS S3 VPC Gateway: access the S3 bucket from the VPC.</li><li>AWS CloudWatch: monitor the application logs, performance and alarms.</li><li>AWS SNS: notificate the stack holder when application performance is abnormal.</li><li>AWS CloudFront: serve the static website and user information.</li></ul><h2 id="AWS-China"><a href="#AWS-China" class="headerlink" title="AWS China"></a>AWS China</h2><p>The AWS China is a separate entity operated by a local partner in compliance with Chinese regulations. Data centers located in Beijing and Ningxia. The operator is different between Beijing and Ningxia. Beijing region operated by Sinnet(光环新网)，Ningxia region operated by NWCD(西云数据). Basically， the service price of Ningxia region is cheaper than Beijing region. You can find the detail pricing in the AWS China link <a href="https://calculator.amazonaws.cn/#/">https://calculator.amazonaws.cn/#/</a>. AWS Fargate priciing is here <a href="https://www.amazonaws.cn/en/fargate/pricing">https://www.amazonaws.cn/en/fargate/pricing</a></p><h2 id="Difference-between-AWS-Global-and-AWS-China"><a href="#Difference-between-AWS-Global-and-AWS-China" class="headerlink" title="Difference between AWS Global and AWS China"></a>Difference between AWS Global and AWS China</h2><p>The AWS China has many limiation and difference with AWS Global. And also some new services are not available in AWS China. When you migrate the application to AWS China, you need to consider the below points:</p><ol><li>AWS China has different pricing policy. The pricing policy is different between Beijing and Ningxia. </li><li>The Infrastructure code is different between AWS Global and AWS China. The code need to be modified to adapt to AWS China.</li><li>The Website should be do the ICP filling and Goverment Filling. (域名备案，网安备案)</li></ol><h3 id="Infrastructure-as-Code"><a href="#Infrastructure-as-Code" class="headerlink" title="Infrastructure as Code"></a>Infrastructure as Code</h3><p>We’re using <code>Pulumi</code> to manage the infrastructure as code. Pulumi is a tool for developing, building, and deploying cloud applications and infrastructure. It supports multiple cloud providers including AWS, Azure, GCP, and Kubernetes.<br>There are AWS Service Resource definition is different with AWS Global on AWS China. In AWS China there is an <code>amazonaws.com.cn</code> string for endpoint, and <code>aws-cn</code> ARN prefix. The code need to be modified to adapt to AWS China.</p><h4 id="AWS-China-1"><a href="#AWS-China-1" class="headerlink" title="AWS China"></a>AWS China</h4><ul><li>AWS EndPoint: xxxxxxx.s3.cn-northwest-1.<strong>amazonaws.com.cn</strong>&#x2F;example.txt</li><li>AWS ARNs: arn:<strong>aws-cn</strong>:s3:::xxxxxxx&#x2F;example.txt</li></ul><h4 id="AWS-Global"><a href="#AWS-Global" class="headerlink" title="AWS Global"></a>AWS Global</h4><ul><li>AWS EndPoint: xxxxxxx.s3.cn-northwest-1.<strong>amazonaws.com</strong>&#x2F;example.txt</li><li>AWS ARNs: arn:<strong>aws</strong>:s3:::xxxxxxx&#x2F;example.txt</li></ul><h3 id="CloudFront"><a href="#CloudFront" class="headerlink" title="CloudFront"></a>CloudFront</h3><p>In our application is much difference between AWS Global and AWS China, especially the CloudFront.</p><ul><li>Requires ICP filing and domain name filing in AWS China.</li><li>The CloudFront provides domain name like “*.cloudfront.cn” which cannot be used in for website serving in AWS China. You can not access the website through the CloudFront domain name. It returns 403 Forbidden error.</li><li>The SSL&#x2F;TLS certificates for CloudFront does not support the Amazon Certificate Manager in AWS China. It requires to use SSL&#x2F;TLS certificate from third party, and then - - import certificate in IAM. It is only support IAM to store the certificates for CloudFront in AWS China.</li><li>The CloudFront does not supports the Amazon WAF in AWS China.</li><li>The Cache polices and Origin request polices does not support in AWS China</li><li>The Lambda@Edge is not available in AWS China.</li><li>CloudFront origin access only supports legacy access identities OAI for S3 bucket, does not support OAC in AWS China</li><li>The CloudFront origin for S3 bucket which is not a website endpoint, the following format: <code>bucket-name.s3.region.amazonaws.com.cn</code>, remember <code>region</code> after <code>s3</code></li><li>The CloudFront origin for S3 bucket which is a website endpoint, use the following format: <code>bucket-name.s3-website.region.amazonaws.com.cn</code>, remember <code>region</code> after <code>s3-website</code></li></ul><p>For more information, please refer to the AWS China CloudFront <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/cloudfront.html#feature-diff">https://docs.amazonaws.cn/en_us/aws/latest/userguide/cloudfront.html#feature-diff</a></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this blog, we have discussed the important points when migrate the aws global application to aws china, especially for the AWS CloudFront. We have listed the difference between AWS Global and AWS China, and also the CloudFront difference between AWS Global and AWS China.</p><p>If you want to know more about AWS China service difference with AWS Global, you can refer to this official link <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html">https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html</a></p><p>Hope this blog can help you to migrate the application to AWS China.</p><h2 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h2><ul><li>AWS China Service Difference: <a href="https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html">https://docs.amazonaws.cn/en_us/aws/latest/userguide/services.html</a></li><li>AWS China Service Pricing: <a href="https://calculator.amazonaws.cn/#/">https://calculator.amazonaws.cn/#/</a></li><li>AWS China Fargate Pricing: <a href="https://www.amazonaws.cn/en/fargate/pricing">https://www.amazonaws.cn/en/fargate/pricing</a></li><li>AWS China Edge Location: <a href="https://www.amazonaws.cn/en/cloudfront/features/">https://www.amazonaws.cn/en/cloudfront/features/</a></li><li>AWS China CloudFront Error Investigation: <a href="https://zhuanlan.zhihu.com/p/182517851">https://zhuanlan.zhihu.com/p/182517851</a></li><li>ICP&#x2F;IP地址&#x2F;域名信息备案管理系统: <a href="https://beian.miit.gov.cn/#/Integrated/index">https://beian.miit.gov.cn/#/Integrated/index</a></li><li>全国互联网安全管理服务平台: <a href="https://beian.mps.gov.cn/#/query/webSearch">https://beian.mps.gov.cn/#/query/webSearch</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;There are much difference between AWS Global and AWS China. The background of this blog is that I’m responsible for migrating the aws glo</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Migrate a legacy application to AWS Cloud</title>
    <link href="https://stonefishy.github.io/2024/03/13/migrate-a-legacy-application-to-aws-cloud/"/>
    <id>https://stonefishy.github.io/2024/03/13/migrate-a-legacy-application-to-aws-cloud/</id>
    <published>2024-03-13T14:20:44.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Recently, we got a requirement from the company to move the application to AWS Cloud. The company has a strong focus on security and compliance, and stack holders also want the application more reliable and scalable. The migration also need to be done as soon as possible.</p><p>The application running on a local data center. The application is consists of two parts, frontend is a static website built with React and provide the user interface to user, the backend is a Python Flask application that provide the API to interact with the frontend. The backend server also contains a machine learning model algorithm that is used to process the user’s ears photo. </p><p>The application main logic is that the user answer some questions and scan and upload their ears photo to the backend server from the website, the backend server will process the photo and return the suggestion result to user to recommend which headset or earphone is the best fit for them.</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>After analysis application technologies and architecture, base on the requirements, we did some architecture design. Below is the architecture of the application on AWS Cloud. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-migrate-legacy-app-arch.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-migrate-legacy-app-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Application Architecture on AWS Cloud"/></div><span class="image-caption">Application Architecture on AWS Cloud</span></div><p>The application is hosted on AWS Cloud, major is that the frontend is served by CloudFront, the backend is served by ECS, and the user’s ears photo is stored in S3 bucket. The application is using the following AWS services:</p><h4 id="AWS-S3-Bucket"><a href="#AWS-S3-Bucket" class="headerlink" title="AWS S3 Bucket"></a>AWS S3 Bucket</h4><p>Setup two s3 buckets, one is for storing the user’s ears photo, and config the object expires after 90 days. second bucket is for storing the static website files. All s3 buckets are public blocked.</p><h4 id="AWS-VPC"><a href="#AWS-VPC" class="headerlink" title="AWS VPC"></a>AWS VPC</h4><p>Create a dedicate VPC for the application, and configure the subnets, route tables, and security groups. Two public subnets and two private subnets are used.</p><h4 id="AWS-ECR"><a href="#AWS-ECR" class="headerlink" title="AWS ECR"></a>AWS ECR</h4><p>Use ECR to store the Docker image of the backend application. The image will be built and pushed to ECR by CI&#x2F;CD pipeline.</p><h4 id="AWS-ECS"><a href="#AWS-ECS" class="headerlink" title="AWS ECS"></a>AWS ECS</h4><p>Use ECS to run the backend application as a container in private subnets, and configure the auto scaling group and load balancer. Autoscaling minimum size is 2 and maximum size is 20.</p><h4 id="AWS-ALB"><a href="#AWS-ALB" class="headerlink" title="AWS ALB"></a>AWS ALB</h4><p>Create a ALB to serve the backend ECS service, and configure the listener rules to forward the traffic to the ECS service. The ALB attached the SSL certificate from ACM.</p><h4 id="AWS-S3-VPC-Gateway-Endpoint"><a href="#AWS-S3-VPC-Gateway-Endpoint" class="headerlink" title="AWS S3 VPC Gateway Endpoint"></a>AWS S3 VPC Gateway Endpoint</h4><p>Use the S3 VPC Gateway Endpoint to access the s3 bucket from the backend ECS container.</p><h4 id="AWS-Internet-Gateway"><a href="#AWS-Internet-Gateway" class="headerlink" title="AWS Internet Gateway"></a>AWS Internet Gateway</h4><p>The Internet Gateway to connect the VPC to the internet. Put the ALB on the two public subnets across two AZs </p><h4 id="AWS-CloudWatch"><a href="#AWS-CloudWatch" class="headerlink" title="AWS CloudWatch"></a>AWS CloudWatch</h4><p>Use CloudWatch to monitor the application performance, and create alarms to notify the team when the application is not running as expected.</p><h4 id="AWS-SNS"><a href="#AWS-SNS" class="headerlink" title="AWS SNS"></a>AWS SNS</h4><p>Use SNS to notify the team when the application performance is not good, and the team can take action to improve the application performance.</p><h4 id="AWS-ACM"><a href="#AWS-ACM" class="headerlink" title="AWS ACM"></a>AWS ACM</h4><p>Use ACM to manage the SSL certificate for the ALB and CloudFront, the certificate is issued by the IT team. The application is served over HTTPS.</p><h4 id="AWS-CloudFront"><a href="#AWS-CloudFront" class="headerlink" title="AWS CloudFront"></a>AWS CloudFront</h4><p>Use CloudFront to serve the static website files, and cache the files to improve the website loading speed. Config CloudFront to access s3 bucket by OAC. Create a another origin for the ALB.</p><h4 id="AWS-Security-Group"><a href="#AWS-Security-Group" class="headerlink" title="AWS Security Group"></a>AWS Security Group</h4><p>Create a security group for the ECS container, and allow the traffic from the ALB to the ECS container. And one more security group for the ALB to allow the traffic only from AWS CloudFront prefix list.</p><h4 id="AWS-IAM"><a href="#AWS-IAM" class="headerlink" title="AWS IAM"></a>AWS IAM</h4><p>Create an IAM role for the ECS container, and attach the necessary policies to the role to access the s3 bucket, ECR, and CloudWatch.</p><h4 id="AWS-WAF"><a href="#AWS-WAF" class="headerlink" title="AWS WAF"></a>AWS WAF</h4><p>Use WAF to protect the application from common web exploits and attacks. This is mandatory for the company’s security policy. The security team will also review the infrastucture and do the security scan the application. The application won’t be deployed to production if the security scan failed.</p><h2 id="IaC-with-Pulumi"><a href="#IaC-with-Pulumi" class="headerlink" title="IaC with Pulumi"></a>IaC with Pulumi</h2><p>Use Pulumi to manage the AWS resources, and create the infrastructure as code. The code will be checked into the source control, and for the pipeline, we’re using Bamboo pipeline as company already using Bamboo for CI&#x2F;CD. The pipeline will doing below major things.</p><ol><li>Build the Docker image and push to ECR.</li><li>Deploy the frontend static website to CloudFront, and invalidate the cache to make the content updated for end user.</li><li>Update the infrastucture by creating or updating the AWS resources by using pulumi.</li></ol><h2 id="Rationale"><a href="#Rationale" class="headerlink" title="Rationale"></a>Rationale</h2><p>The migration of the legacy application to AWS Cloud is a complex task, and we need to follow the best practices to make the migration successful.</p><ol><li>Using CloudFront and S3 bucket to host the static website and user’s ears photo is scalable and cost-effective. </li><li>Using the ECS and ALB to serve the backend application is also a good choice to improve the application performance and scalability. We’re not using AWS API Gateway and AWS Lambda to serve as backend because we are requested to migrate the application to Cloud as soon as possible. Build the python <code>Flask</code> application to a docker image and push to ECR is a good practice to deploy the application to AWS Cloud in this situation.</li><li>Using the VPC and security group to isolate the application and improve the security is a must. The ECS is located in private subnets, and the ALB is in public subnets, and the traffic is only allowed from AWS CloudFront prefix list to ALB, then forward traffic to ECS container.</li><li>Using the ACM to manage the SSL certificate for the ALB and CloudFront is a good practice to improve the security and compliance.</li><li>Using the CloudWatch to monitor the application performance and create alarms to notify the team when the application is not running as expected is a good practice to improve the application reliability.</li><li>Using the IAM role to access the s3 bucket, ECR, and CloudWatch is a good practice to improve the security and control.</li><li>Using the WAF to protect the application from common web exploits and attacks is a mandatory requirement for the company’s security policy.</li><li>Using Pulumi to manage the AWS resources as code is a good practice to improve the automation and reliability of the migration process.</li></ol><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This is just a sample of how to migrate a legacy application to AWS Cloud, and there are many other factors to consider when migrating a legacy application to AWS Cloud. The key is to follow the best practices and use the right tools to make the migration successful base on the requirements.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h2&gt;&lt;p&gt;Recently, we got a requirement from th</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>Manage the Existing Cloud Resources By Using Pulumi Import</title>
    <link href="https://stonefishy.github.io/2024/02/27/importing-existing-cloud-resources-with-pulumi/"/>
    <id>https://stonefishy.github.io/2024/02/27/importing-existing-cloud-resources-with-pulumi/</id>
    <published>2024-02-27T14:26:24.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>In many real-world scenarios, cloud infrastructure is already in place before adopting infrastructure as code (IaC) solutions like Pulumi. Pulumi provides a feature called <code>import</code> to help manage existing cloud resources within its IaC framework. This feature allows users to import the current state of resources into their Pulumi codebase, making it easier to adopt Pulumi for managing existing infrastructure.</p><h2 id="Pulumi-Import"><a href="#Pulumi-Import" class="headerlink" title="Pulumi Import"></a>Pulumi Import</h2><p>Pulumi’s import feature provides a way to bring existing cloud resources under Pulumi’s management. By creating a Pulumi program and using the pulumi import command, users can declare and manage existing infrastructure resources using Pulumi. The pulumi supports both importing existing resources with the CLI and importing existing resources in the code. Here we’re talking about the CLI import to generate the code for the imported resources. </p><h2 id="Usage-and-Syntax"><a href="#Usage-and-Syntax" class="headerlink" title="Usage and Syntax"></a>Usage and Syntax</h2><p>To import an existing cloud resource into Pulumi, you need to follow these steps:</p><ol><li><p>Create a Pulumi Project<br>Create a new Pulumi project or use an existing Pulumi project where you want to manage the imported resources. For creating a pulumi project, you can check the previous blog post on how to create a new Pulumi project.</p></li><li><p>Identify the Resource to Import<br>Identify the existing resource in your cloud provider environment that you want to import into Pulumi. This could be a virtual machine, database, storage bucket, or any other supported resource.</p></li><li><p>Apply the Import<br>Apply the import operation to bring the existing resource under Pulumi’s management. Pulumi will generate the appropriate code for the resource based on its current state in the cloud provider environment.</p></li></ol><p>The syntax for the import command is as follows:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import &lt;type&gt; &lt;name&gt; &lt;id&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;type&gt;</code> is the Pulumi type token to use for the imported resource.</li><li><code>&lt;name&gt;</code> is the resource name to apply to the resource once it’s imported.</li><li><code>&lt;id&gt;</code> is the value to use for the resource lookup in the cloud provider.</li></ul><h2 id="Managing-Imported-Resources"><a href="#Managing-Imported-Resources" class="headerlink" title="Managing Imported Resources"></a>Managing Imported Resources</h2><p>Once the resources are imported, they can be managed just like any other Pulumi-managed resources. The imported resources can be updated, deleted, and included in stacks alongside other Pulumi-declared infrastructure.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>I created a S3 bucket name <code>my-s3-bucket</code> from AWS Console manually. But now I want to manage this S3 bucket by Pulumi. After identifying the bucket to be imported, the import command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:s3/bucket:Bucket my-bucket my-s3-bucket</span><br></pre></td></tr></table></figure><ul><li><code>aws:s3/bucket:Bucket</code> is the Pulumi type token for the S3 bucket resource.</li><li><code>my-bucket</code> is the resource name to apply to the imported resource.</li><li><code>my-s3-bucket</code> is the value to use for the resource lookup in the AWS provider, here it’s bucket name.</li></ul><p>After running the import command, Pulumi will generate the appropriate code for the S3 bucket resource based on its current state in the AWS provider. Below is screenshot of the output of the import command:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-import.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-import.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Import"/></div><span class="image-caption">Pulumi Import</span></div><p>And generated code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">my_bucket = aws.s3.Bucket(<span class="string">&quot;my-bucket&quot;</span>,</span><br><span class="line">    arn=<span class="string">&quot;arn:aws-cn:s3:::my-s3-bucket&quot;</span>,</span><br><span class="line">    bucket=<span class="string">&quot;my-s3-bucket&quot;</span>,</span><br><span class="line">    hosted_zone_id=<span class="string">&quot;Z282HJ1KT0DH03&quot;</span>,</span><br><span class="line">    request_payer=<span class="string">&quot;BucketOwner&quot;</span>,</span><br><span class="line">    server_side_encryption_configuration=aws.s3.BucketServerSideEncryptionConfigurationArgs(</span><br><span class="line">        rule=aws.s3.BucketServerSideEncryptionConfigurationRuleArgs(</span><br><span class="line">            apply_server_side_encryption_by_default=aws.s3.BucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefaultArgs(</span><br><span class="line">                sse_algorithm=<span class="string">&quot;AES256&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            bucket_key_enabled=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure><p>In above code, you will notice there is a <code>protect=True</code> option set for the imported resource. This is to prevent any accidental deletion of the imported resource.</p><p>So when you try to delete the imported resource, Pulumi will give the errors to you. Let’s try to delete the imported S3 bucket:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi destroy</span><br></pre></td></tr></table></figure><p>You see, it displays the error message that the S3 bucket is protected and cannot be deleted.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-destory-import.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-destory-import.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Destory Import Protected Resource"/></div><span class="image-caption">Pulumi Destory Import Protected Resource</span></div><p>If you want to delete the resource in the cloud provider environment, you can remove the <code>protect=True</code> option from the code or change the <code>protect</code> option to <code>False</code>.</p><p>In above we’re using <code>pulumi import</code> to import the s3 bucket resource and code is generated on console. We can also generate the code into python file directly by using below command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi import aws:s3/bucket:Bucket my-bucket my-s3-bucket -o my-s3-bucket.py</span><br></pre></td></tr></table></figure><h2 id="Pulumi-State"><a href="#Pulumi-State" class="headerlink" title="Pulumi State"></a>Pulumi State</h2><p>Pulumi maintains a state file that tracks the current state of all resources in the cloud provider environment. When a resource is imported, Pulumi updates the state file to reflect the imported resource. This allows Pulumi to manage the imported resource as if it were created in the cloud provider environment.</p><p>Sometimes, we want to delete the state which imported in pulumi, but keep the existing cloud resources. In such case, we can use below command to only delete the state and keep the existing cloud resources.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi state delete &lt;urn&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;urn&gt;</code> is the unique resource identifier of the imported resource.</li></ul><p>To check the <code>&lt;urn&gt;</code> of the resource, we can use <code>pulumi stack --show-urns</code> to see the list urns of all resources in the current stack.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack --show-urns</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-stack-show-urns.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-stack-show-urns.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Stack Show Urns"/></div><span class="image-caption">Pulumi Stack Show Urns</span></div><p>In above screenshot, we can see the <code>&lt;urn&gt;</code> of the imported S3 bucket resource.To delete the state of the imported resource, we can use the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi state delete urn:pulumi:dev::pulumi-test::aws:s3/bucket:Bucket::my-bucket --force -y</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-state-delete.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-state-delete.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi State Delete Imported Resource"/></div><span class="image-caption">Pulumi State Delete Imported Resource</span></div><p>After deleting the state, the imported S3 bucket will still exist in the cloud provider environment.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Pulumi’s import feature allows users to seamlessly integrate existing cloud resources into their Pulumi programs. By following the import process and syntax, users can effectively manage their entire infrastructure, including existing resources, through Pulumi’s IaC approach.</p><p>This feature simplifies the transition to Pulumi for managing infrastructure and enables teams to leverage the benefits of IaC without having to recreate their entire cloud environment from scratch.</p><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links"></a>Reference Links</h2><ul><li>Pulumi Import: <a href="https://www.pulumi.com/docs/cli/commands/pulumi_import/">https://www.pulumi.com/docs/cli/commands/pulumi_import/</a></li><li>S3 Bucket Import: <a href="https://www.pulumi.com/registry/packages/aws/api-docs/s3/bucket/#import">https://www.pulumi.com/registry/packages/aws/api-docs/s3/bucket/#import</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In many real-world scenarios, cloud infrastructure is already in place before adopting infrastructure as code (IaC) solutions like Pulumi</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
  <entry>
    <title>Pulumi - A Powerful IaC to manage the cloud infrastructure</title>
    <link href="https://stonefishy.github.io/2024/02/11/pulumi-a-powerful-iac-to-manage-the-cloud-infrastructure/"/>
    <id>https://stonefishy.github.io/2024/02/11/pulumi-a-powerful-iac-to-manage-the-cloud-infrastructure/</id>
    <published>2024-02-11T15:12:13.000Z</published>
    <updated>2024-11-12T06:44:01.445Z</updated>
    
    <content type="html"><![CDATA[<p>To manage the application cloud infrastructure more efficiently, we can use the <code>Terraform</code> for <code>IaC(Infrastructure as Code)</code>. But today, we’re not going to talk about the Terraform, we’re going to talk about the Pulumi. A powerful IaC tool that manages the cloud infrastructure.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-platform.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-platform.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Platform"/></div><span class="image-caption">Pulumi Platform</span></div><p>Pulumi is an open-source <code>infrastructure as code (IaC)</code> tool that provides a powerful way to create, deploy, and manage cloud infrastructure. It is the easiest way to build and deploy infrastructure, of any architecture and on any cloud, using programming languages that you already know and love, such as <code>TypeScript</code>, <code>Python</code>, <code>Go</code>, <code>C#</code>, <code>Java</code> etc.</p><p>It is a cross-platform tool that runs on <code>Windows</code>, <code>Linux</code>, and <code>macOS</code>, and supports a wide range of cloud providers, including <code>AWS</code>, <code>Azure</code>, <code>GCP</code>, <code>Kubernetes</code>, <code>Docker</code>, and more. It is also easy to use and has a simple and intuitive interface.</p><p>CI&#x2F;CD integration is also supported, which means you can use Pulumi to deploy your infrastructure as part of your CI&#x2F;CD pipeline. This makes it easier to manage and update your infrastructure as your application evolves.</p><h2 id="Install-Pulumi"><a href="#Install-Pulumi" class="headerlink" title="Install Pulumi"></a>Install Pulumi</h2><p>The pulumi  is a cross-platform tool that runs on Windows, Linux, and macOS. You can find and download the latest version from the official website: <a href="https://www.pulumi.com/docs/install/versions/">https://www.pulumi.com/docs/install/versions/</a>. Follow this link to <a href="https://www.pulumi.com/docs/install/">https://www.pulumi.com/docs/install/</a> to install the Pulumi CLI. It’s very simple to set up the Pulumi CLI on your machine.</p><p>Once you installed pulumi, simply run the below command to check the version:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi version</span><br></pre></td></tr></table></figure><h2 id="Create-a-new-Pulumi-project"><a href="#Create-a-new-Pulumi-project" class="headerlink" title="Create a new Pulumi project"></a>Create a new Pulumi project</h2><p>To create a new Pulumi project, you can use the <code>pulumi new</code> command. Below command is creating a new project with AWS Python template.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi new aws-python</span><br></pre></td></tr></table></figure><p>This will create a new project with a simple AWS Python template. The project will have a <code>Pulumi.yaml</code> file, which is the configuration file for the project.</p><h2 id="Configure-the-Pulumi-project"><a href="#Configure-the-Pulumi-project" class="headerlink" title="Configure the Pulumi project"></a>Configure the Pulumi project</h2><p>The <code>Pulumi.yaml</code> file is the configuration file for the project. It contains the project name and some configuration.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">my-project</span></span><br><span class="line"><span class="attr">runtime:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">python</span></span><br><span class="line">  <span class="attr">options:</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">venv</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">A</span> <span class="string">minimal</span> <span class="string">AWS</span> <span class="string">Python</span> <span class="string">Pulumi</span> <span class="string">program</span></span><br></pre></td></tr></table></figure><p>In the above configuration, we have set the project name as <code>my-project</code>, the runtime as <code>python</code> and the virtualenv as <code>venv</code>. The description is a brief description of the project.</p><h2 id="Create-a-new-stack"><a href="#Create-a-new-stack" class="headerlink" title="Create a new stack"></a>Create a new stack</h2><p>To create a new stack, you can use the <code>pulumi stack init</code> command. Below command is creating a new stack with the name <code>dev</code>.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack init dev</span><br></pre></td></tr></table></figure><p>Once you created the stack, the pululmi will generate a file named <code>Pulumi.dev.yaml</code> in your project folder. You can select it using the <code>pulumi stack select</code> command.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack select dev</span><br></pre></td></tr></table></figure><h2 id="Configure-the-stack"><a href="#Configure-the-stack" class="headerlink" title="Configure the stack"></a>Configure the stack</h2><p>The <code>Pulumi.dev.yaml</code> file is the configuration file for the stack.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">encryptionsalt:</span> <span class="string">v1:6YTR30z2X9tM=:v1:+fJN/nMOdJM+XjeZ:P7V9XPB9GHKE/dBuXX1uOCNGwgQztre==</span></span><br><span class="line"><span class="attr">config:</span> </span><br><span class="line">  <span class="attr">aws:region:</span> <span class="string">us-west-2</span></span><br><span class="line">  <span class="attr">aws:profile:</span> <span class="string">profile-account-1</span></span><br></pre></td></tr></table></figure><p>In above configuration, we have set the encryption salt (this is generated), and the AWS region and profile. You can add more configuration as per your requirement.</p><h2 id="Create-a-new-resource"><a href="#Create-a-new-resource" class="headerlink" title="Create a new resource"></a>Create a new resource</h2><p>To create a new resource, such as s3 bucket, you can write python code in the <code>main.py</code> file. Below is the code to create a new s3 bucket.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">bucket = aws.s3.Bucket(<span class="string">&quot;my-bucket&quot;</span>)</span><br></pre></td></tr></table></figure><p>In the above code, we have imported the <code>aws</code> module and created a new s3 bucket resource. The <code>Bucket</code> function creates a new s3 bucket with the name <code>my-bucket</code>.</p><h2 id="Preview-the-changes"><a href="#Preview-the-changes" class="headerlink" title="Preview the changes"></a>Preview the changes</h2><p>To preview the changes, you can use the <code>pulumi preview</code> command. This command will show the changes that will be applied to the infrastructure.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi preview</span><br></pre></td></tr></table></figure><p>Below is the project currently I’m working on for <code>pululmi preview</code> showcase.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-preview.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-preview.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Preview"/></div><span class="image-caption">Pulumi Preview</span></div><p>In above screenshot, you can see the changes that will be applied to the infrastructure. Including <code>update</code>, <code>create</code> and <code>delete</code> resources listed. You can also use the <code>--diff</code> option to show the difference between the current state and the desired state.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi preview --diff</span><br></pre></td></tr></table></figure><h2 id="Deploy-the-infrastructure"><a href="#Deploy-the-infrastructure" class="headerlink" title="Deploy the infrastructure"></a>Deploy the infrastructure</h2><p>To deploy the infrastructure, you can use the <code>pulumi up</code> command. This command will deploy the infrastructure as per the configuration in the <code>Pulumi.yaml</code> file.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi up</span><br></pre></td></tr></table></figure><p>This will deploy the infrastructure and show the output.</p><h2 id="Check-the-status-of-the-infrastructure"><a href="#Check-the-status-of-the-infrastructure" class="headerlink" title="Check the status of the infrastructure"></a>Check the status of the infrastructure</h2><p>To check the status of the infrastructure, you can use the <code>pulumi stack</code> command. This command will show the status of the infrastructure.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi stack</span><br></pre></td></tr></table></figure><p>This will show the status of the infrastructure. Below is the output of the <code>pulumi stack</code> command of one project I’m working.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/pulumi/pulumi-stack.png" class="lazyload placeholder" data-srcset="/assets/images/pulumi/pulumi-stack.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi Stack"/></div><span class="image-caption">Pulumi Stack</span></div><h2 id="Destroy-the-infrastructure"><a href="#Destroy-the-infrastructure" class="headerlink" title="Destroy the infrastructure"></a>Destroy the infrastructure</h2><p>To destroy the infrastructure, you can use the <code>pulumi destroy</code> command. This command will destroy the infrastructure as per the configuration in the <code>Pulumi.yaml</code> file.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pulumi destroy</span><br></pre></td></tr></table></figure><p>This will destroy the infrastructure. Please be aware that this command will destroy all the resources in the stack. It’s dangerous to use this command, so use it with caution. You should know what you’re doing before using this command.</p><p>There are much more features of Pulumi, but I hope this article will give you a good idea about Pulumi.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Pulumi is a powerful IaC tool that manages the cloud infrastructure. It is easy to use and has a simple and intuitive interface. It supports a wide range of cloud providers, including AWS, Azure, GCP, Kubernetes, Docker, and more. It is also easy to integrate with CI&#x2F;CD pipeline.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;To manage the application cloud infrastructure more efficiently, we can use the &lt;code&gt;Terraform&lt;/code&gt; for &lt;code&gt;IaC(Infrastructure as Co</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
</feed>
