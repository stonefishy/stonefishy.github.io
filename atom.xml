<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andrewsy&#39;s Space</title>
  
  
  <link href="https://stonefishy.github.io/atom.xml" rel="self"/>
  
  <link href="https://stonefishy.github.io/"/>
  <updated>2025-03-11T07:05:13.590Z</updated>
  <id>https://stonefishy.github.io/</id>
  
  <author>
    <name>Andrewsy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Creating and Rendering a PDF from React Easily</title>
    <link href="https://stonefishy.github.io/2025/03/11/creating-and-rendering-pdf-from-react/"/>
    <id>https://stonefishy.github.io/2025/03/11/creating-and-rendering-pdf-from-react/</id>
    <published>2025-03-11T09:53:13.000Z</published>
    <updated>2025-03-11T07:05:13.590Z</updated>
    
    <content type="html"><![CDATA[<p>Creating or rendering a PDF file in a web page is a common requirement. It allows user to download the pdf file and view it offline in some scenarios. Today, we will learn how to render and generate a PDF file from React using the <code>react-pdf</code> library.</p><p>The <code>react-pdf</code> library is a React component that allows us to design and render PDF documents in React. Let’s get started an example, it’s very simple to create a pdf and render it in React.</p><h2 id="Install-the-react-pdf-Library"><a href="#Install-the-react-pdf-Library" class="headerlink" title="Install the react-pdf Library"></a>Install the <code>react-pdf</code> Library</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install @react-pdf/renderer --save</span><br></pre></td></tr></table></figure><h2 id="Create-a-PDF-Document"><a href="#Create-a-PDF-Document" class="headerlink" title="Create a PDF Document"></a>Create a PDF Document</h2><p>We will create a simple PDF document using the <code>react-pdf</code> library. It supports customize styles and Flex layout to create the PDF.  Below code example using <code>react-pdf</code> library to create a PDF document, including using <code>Document</code>, <code>Page</code>, <code>StyleSheet</code>, <code>Image</code>, <code>View</code>, <code>Text</code>, <code>Link</code> components.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123;<span class="title class_">Document</span>, <span class="title class_">Page</span>, <span class="title class_">StyleSheet</span>, <span class="title class_">Image</span>, <span class="title class_">View</span>, <span class="title class_">Text</span>, <span class="title class_">Link</span>&#125; <span class="keyword">from</span> <span class="string">&#x27;@react-pdf/renderer&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = <span class="title class_">StyleSheet</span>.<span class="title function_">create</span>(&#123;</span><br><span class="line">    <span class="attr">page</span>: &#123;</span><br><span class="line">        <span class="attr">flexDirection</span>: <span class="string">&#x27;column&#x27;</span>,</span><br><span class="line">        <span class="attr">backgroundColor</span>: <span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">        <span class="attr">padding</span>: <span class="string">&quot;20px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">section</span>: &#123;</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;30px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">header</span>: &#123;</span><br><span class="line">        <span class="attr">textAlign</span>: <span class="string">&quot;center&quot;</span>,</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;24px&quot;</span>,</span><br><span class="line">        <span class="attr">fontWeight</span>: <span class="string">&quot;bold&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;30px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">logo</span>: &#123;</span><br><span class="line">        <span class="attr">height</span>: <span class="string">&quot;90px&quot;</span>,</span><br><span class="line">        <span class="attr">width</span>: <span class="string">&quot;100px&quot;</span>,</span><br><span class="line">        <span class="attr">margin</span>: <span class="string">&quot;20px auto&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">title</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="number">18</span>,</span><br><span class="line">        <span class="attr">fontWeight</span>: <span class="string">&quot;bold&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">text</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;14px&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">code</span>: &#123;</span><br><span class="line">        <span class="attr">fontSize</span>: <span class="string">&quot;14px&quot;</span>,</span><br><span class="line">        <span class="attr">backgroundColor</span>: <span class="string">&quot;#3e3e3e&quot;</span>,</span><br><span class="line">        <span class="attr">color</span>: <span class="string">&quot;#fff&quot;</span>,</span><br><span class="line">        <span class="attr">padding</span>: <span class="string">&quot;20px&quot;</span>,</span><br><span class="line">        <span class="attr">marginBottom</span>: <span class="string">&quot;10px&quot;</span>,</span><br><span class="line">        <span class="attr">borderRadius</span>: <span class="string">&quot;5px&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">PdfDocument</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">Document</span> <span class="attr">title</span>=<span class="string">&quot;My PDF Document&quot;</span> <span class="attr">author</span>=<span class="string">&quot;Andrewsy&quot;</span> <span class="attr">subject</span>=<span class="string">&quot;This is a sample PDF document&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Page</span> <span class="attr">size</span>=<span class="string">&quot;A4&quot;</span> <span class="attr">style</span>=<span class="string">&#123;styles.page&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.section&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.header&#125;</span>&gt;</span>React PDF Renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>The react-pdf library allows you to render PDF documents using React components.<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Image</span> <span class="attr">style</span>=<span class="string">&#123;styles.logo&#125;</span> <span class="attr">src</span>=<span class="string">&quot;images/logo.png&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.section&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.title&#125;</span>&gt;</span>Install react-pdf library<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>To install the react-pdf library, you can use npm or yarn:<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.code&#125;</span>&gt;</span>npm install @react-pdf/renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span>&gt;</span><span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.code&#125;</span>&gt;</span>yarn add @react-pdf/renderer<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>For component documentation, visit the official website <span class="tag">&lt;<span class="name">Link</span> <span class="attr">src</span>=<span class="string">&quot;https://react-pdf.org/&quot;</span>&gt;</span>@react-pdf/renderer<span class="tag">&lt;/<span class="name">Link</span>&gt;</span>.<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">Page</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">Document</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="title class_">PdfDocument</span>;</span><br></pre></td></tr></table></figure><p>From above, we can see that we have created a PDF document using <code>react-pdf</code> library. We have used <code>Document</code> and <code>Page</code> components to create the PDF document. We have also used <code>StyleSheet</code> to define the styles for the PDF document. And using <code>Image</code>, <code>View</code>, <code>Text</code>, <code>Link</code> components to create the content of the PDF document.</p><h2 id="View-PDF-Document"><a href="#View-PDF-Document" class="headerlink" title="View PDF Document"></a>View PDF Document</h2><p>To view the PDF document, we need to use <code>PDFViewer</code> component to render the PDF document in the browser. There is one thing need notice, if your project is using <code>Next.js</code>, and you want to use <code>PDFViewer</code> or <code>PDFDownloadLink</code> component in client side render directly, you will get below error:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Error: PDFViewer is a web specific API. You&#x27;re either using this component on Node, or your bundler is not loading react-pdf from the appropriate web build.]</span><br></pre></td></tr></table></figure><p>To fixed the issue in <code>Next.js</code> project. Use Next dynamic function to manually set server-side rendering off and import it through that function instead of the regular import</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&quot;@react-pdf/renderer&quot;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">mod</span>) =&gt;</span> mod. <span class="title class_">PDFViewer</span>),&#123;<span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFDownloadLink</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&quot;@react-pdf/renderer&quot;</span>).<span class="title function_">then</span>(<span class="function">(<span class="params">mod</span>) =&gt;</span> mod. <span class="title class_">PDFDownloadLink</span>),&#123;<span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br></pre></td></tr></table></figure><p>instead of</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">PDFViewer</span>, <span class="title class_">PDFDownloadLink</span> &#125; <span class="keyword">from</span> <span class="string">&quot;@react-pdf/renderer&quot;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>The view PDF document code is below, for the <code>PDFViewer</code> component, we need to set the width and height of the PDF document. Actually it is rendered as a <code>iframe</code> element in the browser. This width and height is setting to iframe.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">PdfDocument</span> <span class="keyword">from</span> <span class="string">&#x27;@/components/pdf-document&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFViewer</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Pdf</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">section</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">display:</span> &#x27;<span class="attr">flex</span>&#x27;, <span class="attr">justifyContent:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">alignItems:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">height:</span> &#x27;<span class="attr">100vh</span>&#x27; &#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFViewer</span> <span class="attr">width</span>=<span class="string">&quot;800px&quot;</span> <span class="attr">height</span>=<span class="string">&quot;900px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">PdfDocument</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFViewer</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">section</span>&gt;</span></span></span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Let’s see the screenshot. It’s beautifully and easily rendered PDF document in the browser.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Renderer"/></div><span class="image-caption">React PDF Renderer</span></div><h2 id="Download-the-PDF-Document"><a href="#Download-the-PDF-Document" class="headerlink" title="Download the PDF Document"></a>Download the PDF Document</h2><p>To download the PDF document, we can use <code>PDFDownloadLink</code> component. It allows us to download the PDF document as a file. The code is below.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;use client&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> dynamic <span class="keyword">from</span> <span class="string">&quot;next/dynamic&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">PdfDocument</span> <span class="keyword">from</span> <span class="string">&#x27;@/components/pdf-document&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFViewer</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFViewer</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"><span class="keyword">const</span> <span class="title class_">PDFDownloadLink</span> = <span class="title function_">dynamic</span>(<span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;@react-pdf/renderer&#x27;</span>).<span class="title function_">then</span>(<span class="function"><span class="params">mod</span> =&gt;</span> mod.<span class="property">PDFDownloadLink</span>), &#123; <span class="attr">ssr</span>: <span class="literal">false</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Pdf</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">section</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">display:</span> &#x27;<span class="attr">flex</span>&#x27;, <span class="attr">flexDirection:</span>&#x27;<span class="attr">column</span>&#x27;, <span class="attr">alignItems:</span> &#x27;<span class="attr">center</span>&#x27;, <span class="attr">height:</span> &#x27;<span class="attr">100vh</span>&#x27; &#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFViewer</span> <span class="attr">width</span>=<span class="string">&quot;850px&quot;</span> <span class="attr">height</span>=<span class="string">&quot;850px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                <span class="tag">&lt;<span class="name">PdfDocument</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFViewer</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">PDFDownloadLink</span> <span class="attr">document</span>=<span class="string">&#123;</span>&lt;<span class="attr">PdfDocument</span> /&gt;</span>&#125; fileName=&quot;my-pdf-document.pdf&quot; style=&#123;&#123;marginTop: &#x27;10px&#x27;&#125;&#125;&gt;</span></span><br><span class="line"><span class="language-xml">                &#123;(&#123; blob, url, loading, error &#125;) =&gt; (</span></span><br><span class="line"><span class="language-xml">                    loading ? &#x27;Loading document...&#x27; : <span class="tag">&lt;<span class="name">button</span> <span class="attr">style</span>=<span class="string">&#123;&#123;</span> <span class="attr">backgroundColor:</span> &#x27;#<span class="attr">171717</span>&#x27;, <span class="attr">color:</span> &#x27;<span class="attr">white</span>&#x27;, <span class="attr">padding:</span> &#x27;<span class="attr">10px</span>&#x27;, <span class="attr">borderRadius:</span> &#x27;<span class="attr">5px</span>&#x27;, <span class="attr">cursor:</span> &#x27;<span class="attr">pointer</span>&#x27; &#125;&#125;&gt;</span>Download<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">                )&#125;</span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;/<span class="name">PDFDownloadLink</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">section</span>&gt;</span></span></span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the above code, we have used <code>PDFDownloadLink</code> component to download the PDF document, passed the <code>PdfDocument</code> component as the <code>document</code> prop of <code>PDFDownloadLink</code> component. We have also set the <code>fileName</code> prop to <code>my-pdf-document.pdf</code> to set the file name of the downloaded file. The <code>style</code> prop is used to set the style of the download button. We also use the <code>loading</code> prop to show the loading message while the PDF document is being downloaded.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf-download.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf-download.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Download"/></div><span class="image-caption">React PDF Download</span></div><p>Below PDF document is downloaded as a file.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-pdf-doc.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-pdf-doc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React PDF Document Opened in Adobe Acrobat Reader"/></div><span class="image-caption">React PDF Document Opened in Adobe Acrobat Reader</span></div><p>See it’s easily to create and render a PDF document in React using the <code>react-pdf</code> library.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The <code>react-pdf</code> library is a React component that allows us to design and render PDF documents in React. It supports customize styles and Flex layout to create the PDF. We have learned how to create a PDF document using <code>react-pdf</code> library, how to view and download the PDF document.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Creating or rendering a PDF file in a web page is a common requirement. It allows user to download the pdf file and view it offline in so</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Next.js" scheme="https://stonefishy.github.io/tags/Next-js/"/>
    
    <category term="PDF" scheme="https://stonefishy.github.io/tags/PDF/"/>
    
  </entry>
  
  <entry>
    <title>Conversational RAG Chatbot - Build a Chatbot with LangChain and Chainlit</title>
    <link href="https://stonefishy.github.io/2025/02/27/conversational-rag-chatbot-build-a-chatbot-with-langchain/"/>
    <id>https://stonefishy.github.io/2025/02/27/conversational-rag-chatbot-build-a-chatbot-with-langchain/</id>
    <published>2025-02-27T15:33:13.000Z</published>
    <updated>2025-03-11T07:05:13.590Z</updated>
    
    <content type="html"><![CDATA[<p>In previous blog, we have converting the PDF documents into the <code>FAISS</code> vector index, and saved in the local. Now, we will build a RAG chatbot using the <code>LangChain</code>, <code>Chainlit</code> and <code>OpenAI</code> base on previous <code>FAISS</code> index.</p><p>Before we get started, let’s talk about what is <code>Chainlit</code> and <code>LangChain</code>.</p><h2 id="Chainlit"><a href="#Chainlit" class="headerlink" title="Chainlit"></a>Chainlit</h2><p>We choose the <code>Chainlit</code> framework to build the chatbot. <code>Chainlit</code> is a framework designed to simplify the process of building and deploying chatbots for large language models (<code>LLMs</code>). It provides a way to create conversational applications that can interact with users through chat interfaces. Chainlit helps developers to chain together different components of a chatbot, such as the model itself, user interfaces, and data sources, making it easier to build complex conversational systems. It is particularly useful for those who want to integrate LLMs into their existing applications or create standalone chatbots. You can find the <code>Chainlit</code> documentation <a href="https://docs.chainlit.io/get-started/overview">here</a>.</p><h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><p><code>LangChain</code> is a framework designed to simplify the process of building language models and applications that leverage these models. It provides a set of tools and libraries that allow developers to integrate language models into their applications more easily, handle data flow, and manage the interactions between different components of their system. LangChain supports various language models and can be used to create a wide range of applications, from chatbots and virtual assistants to document summarization and translation tools. It aims to make it straightforward to build, deploy, and scale language-driven applications.</p><h2 id="Get-started"><a href="#Get-started" class="headerlink" title="Get started"></a>Get started</h2><p>Ok, let’s get started. First, we need to install the <code>LangChain</code> and <code>Chainlit</code> and other libraries, all the required libraries are below. Creating a <code>requirements.txt</code> file and store below libraries in it:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">openai</span><br><span class="line">langchain</span><br><span class="line">chainlit</span><br><span class="line">faiss-cpu</span><br><span class="line">tiktoken</span><br><span class="line">pymupdf</span><br><span class="line">PyPDF2</span><br><span class="line">langchain_openai</span><br><span class="line">langchain_community</span><br></pre></td></tr></table></figure><p>I suggest to create a virtual environment for this project before installing these libraries. We can use the following command to create a virtual environment:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv venv</span><br></pre></td></tr></table></figure><p>After creating the virtual environment, activate it using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> venv/bin/activate</span><br></pre></td></tr></table></figure><p>Then install all the required libraries using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>Now, we can start building the chatbot.</p><h2 id="Building-Chatbot-UI"><a href="#Building-Chatbot-UI" class="headerlink" title="Building Chatbot UI"></a>Building Chatbot UI</h2><p>The <code>Chainlit</code> provides the wonderful API to build the chatbot UI. It saves much time and efforts. In the project, create a <code>app.py</code> and import the <code>chainlit</code> library then write the below code. We will use 3 chainlit annotations. <code>@cl.set_starters</code>, <code>@cl.on_chat_start</code>, and <code>@cl.on_message</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> chainlit <span class="keyword">as</span> cl</span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.set_starters</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">set_starters</span>():</span><br><span class="line">    <span class="comment"># The chatbot starter page which displays the quick list of questions</span></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;The Major Updates in Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;What&#x27;s the major updates in Wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/specifications.svg&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;Migrate Project from Wix4 to Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;How to mirage the wix4 project to wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/jigsaw.png&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">        cl.Starter(</span><br><span class="line">            label=<span class="string">&quot;Build Burn Bootstrapper on Wix5&quot;</span>,</span><br><span class="line">            message=<span class="string">&quot;How to build a burn bootstrapper on wix5?&quot;</span>,</span><br><span class="line">            icon=<span class="string">&quot;/public/images/bundle.svg&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_chat_start</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>():</span><br><span class="line">    <span class="comment"># starting the chatbot logic</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_message</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">message: cl.Message</span>):</span><br><span class="line">    <span class="comment"># chatbot logic and response here</span></span><br></pre></td></tr></table></figure><ol><li><p>The <code>@cl.set_starters</code> annotation is used to set the chatbot starter page. It takes a list of <code>cl.Starter</code> objects as input. Each <code>cl.Starter</code> object represents a question and its corresponding message. The <code>icon</code> parameter is used to set the icon for the question.</p></li><li><p>The <code>@cl.on_chat_start</code> annotation is used to start the chatbot logic. Such as setting the initial state of the chatbot, loading the chatbot model, FAISS index, create a langchain pipeline, etc.</p></li><li><p>The <code>@cl.on_message</code> annotation is used to handle the chatbot logic and response. It takes a <code>cl.Message</code> object as input. The <code>cl.Message</code> object contains the user’s message and other metadata. We can use the <code>message.content</code> attribute to get the user’s message.</p></li></ol><p>The starter page screenshot like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-starter-page.png %" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-starter-page.png %" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Chainlit Chatbot Starter Page"/></div><span class="image-caption">Chainlit Chatbot Starter Page</span></div><p>You can also customize the theme, or do some changes in UI. </p><h2 id="Loading-the-FAISS-Vector-Index"><a href="#Loading-the-FAISS-Vector-Index" class="headerlink" title="Loading the FAISS Vector Index"></a>Loading the FAISS Vector Index</h2><p>Using <code>FAISS</code> library, we can load the <code>FAISS</code> vector index. We need to pass the <code>embeddings</code> and <code>index_name</code> to the <code>FAISS.load_local</code> method. The <code>embeddings</code> parameter is the embedding model we used before, and the <code>index_name</code> parameter is the name of the index. Here, our embedding model is <code>AzureOpenAIEmbeddings</code> and the index name is <code>wix-upgrade</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">VECTOR_INDEX_NAME = <span class="string">&#x27;wix-upgrade&#x27;</span></span><br><span class="line">AZURE_OPENAI_API_KEY = os.getenv(<span class="string">&quot;AZURE_OPENAI_API_KEY&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ENDPOINT = os.getenv(<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_DEPLOYMENT_VERSION = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_DEPLOYMENT_VERSION&quot;</span>)</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION= os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME&quot;</span>)</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME&quot;</span>)</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT_NAME&quot;</span>)</span><br><span class="line"></span><br><span class="line">embeddings = AzureOpenAIEmbeddings(</span><br><span class="line">    deployment=AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,</span><br><span class="line">    model=AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME,</span><br><span class="line">    azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">    openai_api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">    openai_api_version=AZURE_OPENAI_ADA_DEPLOYMENT_VERSION</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">docs_vector_store = FAISS.load_local(</span><br><span class="line">    folder_path=<span class="string">&quot;./vector_stores&quot;</span>, </span><br><span class="line">    embeddings=embeddings, </span><br><span class="line">    index_name=VECTOR_INDEX_NAME,</span><br><span class="line">    allow_dangerous_deserialization=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>Using <code>load_dotenv()</code> method, we can load the environment variables from the <code>.env</code> file. We can put the loading vector index code in the <code>@cl.on_chat_start</code> annotation.</p><h2 id="Building-the-Converstaion-Chain"><a href="#Building-the-Converstaion-Chain" class="headerlink" title="Building the Converstaion Chain"></a>Building the Converstaion Chain</h2><p>After we load the vector index, we can build the conversation chain using <code>LangChain</code>. The main logic are below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureOpenAIEmbeddings,AzureChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain.chains.combine_documents <span class="keyword">import</span> create_stuff_documents_chain</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> create_history_aware_retriever, create_retrieval_chain</span><br><span class="line"><span class="keyword">from</span> langchain_core.chat_history <span class="keyword">import</span> BaseChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables.history <span class="keyword">import</span> RunnableWithMessageHistory</span><br><span class="line"></span><br><span class="line">chat_history_store = &#123;&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_session_history</span>(<span class="params">session_id: <span class="built_in">str</span></span>) -&gt; BaseChatMessageHistory:</span><br><span class="line">    <span class="keyword">if</span> session_id <span class="keyword">not</span> <span class="keyword">in</span> chat_history_store:</span><br><span class="line">        chat_history_store[session_id] = ChatMessageHistory()</span><br><span class="line">    <span class="keyword">return</span> chat_history_store[session_id]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cl.on_chat_start</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>():</span><br><span class="line">    docs_vector_store = FAISS.load_local(</span><br><span class="line">        folder_path=<span class="string">&quot;./vector_stores&quot;</span>, </span><br><span class="line">        embeddings=embeddings, </span><br><span class="line">        index_name=VECTOR_INDEX_NAME,</span><br><span class="line">        allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    llm=AzureChatOpenAI(</span><br><span class="line">        api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">        azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">        api_version=AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION,</span><br><span class="line">        openai_api_type=<span class="string">&quot;azure&quot;</span>,</span><br><span class="line">        azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,</span><br><span class="line">        streaming=<span class="literal">True</span>,</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    retriever = docs_vector_store.as_retriever()</span><br><span class="line">    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)</span><br><span class="line">    question_answer_chain = create_stuff_documents_chain(llm, QA_PROMPT)</span><br><span class="line">    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)</span><br><span class="line"></span><br><span class="line">    conversational_rag_chain = RunnableWithMessageHistory(</span><br><span class="line">        rag_chain,</span><br><span class="line">        get_session_history,</span><br><span class="line">        input_messages_key=<span class="string">&quot;input&quot;</span>,</span><br><span class="line">        history_messages_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">        output_messages_key=<span class="string">&quot;answer&quot;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    cl.user_session.<span class="built_in">set</span>(<span class="string">&quot;chain&quot;</span>, conversational_rag_chain)</span><br></pre></td></tr></table></figure><p>In above code, we first load the <code>FAISS</code> vector index and create the <code>AzureChatOpenAI</code> language model. We then create the <code>retriever</code> using the <code>docs_vector_store</code> and create the <code>history_aware_retriever</code> using the <code>create_history_aware_retriever</code> method. The <code>contextualize_q_prompt</code> method is used to create the contextualized question prompt. The <code>create_stuff_documents_chain</code> method is used to create the question answer chain. Finally, we create the <code>rag_chain</code> using the <code>create_retrieval_chain</code> method.</p><p>We then create the <code>conversational_rag_chain</code> using the <code>RunnableWithMessageHistory</code> class. The <code>get_session_history</code> method is used to get the chat history for each session. The <code>input_messages_key</code>, <code>history_messages_key</code>, and <code>output_messages_key</code> parameters are used to set the keys for the input, history, and output messages.</p><p>We set the <code>conversational_rag_chain</code> as the chatbot chain using the <code>cl.user_session.set</code> method. We can use it later.</p><p>Here you’re notice there is <code>contextualize_q_prompt</code> and <code>QA_PROMPT</code> variable. They are prompts which will passting to LLM to restrict the LLM answers. The code is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    MessagesPlaceholder</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">contextualize_q_system_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Given a chat history and the latest user question \</span></span><br><span class="line"><span class="string">which might reference context in the chat history, formulate a standalone question \</span></span><br><span class="line"><span class="string">which can be understood without the chat history. Do NOT answer the question, \</span></span><br><span class="line"><span class="string">just reformulate it if needed and otherwise return it as is.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">contextualize_q_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, contextualize_q_system_prompt),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">qa_system_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Act like a WiX (WixToolset) development expert and help me with related WiX development questions. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Some **strict rules** you have to follow NO MATTER WHAT:</span></span><br><span class="line"><span class="string">Only answer related questions about WiX development.</span></span><br><span class="line"><span class="string">If you don&#x27;t know the answer, say:</span></span><br><span class="line"><span class="string">I don&#x27;t have such information, please refer to WiX offical documentation for the information. https://docs.firegiant.com/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Please Use the following pieces of context to answer the user&#x27;s question. </span></span><br><span class="line"><span class="string">----------------</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">QA_PROMPT = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, qa_system_prompt),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The <code>contextualize_q_prompt</code> is used to create the contextualized question prompt base on chat history and the latest user iput. The <code>MessagesPlaceholder(&quot;chat_history&quot;)</code> is used to insert the chat history in the prompt. From the prompt, It will formulate a standard question base on chat history and the latest user input.</p><p>The <code>qa_system_prompt</code> is used to create the question answer prompt. It is limit to only answer the related questions about WiX development. If the user’s question is not related to WiX development, it will say I don’t have such information, please refer to the WiX offical documentation for the information. You can also remove this limitation prompt text to make the AI model reply any question.</p><p>So now, our chain is ready to use. Next step we will uset this chain to answer the user’s question.</p><h2 id="Invoke-Chain"><a href="#Invoke-Chain" class="headerlink" title="Invoke Chain"></a>Invoke Chain</h2><p>In previous step, we have set the <code>conversational_rag_chain</code> as the chatbot chain using the <code>cl.user_session.set</code> method. Now, we can use it to answer the user’s question. Below is <code>@cl.on_message</code> annotation to invoke the chain and send the response.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@cl.on_message</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">message: cl.Message</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        chain = cl.user_session.get(<span class="string">&quot;chain&quot;</span>)</span><br><span class="line">        msg = cl.Message(content=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        res = chain.invoke(</span><br><span class="line">            &#123;<span class="string">&quot;input&quot;</span>: message.content&#125;, </span><br><span class="line">            config=&#123;</span><br><span class="line">                <span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: cl.user_session.get(<span class="string">&quot;id&quot;</span>)&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        response = res[<span class="string">&quot;answer&quot;</span>]</span><br><span class="line"></span><br><span class="line">        stream_size = <span class="number">20</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">len</span>(response) / stream_size)) + <span class="number">1</span>):</span><br><span class="line">            msg.content = response[<span class="number">0</span> : (i + <span class="number">1</span>) * stream_size]</span><br><span class="line">            <span class="keyword">await</span> msg.send()</span><br><span class="line">            time.sleep(<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;An error occurred: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> e.code == <span class="string">&quot;content_filter&quot;</span>:</span><br><span class="line">            <span class="keyword">await</span> cl.ErrorMessage(</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                The response was filtered due to the prompt triggering Azure OpenAI&#x27;s content management policy. Please modify your prompt and retry. </span></span><br><span class="line"><span class="string">                To learn more about our content filtering policies please read our documentation: </span></span><br><span class="line"><span class="string">                https://go.microsoft.com/fwlink/?linkid=2198766</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                ).send()</span><br></pre></td></tr></table></figure><p>In above code, we get the <code>conversational_rag_chain</code> from the <code>cl.user_session</code> and invoke it with the user’s message. We set the <code>session_id</code> in the <code>config</code> parameter to get the chat history for each session. We then send the response to the user in chunks of 20 characters.</p><p>The following code is simulating the stream response in the UI. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream_size = <span class="number">20</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(<span class="built_in">len</span>(response) / stream_size)) + <span class="number">1</span>):</span><br><span class="line">    msg.content = response[<span class="number">0</span> : (i + <span class="number">1</span>) * stream_size]</span><br><span class="line">    <span class="keyword">await</span> msg.send()</span><br><span class="line">    time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><p>The AzureOpenAI has content limitation, the user input which pass to the OpenAI API will be filtered if it contains any offensive or inappropriate content. So, we need to handle this situation. We can use the <code>ErrorMessage</code> class to send the error message to the user if the response is filtered.</p><h2 id="Chat-Demo-Screenshoots"><a href="#Chat-Demo-Screenshoots" class="headerlink" title="Chat Demo Screenshoots"></a>Chat Demo Screenshoots</h2><p>Below are screenshots of the chatbot conversation UI and response.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/chainlit-chatbot-chat-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/chainlit-chatbot-chat-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this blog, we have built a RAG chatbot using the <code>LangChain</code>, <code>Chainlit</code> and <code>OpenAI</code> base on previous <code>FAISS</code> index. We have used the <code>Chainlit</code> to build the chatbot UI, and the <code>LangChain</code> to build the conversation chain. We have also used the <code>FAISS</code> library to load the <code>FAISS</code> vector index and the <code>AzureChatOpenAI</code> language model. Finally, we have used the <code>RunnableWithMessageHistory</code> class to handle the chat history and the <code>ErrorMessage</code> class to handle the content filter.</p><p>If you want to get the full code, you can find it in the <a href="https://github.com/stonefishy/converstional-rag-chatbot">GitHub repository</a>. In this demo, we just put the 4 PDF documents which upgrade Wix3, Wix4 to Wix5. You can replace it with your own documents.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In previous blog, we have converting the PDF documents into the &lt;code&gt;FAISS&lt;/code&gt; vector index, and saved in the local. Now, we will bui</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
    <category term="Langchain" scheme="https://stonefishy.github.io/tags/Langchain/"/>
    
    <category term="Chainlit Chatbot" scheme="https://stonefishy.github.io/tags/Chainlit-Chatbot/"/>
    
  </entry>
  
  <entry>
    <title>Conversational RAG Chatbot - Converting PDF Document to Vector</title>
    <link href="https://stonefishy.github.io/2025/02/24/conversational-rag-chatbot-converting-pdf-document-to-vector/"/>
    <id>https://stonefishy.github.io/2025/02/24/conversational-rag-chatbot-converting-pdf-document-to-vector/</id>
    <published>2025-02-24T16:27:50.000Z</published>
    <updated>2025-03-11T07:05:13.590Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this series of blogs, we will build a <code>RAG(Retrieval-Augmented Generation)</code> chatbot which using <code>WiX(WiXToolset)</code> documents as knowledge data. It will contains below steps:</p><ol><li>Converting PDF Document to Vector</li><li>Building a Chatbot that can answer questions based on the documents</li></ol><p>The technology stack used in this project are</p><ul><li>Python</li><li>LangChain</li><li>OpenAI</li><li>Chainlit</li><li>FAISS</li></ul><p>In this blog, we will focus on the first step, Converting PDF Document to Vector. </p><h2 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h2><p>The vector is a mathematical representation of a document or a text. It is a numerical representation of the text that can be used for various natural language processing tasks. The vector can be generated using various techniques like Bag-of-Words, TF-IDF, Word2Vec, etc. To store the vector, we can use various databases like FAISS, Pinecone, chroma etc.</p><h2 id="PDF-Document-to-Vector"><a href="#PDF-Document-to-Vector" class="headerlink" title="PDF Document to Vector"></a>PDF Document to Vector</h2><h3 id="FAISS"><a href="#FAISS" class="headerlink" title="FAISS"></a>FAISS</h3><p>In this blog, we will use <code>FAISS(Facebook AI Similarity Search)</code> to save the vector on local. The FAISS is  is a library for efficient similarity search and clustering of dense vectors. It is developed by Faiss Team at Facebook AI Research. FAISS is designed to handle large-scale nearest neighbor searches, which are common in applications like recommendation systems, image retrieval, and natural language processing. The library provides multiple algorithms for searching and clustering, including exact and approximate methods, and is optimized for both speed and accuracy. It supports various types of vector norms and can be used on both CPU and GPU for fast computation.</p><h3 id="Prepare-the-PDF-documents"><a href="#Prepare-the-PDF-documents" class="headerlink" title="Prepare the PDF documents"></a>Prepare the PDF documents</h3><p>For the WiX documents, we can download the documents from the official website <a href="https://docs.firegiant.com/wix/fivefour/">https://docs.firegiant.com/wix/fivefour/</a>. And here we only use the WiX upgrade guide document. Below are documents we are using:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-pdfs.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-pdfs.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="Extracting-Text-from-PDF-Documents"><a href="#Extracting-Text-from-PDF-Documents" class="headerlink" title="Extracting Text from PDF Documents"></a>Extracting Text from PDF Documents</h3><p>We will using the library <code>PyPDF2</code> to extract the text from the PDF documents. Below is code snippet to extract all the text from the PDF documents and store it in a text variable. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pdf_directory = Path(pdf_storage_path)</span><br><span class="line">text = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">    pdf_reader = PdfReader(pdf_path, <span class="literal">True</span>)</span><br><span class="line">    pdf_text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">        page_text = page.extract_text()</span><br><span class="line">        pdf_text += page_text</span><br><span class="line"></span><br><span class="line">    txt_path = pdf_path.with_name(pdf_path.stem + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(pdf_text)</span><br><span class="line">    text += pdf_text + <span class="string">&quot;\n\n&quot;</span> </span><br></pre></td></tr></table></figure><h3 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h3><p>Using the <code>AzureOpenAIEmbeddings</code> class from <code>langchain</code> library to get the vector representation of the text. For the Azuer OpenAI endpoints and api keys you can define it in the <code>.env</code> file.</p><p>.env file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_ENDPOINT=</span><br><span class="line">AZURE_OPENAI_API_KEY=</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_VERSION=<span class="number">2023</span>-07-01-preview</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME=text-embedding-ada-002</span><br><span class="line">AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002</span><br><span class="line">AZURE_OPENAI_ADA_DEPLOYMENT_VERSION=<span class="number">2023</span>-07-01-preview</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">embeddings = AzureOpenAIEmbeddings(</span><br><span class="line">    deployment=AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,</span><br><span class="line">    model=AZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME,</span><br><span class="line">    azure_endpoint=AZURE_OPENAI_ENDPOINT,</span><br><span class="line">    openai_api_key=AZURE_OPENAI_API_KEY,</span><br><span class="line">    openai_api_version=AZURE_OPENAI_ADA_DEPLOYMENT_VERSION</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="Construct-FAISS"><a href="#Construct-FAISS" class="headerlink" title="Construct FAISS"></a>Construct FAISS</h3><p>After we have extracted the text from the PDF documents, below code snippet will construct the FAISS index. Using the <code>RecursiveCharacterTextSplitter</code> class from <code>langchain</code> library to split the text into chunks. Using <code>AzureOpenAIEmbeddings</code> class from <code>langchain</code> library, we can get the vector representation of the text. And save it into the FAISS index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>, </span><br><span class="line">    chunk_overlap=<span class="number">250</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;splitting text into chunks...&quot;</span>)</span><br><span class="line">chunks = text_splitter.split_text(text)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">vector_store =FAISS.from_texts(chunks, embeddings)</span><br><span class="line">vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>So the entire workflow is that we have downloaded the PDF documents, extracted the text from the PDF documents, and constructed the FAISS index. The FAISS index will be saved in the local directory.</p><p>Below is the function code snippet:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">250</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        pdf_reader = PdfReader(pdf_path, <span class="literal">True</span>)</span><br><span class="line">        pdf_text = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">            page_text = page.extract_text()</span><br><span class="line">            pdf_text += page_text</span><br><span class="line"></span><br><span class="line">        txt_path = pdf_path.with_name(pdf_path.stem + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            file.write(pdf_text)</span><br><span class="line">        text += pdf_text + <span class="string">&quot;\n\n&quot;</span> </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;splitting text into chunks...&quot;</span>)</span><br><span class="line">    chunks = text_splitter.split_text(text)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">    vector_store =FAISS.from_texts(chunks, embeddings)</span><br><span class="line">    vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>There is also another way to construct the FAISS index using the <code>langchain</code> library from pdf documents. Using <code>PyMuPDFLoader</code> to load the pdf documents instead of extracting the text from the pdf documents. Below is the code snippet:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss2</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    docs = []</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">250</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        loader = PyMuPDFLoader(<span class="built_in">str</span>(pdf_path))</span><br><span class="line">        documents = loader.load()</span><br><span class="line">        pdf_docs= text_splitter.split_documents(documents)</span><br><span class="line">        docs += pdf_docs</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;embedding all documents...&quot;</span>)</span><br><span class="line">    vector_store =FAISS.from_documents(docs, embeddings)</span><br><span class="line">    vector_store.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished processing all pdfs!&quot;</span>)</span><br></pre></td></tr></table></figure><p>Above two code snippets are reading all documents from one directory and saving them into the FAISS index. But somehow, if the text is too long and exceed the maximum length of the Azure OpenAI API, it failed to process the text. Refer to Azure OpenAI API documentation <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits">https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits</a>. </p><p>We can count the token by using <code>tiktoken</code> library. The model is used to tokenize the text. If the model is not found, it defaults to using the ‘cl100k_base’ tokenizer. Here we can passing the AzureOpenAIEmbeddings model to the <code>count_tokens</code> function to count the number of tokens in the text.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Counts the number of tokens in a given text using the specified model&#x27;s tokenizer.</span></span><br><span class="line"><span class="string">If the model is not found, it defaults to using the &#x27;cl100k_base&#x27; tokenizer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    text (str): The input text to be tokenized.</span></span><br><span class="line"><span class="string">    model (str): The name of the model for which the tokenizer is used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    int: The total number of tokens in the text.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_tokens</span>(<span class="params">text, model</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        encoding = tiktoken.encoding_for_model(model)</span><br><span class="line">    <span class="keyword">except</span> KeyError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Warning: model not found. Using cl100k_base encoding.&quot;</span>)</span><br><span class="line">        encoding = tiktoken.get_encoding(<span class="string">&quot;cl100k_base&quot;</span>)</span><br><span class="line">    num_tokens = <span class="built_in">len</span>(encoding.encode(text))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total tokens: <span class="subst">&#123;num_tokens&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> num_tokens</span><br></pre></td></tr></table></figure><h3 id="Mergging-Indexes"><a href="#Mergging-Indexes" class="headerlink" title="Mergging Indexes"></a>Mergging Indexes</h3><p>The FAISS supports to merge multiple indexes into one index. So we can merge the index of all the documents into one index. Below is the code snippet to merge the index of all the documents into one index.</p><p>Let’s write another function to embedding pdfs into individual index. Below function will embedding all the pdfs into individual index and save it in the specified directory.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pdfs_to_faiss_files</span>(<span class="params">pdf_storage_path: <span class="built_in">str</span>, faiss_dir_path: <span class="built_in">str</span></span>):</span><br><span class="line">    pdf_directory = Path(pdf_storage_path)</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        chunk_size=<span class="number">1000</span>, </span><br><span class="line">        chunk_overlap=<span class="number">200</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pdf_path <span class="keyword">in</span> pdf_directory.glob(<span class="string">&quot;*.pdf&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Reading document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        loader = PyMuPDFLoader(<span class="built_in">str</span>(pdf_path))</span><br><span class="line">        documents = loader.load()</span><br><span class="line">        pdf_docs= text_splitter.split_documents(documents)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;embedding document <span class="subst">&#123;pdf_path&#125;</span>&quot;</span>)</span><br><span class="line">        vector_store =FAISS.from_documents(pdf_docs, embeddings)</span><br><span class="line">        vector_store.save_local(faiss_dir_path, pdf_path.stem)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;finished processing pdf <span class="subst">&#123;pdf_path&#125;</span>!&quot;</span>)</span><br></pre></td></tr></table></figure><p>Call this function with below code snippet to embedding all the pdfs into individual index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pdfs_to_faiss_files(PDF_STORAGE_PATH, <span class="string">&quot;./faiss_files&quot;</span>)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-pdfs-indexing.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-pdfs-indexing.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-indexes.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-indexes.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After these indexes are created, we can use FAISS to merge them into one index. Below is the code snippet to merge the index of all the documents into one index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Merges multiple FAISS files into a single index.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    faiss_dir_path (str): The path to the directory containing the FAISS files.</span></span><br><span class="line"><span class="string">    index_name (str): The name of the index to be saved.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_faiss_files</span>(<span class="params">faiss_dir_path: <span class="built_in">str</span>, index_name: <span class="built_in">str</span></span>):</span><br><span class="line">    faiss_directory = Path(faiss_dir_path)</span><br><span class="line">    </span><br><span class="line">    is_first_faiss = <span class="literal">True</span></span><br><span class="line">    first_faiss = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> faiss_path <span class="keyword">in</span> faiss_directory.glob(<span class="string">&quot;*.faiss&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading FAISS file <span class="subst">&#123;faiss_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> is_first_faiss:</span><br><span class="line">            is_first_faiss = <span class="literal">False</span></span><br><span class="line">            first_faiss = FAISS.load_local(</span><br><span class="line">                folder_path=faiss_dir_path, </span><br><span class="line">                embeddings=embeddings, </span><br><span class="line">                index_name=faiss_path.stem,</span><br><span class="line">                allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Merging with <span class="subst">&#123;faiss_path&#125;</span>&quot;</span>)</span><br><span class="line">            first_faiss.merge_from(FAISS.load_local(</span><br><span class="line">                folder_path=faiss_dir_path, </span><br><span class="line">                embeddings=embeddings, </span><br><span class="line">                index_name=faiss_path.stem,</span><br><span class="line">                allow_dangerous_deserialization=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    first_faiss.save_local(<span class="string">&quot;./vector_stores&quot;</span>, index_name)</span><br></pre></td></tr></table></figure><p>Call this function with below code snippet to merge all the indexes into one index. We merged all <code>FAISS</code> index files which are saved in the <code>faiss_files</code> directory into one index.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge_faiss_files(<span class="string">&quot;./faiss_files&quot;</span>, INDEX_NAME)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-merging-indexings.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-merging-indexings.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/faiss-wix-merged-index.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/faiss-wix-merged-index.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Next step, we will build a WiX chatbot which loading this <code>FAISS</code> index and passing the question and retrieving the relevant documents from the index. For the entire code, you can check the github <a href="https://github.com/stonefishy/converstional-rag-chatbot">GitHub repository</a> to see the entire code.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this series of blogs, we wi</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
    <category term="Langchain" scheme="https://stonefishy.github.io/tags/Langchain/"/>
    
  </entry>
  
  <entry>
    <title>Deploy User Friendly AI Interface Chatbot on Local by Using Ollama + Open-WebUI.</title>
    <link href="https://stonefishy.github.io/2025/02/10/deploy-user-friendly-ai-interface-on-local-by-using-ollama-open-webui/"/>
    <id>https://stonefishy.github.io/2025/02/10/deploy-user-friendly-ai-interface-on-local-by-using-ollama-open-webui/</id>
    <published>2025-02-10T09:55:11.000Z</published>
    <updated>2025-03-11T07:05:13.590Z</updated>
    
    <content type="html"><![CDATA[<p>In Previous blog, we talk about how to running <code>DeepSeek</code> large language model (LLM) on local machine by using Ollama. For installing Ollama, you can check the previous blog. We play it and chat on terminal. In this blog, we will talk about how to deploy user-friendly AI interface chatbot on local machine by using Ollama and Open-WebUI.</p><h2 id="What-is-Open-WebUI"><a href="#What-is-Open-WebUI" class="headerlink" title="What is Open-WebUI?"></a>What is Open-WebUI?</h2><p><code>Open WebUI</code> is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like <code>Ollama</code> and <code>OpenAI-compatible APIs</code>, with built-in inference engine for RAG, making it a powerful AI deployment solution.</p><h2 id="Install-Ollama"><a href="#Install-Ollama" class="headerlink" title="Install Ollama"></a>Install Ollama</h2><p>To install the Ollama, you can download the <code>Ollama</code> from official website and follow the installation guide. Once installed, you can check the ollama version and commands using below commands in your terminal.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ollama --version</span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-version-commands.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-version-commands.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>For downloading the <code>LLM</code> model, using below command <code>ollama pull &lt;model_name&gt;</code>in your terminal.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>I already downloaded the <code>deepseek</code> and <code>gemma</code> models in my local machine. You can check the downloaded models using <code>ollama ls</code> command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-models-list.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-models-list.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Set-up-Open-WebUI"><a href="#Set-up-Open-WebUI" class="headerlink" title="Set up Open-WebUI"></a>Set up Open-WebUI</h2><p>After you setup the Ollama, to set up Open-WebUI, there are multiple ways</p><h3 id="Docker-way"><a href="#Docker-way" class="headerlink" title="Docker way"></a>Docker way</h3><p>If you have installed <code>Docker</code> on your local, you can easily launch Open-WebUI using below command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure><p>Once it done, access the Open-WebUI by using <code>http://localhost:3000</code> in your browser.</p><h3 id="Python-pip-way"><a href="#Python-pip-way" class="headerlink" title="Python pip way"></a>Python pip way</h3><p>The second way is to install Open-WebUI by using Python pip and launch it locally. It requires <code>Python 3.11</code> to avoid the compatibility issues.</p><p>Check Python version, ensure the version is 3.11 or above.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><p>Next, install Open-WebUI using pip.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install open-webui</span><br></pre></td></tr></table></figure><p>When you install Open-WebUI by using python pip command, if you local machine  Microsoft Visual C++ compiler version is lower than 14, you may encounter the below error.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Building wheels for collected packages: chroma-hnswlib</span><br><span class="line">  Building wheel for chroma-hnswlib (pyproject.toml) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line"></span><br><span class="line">  × Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [5 lines of output]</span><br><span class="line">      running bdist_wheel</span><br><span class="line">      running build</span><br><span class="line">      running build_ext</span><br><span class="line">      building &#x27;hnswlib&#x27; extension</span><br><span class="line">      error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/</span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">  ERROR: Failed building wheel for chroma-hnswlib</span><br><span class="line">Failed to build chroma-hnswlib</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-pip-install-error.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-pip-install-error.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>.<p>To fix this issue, you can install the latest version of C++ compiler and re-install the Open-WebUI. Download the Microsoft C++ Build Tools from the official website <a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/">https://visualstudio.microsoft.com/visual-cpp-build-tools/</a>.</p><p>Install the <code>Desktop development with C++</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-pip-error-resolved.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-pip-error-resolved.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>After the latest C++ compiler installed, re-install <code>Open-WebUI</code> again, once all completed, launch the Open-WebUI using below command.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open-webui serve</span><br></pre></td></tr></table></figure><p>This will start the Open WebUI server, which we can access at <a href="http://localhost:8080/">http://localhost:8080</a></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-serve.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-serve.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>Access the Open-WebUI by using <code>http://localhost:8080</code> in your browser. And create an admin account. Then you can start to use the <code>Open-WebUI</code>.<br>I have already installed some LLM models from <code>Ollama</code>, so we can see there are several models listed in the <code>Open-WebUI</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-models.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-models.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Have-Fun-with-Open-WebUI"><a href="#Have-Fun-with-Open-WebUI" class="headerlink" title="Have Fun with Open-WebUI"></a>Have Fun with Open-WebUI</h2><p>Let’s try to use <code>Gemma</code> model and <code>DeepSeek</code> model to chat with Open-WebUI.</p><h3 id="Using-Gemma-model"><a href="#Using-Gemma-model" class="headerlink" title="Using Gemma model"></a>Using Gemma model</h3><p>To use the <code>Gemma</code> model, select the <code>Gemma</code> model from the <code>Models</code> dropdown list and start to chat with the chatbot. Let’s use the <code>gemma:2b</code> model to chat.<br>If the model is not listed, using <code>Ollama</code> to download the model first.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-gemma-model.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-gemma-model.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="Using-DeepSeek-model"><a href="#Using-DeepSeek-model" class="headerlink" title="Using DeepSeek model"></a>Using DeepSeek model</h3><p>To use the <code>DeepSeek</code> model, select the <code>DeepSeek</code> model from the <code>Models</code> dropdown list and start to chat with the chatbot. Let’s use the <code>deepseek-r1:1.5b</code> model to chat.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-deepseek-model.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-deepseek-model.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>We can see the results of the <code>gemma:2b</code> model and the <code>deepseek-r1:1.5b</code> model are different. The <code>gemma:2b</code> model is just decreased in quality, however, the <code>deepseek-r1:1.5b</code> model is more accurate. It takes some time to deep thinking, and answer it carefully.</p><p>In <code>DeepSeek</code> model, we can see the thinking process of the deepseek model. It is a good way to understand how the deepseek thinking.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/open-webui-deepseek-thinking.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/open-webui-deepseek-thinking.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this blog, we have talked about how to deploy user-friendly AI interface chatbot on local machine by using Ollama and Open-WebUI. We have also used the <code>Gemma</code> and <code>DeepSeek</code> models to chat with the chatbot. We can see the results of the <code>gemma:2b</code> model and the <code>deepseek-r1:1.5b</code> model are different. The <code>gemma:2b</code> model is just decreased in quality, however, the <code>deepseek-r1:1.5b</code> model is more accurate. It takes some time to deep thinking, and answer it carefully.</p><p>Hope you like it. have fun to use <code>Open-WebUI</code>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In Previous blog, we talk about how to running &lt;code&gt;DeepSeek&lt;/code&gt; large language model (LLM) on local machine by using Ollama. For ins</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="Ollama" scheme="https://stonefishy.github.io/tags/Ollama/"/>
    
    <category term="DeepSeek" scheme="https://stonefishy.github.io/tags/DeepSeek/"/>
    
    <category term="Gemma" scheme="https://stonefishy.github.io/tags/Gemma/"/>
    
    <category term="Open-WebUI" scheme="https://stonefishy.github.io/tags/Open-WebUI/"/>
    
  </entry>
  
  <entry>
    <title>Running DeepSeek-R1 locally for free</title>
    <link href="https://stonefishy.github.io/2025/02/07/running-deepseek-r1-locally-for-free/"/>
    <id>https://stonefishy.github.io/2025/02/07/running-deepseek-r1-locally-for-free/</id>
    <published>2025-02-07T10:16:27.000Z</published>
    <updated>2025-03-11T07:05:13.590Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/deepseek-logo.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/deepseek-logo.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><p>The <code>DeepSeek</code> recently is very popular. The application download is on topest of the app store globally. The deepseek has several models, like <code>deepseek-r1</code>, <code>deepseek-coder</code> and <code>deepseek-v3</code> models etc. It’s all open source and free to use.</p><ul><li><code>deepseek-r1</code>: DeepSeek’s first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.</li><li><code>deepseek-coder</code>: It is a capable coding model trained on two trillion code and natural language tokens.</li><li><code>deepseek-v3</code>: A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.</li></ul><p>Here we will run the <code>deepseek-r1</code> model locally. It’s very easy and setup it quickly. Let’s get started.</p><h2 id="Ollama-download-and-installation"><a href="#Ollama-download-and-installation" class="headerlink" title="Ollama download and installation"></a>Ollama download and installation</h2><p>The first step is to download the <code>Ollama</code> and install it on your local machine. It supports Windows, Linux and MacOS. You can download the latest version from the official website. <a href="https://ollama.com/">https://ollama.com/</a></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama" style="width:600px;"/></div><span class="image-caption">Ollama</span></div><p>After download and install it, you can check the version or commands from terminal or command-line.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Check the version of Ollama</span></span><br><span class="line">ollama --version</span><br><span class="line"></span><br><span class="line"><span class="comment">## Check the commands of Ollama</span></span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-version-commands.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-version-commands.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama version and commands"/></div><span class="image-caption">Ollama version and commands</span></div><h2 id="Running-the-deepseek-r1-model"><a href="#Running-the-deepseek-r1-model" class="headerlink" title="Running the deepseek-r1 model"></a>Running the deepseek-r1 model</h2><p>Now, we can run the <code>deepseek-r1</code> model using Ollama. We need to download this model by using ollama. The <code>deepseek-r1</code> model contains serveral models, 1.5b, 7b, 8b, 14b, 32b, 70b and even 671b. For general computer performance, suggestion to use 1.5b model. I tried the 8b model on my local. It can run but the response is slowlly and memory is up to 90%. The 1.5b model running smoothly and response is fast. My local machine has 16GB RAM and i7 processor.</p><p>We can use the following command to download the <code>deepseek-r1</code> model.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>we also can run this model directly, if the model not exist, it will download automatically.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-run-deepseek-r1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-run-deepseek-r1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Ollama run deepseek-r1"/></div><span class="image-caption">Ollama run deepseek-r1</span></div><h2 id="Ask-anything-in-deepseek"><a href="#Ask-anything-in-deepseek" class="headerlink" title="Ask anything in deepseek"></a>Ask anything in deepseek</h2><p>Now, we can ask anything in deepseek. Just type the question and press enter. The model will answer the question. See below screenshot</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-deepseek-answer-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-deepseek-answer-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="DeepSeek-R1 Answer"/></div><span class="image-caption">DeepSeek-R1 Answer</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/ollama-deepseek-answer-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/ollama-deepseek-answer-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="DeepSeek-R1 Answer"/></div><span class="image-caption">DeepSeek-R1 Answer</span></div><p>See, it’s easy to run the <code>deepseek-r1</code> model locally. You can also run other models like <code>deepseek-coder</code> and <code>deepseek-v3</code> models, or <code>llama</code> model. The <code>Ollama</code> models contains many open source models, you can use it for free.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/deepseek-logo.png&quot; class=&quot;lazyload</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Ollama" scheme="https://stonefishy.github.io/tags/Ollama/"/>
    
    <category term="DeepSeek" scheme="https://stonefishy.github.io/tags/DeepSeek/"/>
    
  </entry>
  
  <entry>
    <title>A RAG Chatbot base on Azure OpenAI</title>
    <link href="https://stonefishy.github.io/2025/01/23/rag-chatbot-base-on-azure-openai/"/>
    <id>https://stonefishy.github.io/2025/01/23/rag-chatbot-base-on-azure-openai/</id>
    <published>2025-01-23T11:31:28.000Z</published>
    <updated>2025-03-11T07:05:13.590Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this article, we will build a <code>RAG (Retrieval-Augmented Generation)</code> chatbot using Azure OpenAI’s GPT-4 language model. We will use <code>Python</code>, <code>LangChain</code> and the <code>Streamlit</code> library to build the chatbot interface. Vector store will use <code>FAISS</code> library to store the text chunks and metadata.</p><h2 id="What-is-RAG"><a href="#What-is-RAG" class="headerlink" title="What is RAG?"></a>What is RAG?</h2><p><code>RAG</code> is a technique that combines retrieval-based methods with generative models to enhance the quality and relevance of the information produced by AI systems. Here’s a breakdown of the two components:</p><ol><li><p><strong>Retrieval</strong>: The model first retrieves relevant documents, text, or data from a knowledge base, database, or external source using information retrieval techniques. This allows the model to access specialized or domain-specific knowledge, which it might not have inherently learned during training.</p></li><li><p><strong>Generation</strong>: After retrieving relevant information, the model then uses a generative language model (like GPT-3 or GPT-4) to create a response that is coherent, contextually appropriate, and informed by the retrieved content. This allows the AI to answer questions, generate text, or assist in decision-making with enhanced accuracy and knowledge.</p></li></ol><h2 id="Technical-Stack"><a href="#Technical-Stack" class="headerlink" title="Technical Stack"></a>Technical Stack</h2><p>To build the chatbot, we will use the following techiniques:</p><ul><li><strong>Azure OpenAI GPT-4</strong>: We will use the GPT-4 language model from Azure OpenAI to generate responses. GPT-4 is a transformer-based language model that is capable of generating coherent and diverse text.</li><li><strong>LangChain</strong>: LangChain is a Python library that allows us to use the GPT-4 model from Azure OpenAI in our chatbot. LangChain provides a simple interface for building chatbots using GPT-4.</li><li><strong>Streamlit</strong>: We will use Streamlit to build the chatbot interface. Streamlit is a framework for building web applications in Python. It allows us to create a user-friendly interface for our chatbot.</li><li><strong>FAISS</strong>: FAISS (Facebook AI Similarity Search) is an open-source library developed by Facebook AI Research. It’s designed for efficient similarity search and clustering of high-dimensional data, such as vectors. The primary use case for FAISS is in applications where you need to search for the most similar items to a given query item in large datasets of vectors</li></ul><h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>Before we start, make sure you have the following prerequisites:</p><ul><li>An Azure account</li><li>Python 3.6 or higher</li><li>An IDE or text editor</li><li>A knowledge base or dataset of relevant information</li></ul><h2 id="Setting-up-the-Environment"><a href="#Setting-up-the-Environment" class="headerlink" title="Setting up the Environment"></a>Setting up the Environment</h2><p>To set up the environment, we will need to install the following important libraries:</p><ul><li>LangChain</li><li>Streamlit</li><li>Azure OpenAI GPT-4</li></ul><p>And also include the <code>FAISS</code> and <code>PyPDF2</code> libraries. The <code>FAISS</code> library is used for efficient similarity search, and the <code>PyPDF2</code> library is used to extract text from PDF files.</p><p>Below is the entire python libraries:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">streamlit==1.40.0</span><br><span class="line">PyPDF2==3.0.1</span><br><span class="line">faiss-cpu==1.9.0</span><br><span class="line">openai==1.59.6</span><br><span class="line">tiktoken==0.8.0</span><br><span class="line">langchain==0.3.14</span><br><span class="line">langchain-community==0.3.14</span><br><span class="line">langchain-core==0.3.29</span><br><span class="line">langchain-openai==0.3.0</span><br><span class="line">langchain-text-splitters==0.3.5</span><br></pre></td></tr></table></figure><h2 id="Process-PDFs"><a href="#Process-PDFs" class="headerlink" title="Process PDFs"></a>Process PDFs</h2><p>Here we will read the PDF files and extract the text from them. We will use the <code>PyPDF2</code> library to extract the text from the PDF files. And then save it into local vector store which can be used for similarity search by FAISS. The entire code is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> PyPDF2 <span class="keyword">import</span> PdfReader</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> AzureOpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">azure_endpoint = os.getenv(<span class="string">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>)</span><br><span class="line">api_version = os.getenv(<span class="string">&quot;AZURE_OPENAI_API_VERSION&quot;</span>)</span><br><span class="line">api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line">embedding_deployment = os.getenv(<span class="string">&quot;AZURE_OPENAI_EMBEDDING_DEPLOYMENT&quot;</span>)</span><br><span class="line">chat_deployment = os.getenv(<span class="string">&quot;AZURE_OPENAI_CHAT_DEPLOYMENT&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embeddings</span>():</span><br><span class="line">    <span class="comment"># generating embedding</span></span><br><span class="line">    <span class="keyword">return</span> AzureOpenAIEmbeddings(</span><br><span class="line">        azure_deployment=embedding_deployment,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        azure_endpoint=azure_endpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_files</span>(<span class="params">directory</span>):</span><br><span class="line">    path = Path(os.path.join(os.getcwd(), directory))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> path.exists():</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">f&quot;Directory <span class="subst">&#123;path.absolute()&#125;</span> does not exist&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">str</span>(file) <span class="keyword">for</span> file <span class="keyword">in</span> path.rglob(<span class="string">&quot;*&quot;</span>) <span class="keyword">if</span> file.is_file()]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_pdfs</span>(<span class="params">pdfs_directory, vector_store_folder_path, vector_store_index_name</span>):</span><br><span class="line">    pdf_files = get_all_files(pdfs_directory)</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> pdf_file <span class="keyword">in</span> pdf_files:</span><br><span class="line">        <span class="comment"># Read pdf file</span></span><br><span class="line">        pdf_reader = PdfReader(pdf_file)</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> pdf_reader.pages:</span><br><span class="line">            text += page.extract_text()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Break it into chunks</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        separators=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">        chunk_size=<span class="number">1000</span>,</span><br><span class="line">        chunk_overlap=<span class="number">150</span>,</span><br><span class="line">        length_function=<span class="built_in">len</span></span><br><span class="line">    )</span><br><span class="line">    chunks = text_splitter.split_text(text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Creating vector store - FAISS</span></span><br><span class="line">    vector_store = FAISS.from_texts(chunks, embeddings())</span><br><span class="line">    vector_store.save_local(vector_store_folder_path, vector_store_index_name)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Processed PDF documents to vector store path `<span class="subst">&#123;vector_store_folder_path&#125;</span>`&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    process_pdfs(config.pdfs_directory, config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In above code, we are reading the PDF files and extracting the text from them. We are using the <code>RecursiveCharacterTextSplitter</code> to break the text into chunks of 1000 characters with 150 characters overlap. And then using the <code>FAISS</code> library to create a vector store of the text chunks. The vector store is saved in the local file system. The vector store files contains two files (<code>*.faiss</code> and <code>*.pkl</code>) which can be used for similarity search.</p><p>The <code>*.faiss</code> file contains the vector representation of the text chunks. The <code>*.pkl</code> file contains the metadata of the text chunks.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/rag-chatbot-vector-store.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/rag-chatbot-vector-store.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="RAG Chatbot Vector Store"/></div><span class="image-caption">RAG Chatbot Vector Store</span></div><p>You may noticing that we are using the <code>dotenv</code> library to load the environment variables. You can create a <code>.env</code> file in the root directory of your project and add the following variables:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_ENDPOINT=&lt;your_endpoint_url&gt;</span><br><span class="line">AZURE_OPENAI_API_VERSION=&lt;your_api_version&gt;</span><br><span class="line">OPENAI_API_KEY=&lt;your_api_key?</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o # we are using gpt-4o model, you can use any other model which you deployed in your endpoint.</span><br><span class="line">AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002 # we are using text-embedding-ada-002 model.</span><br></pre></td></tr></table></figure><h2 id="Building-the-Chatbot"><a href="#Building-the-Chatbot" class="headerlink" title="Building the Chatbot"></a>Building the Chatbot</h2><p>After we have processed the PDF files and created the vector store, we can now build the chatbot using LangChain.</p><p>First, we will create a <code>LangChain</code> instance and load the vector store. Using <code>FAISS.load_local</code> method, we can load the vector store from the local file system with the same embeddings model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">embeddings</span>():</span><br><span class="line">    <span class="comment"># generating embedding</span></span><br><span class="line">    <span class="keyword">return</span> AzureOpenAIEmbeddings(</span><br><span class="line">        azure_deployment=embedding_deployment,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        azure_endpoint=azure_endpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_vector_store</span>(<span class="params">vector_store_folder_path, vectore_store_name</span>):</span><br><span class="line">    vector_store = FAISS.load_local(</span><br><span class="line">        folder_path=vector_store_folder_path, </span><br><span class="line">        embeddings=embeddings(), </span><br><span class="line">        index_name=vectore_store_name,</span><br><span class="line">        allow_dangerous_deserialization=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> vector_store </span><br></pre></td></tr></table></figure><p>Then, we will create a <code>AzureChatOpenAI</code> instance and load the chatbot model. We will use the <code>AzureChatOpenAI</code> class to interact with the GPT-4 model from Azure OpenAI. Using <code>load_qa_chain</code> method which is provided by <code>LangChain</code>, we can load the chatbot model from the Azure OpenAI.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generateChain</span>():</span><br><span class="line">    llm =  AzureChatOpenAI(</span><br><span class="line">        azure_endpoint=azure_endpoint,</span><br><span class="line">        api_key=api_key,</span><br><span class="line">        api_version=api_version,</span><br><span class="line">        azure_deployment=chat_deployment,</span><br><span class="line">        temperature=<span class="number">0</span>,</span><br><span class="line">        max_tokens=<span class="number">1000</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># chain -&gt; take the question, get relevant document, pass it to the LLM, generate the output</span></span><br><span class="line">    chain = load_qa_chain(llm, chain_type=<span class="string">&quot;stuff&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> chain</span><br></pre></td></tr></table></figure><p>After the chain and the vector store are loaded, we can use FAISS vector store to similarity search the user input and retrieve the most relevant document. Passing the retrieved document to the LangChain chain which loads the AzureChatOpenAI to generate the response. Below is core code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector_store = load_vector_store(config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line">chain = generateChain()</span><br><span class="line">match_documents = vector_store.similarity_search(prompt)</span><br><span class="line">response = chain.run(input_documents = match_documents, question = prompt)</span><br></pre></td></tr></table></figure><p>The <code>chain.run</code> method takes the input documents and the question as input and returns the generated response. The <code>match_documents</code> variable contains the most relevant documents retrieved from the vector store. The <code>response</code> variable contains the generated response from the chatbot.</p><p>Finally, we will create a Streamlit interface to interact with the chatbot. We will use the <code>streamlit</code> library to create a user-friendly interface for our chatbot. For the <code>streamlit</code> library usage, you can refer to the official documentation. <a href="https://docs.streamlit.io/">https://docs.streamlit.io/</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    st.set_page_config(</span><br><span class="line">        page_title=<span class="string">&quot;JBL Products Chatbot&quot;</span>,</span><br><span class="line">        page_icon=<span class="string">&quot;🧊&quot;</span>,</span><br><span class="line">        layout=<span class="string">&quot;centered&quot;</span>,</span><br><span class="line">        initial_sidebar_state=<span class="string">&quot;expanded&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    st.header(<span class="string">&quot;JBL Products Chatbot&quot;</span>)</span><br><span class="line">    vector_store = load_vector_store(config.vector_store_folder_path, config.vector_store_index_name)</span><br><span class="line">    chain = generateChain()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">        st.markdown(<span class="string">&quot;Ask me anything about JBL devices (JBL Pulse 5, JBL Clip 5, JBL Bar 500)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">        st.session_state.messages = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> st.session_state.messages:</span><br><span class="line">        <span class="keyword">with</span> st.chat_message(message[<span class="string">&quot;role&quot;</span>]):</span><br><span class="line">            st.markdown(message[<span class="string">&quot;content&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> prompt := st.chat_input(<span class="string">&quot;Ask me something&quot;</span>):</span><br><span class="line">        st.chat_message(<span class="string">&quot;user&quot;</span>).markdown(prompt)</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;)</span><br><span class="line"></span><br><span class="line">        response = <span class="string">&quot;I am thinking...&quot;</span></span><br><span class="line">        <span class="keyword">with</span> st.spinner(response):</span><br><span class="line">            match_documents = vector_store.similarity_search(prompt)</span><br><span class="line">            response = chain.run(input_documents = match_documents, question = prompt)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">            st.write_stream(generate_stream(response))</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response&#125;)</span><br></pre></td></tr></table></figure><p>In above code, we are using the <code>st.chat_message</code> method to create a chat message with a specific role, using the <code>st.chat_input</code> method to get the user input. And using the <code>st.spinner</code> method to show a loading spinner while the chatbot is generating the response. Finally using the <code>st.write_stream</code> method to write the response to the chat message.</p><p>For the stream response, actually we mock it by using the <code>generate_stream</code> method. This method is used to generate the stream response. We can use the <code>st.write_stream</code> method to write the stream response to the chat message. This will let the chatbot to print word one by one in the chat message.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_stream</span>(<span class="params">response</span>):</span><br><span class="line">    <span class="comment"># generate the stream of messages</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> response.split(<span class="string">&quot; &quot;</span>):</span><br><span class="line">        <span class="keyword">yield</span> word + <span class="string">&quot; &quot;</span></span><br><span class="line">        time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><p>Below is chatbot conversational interface:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/rag-chatbot-streamlit-interface.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/rag-chatbot-streamlit-interface.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="RAG Chatbot Streamlit Interface"/></div><span class="image-caption">RAG Chatbot Streamlit Interface</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article, we have built a <code>RAG (Retrieval-Augmented Generation)</code> chatbot using Azure OpenAI’s GPT-4 language model. We have used Python, LangChain and the Streamlit library to build the chatbot interface. We have also processed the PDF files and created the vector store using FAISS library. The pdf files is crawled from the website <a href="https://www.manua.ls/">https://www.manua.ls</a></p><p>For the entire code, you can refer to the Github repository: <a href="https://github.com/stonefishy/rag-chatbot">https://github.com/stonefishy/rag-chatbot</a>. Please don’t forget to star the repository if you find it useful. Thank you for reading.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;In this article, we will build</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="RAG" scheme="https://stonefishy.github.io/tags/RAG/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
    <category term="Chatbot" scheme="https://stonefishy.github.io/tags/Chatbot/"/>
    
    <category term="Streamlit" scheme="https://stonefishy.github.io/tags/Streamlit/"/>
    
    <category term="FAISS" scheme="https://stonefishy.github.io/tags/FAISS/"/>
    
  </entry>
  
  <entry>
    <title>How to use Paho MQTT Client Lib in Python3</title>
    <link href="https://stonefishy.github.io/2025/01/06/how-to-use-paho-mqtt-client-lib-in-python3/"/>
    <id>https://stonefishy.github.io/2025/01/06/how-to-use-paho-mqtt-client-lib-in-python3/</id>
    <published>2025-01-06T14:57:57.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>The <code>Paho MQTT client</code> library for Python is a popular choice for building MQTT applications in Python. Here’s how to use it in Python3. <code>Paho MQTT Client</code> provides a simple and easy-to-use API for publishing and subscribing to MQTT topics. It supports MQTT 5.0, 3.1.1, and 3.1 protocols.</p><h2 id="Install-Paho-MQTT-Client"><a href="#Install-Paho-MQTT-Client" class="headerlink" title="Install Paho MQTT Client"></a>Install Paho MQTT Client</h2><p>To install <code>Paho MQTT Client</code> library, you can use the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install paho-mqtt</span><br></pre></td></tr></table></figure><h2 id="Prepare-the-MQTT-Broker"><a href="#Prepare-the-MQTT-Broker" class="headerlink" title="Prepare the MQTT Broker"></a>Prepare the MQTT Broker</h2><p>Before using the <code>Paho MQTT Client</code> library, we need to prepare the MQTT broker. We can use any MQTT broker that supports the MQTT 5.0, 3.1.1, or 3.1 protocols. Here we use the public free MQTT broker: <code>EMQX</code>, below is broker information.</p><blockquote><p>Server：broker.emqx.io<br>TCP Port：1883<br>WebSocket Port：8083<br>SSL&#x2F;TLS Port：8883<br>Secure WebSocket Port：8084</p></blockquote><h2 id="Import-Paho-MQTT-Client"><a href="#Import-Paho-MQTT-Client" class="headerlink" title="Import Paho MQTT Client"></a>Import Paho MQTT Client</h2><p>To use the <code>Paho MQTT Client</code> library in the Python code, need to import it first.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paho.mqtt <span class="keyword">import</span> client <span class="keyword">as</span> mqtt_client</span><br></pre></td></tr></table></figure><h2 id="Create-a-MQTT-Connection"><a href="#Create-a-MQTT-Connection" class="headerlink" title="Create a MQTT Connection"></a>Create a MQTT Connection</h2><p>Before create a MQTT connection, specify the MQTT client id, MQTT broker address, port and mesage topic. We can use the python <code>random.randint()</code> function to generate a random client id.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">broker = <span class="string">&quot;broker.emqx.io&quot;</span></span><br><span class="line">port = <span class="number">1883</span></span><br><span class="line">topic = <span class="string">&quot;paho/mqtt/test&quot;</span></span><br><span class="line">client_id = <span class="string">f&quot;client_<span class="subst">&#123;random.randint(<span class="number">0</span>, <span class="number">1000</span>)&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure><p>Next, we need to write the <code>on_connect</code> callback function in order to connect to the proxy. This function is called after the client successfully connects, we can use the <code>rc</code> parameter to check the connection status. Typically, we also create a client object that is also connected to “broker.emqx.io”.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">connect_mqtt</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_connect</span>(<span class="params">client, userdata, flags, reason_code, properties</span>):</span><br><span class="line">        <span class="keyword">if</span> reason_code == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Connected to MQTT Broker!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Failed to connect, return code %d\n&quot;</span>, reason_code)</span><br><span class="line">    client = mqtt_client.Client(client_id=client_id, callback_api_version=mqtt_client.CallbackAPIVersion.VERSION2)</span><br><span class="line"></span><br><span class="line">    client.on_connect = on_connect</span><br><span class="line">    client.connect(broker, port)</span><br><span class="line">    <span class="keyword">return</span> client</span><br></pre></td></tr></table></figure><p>When execute the <code>connect_mqtt()</code> function, it will return a <code>Client</code> instance that is connected to the MQTT broker, and printed the connection status.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-connected.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-connected.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Connected to Broker"/></div><span class="image-caption">MQTT Connected to Broker</span></div><h2 id="Publish-Messages-to-MQTT-Topics"><a href="#Publish-Messages-to-MQTT-Topics" class="headerlink" title="Publish Messages to MQTT Topics"></a>Publish Messages to MQTT Topics</h2><p>publish messages to MQTT topics, let’s create a <code>publish()</code> function that will publish a message to the specified topic every second. Using <code>client.publish()</code> method, we can publish a message to the specified topic.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">publish</span>(<span class="params">client</span>):</span><br><span class="line">    msg_count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        msg = <span class="string">f&quot;messages: test <span class="subst">&#123;msg_count&#125;</span>&quot;</span></span><br><span class="line">        result = client.publish(topic, msg)</span><br><span class="line">        status = result[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> status == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Send `<span class="subst">&#123;msg&#125;</span>` to topic `<span class="subst">&#123;topic&#125;</span>`&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Failed to send message to topic <span class="subst">&#123;topic&#125;</span>&quot;</span>)</span><br><span class="line">        msg_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> msg_count &gt; <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-publish.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-publish.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Publish Message"/></div><span class="image-caption">MQTT Publish Message</span></div><h2 id="Subscribe-to-MQTT-Topics"><a href="#Subscribe-to-MQTT-Topics" class="headerlink" title="Subscribe to MQTT Topics"></a>Subscribe to MQTT Topics</h2><p>To subscribe to MQTT topics, we can call the <code>subscribe()</code> method of the <code>Client</code> instance. We can define a callback function that will be called when a message is received on a subscribed topic. The callback function <code>on_message()</code> will be called when a message is received on the subscribed topic.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">subscribe</span>(<span class="params">client: mqtt_client</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_message</span>(<span class="params">client, userdata, msg</span>):</span><br><span class="line">        <span class="built_in">print</span>(msg)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Received `<span class="subst">&#123;msg.payload.decode()&#125;</span>` which sent by `<span class="subst">&#123;client._client_id&#125;</span>` from `<span class="subst">&#123;msg.topic&#125;</span>` topic&quot;</span>)</span><br><span class="line"></span><br><span class="line">    client.subscribe(topic)</span><br><span class="line">    client.on_message = on_message</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-subscribe.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-subscribe.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Subscribe Message"/></div><span class="image-caption">MQTT Subscribe Message</span></div><h2 id="Run-the-MQTT-Client"><a href="#Run-the-MQTT-Client" class="headerlink" title="Run the MQTT Client"></a>Run the MQTT Client</h2><p>To run the MQTT client, we can use <code>loop_start()</code> method to run the client in a separate thread, <code>loop_stop()</code> method to stop the client loop. We also can call the <code>loop_forever()</code> method of the <code>Client</code> instance. This method will block the current thread and run the client indefinitely. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">client.loop_start() <span class="comment"># start the client loop</span></span><br><span class="line">client.loop_stop() <span class="comment"># stop the client loop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">client.loop_forever() <span class="comment"># block the current thread and run the client indefinitely</span></span><br></pre></td></tr></table></figure><h2 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h2><p>Here’s the full code that uses the <code>Paho MQTT Client</code> library to connect to the MQTT broker, publish messages to a topic, and subscribe to a topic.</p><h3 id="client1-py"><a href="#client1-py" class="headerlink" title="client1.py"></a>client1.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> paho.mqtt <span class="keyword">import</span> client <span class="keyword">as</span> mqtt_client</span><br><span class="line"></span><br><span class="line">broker = <span class="string">&quot;broker.emqx.io&quot;</span></span><br><span class="line">port = <span class="number">1883</span></span><br><span class="line">topic = <span class="string">&quot;paho/mqtt/test&quot;</span></span><br><span class="line">client_id = <span class="string">f&quot;client_<span class="subst">&#123;random.randint(<span class="number">0</span>, <span class="number">1000</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">connect_mqtt</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_connect</span>(<span class="params">client, userdata, flags, reason_code, properties</span>):</span><br><span class="line">        <span class="keyword">if</span> reason_code == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Connected to MQTT Broker!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Failed to connect, return code %d\n&quot;</span>, reason_code)</span><br><span class="line">    client = mqtt_client.Client(client_id=client_id, callback_api_version=mqtt_client.CallbackAPIVersion.VERSION2)</span><br><span class="line"></span><br><span class="line">    client.on_connect = on_connect</span><br><span class="line">    client.connect(broker, port)</span><br><span class="line">    <span class="keyword">return</span> client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">publish</span>(<span class="params">client</span>):</span><br><span class="line">    msg_count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        msg = <span class="string">f&quot;messages: test <span class="subst">&#123;msg_count&#125;</span>&quot;</span></span><br><span class="line">        result = client.publish(topic, msg)</span><br><span class="line">        status = result[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> status == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Send `<span class="subst">&#123;msg&#125;</span>` to topic `<span class="subst">&#123;topic&#125;</span>`&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Failed to send message to topic <span class="subst">&#123;topic&#125;</span>&quot;</span>)</span><br><span class="line">        msg_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> msg_count &gt; <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    client = connect_mqtt()</span><br><span class="line">    client.loop_start()</span><br><span class="line">    publish(client)</span><br><span class="line">    client.loop_stop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="client2-py"><a href="#client2-py" class="headerlink" title="client2.py"></a>client2.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> paho.mqtt <span class="keyword">import</span> client <span class="keyword">as</span> mqtt_client</span><br><span class="line"></span><br><span class="line">broker = <span class="string">&quot;broker.emqx.io&quot;</span></span><br><span class="line">port = <span class="number">1883</span></span><br><span class="line">topic = <span class="string">&quot;paho/mqtt/test&quot;</span></span><br><span class="line">client_id = <span class="string">f&quot;client_<span class="subst">&#123;random.randint(<span class="number">0</span>, <span class="number">1000</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">connect_mqtt</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_connect</span>(<span class="params">client, userdata, flags, reason_code, properties</span>):</span><br><span class="line">        <span class="keyword">if</span> reason_code == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Connected to MQTT Broker!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Failed to connect, return code %d\n&quot;</span>, reason_code)</span><br><span class="line">    client = mqtt_client.Client(client_id=client_id, callback_api_version=mqtt_client.CallbackAPIVersion.VERSION2)</span><br><span class="line"></span><br><span class="line">    client.on_connect = on_connect</span><br><span class="line">    client.connect(broker, port)</span><br><span class="line">    <span class="keyword">return</span> client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">subscribe</span>(<span class="params">client: mqtt_client</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_message</span>(<span class="params">client, userdata, msg</span>):</span><br><span class="line">        <span class="built_in">print</span>(msg)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Received `<span class="subst">&#123;msg.payload.decode()&#125;</span>` which sent by `<span class="subst">&#123;client._client_id&#125;</span>` from `<span class="subst">&#123;msg.topic&#125;</span>` topic&quot;</span>)</span><br><span class="line"></span><br><span class="line">    client.subscribe(topic)</span><br><span class="line">    client.on_message = on_message</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    client = connect_mqtt()</span><br><span class="line">    subscribe(client)</span><br><span class="line">    client.loop_forever()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure><p>That’s it! You can now use the <code>Paho MQTT Client</code> library to build MQTT applications in Python3.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The &lt;code&gt;Paho MQTT client&lt;/code&gt; library for Python is a popular choice for building MQTT applications in Python. Here’s how to use it i</summary>
      
    
    
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="MQTT" scheme="https://stonefishy.github.io/tags/MQTT/"/>
    
    <category term="IoT" scheme="https://stonefishy.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>The Ultimate MQTT Client Tool - MQTTX</title>
    <link href="https://stonefishy.github.io/2024/12/31/the-ultimate-mqtt-client-tool-mqttx/"/>
    <id>https://stonefishy.github.io/2024/12/31/the-ultimate-mqtt-client-tool-mqttx/</id>
    <published>2024-12-31T14:42:10.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>In the world of <code>IoT (Internet of Things)</code>, <code>MQTT (Message Queuing Telemetry Transport)</code> is a popular lightweight messaging protocol that ensures efficient communication between devices, servers, and clients. MQTT is favored for its low-bandwidth requirements and its ability to work in low network environments. However, testing and debugging MQTT-based applications can be challenging without the right tools.</p><p>Today we’re talking about one such tool called <code>MQTTX</code>. MQTTX is a cross platform, open-source MQTT client tool that provides a user-friendly interface for testing and debugging MQTT-based applications. It supports multiple MQTT brokers, including EMQX, Mosquitto, HiveMQ, and others, and provides a range of features such as message history, message filtering, and more. It is available for multiple platforms, including <code>Windows</code>, <code>macOS</code>, and <code>Linux</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-tool.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-tool.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTTX tool" style="width:800px;"/></div><span class="image-caption">MQTTX tool</span></div><p>MQTTX supports all versions of the MQTT protocol, from MQTT 3.1.1 to MQTT 5.0, which makes it suitable for a wide range of use cases, from simple applications to advanced IoT systems.</p><h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><p>Let’s using MQTTX to test and debug an MQTT-based application. We’ll use the <code>EMQX</code> MQTT broker for this example. And here we using Web version of MQTTX. The web client is <a href="https://mqttx.app/web-client">https://mqttx.app/web-client</a>.</p><p>The public <code>EMQX</code> server information is as follows:</p><blockquote><p><strong>Server</strong>: broker.emqx.io</p><p><strong>TCP Port</strong>: 1883</p><p><strong>WebSocket Port</strong>: 8083</p><p><strong>SSL&#x2F;TLS Port</strong>: 8883</p><p><strong>Secure WebSocket Port</strong>: 8084</p></blockquote><h3 id="Create-a-New-Connection"><a href="#Create-a-New-Connection" class="headerlink" title="Create a New Connection"></a>Create a New Connection</h3><p>Open web client of MQTTX and click on the <code>+</code> button on the top-left corner to create a new connection.  Naming the connection as ‘cloudserver’, and keep to using <code>EMQX</code> as the broker.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-create-connection.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-create-connection.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create a new connection" style="width:800px;"/></div><span class="image-caption">Create a new connection</span></div><h3 id="Subscribe-to-a-Topic"><a href="#Subscribe-to-a-Topic" class="headerlink" title="Subscribe to a Topic"></a>Subscribe to a Topic</h3><p>Once the connection is established, we can subscribe to a topic by clicking on the <code>New Subscription</code> button. Let’s subscribe to the topic <code>test/temperature</code>. </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-subscribe-topic.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-subscribe-topic.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create a subscription to a topic" style="width:800px;"/></div><span class="image-caption">Create a subscription to a topic</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-subscribe-topic2.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-subscribe-topic2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Subscribe to a topic" style="width:800px;"/></div><span class="image-caption">Subscribe to a topic</span></div><h3 id="Create-two-new-clients"><a href="#Create-two-new-clients" class="headerlink" title="Create two new clients"></a>Create two new clients</h3><p>Now, let’s create two new clients connection, naming as <code>sensor1</code> and <code>sensor2</code>. Both clients will subscribe to the same topic <code>test/resp</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-create-clients.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-create-clients.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Create new clients" style="width:800px;"/></div><span class="image-caption">Create new clients</span></div><h3 id="Publish-a-Message"><a href="#Publish-a-Message" class="headerlink" title="Publish a Message"></a>Publish a Message</h3><p>Let’s publish a message which using JSON format from <code>sensor1</code> to the topic <code>test/temperature</code>. And we can see the message is received by <code>sensor1</code>.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Topic: </span><br><span class="line">test/temperature</span><br><span class="line"></span><br><span class="line">Message:</span><br><span class="line">&#123;&quot;id&quot;: &quot;sensor1&quot;, &quot;value&quot;: &quot;2&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-publish-message.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-publish-message.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Publish a message" style="width:800px;"/></div><span class="image-caption">Publish a message</span></div><p>We can see the ‘cloudserver’ client which subscribed the topic <code>test/temperature</code> received the message.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-message-received.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-message-received.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Message received" style="width:800px;"/></div><span class="image-caption">Message received</span></div><p>In ‘cloudserver’ client, we also can send the message to the topic <code>test/resp</code>. Then both <code>sensor1</code> and <code>sensor2</code> will receive the message.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Topic:</span><br><span class="line">test/resp</span><br><span class="line"></span><br><span class="line">Message:</span><br><span class="line">&#123;&quot;id&quot;: &quot;cloudserver&quot;, &quot;value&quot;: &quot;100&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-publish-message2.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-publish-message2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Publish a message to a topic" style="width:800px;"/></div><span class="image-caption">Publish a message to a topic</span></div><h3 id="Topic-with-Wildcard"><a href="#Topic-with-Wildcard" class="headerlink" title="Topic with Wildcard"></a>Topic with Wildcard</h3><p>The MQTT protocol forwards messages based on the topic. Topics are hierarchical by <code>/</code>, similar to URL paths, for example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chat/room/1</span><br><span class="line"></span><br><span class="line">sensor/10/temperature</span><br><span class="line"></span><br><span class="line">sensor/+/temperature</span><br></pre></td></tr></table></figure><p>MQTT topics support two wildcards: <code>+</code> and <code>#</code>.</p><p><strong>+</strong>: Represents a single-layer wildcard, such as A&#x2F;+ matching A&#x2F;X or A&#x2F;Y.<br><strong>#</strong>: Represents a multi-layered wildcard, e.g. A&#x2F;# matches A&#x2F;X, A&#x2F;B&#x2F;C&#x2F;D.</p><blockquote><p>Note: Wildcard topics can only be used for subscriptions, not for publishing.</p></blockquote><p>Let’s update the subscription of <code>cloudserver</code> client to subscribe to the topic <code>test/+/temperature</code>. This will match all topics that start with <code>test/</code> and end with <code>temperature</code>. And using <code>sensor1</code> client to publish a message to the topic <code>test/1/temperature</code>, <code>sensor2</code> client to publish a message to the topic <code>test/2/temperature</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-subscribe-topic3.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-subscribe-topic3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Subscribe to a topic with wildcard" style="width:800px;"/></div><span class="image-caption">Subscribe to a topic with wildcard</span></div><p>As you can see the <code>cloudserver</code> client received both messages.</p><p>The MQTTX tool provides QoS, message retained and more features for testing and debugging MQTT-based applications. You can test and debug your MQTT-based applications using MQTTX.</p><h2 id="Client-Version"><a href="#Client-Version" class="headerlink" title="Client Version"></a>Client Version</h2><p>The MQTTX tool client version includes more features such as topic tree visualization.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/mqttx-topic-tree.png" class="lazyload placeholder" data-srcset="/assets/images/tools/mqttx-topic-tree.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Topic tree visualization" style="width:800px;"/></div><span class="image-caption">Topic tree visualization</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>MQTTX is a powerful and user-friendly MQTT client tool that provides a range of features for testing and debugging MQTT-based applications. It supports multiple MQTT brokers, including EMQX, Mosquitto, HiveMQ, and others, and provides a cross-platform client for Windows, macOS, and Linux.   </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the world of &lt;code&gt;IoT (Internet of Things)&lt;/code&gt;, &lt;code&gt;MQTT (Message Queuing Telemetry Transport)&lt;/code&gt; is a popular lightweight m</summary>
      
    
    
    
    <category term="Tools" scheme="https://stonefishy.github.io/categories/Tools/"/>
    
    
    <category term="MQTT" scheme="https://stonefishy.github.io/tags/MQTT/"/>
    
    <category term="IoT" scheme="https://stonefishy.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>浅谈物联网IoT中常见的消息传输协议MQTT</title>
    <link href="https://stonefishy.github.io/2024/12/30/what-is-mqtt-and-how-it-works/"/>
    <id>https://stonefishy.github.io/2024/12/30/what-is-mqtt-and-how-it-works/</id>
    <published>2024-12-30T15:02:06.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是MQTT？"><a href="#什么是MQTT？" class="headerlink" title="什么是MQTT？"></a>什么是MQTT？</h2><p><code>MQTT （Message Queuing Telemetry Transport, 消息队列遥测传输协议）</code>是一种基于<code>发布/订阅（Publish/Subscribe）</code>模式的轻量级消息传输协议，最初由IBM在1999年开发，主要用于<code>低带宽</code>、<code>不稳定网络环境</code>下的设备通信。MQTT协议设计简单，占用资源少，适合在资源受限的嵌入式设备上运行。</p><p>MQTT的核心思想是将消息的发送者（发布者）和接收者（订阅者）解耦，通过一个中间代理（Broker）来传递消息。发布者将消息发送到特定的主题（Topic），订阅者则订阅感兴趣的主题，从而接收相关消息。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-diagram.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-diagram.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT (Message Queuing Telemetry Transport)"/></div><span class="image-caption">MQTT (Message Queuing Telemetry Transport)</span></div><h2 id="MQTT的应用场景"><a href="#MQTT的应用场景" class="headerlink" title="MQTT的应用场景"></a>MQTT的应用场景</h2><p><code>MQTT</code>广泛应用于IoT(Internet of Things, 物联网)领域，主要用于物联网、移动互联网、智能家居、工业自动化等领域。以下是一些典型的应用场景：</p><ol><li><p>物联网（IoT）<br>在物联网中，设备通常分布在不同的地理位置，且网络条件可能不稳定。MQTT的低带宽消耗和可靠性使其成为连接这些设备的理想选择。例如，传感器可以通过MQTT将数据发送到云端，供其他设备或应用程序使用。</p></li><li><p>智能家居<br>在智能家居系统中，各种设备（如灯光、温控器、安防系统等）需要相互通信。MQTT可以帮助这些设备高效地交换信息，实现自动化控制。</p></li><li><p>工业自动化<br>在工业自动化领域，MQTT可以用于监控和控制生产线上的设备。通过MQTT，工厂可以实时获取设备状态，进行远程控制和故障诊断。</p></li><li><p>移动应用<br>在移动应用中，MQTT可以用于推送通知、实时消息传递等场景。由于MQTT协议轻量且高效，非常适合在移动设备上使用。</p></li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/mqtt/mqtt-example.png" class="lazyload placeholder" data-srcset="/assets/images/mqtt/mqtt-example.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="MQTT Example"/></div><span class="image-caption">MQTT Example</span></div><h2 id="MQTT的工作原理"><a href="#MQTT的工作原理" class="headerlink" title="MQTT的工作原理"></a>MQTT的工作原理</h2><p>MQTT协议基于发布&#x2F;订阅模式，其核心组件包括以下三个：</p><p><strong>发布者（Publisher）</strong>：负责将消息发送到特定的主题Topic。<br><strong>订阅者（Subscriber）</strong>：订阅感兴趣的主题，接收相关消息。<br><strong>代理（Broker）</strong>：负责接收发布者的消息，并将其转发给订阅者。</p><h4 id="主题（Topic）"><a href="#主题（Topic）" class="headerlink" title="主题（Topic）"></a>主题（Topic）</h4><p>主题是MQTT中消息的分类标识符，采用<code>分层结构</code>。例如，home&#x2F;livingroom&#x2F;temperature 表示“客厅温度”主题。发布者将消息发送到特定主题，订阅者则通过订阅主题来接收消息。</p><h4 id="服务质量（QoS）"><a href="#服务质量（QoS）" class="headerlink" title="服务质量（QoS）"></a>服务质量（QoS）</h4><p>MQTT支持三种服务质量级别，用于控制消息传递的可靠性：</p><p><strong>QoS 0</strong>：最多一次传递。消息可能会丢失，但不会重复。<br><strong>QoS 1</strong>：至少一次传递。消息不会丢失，但可能会重复。<br><strong>QoS 2</strong>：恰好一次传递。消息既不会丢失，也不会重复。</p><h4 id="持久会话（Persistent-Session）"><a href="#持久会话（Persistent-Session）" class="headerlink" title="持久会话（Persistent Session）"></a>持久会话（Persistent Session）</h4><p>MQTT支持持久会话，允许客户端在断开连接后重新连接时，继续接收未处理的消息。这对于不稳定的网络环境非常有用。</p><h2 id="MQTT的工作流程"><a href="#MQTT的工作流程" class="headerlink" title="MQTT的工作流程"></a>MQTT的工作流程</h2><p>MQTT的工作流程可以分为以下几个步骤：</p><ol><li><p>连接代理<br>客户端(Client)（发布者或订阅者）首先与MQTT代理(Broker)建立连接。连接时，客户端需要提供客户端ID、用户名、密码等信息。</p></li><li><p>订阅主题<br>订阅者向代理发送订阅请求，指定感兴趣的主题。代理会记录订阅者的订阅信息。</p></li><li><p>发布消息<br>发布者将消息发送到特定主题。代理接收到消息后，会根据主题将消息转发给所有订阅该主题的订阅者。</p></li><li><p>接收消息<br>订阅者从代理接收消息，并根据需要进行处理。</p></li><li><p>断开连接<br>客户端可以主动断开与代理的连接，或者由于网络问题导致连接断开。如果启用了持久会话，客户端重新连接后可以继续接收未处理的消息。</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>MQTT</code>作为一种轻量级、高效的通信协议，在物联网、智能家居、工业自动化等领域有着广泛的应用。其基于发布&#x2F;订阅模式的设计，使得设备之间的通信更加灵活和高效。通过理解MQTT的工作原理和工作流程，开发者可以更好地利用这一协议，构建稳定、可靠的物联网系统。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是MQTT？&quot;&gt;&lt;a href=&quot;#什么是MQTT？&quot; class=&quot;headerlink&quot; title=&quot;什么是MQTT？&quot;&gt;&lt;/a&gt;什么是MQTT？&lt;/h2&gt;&lt;p&gt;&lt;code&gt;MQTT （Message Queuing Telemetry Transpor</summary>
      
    
    
    
    <category term="中间件" scheme="https://stonefishy.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="MQTT" scheme="https://stonefishy.github.io/tags/MQTT/"/>
    
    <category term="IoT" scheme="https://stonefishy.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>Sentry: The Developer’s Best Friend for Error Tracking and Performance Monitoring</title>
    <link href="https://stonefishy.github.io/2024/12/19/sentry-the-developer-s-best-friend-for-error-tracking-and-performance-monitoring/"/>
    <id>https://stonefishy.github.io/2024/12/19/sentry-the-developer-s-best-friend-for-error-tracking-and-performance-monitoring/</id>
    <published>2024-12-19T14:31:21.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/sentry.png" class="lazyload placeholder" data-srcset="/assets/images/tools/sentry.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Sentry"/></div><span class="image-caption">Sentry</span></div><p>As developers, we know how frustrating it can be to track down bugs and performance issues, especially when they slip through the cracks and impact end-users. Fortunately, <code>Sentry</code> is here to help you take control of your application’s stability and performance, offering a comprehensive solution for error tracking and performance monitoring.</p><p>In this post, we’ll dive into what Sentry is, how it works, and why it should be a key part of your development workflow.</p><h2 id="What-is-Sentry"><a href="#What-is-Sentry" class="headerlink" title="What is Sentry?"></a>What is Sentry?</h2><p><code>Sentry</code> is an <code>open-source</code> <code>error tracking</code> and <code>performance monitoring</code> tool that helps you find and fix issues in your applications—whether they’re web-based, mobile, or server-side. It captures errors in real-time, giving you deep insights into what went wrong, where it happened, and what might be causing it. Whether you’re building an app with React, Django, or even a mobile app, Sentry works across a wide variety of languages and platforms.</p><h2 id="Why-Should-Developers-Use-Sentry"><a href="#Why-Should-Developers-Use-Sentry" class="headerlink" title="Why Should Developers Use Sentry?"></a>Why Should Developers Use Sentry?</h2><ol><li><p>Track Errors in Real-Time<br>No one likes finding out about an issue after a user complains. Sentry sends real-time error alerts straight to your team—whether it’s through email, Slack, or other channels—so you can address problems as they arise. And with detailed stack traces and contextual information, you’re not left guessing about where or why the issue happened.</p></li><li><p>Monitor Performance Issues<br>Sentry isn’t just for catching errors; it also provides powerful performance monitoring. From slow page loads to database bottlenecks, Sentry helps you track performance metrics and diagnose why your app might be lagging, allowing you to optimize performance proactively.</p></li><li><p>Understand Context Around Errors<br>When an error happens, Sentry doesn’t just provide a stack trace. It enriches the error data with contextual information like user actions, environment (production vs. staging), browser version, and the specific code version that caused the issue. This context allows you to fix issues faster because you get a better sense of what happened right before the error occurred.</p></li><li><p>Release Tracking<br>Have you ever deployed a new release, only to realize later that it introduced a bug? Sentry connects errors to specific releases, so you can quickly figure out which version of your app caused the problem. Plus, you can monitor the health of each release, so you know when it’s time to roll back or fix issues.</p></li></ol><h2 id="Core-Features-You’ll-Love"><a href="#Core-Features-You’ll-Love" class="headerlink" title="Core Features You’ll Love"></a>Core Features You’ll Love</h2><ol><li><p>Error Aggregation<br>Sentry aggregates errors that are similar or identical, helping you prioritize the most critical issues without being overwhelmed by duplicates. This makes it easier to focus on the errors that matter.</p></li><li><p>Customizable Alerts &amp; Notifications<br>You can set custom thresholds for error severity or the frequency of an error before triggering an alert. This ensures you’re not flooded with notifications for every minor issue but are still on top of critical bugs.</p></li><li><p>Issue Resolution Workflow<br>With issue tracking integration (e.g., JIRA, GitHub), you can automatically assign issues to team members and track their resolution status without leaving your existing tools. This helps streamline your workflow and ensures bugs don’t fall through the cracks.</p></li><li><p>Contextual Information<br>The error reports include all the context you need to solve a bug, like the user’s device info, the environment it happened in, stack traces, request URLs, and even relevant logs. This reduces the time it takes to identify and fix problems.</p></li><li><p>Performance Monitoring<br>With Sentry’s performance monitoring, you can trace the performance of specific transactions across your app. This helps pinpoint slow database queries, inefficient API calls, and anything else that might be affecting performance.</p></li><li><p>Wide Integration Support<br>Sentry integrates with many of the tools you already use, such as <code>GitHub</code>, <code>GitLab</code>, <code>Slack</code>, <code>JIRA</code>, <code>Trello</code>, and more. This makes it simple to plug Sentry into your existing workflow and ensure your development process is smooth.</p></li></ol><h2 id="How-Does-Sentry-Work"><a href="#How-Does-Sentry-Work" class="headerlink" title="How Does Sentry Work?"></a>How Does Sentry Work?</h2><p>Integrating Sentry is simple and quick, and once you set it up, it works seamlessly behind the scenes. Here’s a high-level look at how it works:</p><ol><li><p>Error Detection:<br>Sentry works by using SDKs specific to your tech stack. Once integrated, it automatically detects unhandled errors in your application.</p></li><li><p>Context Collection:</p><span class='pbg danger'>When an error is captured</span></li><li><p>Error Aggregation &amp; Notifications:<br>The error is aggregated and displayed on your Sentry dashboard. If you’ve set up notifications, your team will be alerted in real-time via Slack, email, or any other supported channel.</p></li><li><p>Resolution &amp; Feedback:<br>Once a developer resolves an issue, Sentry marks it as resolved. If the issue reoccurs, Sentry notifies you again, keeping you in the loop.</p></li></ol><h2 id="How-to-Get-Started-with-Sentry"><a href="#How-to-Get-Started-with-Sentry" class="headerlink" title="How to Get Started with Sentry"></a>How to Get Started with Sentry</h2><ol><li><p>Create an Account<br>Go to Sentry’s website and sign up for a free account. You’ll be guided through the setup process, and you can create a new project for your app. Accessing <a href="https://sentry.io/">https://sentry.io</a> to create your own account.</p></li><li><p>Install the SDK<br>Depending on the tech stack you’re using, you’ll need to install the appropriate SDK. For example:</p></li></ol><p>In React Application:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install @sentry/react</span><br></pre></td></tr></table></figure><p>Then, initialize Sentry in your app:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&quot;react&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">ReactDOM</span> <span class="keyword">from</span> <span class="string">&quot;react-dom&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> <span class="title class_">Sentry</span> <span class="keyword">from</span> <span class="string">&quot;@sentry/react&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">App</span> <span class="keyword">from</span> <span class="string">&quot;./App&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="title class_">Sentry</span>.<span class="title function_">init</span>(&#123;</span><br><span class="line">  <span class="attr">dsn</span>: <span class="string">&quot;https://&lt;key&gt;@sentry.io/&lt;project&gt;&quot;</span>,</span><br><span class="line">  <span class="comment">// This enables automatic instrumentation (highly recommended)</span></span><br><span class="line">  <span class="comment">// If you only want to use custom instrumentation:</span></span><br><span class="line">  <span class="comment">// * Remove the BrowserTracing integration</span></span><br><span class="line">  <span class="comment">// * add Sentry.addTracingExtensions() above your Sentry.init() call</span></span><br><span class="line">  <span class="attr">integrations</span>: [</span><br><span class="line">    <span class="title class_">Sentry</span>.<span class="title function_">browserTracingIntegration</span>(),</span><br><span class="line">    <span class="comment">// Or, if you are using react router, use the appropriate integration</span></span><br><span class="line">    <span class="comment">// See docs for support for different versions of react router</span></span><br><span class="line">    <span class="comment">// https://docs.sentry.io/platforms/javascript/guides/react/configuration/integrations/react-router/</span></span><br><span class="line">    <span class="title class_">Sentry</span>.<span class="title function_">reactRouterV6BrowserTracingIntegration</span>(&#123;</span><br><span class="line">      <span class="attr">useEffect</span>: <span class="title class_">React</span>.<span class="property">useEffect</span>,</span><br><span class="line">      useLocation,</span><br><span class="line">      useNavigationType,</span><br><span class="line">      createRoutesFromChildren,</span><br><span class="line">      matchRoutes,</span><br><span class="line">    &#125;),</span><br><span class="line">  ],</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For finer control of sent transactions you can adjust this value, or</span></span><br><span class="line">  <span class="comment">// use tracesSampler</span></span><br><span class="line">  <span class="attr">tracesSampleRate</span>: <span class="number">1.0</span>,</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Set tracePropagationTargets to control for which URLs distributed tracing should be enabled</span></span><br><span class="line">  <span class="attr">tracePropagationTargets</span>: [<span class="string">&#x27;localhost&#x27;</span>, <span class="regexp">/^https:/</span><span class="regexp">/yourserver.io/</span>api/],</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="title class_">ReactDOM</span>.<span class="title function_">render</span>(<span class="language-xml"><span class="tag">&lt;<span class="name">App</span> /&gt;</span></span>, <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&quot;root&quot;</span>));</span><br></pre></td></tr></table></figure><p>Sentry SDK supports multiple languages and frameworks, including React, Angular, Vue, .NET, Go, Python, SpringBoot, Next.js and more.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/tools/sentry-sdks.png" class="lazyload placeholder" data-srcset="/assets/images/tools/sentry-sdks.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Sentry SDK Integrations"/></div><span class="image-caption">Sentry SDK Integrations</span></div><ol start="3"><li><p>Integrate Error &amp; Performance Monitoring<br>Sentry works out of the box for most errors, but you can also use it to track performance. You can instrument specific parts of your code to track performance issues, like database queries or API calls.</p></li><li><p>Configure Notifications<br>Set up notification channels (e.g., <code>Slack</code>, <code>email</code>) so your team is alerted whenever a critical error occurs. Customize the rules to avoid spamming you with minor issues.</p></li><li><p>Monitor in the Dashboard<br>Once the integration is complete, you’ll start seeing error logs, performance metrics, and more on your Sentry dashboard. You can drill down into individual issues, see affected users, and get all the data you need to fix the bug fast.</p></li></ol><h2 id="Benefits-of-Using-Sentry-for-Developers"><a href="#Benefits-of-Using-Sentry-for-Developers" class="headerlink" title="Benefits of Using Sentry for Developers"></a>Benefits of Using Sentry for Developers</h2><ol><li><p>Faster Debugging:<br>With all the contextual data Sentry provides, debugging becomes faster. No more chasing elusive bugs—get right to the root cause.</p></li><li><p>Proactive Monitoring:<br>Monitor both errors and performance, which helps you prevent issues before they affect users. Sentry gives you the insights to optimize performance and fix bugs early.</p></li><li><p>Increased Collaboration:<br>Integrated workflows with tools like GitHub, JIRA, and Slack mean you and your team can stay on the same page, and bugs can be tracked, assigned, and resolved efficiently.</p></li><li><p>Free Tier Available:<br>Sentry offers a free plan with generous limits, so you can get started without any upfront costs. As your project grows, you can scale to a paid plan with more features.</p></li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Sentry is an invaluable tool for developers, offering real-time error tracking and powerful performance monitoring. By integrating Sentry into your workflow, you can catch and resolve errors faster, improve your app’s performance, and provide a better experience for your users.</p><p>So if you’re looking to streamline your debugging process, improve performance monitoring, and keep your app healthy, you can try sentry in your application!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/tools/sentry.png&quot; class=&quot;lazyload placeh</summary>
      
    
    
    
    <category term="Tools" scheme="https://stonefishy.github.io/categories/Tools/"/>
    
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
    <category term="Sentry" scheme="https://stonefishy.github.io/tags/Sentry/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to LangChain: Make AI Smarter and Easier to use</title>
    <link href="https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/"/>
    <id>https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/</id>
    <published>2024-11-12T13:49:12.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-image.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-image.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:600px;"/></div></div><p>Have you ever wondered how some apps and websites can have conversations with you, answer your questions? Many of these apps use <code>artificial intelligence (AI)</code>, like the chatbot you might use to ask questions or get advice. But creating these smart systems can be tricky. This is where a tool called <code>LangChain</code> comes in to help!</p><p><code>LangChain</code> is a framework that makes it easier for developers to build applications that use <code>AI models</code>, like chatbots or smart helpers. In this blog, we’re going to explain what LangChain is, how it works, and why it’s useful for making AI apps.</p><h2 id="What-is-LangChain"><a href="#What-is-LangChain" class="headerlink" title="What is LangChain?"></a>What is LangChain?</h2><p>LangChain is a tool for developers that helps them build applications using <code>large language models (LLMs)</code>—the same kind of AI that powers chatbots, writing assistants, and more. LLMs can understand and generate text in a way that sounds like a real person. However, using these models to make powerful apps can be complicated. LangChain makes it easier by offering ready-made building blocks to connect these models to other tools, data, and even databases.</p><p>Think of LangChain like a set of Lego blocks that you can use to build cool things with AI. It saves developers time by giving them ready-made pieces to use, rather than having to create everything from scratch.</p><h2 id="Features-of-LangChain"><a href="#Features-of-LangChain" class="headerlink" title="Features of LangChain"></a>Features of LangChain</h2><p>Let’s break down some of the cool features LangChain offers and how they help developers make smarter apps.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/langchain-features.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/langchain-features.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="LangChain Features"/></div><span class="image-caption">LangChain Features</span></div><ol><li><p><strong>Chains</strong>: Putting Multiple Steps Together<br>Imagine you have a robot that can help with math homework. The robot might need to do multiple things to solve a problem. First, it could look up the math formula, then solve the problem, and finally explain the answer. In LangChain, these steps are called chains.</p><blockquote><p>A chain is a sequence of actions where each step depends on the previous one. For example, you could create a chain where:</p><p>First, the app asks the AI to pull data from a website.<br>Then, it uses that data to answer a question.<br>Finally, it summarizes the answer for the user.</p></blockquote></li><li><p><strong>Prompt Management</strong>: Talking to AI the Right Way<br>When you talk to an AI, how you ask your question or give your instruction is really important. That’s called a prompt. LangChain helps developers make the best prompts by letting them create templates. These templates let developers easily change certain parts of the prompt without having to rewrite it every time.</p><blockquote><p>For example, if you wanted to ask the AI to summarize a story, you could have a prompt like this:</p><p>“Please summarize the following story: {story}”</p><p>In this template, {story} is a placeholder that can be replaced with any story you want the AI to summarize.</p></blockquote></li><li><p><strong>Agents</strong>: Letting AI Decide What to Do Next<br>Sometimes, a smart system needs to decide what to do next based on the information it gets. For example, if you ask an AI about the weather, it might decide to pull the latest weather data from the internet. This decision-making is done by agents.</p><blockquote><p>An agent is like a helper that looks at the information it gets and chooses the best action. LangChain helps developers build agents that can make these decisions automatically.</p></blockquote></li><li><p><strong>Memory</strong>: Remembering What Happened Before<br>Have you ever talked to a chatbot and then later felt like it forgot what you said earlier? That can make a conversation feel weird. <code>LangChain helps solve this problem by letting the AI remember what was said earlier in the conversation</code>. This feature is called memory.</p><blockquote><p>or example, if you ask a chatbot for homework help and then ask a follow-up question, LangChain can help the AI remember the first question and give a more useful answer based on that memory.</p></blockquote></li><li><p><strong>Integrations</strong>: Connecting to Other Tools and Websites<br>Sometimes, an AI app needs to talk to other systems to get more information. <span class='pbg success'>LangChain makes this easy by letting developers connect their AI app to other tools</span> This is like having a personal assistant that not only talks to you but also has access to tons of information online.</p><blockquote><p>For example, an AI app could pull up the latest sports scores, or check the weather for you, using real-time data from the internet.</p></blockquote></li><li><p><strong>Retrieval-Augmented Generation (RAG)</strong>: Getting Smarter Answers<br>LangChain also lets AI search for information in real-time. This is called retrieval-augmented generation (RAG). It allows the AI to look up the latest data, like news stories or facts, and use that information to create smarter answers.</p><blockquote><p>For example, if you ask about the latest trends in video games, the AI can search the web for the most up-to-date information and then explain it to you.</p></blockquote></li></ol><h2 id="Why-Do-Developers-Use-LangChain"><a href="#Why-Do-Developers-Use-LangChain" class="headerlink" title="Why Do Developers Use LangChain?"></a>Why Do Developers Use LangChain?</h2><p>There are several reasons why developers might want to use LangChain:</p><ol><li><p>Makes It Easier to Build AI Apps<br>Instead of starting from scratch, LangChain gives developers tools that speed up the process of creating AI apps. Developers can use LangChain’s building blocks to create powerful applications without needing to write everything by hand.</p></li><li><p>It’s Flexible<br>LangChain can be used for a wide variety of apps. Whether you want to build a chatbot, a smart search engine, or an app that helps you study, LangChain has tools that make it easier to put everything together.</p></li><li><p>Saves Time<br>Developers don’t have to spend a lot of time figuring out how to make an AI model work with a database or how to chain steps together. LangChain does much of the heavy lifting, so developers can focus on the fun and creative parts of building their apps.</p></li><li><p>It’s <code>Open-Source</code><br>LangChain is free for anyone to use and improve. It’s open-source, which means developers from all over the world can contribute to making it better. If you’re learning to code or want to help improve the tool, you can!</p></li></ol><h2 id="Real-World-Examples-of-LangChain"><a href="#Real-World-Examples-of-LangChain" class="headerlink" title="Real-World Examples of LangChain"></a>Real-World Examples of LangChain</h2><p>LangChain is already being used in many cool ways. Here are a few examples:</p><ol><li><p>Chatbots<br>Developers can use LangChain to build chatbots that remember previous conversations and can talk to you like a real person. For example, you could create a chatbot to help you study for a test, and it would remember what you’ve learned so far.</p></li><li><p>Smart Assistants<br>LangChain can help build systems that pull information from the internet and use AI to explain things in simple terms. For example, if you’re stuck on a science problem, an AI could look up the topic online and explain it to you in a way you understand.</p></li><li><p>Automated Content Creation<br>Some apps use LangChain to automatically write articles or summaries. For example, a news website could use LangChain to summarize long articles or pull out the key points from reports, saving readers time.</p></li><li><p>Personalized Search Engines<br>LangChain can be used to build search engines that don’t just give you a list of links but also summarize the best results for you. This could help you find the exact answer you need faster.</p></li></ol><h2 id="How-to-Get-Started-with-LangChain"><a href="#How-to-Get-Started-with-LangChain" class="headerlink" title="How to Get Started with LangChain"></a>How to Get Started with LangChain</h2><p>If you’re excited to try out LangChain, here’s how you can get started:</p><ol><li>Install Python: LangChain works with Python, a programming language that’s great for beginners.</li><li>Install LangChain: You can install LangChain by running the command <code>pip install langchain</code> in Python.</li><li>Start Building: Once LangChain is installed, you can start building your own AI-powered applications! LangChain has tutorials and guides to help you learn how to use it.</li></ol><p>For more information, check out the LangChain documentation at <a href="https://python.langchain.com/docs/introduction/">https://python.langchain.com/docs/introduction/</a></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>LangChain is a super helpful tool for developers who want to build cool apps powered by AI. It makes it easier to connect different parts of an app, like databases or the web, with a language model that can understand and generate text. Whether it’s helping with homework, answering questions, or building a chatbot, LangChain is a great way to build smarter, more interactive applications.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;/assets/images/ai-ml/langchain-image.png&quot; class=&quot;lazylo</summary>
      
    
    
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="LangChain" scheme="https://stonefishy.github.io/tags/LangChain/"/>
    
  </entry>
  
  <entry>
    <title>What is Prompt Engineering? Best Practices and Examples</title>
    <link href="https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/"/>
    <id>https://stonefishy.github.io/2024/11/05/what-is-prompt-engineer/</id>
    <published>2024-11-05T14:08:09.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophisticated, a new role has emerged in the AI ecosystem: <code>the Prompt Engineer</code>. The term might sound technical or niche, but it’s actually pivotal to leveraging AI models effectively. Whether you’re interacting with AI in your personal or professional life, the quality of the interaction largely depends on how well the prompt is designed. This article will explore what a prompt engineer does, the best practices for writing effective prompts, and provide examples comparing outputs with and without a prompt engineer’s expertise.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineering.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineering.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div><h2 id="What-is-a-Prompt-Engineer"><a href="#What-is-a-Prompt-Engineer" class="headerlink" title="What is a Prompt Engineer?"></a>What is a Prompt Engineer?</h2><p><em>A Prompt Engineer is someone who specializes in crafting, refining, and optimizing prompts to ensure that AI models respond with the most relevant,accurate,and actionable information.</em> The role requires a blend of creativity, technical understanding, and knowledge of the AI’s underlying model architecture.</p><p>In essence, the prompt engineer’s job is to “speak” the language of the AI model. Since AI models like <code>GPT-3</code> or <code>GPT-4</code> don’t “think” like humans, their responses depend heavily on how the question or task is framed. A prompt engineer ensures that the right context, constraints, and phrasing are in place to guide the model toward producing the most useful responses.</p><h2 id="Why-is-Prompt-Engineering-Important"><a href="#Why-is-Prompt-Engineering-Important" class="headerlink" title="Why is Prompt Engineering Important?"></a>Why is Prompt Engineering Important?</h2><p>While AI models are capable of generating human-like text and performing complex tasks, their outputs are highly sensitive to the structure of the prompt. The same AI model could provide vastly different answers depending on the way a question is asked. Prompt engineers understand this sensitivity and use it to maximize the effectiveness of the interaction with AI.</p><p>Here are some reasons why prompt engineering is important:</p><p><strong>Maximizing output quality</strong>: Well-designed prompts improve the accuracy, relevance, and clarity of responses.<br><strong>Reducing errors</strong>: By properly framing a prompt, prompt engineers can help reduce misunderstandings or irrelevant responses.<br><strong>Efficiency</strong>: Instead of relying on trial and error to get useful responses, prompt engineers streamline the interaction process, saving time and resources.<br><strong>Contextuality</strong>: A good prompt will provide the necessary context for the model, ensuring that the response is in line with the user’s expectations.</p><h2 id="The-Path-of-a-Prompt-Engineer"><a href="#The-Path-of-a-Prompt-Engineer" class="headerlink" title="The Path of a Prompt Engineer"></a>The Path of a Prompt Engineer</h2><p>The process that a prompt engineer follows to ensure optimal results involves several stages. Each stage builds upon the last, leading to an iterative cycle that refines both the prompt and the AI’s output. Here’s a breakdown of the typical path of a prompt engineer:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/prompt-engineer-path.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/prompt-engineer-path.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="The Path of a Prompt Engineer" style="width:800px;"/></div><span class="image-caption">The Path of a Prompt Engineer</span></div><h3 id="1-Task-Understanding"><a href="#1-Task-Understanding" class="headerlink" title="1.Task Understanding:"></a>1.Task Understanding:</h3><p>Before crafting any prompt, the first step is to fully understand the task at hand. This involves clarifying the user’s goal, determining the desired output format, and understanding the nuances of the request. A deep understanding of the problem ensures that the prompt engineer can craft a question or instruction that addresses all necessary aspects.</p><blockquote><p>Example: If the task is to generate a poem, the prompt engineer will need to understand the tone, style, and subject matter required.</p></blockquote><h3 id="2-Crafting-Prompts"><a href="#2-Crafting-Prompts" class="headerlink" title="2.Crafting Prompts:"></a>2.Crafting Prompts:</h3><p>The next step is to craft the prompt. This involves framing the task clearly, with enough specificity to guide the AI toward the desired output. Crafting an effective prompt is not about asking a single question, but about <em>providing the model with the right context, constraints, and direction</em>.</p><blockquote><p>Example: Instead of asking, “Write a poem,” a more specific prompt might be, “Write a rhyming poem about the beauty of autumn, focusing on imagery and feelings of nostalgia.”</p></blockquote><h3 id="3-Prompt-Alignment"><a href="#3-Prompt-Alignment" class="headerlink" title="3.Prompt Alignment:"></a>3.Prompt Alignment:</h3><p>At this stage, the prompt must be aligned with the intended outcome. This means considering the AI model’s strengths and limitations and ensuring that the prompt leads the AI to produce a response that fits the desired format, tone, and depth. The prompt should ensure the model understands the context of the task, as well as any constraints or preferences that need to be respected.</p><blockquote><p>Example: For a technical article, aligning the prompt would involve ensuring the language model knows to prioritize clarity, accuracy, and technical precision.</p></blockquote><h3 id="4-Optimizing-Prompt"><a href="#4-Optimizing-Prompt" class="headerlink" title="4.Optimizing Prompt:"></a>4.Optimizing Prompt:</h3><p>After alignment, the prompt may need further refinement. This step involves fine-tuning the wording, simplifying complex instructions, or narrowing down the scope to ensure that the prompt is as effective as possible. <em>Optimization often involves making the prompt more specific and reducing ambiguity.</em></p><blockquote><p>Example: “Write a 300-word summary of the research paper on AI ethics, emphasizing the ethical dilemmas and implications for technology companies.” This version is more optimized than a broad, vague instruction.</p></blockquote><h3 id="5-AI-Model-Processing"><a href="#5-AI-Model-Processing" class="headerlink" title="5.AI Model Processing:"></a>5.AI Model Processing:</h3><p>Once the optimized prompt is provided, the AI model processes it and generates a response. This is where the model applies its underlying machine learning architecture, leveraging its training data to formulate a response.</p><blockquote><p>Example: The AI will analyze the prompt, consider patterns in its training data, and produce a response based on its understanding of the language and context.</p></blockquote><h3 id="6-Generating-Output"><a href="#6-Generating-Output" class="headerlink" title="6.Generating Output:"></a>6.Generating Output:</h3><p>The AI model generates the initial output based on the prompt. Depending on the AI model’s capabilities, this output may vary in length, style, accuracy, or even relevance to the task.</p><blockquote><p>Example: If the task was to summarize a paper, the output might include key findings, conclusions, and references to methodology.</p></blockquote><h3 id="7-Output-Refinement"><a href="#7-Output-Refinement" class="headerlink" title="7.Output Refinement:"></a>7.Output Refinement:</h3><p>Once the output is generated, prompt engineers review and refine it. This may involve removing irrelevant information, adjusting tone, adding details, or improving clarity. In some cases, the output might need to be restructured to fit the desired format.</p><blockquote><p>Example: If the AI’s response contains tangential information or lacks clarity, the prompt engineer would reword it or fine-tune the output to better align with the user’s expectations.</p></blockquote><h3 id="8-Iterative-Improvement"><a href="#8-Iterative-Improvement" class="headerlink" title="8.Iterative Improvement:"></a>8.Iterative Improvement:</h3><p>Finally, the process of prompt engineering is iterative. After refining the output, prompt engineers analyze the effectiveness of the response and assess how the prompt can be improved for future tasks. This leads to continuous improvement, ensuring that future prompts are even more optimized, concise, and aligned with user needs.</p><blockquote><p>Example: The engineer might adjust the prompt for the next interaction to ensure more relevant details or a more focused response.</p></blockquote><h2 id="Key-Skills-and-Tools-of-a-Prompt-Engineer"><a href="#Key-Skills-and-Tools-of-a-Prompt-Engineer" class="headerlink" title="Key Skills and Tools of a Prompt Engineer"></a>Key Skills and Tools of a Prompt Engineer</h2><p>Prompt engineering requires a variety of skills:</p><p><strong>Understanding of Language Models</strong>:<br>A prompt engineer should have a deep understanding of how LLMs like GPT process language. Knowing their strengths and weaknesses allows for better prompt design.</p><p><strong>Communication Skills</strong>:<br>Effective communication is critical, as prompt engineers must be able to convey complex instructions in a way that the model can interpret clearly.</p><p><strong>Creativity and Experimentation</strong>:<br>Crafting effective prompts often requires trial and error, testing different phrasings and structures to see what works best.</p><p><strong>Analytical Thinking</strong>:<br>Understanding how different types of inputs influence the model’s outputs and iterating to improve results.</p><p>In addition to these skills, prompt engineers also use tools to test and refine their prompts. For instance, platforms like OpenAI’s Playground allow users to experiment with various prompts in real-time, while more advanced professionals might leverage APIs to automate or scale their prompt engineering work.</p><h2 id="Best-Practices-for-Prompt-Engineering"><a href="#Best-Practices-for-Prompt-Engineering" class="headerlink" title="Best Practices for Prompt Engineering"></a>Best Practices for Prompt Engineering</h2><p>There are several strategies that a prompt engineer can employ to get the most out of a language model. Below are some of the best practices:</p><ol><li><p><strong>Be Specific and Clear</strong>: Ambiguous prompts can confuse AI models, leading to vague or incorrect responses. Make sure the prompt is clear and as specific as possible.</p><blockquote><p>Example: Instead of asking, “Tell me about AI,” a more specific prompt would be, “Can you explain the difference between supervised and unsupervised learning in AI?”</p></blockquote></li><li><p><strong>Use Context Effectively</strong>: Providing context can guide the model to better understand the desired output.</p><blockquote><p>Example: Instead of saying, “Write a poem,” say, “Write a rhyming poem about the beauty of autumn with a melancholic tone.”</p></blockquote></li><li><p><strong>Limit the Scope</strong>: Sometimes, less is more. Limit the scope of the prompt to avoid overwhelming the model with too much information or too many instructions.</p><blockquote><p>Example: Instead of “Write an article about the importance of artificial intelligence in modern business, covering all aspects of AI from machine learning to natural language processing,” you could say, “Write a short article explaining the importance of AI in customer service.”</p></blockquote></li><li><p><strong>Test and Iterate</strong>: A prompt engineer should test various iterations of a prompt to identify the most effective structure.</p></li><li><p><strong>Give Examples</strong>: For tasks requiring specific output formats, include an example to guide the model.</p><blockquote><p>Example: If you want a bulleted list, you could say, “List the steps in a process to build a website. For example: Step 1: Plan the layout.”</p></blockquote></li><li><p><strong>Use Temperature and Max Tokens</strong>: Some models allow you to adjust the <code>temperature (which controls randomness)</code> and the <code>max tokens (which sets a character limit)</code> to control the output. These can be adjusted to fine-tune the model’s output.</p></li></ol><h2 id="Comparing-with-and-without-Prompt-Engineering"><a href="#Comparing-with-and-without-Prompt-Engineering" class="headerlink" title="Comparing with and without Prompt Engineering"></a>Comparing with and without Prompt Engineering</h2><p>Now let’s look at some concrete examples of how a well-crafted prompt versus a poorly constructed one can affect the outcome.</p><h3 id="Example-1-Writing-a-Research-Summary"><a href="#Example-1-Writing-a-Research-Summary" class="headerlink" title="Example 1: Writing a Research Summary"></a>Example 1: Writing a Research Summary</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize this research paper.”</p><p>The AI may generate a generic or overly simplistic summary, without capturing the key aspects of the paper, such as methodology, results, and conclusions.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Summarize the research paper titled ‘Exploring AI Ethics in Autonomous Vehicles.’ Focus on the methodology, key findings, and implications for policy. Keep the summary under 200 words.”</p><p>The AI’s response will be more targeted, concise, and aligned with the user’s expectations, providing a detailed summary that addresses the core aspects of the paper.</p><h3 id="Example-2-Writing-a-Creative-Story"><a href="#Example-2-Writing-a-Creative-Story" class="headerlink" title="Example 2: Writing a Creative Story"></a>Example 2: Writing a Creative Story</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a story.”</p><p>The story might lack direction, coherence, or creativity, leading to a generic or even nonsensical narrative.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a short story set in a post-apocalyptic world where humans are living on Mars. The protagonist is a scientist struggling with the ethical implications of using artificial intelligence to terraform the planet. Make the tone introspective and thought-provoking.”</p><p>The story produced will be richer, more engaging, and aligned with the specific context and themes the user wanted.</p><h3 id="Example-3-Asking-for-Code"><a href="#Example-3-Asking-for-Code" class="headerlink" title="Example 3: Asking for Code"></a>Example 3: Asking for Code</h3><ul><li>Without a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function.”</p><p>The AI may generate a simple function, but it may not meet the user’s needs or lack important features such as error handling or optimization.</p><ul><li>With a Prompt Engineer:</li></ul><p><strong>Prompt</strong>: “Write a Python function to validate an email address using regular expressions. The function should return True if the email is valid and False if it is invalid. It should also handle common edge cases such as missing domain names or incorrect characters.”</p><p>The AI’s response will be much more precise, including the correct implementation, error handling, and edge case considerations.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In the world of AI, a <code>Prompt Engineer</code> plays a critical role in ensuring that AI models deliver optimal results. The expertise of prompt engineers can dramatically influence the quality, relevance, and accuracy of responses from language models like <code>GPT-4</code>. By following best practices—such as being specific, providing context, testing different iterations, and using examples—they can significantly improve the interaction between humans and AI.</p><p>As AI continues to evolve, the role of prompt engineering will become even more important, helping users and businesses unlock the full potential of artificial intelligence. Whether it’s writing, problem-solving, or complex technical tasks, the way we interact with AI will increasingly depend on how well we craft our prompts.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;As artificial intelligence (AI) models, especially large language models (LLMs) like OpenAI’s GPT series, have become increasingly sophis</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
    <category term="GPT-3" scheme="https://stonefishy.github.io/tags/GPT-3/"/>
    
    <category term="Prompt Engineering" scheme="https://stonefishy.github.io/tags/Prompt-Engineering/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Azure OpenAI GPT-4 API Chat Role Usage</title>
    <link href="https://stonefishy.github.io/2024/11/01/understanding-the-azure-openai-gpt-4-api-role/"/>
    <id>https://stonefishy.github.io/2024/11/01/understanding-the-azure-openai-gpt-4-api-role/</id>
    <published>2024-11-01T10:34:01.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p><code>Azure OpenAI</code> is a service provided by Microsoft that integrates OpenAI’s advanced language models into the Azure cloud platform. It allows developers to access and use OpenAI’s capabilities, such as natural language processing, code generation, and more, through Azure’s infrastructure.</p><p>Recently, we have deployed our first version of the OpenAI <code>GPT-4</code> model into the Azure cloud platform. This model is a powerful natural language model that can generate text based on a given prompt.</p><h2 id="What-is-GPT-4"><a href="#What-is-GPT-4" class="headerlink" title="What is GPT-4?"></a>What is GPT-4?</h2><p><code>GPT-4</code> is a transformer-based language model that was developed by OpenAI. It is a powerful language model that can generate text based on a given prompt. It has been trained on a large dataset of text and can generate coherent and engaging text that is often considered to be the next big thing in language models.</p><h2 id="How-can-I-use-the-GPT-4-API"><a href="#How-can-I-use-the-GPT-4-API" class="headerlink" title="How can I use the GPT-4 API?"></a>How can I use the GPT-4 API?</h2><p>To use the GPT-4 API, you need to follow these steps:</p><ol><li>Create an Azure account.</li><li>Create a resource group.</li><li>Create a new OpenAI resource.</li><li>Generate an API key.</li><li>Use the API key to make API requests.</li></ol><h3 id="1-Create-an-Azure-account"><a href="#1-Create-an-Azure-account" class="headerlink" title="1. Create an Azure account"></a>1. Create an Azure account</h3><p>To use the GPT-4 API, you need to have an Azure account. If you don’t have one, you can create one for free by following the steps in the <a href="https://azure.microsoft.com/en-us/free/">Azure sign-up page</a>.</p><h3 id="2-Create-a-resource-group"><a href="#2-Create-a-resource-group" class="headerlink" title="2. Create a resource group"></a>2. Create a resource group</h3><p>Create a resource group to organize your Azure resources. To create a new resource group, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>Resource groups</code> option in the left-hand menu.</li><li>Click on the <code>+ Create</code> button.</li><li>Enter a name for your resource group and select your subscription.</li><li>Click on the <code>Review + create</code> button.</li></ol><h3 id="3-Create-a-new-OpenAI-resource"><a href="#3-Create-a-new-OpenAI-resource" class="headerlink" title="3. Create a new OpenAI resource"></a>3. Create a new OpenAI resource</h3><p>To create a new OpenAI resource, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>Create a resource</code> button.</li><li>Search for <code>OpenAI</code> in the search bar.</li><li>Click on the <code>OpenAI</code> resource.</li><li>Click on the <code>Create</code> button.</li><li>Enter a name for your OpenAI resource and select your subscription.</li><li>Select the resource group you created earlier.</li><li>Select the pricing tier.</li><li>Click on the <code>Create</code> button.</li></ol><h3 id="4-Generate-an-API-key"><a href="#4-Generate-an-API-key" class="headerlink" title="4. Generate an API key"></a>4. Generate an API key</h3><p>To generate an API key, follow these steps:</p><ol><li>Go to the <a href="https://portal.azure.com/">Azure portal</a>.</li><li>Click on the <code>All resources</code> option in the left-hand menu.</li><li>Search for your OpenAI resource.</li><li>Click on the resource.</li><li>Click on the <code>Show access keys</code> button.</li><li>Copy the <code>Key 1</code> value.</li></ol><h3 id="5-Use-the-API-key-to-make-API-requests"><a href="#5-Use-the-API-key-to-make-API-requests" class="headerlink" title="5. Use the API key to make API requests"></a>5. Use the API key to make API requests</h3><p>To make API requests, we need to include the API key in the request headers. Here’s an example of how to make a request to the GPT-4 API with REST styles. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="variable">$AZURE_OPENAI_ENDPOINT</span>/openai/deployments/gpt-4o/chat/completions?api-version=2023-07-01-preview \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;api-key: <span class="variable">$AZURE_OPENAI_API_KEY</span>&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;&quot;messages&quot;:[&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;There are 5 classifications: Suggestion, Meanless, Compliment, Complaint, Please provide a classification for user input.&quot;&#125;,&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Does Azure OpenAI support customer managed keys?&quot;&#125;,&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;A classification word&quot;&#125;,&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;its great and easy to use&quot;&#125;]&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>Place your API key and endpoint in the appropriate variables, and update which deployments model (gpt-4, gpt-4o or other models) and model version of your endpoint is using.</p><p>The Azure OpenAI also supports multiple programming languages, including <code>Python</code>, <code>JavaScript</code>, and <code>C#</code>. You can use the API to generate text in your preferred programming language.</p><h2 id="GPT-4-Chat-Roles"><a href="#GPT-4-Chat-Roles" class="headerlink" title="GPT-4 Chat Roles"></a>GPT-4 Chat Roles</h2><p>In above message parameter, you may notice thata there are three roles: <code>system</code>, <code>user</code>, and <code>assistant</code>. The GPT-4 API supports three chat roles. Let digger deeper into each role:</p><p><strong>System</strong>: This role sets the context or guidelines for the conversation. It’s where you can specify instructions or constraints for how the assistant should behave throughout the interaction.</p><p><strong>User</strong>: This role represents the input from the person interacting with the model. Any questions or prompts posed by the user fall under this role.</p><p><strong>Assistant</strong>: This role is for the model’s responses. It contains the output generated by the assistant based on the user input and the context provided by the system.</p><p>In another word. The <code>system</code> role sets the context, the <code>user</code> role represents the input, and the <code>assistant</code> role contains the output.</p><blockquote><p>Use system to define the conversation’s tone, behavior, or rules.<br>Use user for all queries or statements made by the person.<br>Use assistant for the model’s replies.</p></blockquote><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Let’s say we want to classify the product feedback classification as <code>Suggestion</code>, <code>Meanless</code>, <code>Compliment</code>, <code>Complaint</code>, or <code>Others</code>. We can use the GPT-4 API to generate text based on the given prompt and classify the feedback.</p><p>First, we define the context or guidelines to let the assistant know what result we want to achieve. Given below content to the <code>system</code> role.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;There are 5 classifications: Suggestion, Meanless, Compliment, Complaint, Please provide a classification for user input.&quot;&#125;,</span><br></pre></td></tr></table></figure><p>And, we only the <code>OpenAI</code> to reply me the classification word when user input is provided. So we define the <code>assistant</code> role as <code>classification word</code>.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;A classification word&quot;&#125;</span><br></pre></td></tr></table></figure><p>Now, we can ask the user to provide the feedback and provide the <code>user</code> role.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;its great and easy to use&quot;&#125;</span><br></pre></td></tr></table></figure><p>After the conversation, the <code>assistant</code> role will provide the classification word as <code>Compliment</code>. You will notice that there is a piece of json indicates the <code>assistant</code> role content value in the response. The OpenAI gpt-4o model knows “its great and easy to use” is a “Compliment” and provides the classification word as “Compliment”.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;message&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Compliment&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/openai-chat-role-api-usage-example-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/openai-chat-role-api-usage-example-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Classification - its great and easy to use" style="width:800px;"/></div><span class="image-caption">Classification - its great and easy to use</span></div><p>Let’s try another user input.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I&#x27;m in your walls&quot;&#125;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/openai-chat-role-api-usage-example-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/openai-chat-role-api-usage-example-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Classification - I'm in your walls" style="width:800px;"/></div><span class="image-caption">Classification - I'm in your walls</span></div><p>The <code>assistant</code> role will provide the classification word as <code>Meanless</code>. Because this input is not meanful for any product feedback.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article, we have explored the role of the Azure OpenAI GPT-4 API and how it can be used to generate text. We have also learned about the chat roles and how to use them to classify the product feedback.</p>]]></content>
    
    
    <summary type="html">In this article, we will explore the role of the Azure OpenAI GPT-4 API and how it can be used to generate text.</summary>
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="OpenAI" scheme="https://stonefishy.github.io/tags/OpenAI/"/>
    
    <category term="Azure" scheme="https://stonefishy.github.io/tags/Azure/"/>
    
    <category term="GPT-4" scheme="https://stonefishy.github.io/tags/GPT-4/"/>
    
  </entry>
  
  <entry>
    <title>Data Analysis Chart by Generative AI</title>
    <link href="https://stonefishy.github.io/2024/10/29/data-analysis-chart-by-generative-ai/"/>
    <id>https://stonefishy.github.io/2024/10/29/data-analysis-chart-by-generative-ai/</id>
    <published>2024-10-29T14:18:48.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>In data analysis, we often need to create charts to visualize the data by using BI tools, such as <code>Tableau</code>, <code>Power BI</code>, <code>AWS Quicksight</code>, or <code>Qlik Sense</code>. These tools allow us to create interactive and visually appealing charts, which can help us to identify patterns and trends in the data.</p><h2 id="General-Solution-Architecture-for-Data-Analysis-BI-Chart"><a href="#General-Solution-Architecture-for-Data-Analysis-BI-Chart" class="headerlink" title="General Solution Architecture for Data Analysis BI Chart"></a>General Solution Architecture for Data Analysis BI Chart</h2><p>The general data analysis BI chart solution architecture like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-general-arch.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-general-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="General Solution Architecture for Data Analysis BI Chart" style="width:800px;"/></div><span class="image-caption">General Solution Architecture for Data Analysis BI Chart</span></div>.<p>Usually, the engieering create business chart by using BI tools after data is ETL proceseed. If the business want to see the data distribution chart, they need to ask the data engineer to create the chart. The data engineer will create the chart using BI tools and share it with the business. This may take some time and effort.</p><h2 id="Solution-Architecture-for-Data-Analysis-BI-Chart-by-Generative-AI"><a href="#Solution-Architecture-for-Data-Analysis-BI-Chart-by-Generative-AI" class="headerlink" title="Solution Architecture for Data Analysis BI Chart by Generative AI"></a>Solution Architecture for Data Analysis BI Chart by Generative AI</h2><p>Think about the scenario where the business want to see the data distribution chart without the data engineer’s help. How can we create the chart without the data engineer’s help?</p><p>One way to create the data distribution chart without the data engineer’s help is to use a generative AI model. The business just need to describe what the data they want to see and want to display as which chart type. The generative AI application will create the chart for them.</p><p>The core important thing we need to let the GenAI to understand user’s natural language and generate the information which application can be use. The solution architecture like below:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-AI-arch.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-AI-arch.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AI Solution Architecture for Data Analysis BI Chart" style="width:800px;"/></div><span class="image-caption">AI Solution Architecture for Data Analysis BI Chart</span></div>.<p>The AI application will take the user’s natural language as input and generate the chart for them. The AI application will use the following steps to generate the chart:</p><ol><li>Understand the user’s natural language and generate the chart title, chart type and chart related sql.</li><li>Connect to the database or dataset and execute the chart related sql to get the data.</li><li>Use the data to create the chart using the chart type.</li></ol><p>The AI model could be <code>ChatGPT</code>, <code>OpenAI</code> or <code>Claude</code> model. The AI model will generate the chart related sql, chart type and chart title based on the user’s natural language. The AI model will use the chart type to create the chart.</p><p>For example, if the user’s natural language is “Show the distribution of the sales by product category”, the AI application will generate the chart title as “Sales Distribution by Product Category” and chart type as “Bar Chart”. The AI application will execute the following sql to get the data:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> product_category, <span class="built_in">SUM</span>(sales) <span class="keyword">as</span> total_sales</span><br><span class="line"><span class="keyword">FROM</span> sales_data</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> product_category</span><br></pre></td></tr></table></figure><p>Below is a demo to generate the chart for the user’s natural language base on testing sample data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>User input natural language: </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;I want to see the distribution of all product categories with duplicate devices removed, and exclude the empty category, please display it in a pie chart.&quot;</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-1a.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-1a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>The AI model response below base on the user’s natural language and prompts.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    &#x27;sql&#x27;<span class="punctuation">:</span> <span class="string">&quot;SELECT category, COUNT(DISTINCT macaddress) as device_count FROM device_demo_data WHERE category != &#x27;&#x27; GROUP BY category ORDER BY device_count DESC&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    &#x27;chart&#x27;<span class="punctuation">:</span> &#x27;pie&#x27;<span class="punctuation">,</span> </span><br><span class="line">    &#x27;title&#x27;<span class="punctuation">:</span> &#x27;Distribution of Unique Devices by Product Category&#x27;</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>There is a question, how the AI model know to generate this data format for us? Actually it is because we provide the prompts to the AI model. The prompts will guide the AI model to generate the chart related sql, chart type and chart title. Below is sample prompts:</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">You are a data analyst. Below is the table structure information about devices reported data. I will ask you questions, and then please generate the json data format &#123;&#x27;sql&#x27;:&#x27;&#x27;,&#x27;chart&#x27;:&#x27;table&#x27;,&#x27;title&#x27;:&#x27;&#x27;&#125; based on the questions I asked. </span><br><span class="line">Emphasize: I only need this json data format. The &#x27;sql&#x27; value is used by AWS Athena to query and generate the chart data. </span><br><span class="line">The &#x27;chart&#x27; value is the chart type, &#x27;numeric&#x27; represents a just a number, &#x27;table&#x27; represents a table chart, &#x27;pie&#x27; represents a pie chart, &#x27;bar&#x27; represents a bar chart, &#x27;line&#x27; represents a line chart. </span><br><span class="line">The &#x27;title&#x27; value is the chart title. Please remember, I only need the json string format data, don&#x27;t need other sentence.</span><br><span class="line">CREATE EXTERNAL TABLE `device_demo_data`(</span><br><span class="line">  `macaddress` string COMMENT &#x27;设备mac地址 / The device macaddress&#x27;, </span><br><span class="line">  `productname` string COMMENT &#x27;设备产品名称 / The device product name&#x27;, </span><br><span class="line">  `category` string COMMENT &#x27;设备产品的分类 / The device product category&#x27;, </span><br><span class="line">  `country` string COMMENT &#x27;设备所在的国家 / The country where the device is located&#x27;, </span><br><span class="line">  `region` string COMMENT &#x27;设备上传数据所在的区域 / The region where the device data is reported&#x27;, </span><br><span class="line">  `default_region` string COMMENT &#x27;设备出厂设置的默认区域 / The default region set by the device&#x27;, </span><br><span class="line">  `oneosversion` string COMMENT &#x27;设备OneOS的版本号 / The OneOS version of the device&#x27;, </span><br><span class="line">  `firmwareversion` string COMMENT &#x27;设备的固件版本号 / The firmware version of the device&#x27;, </span><br><span class="line">  `officialversion` string COMMENT &#x27;设备是否是官方的发布版本，1为官方版本， 0为非官方版本 / Whether the device is an official release, 1 for official version, 0 for non-official version&#x27;, </span><br><span class="line">  `createtime` string COMMENT &#x27;设备上报数据的日期, 数据类型是字符串，日期格式是2024-09-01，表示2024年9月1日 / The date when the device reported data, the data type is string, the date format is 2024-09-01, which means September 1, 2024&#x27;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>We tell AI model the data schema and each field means, and indicate only need the json format response with specific field. Once the AI model generate the response, we can use it to create the chart for the user’s natural language.</p><p>We can also generate the line chart base on time line.</p><p>User input natural language: </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">How many distinct devices reported every week, exclude the empty date, display the data in line graph</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-test-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-test-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<p>For the front-end UI to display the chart, we can use some chart library like <code>Echarts</code>, <code>Hightcharts</code>, <code>D3.js</code> or <code>Chart.js</code>. The front-end UI display the chart base on chart type and the data which queried by SQL.</p><p>All these generated charts can be added into dashboard.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/bi-chart-by-ai-dashboard.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/bi-chart-by-ai-dashboard.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="width:800px;"/></div></div>.<h2 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h2><p>As you can see, the AI solution architecture is a new way to create BI chart. However, it still has some limitations. It can not generate the complex chart which like some BI tools advanced chart fucntionality. But it is still a good start to create the chart for business users.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In data analysis, we often need to create charts to visualize the data by using BI tools, such as &lt;code&gt;Tableau&lt;/code&gt;, &lt;code&gt;Power BI&lt;/c</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>The Intelligent SQL Generator base on Spring AI with AWS Bedrock</title>
    <link href="https://stonefishy.github.io/2024/10/23/intelligent-sql-generator-base-on-spring-ai-with-aws-bedrock/"/>
    <id>https://stonefishy.github.io/2024/10/23/intelligent-sql-generator-base-on-spring-ai-with-aws-bedrock/</id>
    <published>2024-10-23T15:01:12.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>The generative AI is a type of artificial intelligence (AI) that can learn from data and generate new data. In this article, we will discuss how to build an intelligent SQL generator using <code>Spring AI</code> and <code>AWS Bedrock</code>. For example, the application able to provide the data sql to us after we input the natural language questions, and we can query the data by using the sql, even display the chart base on data queried.</p><h2 id="Spring-AI"><a href="#Spring-AI" class="headerlink" title="Spring AI"></a>Spring AI</h2><p>The <code>Spring AI</code> is a project of <code>Spring</code>. It support for all major AI Model providers such as <code>Anthropic</code>, <code>OpenAI</code>, <code>Microsoft</code>, <code>Amazon</code>, <code>Google</code>, and <code>Ollama</code>. Model type supports such as <code>Chart Completion</code>, <code>Text to Image</code>, <code>Text to Speech</code>, <code>Translation</code>, <code>Audio Transcription</code> and so on. It make it easy to integrate AI models into the application.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/spring-ai.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/spring-ai.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Spring AI" style="width:500px;"/></div><span class="image-caption">Spring AI</span></div><h2 id="AWS-Bedrock"><a href="#AWS-Bedrock" class="headerlink" title="AWS Bedrock"></a>AWS Bedrock</h2><p>Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case. It contains <code>Anthropic</code> (<code>Claude</code>), <code>Meta</code> (<code>Llama</code>) and <code>Stability AI</code> models. In this blog, we will use <code>Claude</code> AI model of <code>Anthropic</code> to build our intelligent SQL generator.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-ai.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-ai.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock" style="width:600px;"/></div><span class="image-caption">AWS Bedrock</span></div><h2 id="Building-Intelligent-SQL-Generator"><a href="#Building-Intelligent-SQL-Generator" class="headerlink" title="Building Intelligent SQL Generator"></a>Building Intelligent SQL Generator</h2><p>Assuming we’re data analyzer, we have product_sales, products and customers three tables data in mysql. And we want to query the data by input natural language instead of write specific SQL manually. We can use AI to understand user natural langauge to generate the SQL base on table schemas. Let’s get start. </p><h3 id="Create-a-new-Spring-Boot-project"><a href="#Create-a-new-Spring-Boot-project" class="headerlink" title="Create a new Spring Boot project"></a>Create a new Spring Boot project</h3><p>Create a <code>Spring Boot</code> project with restful api, add the following dependencies in maven <code>pom.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.ai<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-ai-bedrock-ai-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The <code>spring-ai-bedrock-ai-spring-boot-starter</code> is library that provides integration with <code>AWS Bedrock</code> models in <code>Spring AI</code>.</p><h3 id="Configure-AWS-Bedrock-configuraitons"><a href="#Configure-AWS-Bedrock-configuraitons" class="headerlink" title="Configure AWS Bedrock configuraitons"></a>Configure AWS Bedrock configuraitons</h3><p>In application.properties, configur below configurations.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=spring-ai-datasql</span><br><span class="line">spring.ai.bedrock.aws.region=us-east-1</span><br><span class="line">spring.ai.bedrock.aws.timeout=5m</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.enabled=true</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.options.max-tokens=4000</span><br><span class="line"></span><br><span class="line"># config below AWS credential key, configure it in Java environments or System environments</span><br><span class="line">spring.ai.bedrock.aws.access-key=$&#123;AWS_ACCESS_KEY_ID&#125;</span><br><span class="line">spring.ai.bedrock.aws.secret-key=$&#123;AWS_SECRET_ACCESS_KEY&#125;</span><br></pre></td></tr></table></figure><h3 id="Prepare-prompts-for-AI"><a href="#Prepare-prompts-for-AI" class="headerlink" title="Prepare prompts for AI"></a>Prepare prompts for AI</h3><p>Since we only need AI to generate the SQL base on mysql table schema. So we need prepare prompts to <code>AI</code> to fully understand our requirements. Below is <code>prompts.txt</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">There are 3 mysql tables schema product_sales, products, customers.</span><br><span class="line">CREATE TABLE product_sales (</span><br><span class="line">    sale_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    product_id INT NOT NULL,</span><br><span class="line">    sale_date DATETIME DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">    price DECIMAL(10, 2) NOT NULL,</span><br><span class="line">    customer_id INT,</span><br><span class="line">    region VARCHAR(100),</span><br><span class="line">    FOREIGN KEY (product_id) REFERENCES products(product_id),</span><br><span class="line">    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE products (</span><br><span class="line">    product_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    product_name VARCHAR(100),</span><br><span class="line">    product_category VARCHAR(100)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE customers (</span><br><span class="line">    customer_id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    customer_name VARCHAR(100)</span><br><span class="line">);</span><br><span class="line">I will ask you question, please base on table schema to generate the SQL text in single line, please note I only need full correct sql text, do not</span><br><span class="line">need other text or any other characters.</span><br></pre></td></tr></table></figure><p>In above prompts, you can see it tells AI we only need SQL text base on the 3 mysql table schemas.</p><h3 id="Core-Code"><a href="#Core-Code" class="headerlink" title="Core Code"></a>Core Code</h3><p>Create a restful controller and pass the prompts and user input message to AI model.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spring.ai.datasql.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.ai.bedrock.anthropic3.BedrockAnthropic3ChatModel;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.*;</span><br><span class="line"><span class="keyword">import</span> spring.ai.datasql.service.PromptService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SQLGenController</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BedrockAnthropic3ChatModel chatModel;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> PromptService prompts;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SQLGenController</span><span class="params">(BedrockAnthropic3ChatModel chatModel)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.chatModel = chatModel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/ai/sql&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Map <span class="title function_">generate</span><span class="params">(<span class="meta">@RequestBody</span> String message)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">newMsg</span> <span class="operator">=</span> prompts.getContent() + message;</span><br><span class="line">        <span class="keyword">return</span> Map.of(<span class="string">&quot;sql&quot;</span>, chatModel.call(newMsg));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, we inject <code>BedrockAnthropic3ChatModel</code> which is <code>Anthropic</code> model of <code>AWS Bedrock</code> provided by <code>Spring AI</code>. We also inject <code>PromptService</code> which is a service to read prompts.<br>In <code>generate</code> method, we read prompts from <code>PromptService</code> and append user input message to it. Then we call <code>chatModel.call</code> method to generate the SQL text.</p><p>Code of <code>PromptService</code> to read prompts from file.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spring.ai.datasql.service;</span><br><span class="line"><span class="keyword">import</span> jakarta.annotation.PostConstruct;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Files;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Paths;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PromptService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;classpath:prompts.txt&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> org.springframework.core.io.Resource resource;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String fileContent;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        fileContent = <span class="keyword">new</span> <span class="title class_">String</span>(Files.readAllBytes(Paths.get(resource.getURI())));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getContent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fileContent;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Run-the-application"><a href="#Run-the-application" class="headerlink" title="Run the application"></a>Run the application</h3><p>Run the application and test the API by sending a request with user input message. We may encounter below errors.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-model-can-not-access.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-model-can-not-access.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock Model can not access"/></div><span class="image-caption">AWS Bedrock Model can not access</span></div><p>This is because the <code>spring.ai.bedrock.anthropic3.chat.model</code> in  current Spring AI version default value is <code>anthropic.claude-3-sonnet-20240229-v1:0</code>. Let’s check the anthropic available Claude models in AWS Bedrock. Here we use <code>Claude 3.5</code> AI model.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/aws-bedrock-claude-model-id.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/aws-bedrock-claude-model-id.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Bedrock Anthropic Claude Model Id"/></div><span class="image-caption">AWS Bedrock Anthropic Claude Model Id</span></div><p>Copy this model id and update the <code>spring.ai.bedrock.anthropic3.chat.model</code> in <code>application.properties</code> file. The fully updated <code>application.properties</code> file should be like below.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=spring-ai-datasql</span><br><span class="line">spring.ai.bedrock.aws.region=us-east-1</span><br><span class="line">spring.ai.bedrock.aws.timeout=5m</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.enabled=true</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.options.max-tokens=4000</span><br><span class="line">spring.ai.bedrock.anthropic3.chat.model=anthropic.claude-3-5-sonnet-20240620-v1:0</span><br><span class="line"></span><br><span class="line"># config below AWS credential key, it also can be configure in Java environments or System environments</span><br><span class="line">spring.ai.bedrock.aws.access-key=$&#123;AWS_ACCESS_KEY_ID&#125;</span><br><span class="line">spring.ai.bedrock.aws.secret-key=$&#123;AWS_SECRET_ACCESS_KEY&#125;</span><br></pre></td></tr></table></figure><p>Now, we can run the application and test the API.</p><h4 id="Test-Example-1"><a href="#Test-Example-1" class="headerlink" title="Test Example 1"></a>Test Example 1</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">What&#x27;s the total prices of product sales ?</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><p>The response will be like below.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(price) <span class="keyword">FROM</span> product_sales;</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-1.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>The <code>AI</code> model can generate the SQL text base on user input message.</p><h4 id="Test-Example-2"><a href="#Test-Example-2" class="headerlink" title="Test Example 2"></a>Test Example 2</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">How many customers by our products? I only need unique customers.</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id) <span class="keyword">FROM</span> product_sales</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-2.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-3"><a href="#Test-Example-3" class="headerlink" title="Test Example 3"></a>Test Example 3</h4><p><strong>Input:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I want to see the total sales prices for each product categories.</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> product_category, <span class="built_in">SUM</span>(price) <span class="keyword">AS</span> total_sales <span class="keyword">FROM</span> product_sales <span class="keyword">JOIN</span> products <span class="keyword">ON</span> product_sales.product_id <span class="operator">=</span> products.product_id <span class="keyword">GROUP</span> <span class="keyword">BY</span> product_category;</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-3.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-4"><a href="#Test-Example-4" class="headerlink" title="Test Example 4"></a>Test Example 4</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please show me all sales data which contains price, sales date, customer name and product name and product categories</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ps.price, ps.sale_date, c.customer_name, p.product_name, p.product_category <span class="keyword">FROM</span> product_sales ps <span class="keyword">JOIN</span> products p <span class="keyword">ON</span> ps.product_id <span class="operator">=</span> p.product_id <span class="keyword">JOIN</span> customers c <span class="keyword">ON</span> ps.customer_id <span class="operator">=</span> c.customer_id</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-4.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Test-Example-5"><a href="#Test-Example-5" class="headerlink" title="Test Example 5"></a>Test Example 5</h4><p><strong>Input:</strong> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please show total sales prices of each product category on 2nd quarter this year</span><br></pre></td></tr></table></figure><p><strong>Output:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> p.product_category, <span class="built_in">SUM</span>(ps.price) <span class="keyword">AS</span> total_sales <span class="keyword">FROM</span> product_sales ps <span class="keyword">JOIN</span> products p <span class="keyword">ON</span> ps.product_id <span class="operator">=</span> p.product_id <span class="keyword">WHERE</span> <span class="keyword">YEAR</span>(ps.sale_date) <span class="operator">=</span> <span class="keyword">YEAR</span>(CURDATE()) <span class="keyword">AND</span> QUARTER(ps.sale_date) <span class="operator">=</span> <span class="number">2</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> p.product_category</span><br></pre></td></tr></table></figure><p><strong>Postman Screenshot:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/ai-ml/gen-sql-by-ai-test-5.png" class="lazyload placeholder" data-srcset="/assets/images/ai-ml/gen-sql-by-ai-test-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>As you can see the <code>AI</code> model can generate the SQL text base on user input message. Base on this function, we can download the data from mysql or display the chart base on data queried. It’s good for business analyst to query the data by natural language.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The generative AI is a type of artificial intelligence (AI) that can learn from data and generate new data. In this article, we will disc</summary>
      
    
    
    
    <category term="AI/ML" scheme="https://stonefishy.github.io/categories/AI-ML/"/>
    
    
    <category term="Java" scheme="https://stonefishy.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://stonefishy.github.io/tags/Spring/"/>
    
    <category term="AI" scheme="https://stonefishy.github.io/tags/AI/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
    <category term="Spring AI" scheme="https://stonefishy.github.io/tags/Spring-AI/"/>
    
  </entry>
  
  <entry>
    <title>The useEffect of React Runs Twice in Development Mode.</title>
    <link href="https://stonefishy.github.io/2024/10/16/the-useeffect-of-react-runs-twice-in-development-mode/"/>
    <id>https://stonefishy.github.io/2024/10/16/the-useeffect-of-react-runs-twice-in-development-mode/</id>
    <published>2024-10-16T16:23:44.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>Have you noticed that your <code>useEffect</code> hook of <code>React</code> runs twice when the page first loads in development mode? This occurs because since <code>React 18</code>, it can be confusing, especially for new developers. Let’s explore why this happens and what it means.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-hook-useEffect.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-hook-useEffect.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React Hook useEffect" style="width:800px;"/></div><span class="image-caption">React Hook useEffect</span></div><h2 id="What-is-useEffect"><a href="#What-is-useEffect" class="headerlink" title="What is useEffect?"></a>What is <code>useEffect</code>?</h2><p><code>useEffect</code> is a hook that allows you to perform side effects in your components. Side effects can be things like <strong>fetching data</strong>, <strong>subscribing to events</strong>, or <strong>changing the DOM</strong>. This hook takes two arguments:</p><ol><li>A function to run your side effect.</li><li>An optional array of dependencies that tells React when to run the effect again.</li></ol><p>Here’s a simple example of useEffect in action:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; useEffect, useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">ExampleComponent</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [count, setCount] = <span class="title function_">useState</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Effect has been executed&#x27;</span>);</span><br><span class="line">    <span class="comment">// Side effect logic here</span></span><br><span class="line">  &#125;, [count]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">p</span>&gt;</span>You clicked &#123;count&#125; times<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;()</span> =&gt;</span> setCount(count + 1)&#125;&gt;Click me<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In above code, the log ‘Effect has been executed’ will be printed to the console twice when the component is first render on development mode.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/react/react-useEffect-runs-twice.png" class="lazyload placeholder" data-srcset="/assets/images/react/react-useEffect-runs-twice.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="React useEffect runs twice in development mode"/></div><span class="image-caption">React useEffect runs twice in development mode</span></div><h2 id="Why-Does-useEffect-Run-Twice-in-Development-Mode"><a href="#Why-Does-useEffect-Run-Twice-in-Development-Mode" class="headerlink" title="Why Does useEffect Run Twice in Development Mode?"></a>Why Does useEffect Run Twice in Development Mode?</h2><p>When you run your React app in development mode, you might see that the useEffect runs twice when the component loads for the first time. This can be confusing, especially for new developers.</p><h3 id="Reasons-for-the-Double-Execution"><a href="#Reasons-for-the-Double-Execution" class="headerlink" title="Reasons for the Double Execution"></a>Reasons for the Double Execution</h3><p><strong>Strict Mode:</strong> This behavior is part of React’s <code>Strict Mode</code>. It purposely runs certain lifecycle methods and hooks like useEffect twice during development. This helps check if your code can handle side effects correctly.</p><p><strong>Testing Effects:</strong> By running the effect two times, React tests if your side effects can handle being called multiple times without causing bugs. This helps catch problems early.</p><h3 id="What-Happens-in-Production"><a href="#What-Happens-in-Production" class="headerlink" title="What Happens in Production?"></a>What Happens in Production?</h3><span class='pbg danger'>The double call only happens in development mode. When you make your app for production</span><h2 id="How-to-Handle-the-Double-Execution"><a href="#How-to-Handle-the-Double-Execution" class="headerlink" title="How to Handle the Double Execution"></a>How to Handle the Double Execution</h2><p>Here are some tips for dealing with the double execution of useEffect:</p><p><strong>Be Careful with State Updates</strong>: If your effect updates state, make sure it’s safe to run the effect multiple times without causing issues.</p><p><strong>Use Cleanup Functions</strong>: Always return a cleanup function from your useEffect to free up resources and avoid memory issues.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">useEffect</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// Your side effect code here</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// Cleanup code here</span></span><br><span class="line">  &#125;;</span><br><span class="line">&#125;, [dependencies]);</span><br></pre></td></tr></table></figure><p><strong>Test Your Effects</strong>: Use the extra invocation to ensure that your effects work correctly.</p><h2 id="Disable-Strict-Mode"><a href="#Disable-Strict-Mode" class="headerlink" title="Disable Strict Mode"></a>Disable Strict Mode</h2><p>It is not recommend this way, but if you want to disable Strict Mode, in <code>React 18</code> you can disable Strict Mode by removing the <code>&lt;React.StrictMode&gt;</code> tag from the return statement in your root component.</p><p>In <code>Next.js</code>, you can disable Strict Mode by setting the following parameter in <code>next.config.js</code>:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">  <span class="attr">reactStrictMode</span>: <span class="literal">false</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><span class='pbg green'>Seeing useEffect run twice in development mode can be surprising</span> Understanding this behavior and preparing your code for it will allow you to use React hooks effectively and build better applications.<p>Even though this might seem confusing at first, it’s an important part of the React development experience. Happy coding!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Have you noticed that your &lt;code&gt;useEffect&lt;/code&gt; hook of &lt;code&gt;React&lt;/code&gt; runs twice when the page first loads in development mode? Th</summary>
      
    
    
    
    <category term="Frontend" scheme="https://stonefishy.github.io/categories/Frontend/"/>
    
    
    <category term="JavaScript" scheme="https://stonefishy.github.io/tags/JavaScript/"/>
    
    <category term="React" scheme="https://stonefishy.github.io/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>AWS Glue Iceberg tables schema can&#39;t be updated with Pulumi</title>
    <link href="https://stonefishy.github.io/2024/10/09/aws-glue-iceberg-tables-schema-can-t-be-updated-with-pulumi/"/>
    <id>https://stonefishy.github.io/2024/10/09/aws-glue-iceberg-tables-schema-can-t-be-updated-with-pulumi/</id>
    <published>2024-10-09T09:46:22.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>Recently, we’re planing to use <code>Pulumi</code> to manage all current existing <code>AWS Glue Datacatalog</code> tables which are <code>Iceberg</code> format. For the <code>Iceberg</code> tables, I have post a blog before to talk about what is iceberg and what’s feature of it. Here is post link: <a href="https://stonefishy.github.io/2020/05/23/what-is-apache-iceberg/">https://stonefishy.github.io/2020/05/23/what-is-apache-iceberg/</a></p><p>To manage the AWS Glue Iceberg tables with <code>Pulumi</code>, due to our catalog table schemas are continue changes base on requirements. We need to do some technical POC whethere the pulumi can also support to update the iceberg metadata schema as well.</p><h2 id="Create-Glue-Iceberg-Table"><a href="#Create-Glue-Iceberg-Table" class="headerlink" title="Create Glue Iceberg Table"></a>Create Glue Iceberg Table</h2><p>We’re using <code>Pulumi</code> to manage the AWS Cloud Infrastructure. Before create glue table, a glue database is indeed.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_database_test = aws.glue.CatalogDatabase(<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    create_table_default_permissions=[aws.glue.CatalogDatabaseCreateTableDefaultPermissionArgs(</span><br><span class="line">        permissions=[<span class="string">&quot;ALL&quot;</span>],</span><br><span class="line">        principal=aws.glue.CatalogDatabaseCreateTableDefaultPermissionPrincipalArgs(</span><br><span class="line">            data_lake_principal_identifier=<span class="string">&quot;IAM_ALLOWED_PRINCIPALS&quot;</span>,</span><br><span class="line">        ),</span><br><span class="line">    )],</span><br><span class="line">    name=<span class="string">&quot;pulumi_database_test&quot;</span>)</span><br></pre></td></tr></table></figure><p>Above code is to create a glue database named pulumi_database_test. Next Step is to create a glue table with <code>Iceberg</code> format.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_external_table_test = aws.glue.CatalogTable(<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    database_name=<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    storage_descriptor=aws.glue.CatalogTableStorageDescriptorArgs(</span><br><span class="line">        additional_locations=[<span class="string">&quot;s3://xxx/pulumi_external_table_test/data&quot;</span>],</span><br><span class="line">        columns=[</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test1&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test2&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test3&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;boolean&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test4&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ],</span><br><span class="line">        location=<span class="string">&quot;s3://xxx/pulumi_external_table_test&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    table_type=<span class="string">&quot;EXTERNAL_TABLE&quot;</span>,</span><br><span class="line">        open_table_format_input=aws.glue.CatalogTableOpenTableFormatInputArgs(</span><br><span class="line">        iceberg_input=aws.glue.CatalogTableOpenTableFormatInputIcebergInputArgs(</span><br><span class="line">            metadata_operation=<span class="string">&quot;CREATE&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>There is important thing to notice here is that we need to set <code>open_table_format_input</code> with <code>iceberg_input</code> and set <code>metadata_operation</code> as <code>CREATE</code>. This is because we want to create a new Iceberg table with new schema. </p><p>Below is glue iceberg table created screenshot. You can see the 4 fields is added in schema and table format is <code>Apache Iceberg</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-table.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-table.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue Table Schema Created by Pulumi"/></div><span class="image-caption">AWS Glue Table Schema Created by Pulumi</span></div><p>Next, let’s check the important file that is <code>Apache Iceberg</code> metadata file which is located in <code>s3://xxx/pulumi_external_table_test/metadata/</code>.  Download this json file <code>00006-fd122b03-a7aa-42cf-8fec-001535a9fcf5.metadata.json</code> from <code>S3</code>. The 4 fields are defined in metadata json file. That is good. The metadata json is created as well when creating glue table.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-metadata.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-metadata.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue Table Iceberg metadata"/></div><span class="image-caption">AWS Glue Table Iceberg metadata</span></div><h2 id="Insert-new-data-in-Glue-iceberg-table"><a href="#Insert-new-data-in-Glue-iceberg-table" class="headerlink" title="Insert new data in Glue iceberg table"></a>Insert new data in Glue iceberg table</h2><p>Let’s using <code>AWS Athena</code> to insert a test data in the table.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pulumi_database_test.pulumi_external_table_test(test1,test2,test3,test4) <span class="keyword">VALUES</span>(<span class="string">&#x27;1a&#x27;</span>, <span class="string">&#x27;2a&#x27;</span>, <span class="literal">true</span>, <span class="string">&#x27;4a&#x27;</span>)</span><br></pre></td></tr></table></figure><p>The data is insert success and we can use <code>SELECT</code> sql to query the data.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-table-query.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-table-query.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Query inserted data in AWS Glue Iceberg table"/></div><span class="image-caption">Query inserted data in AWS Glue Iceberg table</span></div><p>In Iceberg table, we can <code>insert</code>, <code>update</code>, <code>delete</code> data as well.</p><h2 id="Update-Glue-Iceberg-table-schema"><a href="#Update-Glue-Iceberg-table-schema" class="headerlink" title="Update Glue Iceberg table schema"></a>Update Glue Iceberg table schema</h2><p>Let’s add a new field <code>test5</code> in the glue iceberg table base on previous code.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pulumi</span><br><span class="line"><span class="keyword">import</span> pulumi_aws <span class="keyword">as</span> aws</span><br><span class="line"></span><br><span class="line">pulumi_external_table_test = aws.glue.CatalogTable(<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    database_name=<span class="string">&quot;pulumi_database_test&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;pulumi_external_table_test&quot;</span>,</span><br><span class="line">    storage_descriptor=aws.glue.CatalogTableStorageDescriptorArgs(</span><br><span class="line">        additional_locations=[<span class="string">&quot;s3://xxx/pulumi_external_table_test/data&quot;</span>],</span><br><span class="line">        columns=[</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test1&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test2&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test3&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;boolean&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test4&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            aws.glue.CatalogTableStorageDescriptorColumnArgs(</span><br><span class="line">                name=<span class="string">&quot;test5&quot;</span>,</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ],</span><br><span class="line">        location=<span class="string">&quot;s3://xxx/pulumi_external_table_test&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    table_type=<span class="string">&quot;EXTERNAL_TABLE&quot;</span>,</span><br><span class="line">        open_table_format_input=aws.glue.CatalogTableOpenTableFormatInputArgs(</span><br><span class="line">        iceberg_input=aws.glue.CatalogTableOpenTableFormatInputIcebergInputArgs(</span><br><span class="line">            metadata_operation=<span class="string">&quot;CREATE&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">    opts=pulumi.ResourceOptions(protect=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Execute <code>pulumi up</code> command to update the glue table schema.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-update-by-pulumi.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-update-by-pulumi.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi update AWS Glue Iceberg table schema"/></div><span class="image-caption">Pulumi update AWS Glue Iceberg table schema</span></div><p>After that, we can check the glue table schema is updated to add a new field <code>test5</code>.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-table-new-field.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-table-new-field.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue iceberg table new field"/></div><span class="image-caption">AWS Glue iceberg table new field</span></div><p>Let’s insert new data in the table with new field <code>test5</code> and run it in <code>AWS Athena</code>.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pulumi_database_test.pulumi_external_table_test(test1,test2,test3,test4,test5) <span class="keyword">VALUES</span>(<span class="string">&#x27;1b&#x27;</span>, <span class="string">&#x27;2b&#x27;</span>, <span class="literal">true</span>, <span class="string">&#x27;4b&#x27;</span>, <span class="string">&#x27;5b&#x27;</span>)</span><br></pre></td></tr></table></figure><p>The Athena execute show below errors:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">COLUMN_NOT_FOUND: Insert column name does not exist in target table: test5. If a data manifest file was generated at &#x27;s3://xxxxxx/4c346103-60d2-45ea-9813-d7060bd5efe9/Unsaved/2024/10/09/37f67a67-4604-43cb-b113-af351c363a51-manifest.csv&#x27;, you may need to manually clean the data from locations specified in the manifest. Athena will not delete data in your account.</span><br><span class="line">This query ran against the &quot;pulumi_database_test&quot; database, unless qualified by the query. Please post the error message on our forum  or contact customer support  with Query Id: 37f67a67-4604-43cb-b113-af351c363a51</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-athena-insert-failed.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-athena-insert-failed.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Athena insert glue iceberg table failed"/></div><span class="image-caption">AWS Athena insert glue iceberg table failed</span></div><p>But when we check the <code>Apache Iceberg</code> metadata file again. The new field <code>test5</code> is not added in the new metadata file. That’s why the insert new data with new field failed.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-metadata-not-updated.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-metadata-not-updated.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Glue iceberg table metadata not updated"/></div><span class="image-caption">AWS Glue iceberg table metadata not updated</span></div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In Pulumi documentation. The <code>metadata_operation</code> of <code>iceberg_input</code> in <code>open_table_format_input</code> is only support <code>CREATE</code> value. It seems it only can create the iceberg metadata file when glue table created.</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-glue-iceberg-pulumi-doc.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-glue-iceberg-pulumi-doc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="Pulumi API Doc"/></div><span class="image-caption">Pulumi API Doc</span></div><p>It seems this is <code>pulumi</code> issue. It is not updating the iceberg metadata file when the glue table schema is updated. I’ve raised a issue to pulumi,  here is issue link: <a href="https://github.com/pulumi/pulumi/issues/17516">https://github.com/pulumi/pulumi/issues/17516</a>. Hope this issue can be fixed soon.</p><p>Mean while, I found there is same issue in <code>Terraform</code> which also can not update the iceberg metadata file when the glue table schema is updated. Terraform issue link here <a href="https://github.com/hashicorp/terraform-provider-aws/issues/36641">https://github.com/hashicorp/terraform-provider-aws/issues/36641</a>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h2&gt;&lt;p&gt;Recently, we’re planing to use &lt;code&gt;Pulumi&lt;/code&gt;</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="Pulumi" scheme="https://stonefishy.github.io/tags/Pulumi/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="IaC" scheme="https://stonefishy.github.io/tags/IaC/"/>
    
  </entry>
  
  <entry>
    <title>User Survey Feedback Sentiment Analysis Base on AWS Cloud Solution</title>
    <link href="https://stonefishy.github.io/2024/09/19/user-survey-feedback-sentiment-analysis-base-on-aws-cloud-solution/"/>
    <id>https://stonefishy.github.io/2024/09/19/user-survey-feedback-sentiment-analysis-base-on-aws-cloud-solution/</id>
    <published>2024-09-19T14:00:33.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The App Product User Survey Feedback Sentiment Analysis Solution is a cloud-based solution that uses AWS services to analyze user feedback and sentiment of the app product. The solution uses Amazon Comprehend to perform sentiment analysis on the feedback and Amazon S3 to store the data. The solution is designed to be scalable and cost-effective, and can be easily integrated into any app product.</p><p>Basically, our survey feedback file is Excel file that contains the user feedback of app and related application info such as OS verion and app version. The feedback text is different language from global users, so we need to translate the text into English using Amazon Translate.  Besides, the feedback file is generated monthly. So, the solution will extract the feedback data from the Excel file, translate the text into English using Amazon Translate, perform sentiment analysis using Amazon Comprehend, and store the data in Amazon S3. The solution will also provide a dashboard to visualize the sentiment analysis results.</p><p>The <code>Amazon Comprehend</code> is a natural language processing (NLP) service that can analyze text and extract insights such as sentiment, syntax, entities, and key phrases. </p><h2 id="Solution-Architecture"><a href="#Solution-Architecture" class="headerlink" title="Solution Architecture"></a>Solution Architecture</h2><p>Below is the high-level architecture of the solution:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-sentiment-analysis-solution.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-sentiment-analysis-solution.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Sentiment Analysis Solution"/></div><span class="image-caption">AWS Sentiment Analysis Solution</span></div><h3 id="AWS-Services-Used"><a href="#AWS-Services-Used" class="headerlink" title="AWS Services Used"></a>AWS Services Used</h3><p>The solution uses the following AWS services:<br><code>AWS S3</code>: Amazon Simple Storage Service (S3) is a scalable object storage service that can store large amounts of data.<br><code>AWS Lambda</code>: AWS Lambda is a serverless compute service that can run code without provisioning or managing servers.<br><code>AWS Comprehend</code>: Amazon Comprehend is a natural language processing (NLP) service that can analyze text and extract insights such as sentiment, syntax, entities, and key phrases.<br><code>AWS SNS</code>: Amazon Simple Notification Service (SNS) is a messaging service that can be used to send notifications to users.<br><code>AWS Translate</code>: Amazon Translate is a machine translation service that can translate text from one language to another.<br><code>AWS SQS</code>: Amazon Simple Queue Service (SQS) is a messaging service that can be used to store and process large amounts of messages.<br><code>AWS CloudWatch</code>: Amazon CloudWatch is a monitoring service that can be used to monitor the solution and generate metrics.<br><code>AWS Glue</code>: Amazon Glue is a serverless ETL (extract, transform, and load) service that can be used to extract data from the survey feedback file and store it in Amazon S3.<br><code>AWS Athena</code>: Amazon Athena is a serverless data analytics service that can be used to query and analyze data stored in Amazon S3.<br><code>AWS QuickSight</code>: Amazon QuickSight is a business intelligence (BI) service that can be used to create visualizations and dashboards based on the sentiment analysis results.</p><h3 id="Solution-Implementation"><a href="#Solution-Implementation" class="headerlink" title="Solution Implementation"></a>Solution Implementation</h3><p>The solution implementation is divided into the following steps:</p><ol><li>Create an Amazon S3 bucket as raw data bucket to store the survey feedback Excel file.</li><li>Uploaded a survey feedback Excel file to the S3 bucket to trigger the AWS Lambda function.</li><li>AWS Lambda to extract the survey feedback data from the Excel file, translate the text into English using Amazon Translate, sentiment analysis using Amazon Comprehend, and store the data as Parquet format in another Amazon S3 Bucket.</li><li>Create an Amazon SNS topic to notify users by email when the Lambda process data failed.</li><li>Create an Amazon CloudWatch to log the lamdba exeuction logs, generate metrics.</li><li>AWS Glue Crawler to extract the parquet data from the processed amazon S3 bucket and generate a table schema.</li><li>Using Amazon Athena to query the data from the processed Amazon S3 bucket.</li><li>Create an Amazon QuickSight dashboard to visualize the sentiment analysis results.</li></ol><p>The AWS Lambda core function code is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pyarrow <span class="keyword">as</span> pa</span><br><span class="line"><span class="keyword">import</span> pyarrow.parquet <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> urlparse</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">S3_TARGET_BUCKET = os.environ[<span class="string">&#x27;QE_SURVEY_PROCESSED_TARGET_BUCKET&#x27;</span>]</span><br><span class="line">SNS_TOPIC_ARN = os.environ[<span class="string">&#x27;SNS_TOPIC_ARN&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">translate_feedbacks</span>(<span class="params">feedbacks</span>):</span><br><span class="line">    translate = boto3.client(<span class="string">&#x27;translate&#x27;</span>)</span><br><span class="line">    feedbacks_en = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Translate to auto detect language and translate feedback, total <span class="subst">&#123;feedbacks.__len__()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feedback <span class="keyword">in</span> feedbacks:</span><br><span class="line">        response = translate.translate_text(</span><br><span class="line">            Text=feedback,</span><br><span class="line">            SourceLanguageCode=<span class="string">&#x27;auto&#x27;</span>,  <span class="comment"># Detect source language automatically</span></span><br><span class="line">            TargetLanguageCode=<span class="string">&#x27;en&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        feedbacks_en.append(response[<span class="string">&#x27;TranslatedText&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Finished transalate sourceText: <span class="subst">&#123;feedback&#125;</span> to targetText: <span class="subst">&#123;response[<span class="string">&#x27;TranslatedText&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feedbacks_en</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comprehend_sentiment</span>(<span class="params">feedbacks</span>):</span><br><span class="line">    comprehend = boto3.client(<span class="string">&#x27;comprehend&#x27;</span>)</span><br><span class="line">    batch_size = <span class="number">25</span></span><br><span class="line">    all_sentiments = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Comprehend AI to analysis feedback, total <span class="subst">&#123;feedbacks.__len__()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feedbacks), batch_size):</span><br><span class="line">        batch_feedbacks = feedbacks[i:i+batch_size]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;calling AWS Comprehend AI to analysis feedback, batch <span class="subst">&#123;i&#125;</span> - <span class="subst">&#123;i+batch_size&#125;</span>&quot;</span>)</span><br><span class="line">        comprehend_response = comprehend.batch_detect_sentiment(TextList=batch_feedbacks, LanguageCode=<span class="string">&#x27;en&#x27;</span>)</span><br><span class="line">        sentiments = [response[<span class="string">&#x27;Sentiment&#x27;</span>] <span class="keyword">for</span> response <span class="keyword">in</span> comprehend_response[<span class="string">&#x27;ResultList&#x27;</span>]]</span><br><span class="line">        all_sentiments.extend(sentiments)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> all_sentiments</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">    sns_client = boto3.client(<span class="string">&#x27;sns&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    source_bucket = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;bucket&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    source_key = urlparse.unquote_plus(event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;object&#x27;</span>][<span class="string">&#x27;key&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    target_bucket = S3_TARGET_BUCKET</span><br><span class="line">    target_key = <span class="string">f&quot;qe-survey/<span class="subst">&#123;source_key.replace(<span class="string">&#x27;.xlsx&#x27;</span>, <span class="string">&#x27;.parquet&#x27;</span>)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = s3.get_object(Bucket=source_bucket, Key=source_key)</span><br><span class="line">        excel_file = response[<span class="string">&#x27;Body&#x27;</span>].read()</span><br><span class="line">        </span><br><span class="line">        columns = [<span class="string">&#x27;ce_timestamp&#x27;</span>, <span class="string">&#x27;ce_host_id&#x27;</span>, <span class="string">&#x27;ce_host_os&#x27;</span>, <span class="string">&#x27;ce_hw&#x27;</span>, <span class="string">&#x27;ce_fw&#x27;</span>, <span class="string">&#x27;ce_sw&#x27;</span>, <span class="string">&#x27;survey_feedback&#x27;</span>, <span class="string">&#x27;survey_rating&#x27;</span>]</span><br><span class="line">        df = pd.read_excel(io.BytesIO(excel_file), usecols=columns)</span><br><span class="line">        df[<span class="string">&#x27;ce_timestamp&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;ce_timestamp&#x27;</span>], <span class="built_in">format</span>=<span class="string">&#x27;%Y-%m-%d %H:%M:%S:%f&#x27;</span>)</span><br><span class="line">        df[<span class="string">&#x27;survey_feedback&#x27;</span>] = df[<span class="string">&#x27;survey_feedback&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">        valid_df = df[df[<span class="string">&#x27;survey_feedback&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.strip() != <span class="string">&#x27;&#x27;</span>)]</span><br><span class="line">        valid_df = valid_df[valid_df[<span class="string">&#x27;survey_feedback&#x27;</span>] != <span class="string">&#x27;nan&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        feedbacks = valid_df[<span class="string">&#x27;survey_feedback&#x27;</span>].tolist()</span><br><span class="line">        </span><br><span class="line">        feedbacks_en = translate_feedbacks(feedbacks)</span><br><span class="line">        valid_df[<span class="string">&quot;survey_feedback_en&quot;</span>]= feedbacks_en</span><br><span class="line">        valid_df[<span class="string">&#x27;sentiment&#x27;</span>] = comprehend_sentiment(feedbacks_en)</span><br><span class="line">        </span><br><span class="line">        parquet_buffer = io.BytesIO()</span><br><span class="line">        pq.write_table(pa.Table.from_pandas(valid_df), parquet_buffer)</span><br><span class="line">        parquet_buffer.seek(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        s3.put_object(Bucket=target_bucket, Key=target_key, Body=parquet_buffer)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;source_key&#125;</span> File converted to Parquet <span class="subst">&#123;target_key&#125;</span> and stored in S3 bucket <span class="subst">&#123;target_bucket&#125;</span> successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;statusCode&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">            <span class="string">&#x27;body&#x27;</span>: json.dumps(<span class="string">f&#x27;<span class="subst">&#123;source_key&#125;</span> File converted to Parquet <span class="subst">&#123;target_key&#125;</span> and stored in S3 bucket <span class="subst">&#123;target_bucket&#125;</span> successfully&#x27;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Error processing <span class="subst">&#123;source_key&#125;</span>: <span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">        sns_client.publish(</span><br><span class="line">            TopicArn=SNS_TOPIC_ARN,</span><br><span class="line">            Subject=<span class="string">&#x27;Lambda Function Processing QE Survey Feedback Failure Notification&#x27;</span>,</span><br><span class="line">            Message=<span class="string">f&#x27;An error occurred: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&#x27;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>The above code extracts the survey feedback data from the Excel file, translates the text into English using Amazon Translate, performs sentiment analysis using Amazon Comprehend, and stores the data as Parquet format in another Amazon S3 Bucket. also notify users by email when the Lambda process data failed by using Amazon SNS. </p><p>Below is sentiment analysis results visualization using Amazon QuickSight:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/assets/images/aws/aws-sentiment-analysis-result.png" class="lazyload placeholder" data-srcset="/assets/images/aws/aws-sentiment-analysis-result.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="AWS Sentiment Analysis Results"/></div><span class="image-caption">AWS Sentiment Analysis Results</span></div><p>This is a high-level overview of the solution implementation. The solution can be further customized and enhanced based on the specific requirements of the app product.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;The App Product User Survey Fe</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="Machine Learning" scheme="https://stonefishy.github.io/tags/Machine-Learning/"/>
    
    <category term="Sentiment Analysis" scheme="https://stonefishy.github.io/tags/Sentiment-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>How to Fix AWS S3 Event Replacing Space With &#39;+&#39; Character Sign in Object Key Name</title>
    <link href="https://stonefishy.github.io/2024/09/10/aws-s3-event-replacing-space-with-character-sign-in-object-key-name/"/>
    <id>https://stonefishy.github.io/2024/09/10/aws-s3-event-replacing-space-with-character-sign-in-object-key-name/</id>
    <published>2024-09-10T09:22:34.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>The issue with AWS S3 Event notifications is that it replaces spaces with ‘+’ character sign in the object key name. This can cause issues when trying to access the object in S3. It will occurs <code>NoSuchKey</code> error if not handling this issue properly.</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Configured a S3 bucket put event notification to a Lambda function. The Lambda function will be triggered when a new object is uploaded to the S3 bucket. I upload a file named ‘2023 2nd quarter QE survey raw data.xlsx’ into S3 bucket, the Lambda function is triggered, but when I try to access the object in S3, I get <code>NoSuchKey</code> error in <code>AWS CloudWatch Logs</code>. Debugging shows that the object key name is ‘2023+2nd+quarter+QE+survey+raw+data.xlsx’ instead of ‘2023 2nd quarter QE survey raw data.xlsx’. It means the S3 event notification is replacing the space with ‘+’ character sign in the object key name.</p><p>The detail error is below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] NoSuchKey: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.</span><br></pre></td></tr></table></figure><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>There are two solutions to fix this issue, one is from AWS S3 upload file side, another is from Lambda function side.</p><h3 id="1-From-AWS-S3-upload-file-side"><a href="#1-From-AWS-S3-upload-file-side" class="headerlink" title="1. From AWS S3 upload file side:"></a>1. From AWS S3 upload file side:</h3><p>If you have control over the upload process, ensure that the keys are properly URL-encoded.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example key with spaces</span></span><br><span class="line">object_key = <span class="string">&quot;2023 2nd quarter QE survey raw data.xlsx&quot;</span></span><br><span class="line">encoded_key = urllib.parse.quote(object_key)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Upload the object</span></span><br><span class="line">s3_client.upload_file(<span class="string">&quot;/tmp/2023 2nd quarter QE survey raw data.xlsx&quot;</span>, <span class="string">&quot;my-bucket-name&quot;</span>, encoded_key)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>This will ensure that the object key name is properly URL-encoded, which will prevent the S3 event notification from replacing spaces with ‘+’ character sign. The <code>urllib.parse.quote</code> function will replace spaces with ‘%20’ and ‘+’ with ‘%2B’.</p><h3 id="2-From-Lambda-function-side"><a href="#2-From-Lambda-function-side" class="headerlink" title="2. From Lambda function side:"></a>2. From Lambda function side:</h3><p>To fix this issue, we need to modify the Lambda function to handle the object key name with ‘+’ character sign. We can use the <code>urllib.parse</code> package to handle it. The package library provide the function <code>unquote_plus</code> to replace ‘+’ with space. Here is the code to handle the object key name with ‘+’ character sign:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> urlparse</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line">s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    bucket_name = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;bucket&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    object_key = event[<span class="string">&#x27;Records&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;s3&#x27;</span>][<span class="string">&#x27;object&#x27;</span>][<span class="string">&#x27;key&#x27;</span>]</span><br><span class="line">    <span class="comment"># Replace &#x27;+&#x27; with space</span></span><br><span class="line">    object_key = urlparse.unquote_plus(object_key)</span><br><span class="line">    <span class="comment"># Download the object</span></span><br><span class="line">    s3.download_file(bucket_name, object_key, <span class="string">&#x27;/tmp/file.txt&#x27;</span>)</span><br><span class="line">    <span class="comment"># Do something with the downloaded file</span></span><br><span class="line">    <span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>In the above code, we first get the bucket name and object key from the S3 event notification. We then use the <code>urlparse.unquote_plus</code> function to replace ‘+’ with space in the object key name. Finally, we download the object using the <code>s3.download_file</code> function.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>To fix the issue with AWS S3 Event notifications replacing space with ‘+’ character sign in the object key name, we need to handle it properly in the Lambda function. We can use the <code>urllib.parse</code> package to handle it.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The issue with AWS S3 Event notifications is that it replaces spaces with ‘+’ character sign in the object key name. This can cause issue</summary>
      
    
    
    
    <category term="Cloud" scheme="https://stonefishy.github.io/categories/Cloud/"/>
    
    
    <category term="Python" scheme="https://stonefishy.github.io/tags/Python/"/>
    
    <category term="Cloud" scheme="https://stonefishy.github.io/tags/Cloud/"/>
    
    <category term="AWS" scheme="https://stonefishy.github.io/tags/AWS/"/>
    
    <category term="AWS S3" scheme="https://stonefishy.github.io/tags/AWS-S3/"/>
    
    <category term="AWS Lambda" scheme="https://stonefishy.github.io/tags/AWS-Lambda/"/>
    
  </entry>
  
  <entry>
    <title>SQL 中的 IS DISTINCT FROM 语法详解</title>
    <link href="https://stonefishy.github.io/2024/08/16/introduce-is-distinct-from-in-sql/"/>
    <id>https://stonefishy.github.io/2024/08/16/introduce-is-distinct-from-in-sql/</id>
    <published>2024-08-16T09:22:15.000Z</published>
    <updated>2025-03-11T07:05:13.589Z</updated>
    
    <content type="html"><![CDATA[<p>在SQL查询中，比较操作符 <code>=</code> 通常用于检查两个值是否相等。然而，当涉及到处理缺失值（<code>NULL</code>）时，这种操作符就会面临挑战。为了解决这一问题，<span class='pbg green'>SQL 提供了 `IS DISTINCT FROM` 操作符，它用于精确比较两个值是否不同，即使这些值中有 NULL</span>。本文将详细介绍 IS DISTINCT FROM 的语法、解决的问题以及常见的使用场景。</p><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><p>IS DISTINCT FROM 的基本语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expression1 <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> expression2</span><br></pre></td></tr></table></figure><p>其中 expression1 和 expression2 是要进行比较的两个表达式。 该操作符返回布尔值：TRUE、FALSE。</p><h2 id="主要解决的问题"><a href="#主要解决的问题" class="headerlink" title="主要解决的问题"></a>主要解决的问题</h2><p>在SQL中，<code>NULL</code> 值代表缺失或未知的数据。当两个表达式中至少有一个为 NULL 时，使用传统的比较操作符（如 &#x3D; 或 &lt;&gt;）进行比较会导致不确定的结果。具体来说：</p><ul><li>expression1 &#x3D; expression2 在 expression1 或 expression2 为 NULL 时会返回 UNKNOWN。</li><li>expression1 &lt;&gt; expression2 在 expression1 或 expression2 为 NULL 时也会返回 UNKNOWN。</li></ul><p>比如下面的查询语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A1,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">&lt;&gt;</span> <span class="number">1</span> <span class="keyword">as</span> A2,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">=</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A3,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="operator">&lt;&gt;</span> <span class="keyword">NULL</span> <span class="keyword">as</span> A4,</span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="number">1</span> <span class="keyword">as</span> A5, </span><br><span class="line">    <span class="number">1</span> <span class="operator">&lt;&gt;</span> <span class="number">1</span> <span class="keyword">as</span> A6</span><br></pre></td></tr></table></figure><p>会返回以下结果：</p><table><thead><tr><th>A1</th><th>A2</th><th>A3</th><th>A4</th><th>A5</th><th>A6</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td>TRUE</td><td>FALSE</td></tr></tbody></table><p>可以看到，当 expression1 或 expression2 为 NULL 时，传统的比较操作符会返回 UNKNOWN空值， 如上面的A1, A2, A3, A4的结果值，这就会导致不确定性。</p><p><code>IS DISTINCT FROM</code> 操作符的出现，解决了这些问题。它能正确处理 <code>NULL</code> 值，会返回 <code>TRUE 或 FALSE</code>，确保结果的可靠性。 在以下情况下返回 TRUE：</p><ul><li>expression1 和 expression2 都为 NULL。</li><li>expression1 和 expression2 的值不同（不论是否为 NULL）。</li></ul><p>而在 expression1 和 expression2 相等（包括都是 NULL）的情况下，IS DISTINCT FROM 返回 FALSE。 另外还有一个 <code>IS NOT DISTINCT FROM</code> 操作符，用于判断两个值是否相等。其用法一样，只是语义相反。</p><p>下面的例子查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="keyword">NULL</span> <span class="keyword">as</span> B1,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B2,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">2</span> <span class="keyword">as</span> B3,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="keyword">NULL</span> <span class="keyword">as</span> B4,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B5,</span><br><span class="line">    <span class="number">1</span> <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="number">1</span> <span class="keyword">as</span> B6</span><br></pre></td></tr></table></figure><p>查询结果如下:</p><table><thead><tr><th>B1</th><th>B2</th><th>B3</th><th>B4</th><th>B5</th><th>B6</th></tr></thead><tbody><tr><td>TRUE</td><td>TRUE</td><td>TRUE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td></tr></tbody></table><p>可以看到，IS DISTINCT FROM 正确处理 NULL 值，返回 TRUE 或 FALSE，确保结果的可靠性。</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><h3 id="数据清洗和验证"><a href="#数据清洗和验证" class="headerlink" title="数据清洗和验证"></a>数据清洗和验证</h3><p>在<code>数据清洗</code>和<code>数据验证</code>过程中，经常需要检查数据库中的值是否不同，包括对 NULL 值的处理。例如，比较用户输入的数据与现有记录，以确定是否有不同的记录。<span class='pbg warning'>使用 IS DISTINCT FROM 可以更准确地处理 NULL 值，避免出现错误或遗漏。</span></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> users</span><br><span class="line"><span class="keyword">WHERE</span> username <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="string">&#x27;andrewsy&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询会返回所有 username 与 ‘andrewsy’ 不同的记录，包括那些 username 为 NULL 的记录。</p><h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><p>在更新数据时，使用 IS DISTINCT FROM 可以确保只有在数据实际变化时才进行更新，从而避免不必要的更新操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> users</span><br><span class="line"><span class="keyword">SET</span> email <span class="operator">=</span> <span class="string">&#x27;new_andrewsy@email.com&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> email <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> <span class="string">&#x27;new_andrewsy@email.com&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询会更新所有 email 不同于 ‘<a href="mailto:&#110;&#x65;&#119;&#95;&#x61;&#x6e;&#100;&#x72;&#101;&#119;&#x73;&#121;&#x40;&#101;&#109;&#97;&#105;&#108;&#x2e;&#99;&#111;&#109;">&#110;&#x65;&#119;&#95;&#x61;&#x6e;&#100;&#x72;&#101;&#119;&#x73;&#121;&#x40;&#101;&#109;&#97;&#105;&#108;&#x2e;&#99;&#111;&#109;</a>‘ 的记录，包括那些 email 为 NULL 的记录。</p><h3 id="数据比较"><a href="#数据比较" class="headerlink" title="数据比较"></a>数据比较</h3><p>在进行复杂的数据比较时，尤其是涉及到 NULL 值时，IS DISTINCT FROM 提供了更直观的比较逻辑。例如，在合并两个数据集时，可以使用此操作符来确保唯一性。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> </span><br><span class="line">    dataset1</span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> </span><br><span class="line">    dataset2</span><br><span class="line"><span class="keyword">ON</span> </span><br><span class="line">    dataset1.id <span class="keyword">IS</span> <span class="keyword">DISTINCT</span> <span class="keyword">FROM</span> dataset2.id</span><br></pre></td></tr></table></figure><p>这条查询会找出两个数据集中 id 不同的记录，包括 id 为 NULL 的情况。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p><code>IS DISTINCT FROM</code> 是 SQL 标准中的一部分，但并非所有数据库系统都支持。具体的支持情况需要查阅数据库的文档。在使用 IS DISTINCT FROM 时，确保数据库系统的版本和文档中对此操作符的支持及行为一致。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>IS DISTINCT FROM</code> 是一个强大的工具，用于在 SQL 中处理包含 NULL 值的数据比较。它解决了传统比较操作符在处理 NULL 值时的不足，使得数据验证、更新和比较更加准确和可靠。在实际应用中，根据数据库系统的支持情况，合理使用 IS DISTINCT FROM 可以显著提高数据操作的精确性和健壮性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在SQL查询中，比较操作符 &lt;code&gt;=&lt;/code&gt; 通常用于检查两个值是否相等。然而，当涉及到处理缺失值（&lt;code&gt;NULL&lt;/code&gt;）时，这种操作符就会面临挑战。为了解决这一问题，&lt;span class=&#39;pbg green&#39;&gt;SQL 提供了 `IS DIST</summary>
      
    
    
    
    <category term="Database" scheme="https://stonefishy.github.io/categories/Database/"/>
    
    
    <category term="Big Data" scheme="https://stonefishy.github.io/tags/Big-Data/"/>
    
    <category term="MySQL" scheme="https://stonefishy.github.io/tags/MySQL/"/>
    
    <category term="SQL" scheme="https://stonefishy.github.io/tags/SQL/"/>
    
  </entry>
  
</feed>
